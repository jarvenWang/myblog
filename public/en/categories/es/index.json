[{"content":"什么是StarRocks  官网地址 https://docs.starrocks.io/zh/docs/introduction/\n StarRocks 是一款高性能分析型数据仓库，使用向量化、MPP 架构、可实时更新的列式存储引擎等技术实现多维、实时、高并发的数据分析。\n适用场景 StarRocks 可以满足企业级用户的多种分析需求，包括 OLAP 多维分析、定制报表、实时数据分析和 Ad-hoc 数据分析等。\nOLAP 多维分析：  用户画像、标签分析、圈人 用户行为分析 财务报表 业务问题探查分析 高维业务指标报表 自助式报表平台 系统监控分析 跨主题业务分析  实时数据仓库：  电商大促数据分析 物流行业的运单分析 金融行业绩效分析、指标计算 直播质量分析 广告投放分析 管理驾驶舱 探针分析APM  高并发查询：  广告主报表分析 零售行业渠道人员分析 SaaS 行业面向用户分析报表 Dashbroad 多页面分析  统一分析：  通过使用一套系统解决多维分析、高并发查询、预计算、实时分析查询等场景，降低系统复杂度和多技术栈开发与维护成本。 使用StarRocks 来统一数据湖和数据仓库，将高并发和实时要求性很高的业务放在StarRocks中分析，把数据湖上的分析使用StarRocks外表查询，统一使用 StarRocks 管理湖仓数据。  系统架构 StarRocks的架构简洁，整个系统的核心只有FE（Frontend）、BE（Backend）两类进程，不依赖任何外部组件，方便部署与维护。同时，FE和BE模块都可以在线水平扩展，元数据和数据都有副本机制，确保整个系统无单点。\nFE（Frontend）是StarRocks的前端节点，负责管理元数据，管理客户端连接，进行查询规划，查询调度等工作。FE根据配置会有两种角色：Follower 和 Observer。\n Follower 会通过类Paxos的BDBJE协议选主出一个Leader（实现选主需要集群中有半数以上的Follower实例存活），只有Leader会对元数据进行写操作。非Leader节点会自动的将元数据写入请求路由到Leader节点。每次元数据写入时，必须有多数Follower成功才能确认是写入成功。 Observer 不参与选主操作，只会异步同步并且回放日志，主要用于扩展集群的查询并发能力。每个FE节点都会在内存保留一份完整的元数据，这样每个FE节点都能够提供无差别的服务。  BE（Backend） 是StarRocks的后端节点，负责数据存储以及SQL执行等工作。\n数据存储方面，StarRocks的BE节点都是完全对等的，FE按照一定策略将数据分配到对应的BE节点。在数据导入时，数据会直接写入到BE节点，不会通过FE中转，BE负责将导入数据写成对应的格式以及生成相关索引。\n在执行SQL计算时，一条SQL语句首先会按照具体的语义规划成逻辑执行单元，然后再按照数据的分布情况拆分成具体的物理执行单元。物理执行单元会在数据存储的节点上进行执行，这样可以避免数据的传输与拷贝，从而能够得到极致的查询性能。\nStarRocks整体对外暴露的是一个 MySQL协议接口 ，支持标准SQL语法。用户通过已有的MySQL客户端能够方便地对StarRocks里的数据进行查询和分析。\n数据管理 StarRocks 使用 列式存储 ，采用分区分桶机制进行数据管理。一张表可以被划分成多个分区，一个分区内的数据可以根据一列或者多列进行分桶，将数据切分成多个 Tablet。Tablet 是 StarRocks 中最小的数据管理单元。每个 Tablet 都会以多副本 (replica) 的形式存储在不同的 BE 节点中。用户可以自行指定 Tablet 的个数和大小，StarRocks 会管理好每个 Tablet 副本的分布信息。\n下图展示了 StarRocks 的数据划分以及 Tablet 多副本机制。表按照日期划分为 4 个分区，第一个分区进一步切分成 4 个 Tablet。每个 Tablet 使用 3 副本进行备份，分布在 3 个不同的 BE 节点上。\n在执行 SQL 语句时，StarRocks 可以对所有 Tablet 实现并发处理，从而充分利用多机、多核提供的计算能力。用户也可以将高并发请求压力分摊到多个物理节点，通过增加物理节点的方式来扩展系统的高并发能力。\nStarRocks 支持 Tablet 多副本存储（默认三个），多副本能够保证数据存储的高可靠以及服务的高可用。在三副本下，一个节点的异常不会影响服务的可用性，集群的读写服务仍然能够正常进行。增加副本数还有助于提高系统的高并发查询能力。\n在 BE 节点数量发生变化时 （比如扩缩容时），StarRocks 可以自动完成节点的增减，无需停止服务。节点变化会触发 Tablet 的自动迁移。当节点增加时，一部分 Tablet 会自动均衡到新增的节点，保证数据能够在集群内分布的更加均衡；当节点减少时，待下线机器上的 Tablet 会被自动均衡到其他节点，从而自动保证数据的副本数不变。管理员能够非常容易的实现弹性伸缩，无需手工进行数据的重分布。\n存算一体架构 的优势在于极速的查询性能，但也存在一些局限性：\n 成本高：需要使用三副本保证数据可靠性；随着用户存储数据量的增加，需要不断扩容存储资源，导致计算资源浪费。 架构复杂：存算一体架构需要维护多数据副本的一致性，增加了系统的复杂度。 弹性不够：存算一体模式下，扩缩容会触发数据重新平衡，弹性体验不佳。  数据模型 数据模型分为四类：明细模型（Duplicate Key）、聚合模型（Aggregate Key）、更新模型（Unique Key）、主键模型（Primary Key）\n明细模型（Duplicate Key） 关键字 DUPLICATE KEY\n1 2 3 4 5 6 7 8 9  CREATETABLEIFNOTEXISTStable1(event_timeDATETIMENOTNULLCOMMENT\u0026#34;datetime of event\u0026#34;,event_typeINTNOTNULLCOMMENT\u0026#34;type of event\u0026#34;,user_idINTCOMMENT\u0026#34;id of user\u0026#34;,device_codeINTCOMMENT\u0026#34;device of \u0026#34;,channelINTCOMMENT\u0026#34;\u0026#34;)DUPLICATEKEY(event_time,event_type)DISTRIBUTEDBYHASH(user_id)BUCKETS8  聚合模型 关键字 AGGREGATE KEY （默认全表排序，一般可省略）\n1 2 3 4 5 6 7  CREATETABLEIFNOTEXISTStable2(site_idLARGEINTNOTNULLCOMMENT\u0026#34;id of site\u0026#34;,dateDATENOTNULLCOMMENT\u0026#34;time of event\u0026#34;,city_codeVARCHAR(20)COMMENT\u0026#34;city_code of user\u0026#34;,pvBIGINTSUMDEFAULT\u0026#34;0\u0026#34;COMMENT\u0026#34;total page views\u0026#34;)DISTRIBUTEDBYHASH(site_id)BUCKETS8;  更新模型 关键字 UNIQUE KEY\n1 2 3 4 5 6 7 8  CREATETABLEIFNOTEXISTStable3(create_timeDATENOTNULLCOMMENT\u0026#34;create time of an order\u0026#34;,order_idBIGINTNOTNULLCOMMENT\u0026#34;id of an order\u0026#34;,order_stateINTCOMMENT\u0026#34;state of an order\u0026#34;,total_priceBIGINTCOMMENT\u0026#34;price of an order\u0026#34;)UNIQUEKEY(create_time,order_id)DISTRIBUTEDBYHASH(order_id)BUCKETS8  StarRocks存储内部会给每一个批次导入数据分配一个版本号, 同一主键的数据可能有多个版本, 查询时最大(最新)版本的数据胜出。\n主键模型 目前primary主键存储在内存中，为防止滥用造成内存占满，限制主键字段长度全部加起来编码后不能超过127字节。\n主要适用场景有：\n1.实时对接 TP 数据至 StarRocks。\n2.利用部分列更新轻松实现多流 JOIN\n关键字 PRIMARY KEY\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  createtabletable4(dtdateNOTNULL,order_idbigintNOTNULL,user_idintNOTNULL,merchant_idintNOTNULL,good_idintNOTNULL,good_namestringNOTNULL,priceintNOTNULL,cntintNOTNULL,revenueintNOTNULL,statetinyintNOTNULL)PRIMARYKEY(dt,order_id)PARTITIONBYRANGE(`dt`)(PARTITIONp20210820VALUES[(\u0026#39;2021-08-20\u0026#39;),(\u0026#39;2021-08-21\u0026#39;)),PARTITIONp20210821VALUES[(\u0026#39;2021-08-21\u0026#39;),(\u0026#39;2021-08-22\u0026#39;)),...PARTITIONp20210929VALUES[(\u0026#39;2021-09-29\u0026#39;),(\u0026#39;2021-09-30\u0026#39;)),PARTITIONp20210930VALUES[(\u0026#39;2021-09-30\u0026#39;),(\u0026#39;2021-10-01\u0026#39;)))DISTRIBUTEDBYHASH(order_id)BUCKETS4PROPERTIES(\u0026#34;replication_num\u0026#34;=\u0026#34;3\u0026#34;);   注意:\n1.主键列仅支持类型: boolean, tinyint, smallint, int, bigint, largeint, string/varchar, date, datetime, 不允许NULL。\n2.分区列(partition)、分桶列(bucket)必须在主键列中。\n3.和更新模型不同，主键模型允许为非主键列创建bitmap等索引，注意需要建表时指定。\n4.由于其列值可能会更新，主键模型目前还不支持rollup index和物化视图。\n5.暂不支持使用ALTER TABLE修改列类型。 ALTER TABLE的相关语法说明和示例，请参见 ALTER TABLE。\n6.在设计表时应尽量减少主键的列数和大小以节约内存，建议使用int/bigint等占用空间少的类型。暂时不建议使用varchar。建议提前根据表的行数和主键列类型来预估内存使用量，避免出现OOM。内存估算举例：\na. 假设表的主键为: dt date (4byte), id bigint(8byte) = 12byte\nb. 假设热数据有1000W行, 存储3副本\nc. 则内存占用: (12 + 9(每行固定开销) ) * 1000W * 3 * 1.5(hash表平均额外开销) = 945M\n 建表语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  CREATETABLEkg_hr_ods.test(`ds`dateNULLCOMMENT\u0026#34;etl时间\u0026#34;,`business_unit`varchar(65533)NULLCOMMENT\u0026#34;业务单位\u0026#34;)ENGINE=OLAPDUPLICATEKEY(`ds`)COMMENT\u0026#34;员工信息表\u0026#34;PARTITIONBYRANGE(`ds`)(PARTITIONp20231130VALUESLESSTHAN(\u0026#34;2023-12-01\u0026#34;),PARTITIONp20231201VALUESLESSTHAN(\u0026#34;2023-12-02\u0026#34;),PARTITIONp20231202VALUESLESSTHAN(\u0026#34;2023-12-03\u0026#34;),PARTITIONp20231203VALUESLESSTHAN(\u0026#34;2023-12-04\u0026#34;))DISTRIBUTEDBYHASH(`ds`)BUCKETS24PROPERTIES(\u0026#34;replication_num\u0026#34;=\u0026#34;3\u0026#34;);  创建分区 目前 StarRocks 只支持 range 分区，以下面的例子来介绍分区功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13  CREATETABLEkg_hr_ods.test(`ds`dateNULLCOMMENT\u0026#34;etl时间\u0026#34;,`business_unit`varchar(65533)NULLCOMMENT\u0026#34;业务单位\u0026#34;)ENGINE=OLAPDUPLICATEKEY(`ds`)COMMENT\u0026#34;员工信息表\u0026#34;PARTITIONBYRANGE(`ds`)(PARTITIONp20231130VALUESLESSTHAN(\u0026#34;2023-12-01\u0026#34;),PARTITIONp20231201VALUESLESSTHAN(\u0026#34;2023-12-02\u0026#34;),PARTITIONp20231202VALUESLESSTHAN(\u0026#34;2023-12-03\u0026#34;),PARTITIONp20231203VALUESLESSTHAN(\u0026#34;2023-12-04\u0026#34;))DISTRIBUTEDBYHASH(`ds`)BUCKETS24;  批量创建分区 如下例，通过指定 START END EVERY 语句可以自动创建分区。其中，START 的值将被 包括在内，而 END 的值会被 排除在外。\n1 2 3 4 5 6 7 8 9 10  CREATETABLEkg_hr_ods.test(`ds`dateNULLCOMMENT\u0026#34;etl时间\u0026#34;,`business_unit`varchar(65533)NULLCOMMENT\u0026#34;业务单位\u0026#34;)ENGINE=OLAPDUPLICATEKEY(`ds`)COMMENT\u0026#34;员工信息表\u0026#34;PARTITIONBYRANGE(`ds`)(START(\u0026#34;2023-01-01\u0026#34;)END(\u0026#34;2023-02-01\u0026#34;)EVERY(INTERVAL1DAY))DISTRIBUTEDBYHASH(`ds`)BUCKETS24;  查看所有分区：\n1  showpartitionsfromkg_hr_ods.test;  管理分区 添加分区\n1  ALTERTABLEkg_hr_ods.testADDPARTITIONp20230209VALUESLESSTHAN(\u0026#34;2023-02¬10\u0026#34;)  删除分区\n1  ALTERTABLEkg_hr_ods.testdropPARTITIONp20230101;  修改分区\n1 2  ALTERTABLEsite_accessSET(\u0026#34;dynamic_partition.enable\u0026#34;=\u0026#34;false\u0026#34;);ALTERTABLEsite_accessSET(\u0026#34;dynamic_partition.enable\u0026#34;=\u0026#34;true\u0026#34;);  查看分区信息\n1  showpartitionsfromkg_hr_ods.test;  ","description":"高性能分析型数据仓库，使用向量化、MPP 架构、可实时更新的列式存储引擎等技术实现多维、实时、高并发的数据分析","id":2,"section":"stack","tags":["db",""],"title":"StarRocks使用","uri":"http://wangjinbao.netlify.app/en/stack/db/starrocks/"},{"content":" PS:数仓的设计流程：\n步骤一：了解业务流程\n 建设过程： 一、数据整合及管理体系 定位与价值 建设统一的、规范化的数据接入层（ODS）和 数据中间层（DWD 和 DWS），通过 数据服务 和 数据产品\n体系架构 包括三块：\n 维表 事实表 指标  名词术语  主题域（数据域）： 业务过程： 时间周期； 修饰类型 修饰词： 度量：原子指标 维度 维度属性 派生指标  指标体系 包括：原子指标、派生指标、修饰类型、修饰词、时间周期。\n派生指标 = 原子指标 + 时间周期 + 修饰词\n阿里巴巴常用的时候周期修饰词如下表：\n   中文名 英文名     最近1天 1d   最近3天 3d   最近7天 1w   最近14天 2w   最近30天 1m   最近60天 2m   最近90天 3m   最近180天 6m   自然周 cw   自然月 cm   自然季度 cq   截至当日 td   财年 fy   最近1小时 1h   准实时 ts   未来7天 f1w   未来4周 f4w    模型设计 数仓分层 数据模型的维度设计 主要以 维度建模理论 为基础，基于维度数据模型总线架构，构建一致性的 维度 和 事实。\n数据模型一般分为三层：操作数据层（ODS）、公共维度模型层（CDM） 和 应用数据层（ADS）,其中公共维度模型层包括 明细数据层（DWD）和汇总数据层（DWS）\n操作数据层（ODS） 定义：把操作系统数据几乎无处理地存放在数据仓库中\n 同步：结构化数据增量或全量同步到 MaxCompute 结构化：非结构（日志）结构化处理并存储到 MaxCompute 累积历史、清洗：根据数据业务需求及稽核和审计要求保存历史数据、清洗数据  模型层次关系如下图：\n公共维度模型层（CDM） 存放 明细数组层(DWD) 、汇总数据层(DWS) 及 维度指标数据(DIM)\n明细数组层(DWD) 和 维度数据一般根据ODS层数据加工生成。\n汇总数据层(DWS) 由维度数据和明细数据加工生成。\n应用数据层（ADS） 存储数据产品个性化的统计指标数据，根据CDM层与ODS层加工生成\n模型建议 基本原则：  高内聚和低耦合： 核心模型与扩展模型分离 公共处理逻辑下沉及单一 成本与性能平衡 数据可回滚 一致性 全名清晰、可理解  构建流程 维度建模 维度建模：数据仓库的经典模型了解一下。\n维度建模 以分析决策的需求出发构建模型，构建的数据模型为分析需求（也就是我们通常所说的数据分析）服务。它重点解决如何更快速完成分析需求，同时还有较好的大规模复杂查询的响应性能。\n说白了，所谓的维度建模就是一种组织数据仓库的形式、模型，用这种方式组织搭建的数据仓库，对快速支持数据分析有着巨大的帮助。目前也是比较主流的数仓模型了\n维度建模基础知识 （1）事实与事实表（Fact Table） 事实表: 是指其中保存了大量业务度量数据的表，是数仓最核心的表。\n事实表中的度量值一般称为 事实 。通常，最有用的事实就是数字类型的事实和可加类型的事实。事实表的粒度，决定了数据仓库中数据的详细程度。\n下图为例。中间的表：服装销售明细表，就是一张事实表。其中的销售金额、成本、利润，都是事实，也是我们需要分析的目标数据。\n一般事实表中只存放数字或一些flag用来统计，如：销售金额、成本等。另外，通常事实表中的数据不允许修改，新的数据只是简单地添加到事实表中。\n事实表特点：数据量庞大、列数少、经常变化。这个比较好理解，因为实事表是一张业务表嘛，业务肯定是不断有新的数据加进来的。\n（2）维度与维度表（Dimension Table） 维度表是用户来分析数据的窗口，比如时间、地区、用户等。\n维度表中包含事实表中记录的特性，有些特性提供描述性信息，有些特性指定如何汇总事实数据表数据，以便为分析者提供有用的信息。\n例如上图，包括了五张维度表：时间维表、产品维表、地域维表、用户维表、支付维表。每一张维度表对应现实世界中的一个对象或概念。\n每一张维度表利用维度关键字（图中标红字段）通过事实表中的外键约束事实表的中某一行。\n维度表等特点：很多描述性的列，行数较少，内容较固定。这个也好理解，比如地域，省市区县这些内容十几年都不会有啥变化\n（3）粒度 粒度是指数据仓库的数据单位中，保存数据的细化程度的级别。简单点来看，在实事表中一条记录所表达的业务细节，就是粒度。\n通常，为了便捷的下钻分析，我们都会使用到最小粒度。比如订单表中，最小粒度就是一条订单的记录。\n使用最小粒度的优点：\n 可以频繁的ETL操作 很多数据挖掘需要最小粒度数据 方便向下钻取  当然，使用最小粒度也有缺点：\n 存储和维护代价较高 需要进一步构建汇总事实表来支持汇总数据查询  （4）切片、切块与旋转 切片 与 切块 主要是用来进行数据分析的。我们以下面的三维（产品、年度、地区）为例。\n 切片：从多维数组中选定一个二维子集，切出一个“平面” 。比如选中上图的2011年，这就是一个切片。 切块：从多维数组中选定一个三维子集，切出一个“立方体” 。比如上图中，年度选择了2011、2012，然后看所有的数据内容，这就是一个切块。 旋转：改变一个报告（页面）显示的维方向  （5）钻取 根据维层次，改变数据分析的粒度，就是钻取分析，主要包括上钻（也叫上卷）和下钻。其实Excel中的数据透视就是各种上卷和下钻。\n 下钻：从汇总数据深入到细节数据进行观察或增加新维 上钻（上卷）：从某一维上将低层次的细节数据概括到高层次的汇总数据或减少维数 钻透：直接下钻到最明细的数据。  维度建模的三种模型 上面介绍了关于维度建模的一些基础知识，下面聊一聊维度建模的几种具体模型：\n星型模型、雪花模型、星座模型。\n（1）星型模型 所谓 星型模型 ，具体表现是：事实被维度所包围，且维度没有被新的表连接。如下图:\n每个维表都有一个维作为主键，所有这些维的主键组合成事实表的主键。\n可以看出，星型模型是比较单纯的模型，像星星一样触角没有延伸了。\n（2）雪花模型 所谓的雪花模型，是有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上，就像雪花一样。如下图：\n雪花模型去除了数据冗余，更贴近与业务。尽可能降低数据存储量以及联合较小的维表来改善查询性能。\n可以想象到，雪花模型分析数据时，操作比较复杂。毕竟需要关联的内容越来越多。但数据的存储量下来了，因为冗余信息进行了提炼嘛\n（3）星座模型 无论是星型模型还是雪花模型，都是单事实表的情况。但通常来讲，实践当中大部分情况都是多事实表的。这时就是需要星座模型了。\n所谓星座模型，是多个事实表共享维度表， 因而可以视为星型模型的集合，故亦称星座模型\n星座模型是数据仓库最常使用的模型。\n实事表和维度表 （1）实事表 事实表主要包括以下四种：\n 事务事实表 ：\n该类型表的一行对应空间或时间上某点的度量事件。与粒度同层次的事实表，可以直接将事实字段进行Sum、Count等聚合操作。 周期快照事实表 ：\n该类型表中的每行汇总了发生在某一标准周期，如某天、某周、某月的多个度量事件。这类表非常适合跟踪长期的过程，如银行账户和其他形式的财务报表。 无事实事实表 :\n没有度量事实，仅记录一系列某一时刻发生的多维实体。非事实型事实表通常用来跟踪一些时间或者说明某些活动的范围。 累积快照事实表 ：\n行汇总了发生在过程开始和结束之间可预测步骤内的度量事件。管道或工作流过程（履行订单、索赔过程），都可以在此类事实表中被建模。  （2）维度表 关于维度表，主要看看 缓慢变化维\n比如，在一个零售业数据仓库中，事实表存着销售人员的销售记录，某天一个销售人员从北京分公司调到上海分公司了，那么如何来保存、处理这个变化呢？\n如果我们要统计北京地区或上海地区的总销售情况的时候，这个销售人员的销售记录应该算在北京还是算在上海？当然是调离前的算在北京，调离后的算在上海,但是如何标记这个销售人员所属区域？这里就需要处理一下这个维度的数据，即我们缓慢变化维需要做的事情。\n处理缓慢变化维的三种方式：  直接覆盖原值：这个比较简单粗暴。但是如果想要做历史分析的话，就比较难了，一般不太覆盖。 增加属性列：增加一个新列，来记录变化。这种适合变化比较少的情况，如果经常变化，增加无限量个字段明显不合适。 增加维度行：直接增加一条新纪录，并用一个专门的字段（可以是时间、版本、是否生效等等）进行标识，区分哪个数据是最新的  数仓的特性 （1）面向主题的 传统数据库都是面向应用的，即功能层面需要什么数据，数据库就是什么数据。但数仓是基于分析人员分析时关注的 主题 ，进行数据的组织。这就为数仓的便捷分析应用奠定了基础。\n比如电商行业中，一般分为以下主题，供参考：\n业务主题：用户、采购、配送、流量、仓储、商品、订单、售后、促销\n（2）集成的 集成的含义，指的是数据仓库的数据是从原有的分散的数据库数据抽取来的，进行了系统的整合。同一个主题的数据往往是 多个业务模块进行的整合 。同时，数仓通过分层，将数据从底层一直整合到顶层，实现统一。\n（3）相对稳定的 数据仓库的数据和业务数据库的差别之一，是数仓的数据由于为了满足各种查询分析的需求，是 不能对数据进行修改的 。\n比如用户的账户余额，在业务库中是不断变化的，但在数仓中，是固定时间进行的同步，发生了变化是通过时间分区进行区别，而不是去修改数仓中的数据。\n（4）随时间变化的 每隔一段固定的时间间隔后，抽取运行数据库系统中产生的数据，转换后集成到数据仓库中。随着时间的变化，数据以更高的综合层次被不断综合，以适应趋势分析的要求。因此，数仓的数据是随着时间变化的。\n数仓的意义和价值 （1）数仓极大提升BI分析效率，促进业务发展 在没有数仓的时候，领导想要个用户购买行为分析，分析师要怎么办呢？往往得找订单研发提订单数据，找商品研发提商品数据，然后在SQL、Excel中进行各种数据处理、各种数据计算，最终才能做出购买分\n但有了数仓以后，只要给数据部的同事提一下需求，甚至如果自己会的话，也可以自己完成数据的提取分析工作了。效率简直高了一大截。这在互联网快速响应、业务变化异常快的今天，更是异常重要。\n（2）提升数据开发效率，降低重复性建设成本 数仓是通过有组织的分层，将数据集中在一起。对于很多场景，数仓通过维度模型可以很灵活的进行支持，提升了业务数据研发的效率\n比如之前想开发个数据，都是需要从原始数据层面开始抽取。有了数仓，可以自上而下，先看应用层是否可以满足需求，如果不满足再看通用层。这样避免了每次数据开发都是烟囱式重复开发。\n（3）可以提高数据质量和一致性 因为现在的数据都集中到统一的数仓里了，所有的指标、逻辑都维持一套统一的口径，避免了出现各个部门数据不一致的情况。公司整体的数据质量也相应提升\n","description":"明确业务需求、清晰数据架构、有效维度建模、模块化可维护、数据质量保证、保证数据安全、可操作性和易用性","id":3,"section":"stack","tags":["db",""],"title":"数仓模型设计原则","uri":"http://wangjinbao.netlify.app/en/stack/db/design/"},{"content":"k8s的组件 node node是K8S集群中的一个节点\npod pod最小单元\n ps:一个pod中是可以运行多个容器中的\n service:svc  内部服务：数据库、后端API 外部服务：微服务API、前端界面   外部服务 中包含 ：nodePort 外部端口，映射svc的端口，即可访问svc\n这样即可通过ip + 端口 访问服务\n ingress 是用来管理集群外部访问集群内部服务的入口和方式的，可能通过ingress来配置不同的 转发规则\ningress可以配置域名，这样代替 ip + 端口的访问方式,另外可以配置 负载均衡、SSL 等\n 生产环境都是用域名访问的\n ConfigMap ConfigMap 把配置信息封装起来，然后就可以在应用程序中读取和使用了\n如：URL username password\n 避免生产环境 中的配置信息经常修改\n secret 在configMap的基础上 加密一层，解决敏感问题，如：base64 + 其它的算法\nvolumes 解决数据的 持久化问题， 挂载到集群外部的远程存储上\ndeployment deployment 解决单点node挂掉后的 高可用，它可以定义和管理应用程序的副本数量，以及应用程序的 更新策略\n PS: 理解总结\npod：可以理解为在 容器上加了一层抽象，把多个容器放在一起组成pod\ndeployment: 可以理解为在 pod上加了一层抽象 ，将一个或多个pod组合在一起，并且还有副本控制、滚动更新、自动扩缩 等\n statefulSet 针对pod自动删除、新增、更新等操作，数据库的持久化的问题，因此一些 有状态 的应用，如:数据库、缓存、消息队列 等，都要使用 statefulSet\n PS: 一般有状态的应用，如 数据库、缓存、消息队列等都从中分离出来，在群集外单独部署。\n k8s架构 master - worker 架构\nmaster-node master-node 负责管理整个集群\n由4个核心组件：\n apiServer etcd controllerManager scheduler cloudControllerManager  apiServer 提供k8s集群的API接口服务，所有的组件都会通过这个接口来进行通信，如： kubectl、DashBoard 等 工具。\n并且pod的增、删、改、查等操作进行认证、授权和访问控制\nscheduler 负责 监控资源并协调调度使用\ncontrollerManager 当pod发生故障时，监控和检测到这个故障，然后快速处理。如：重新启动pod、其它pod代替它\netcd 高可用的 键-值存储系统，用来存储所有资源对象的状态信息，每个pod的信息都记录在里面（集群的大脑）\ncloudControllerManager 云平台服务特有的\nworker-node worker-node 负责运行应用程序和服务\n为了每个node都能正常运行，node包含三个组件：\n kubelet：维护每个节点上的pod，并确保它按预期运行，定期从apiServer中更新修改后的pod规范，监控节点的运行情况，汇报给apiServer kube-proxy：为pod对象提供 网络代理 和 负载均衡 服务 container-runtime: 拉取、创建、启动、停止容器   通常一个service中由多个node(节点)组成，这个service的负载均衡就是通过kube-proxy完成的\n k3s + multipass 安装multipass multipass官网地址：\nhttps://multipass.run/\nmac:\nbrew install multipass\n验证：\nmultipass version\n创建虚拟机\nmultipass launch --name k3s --cpus 2 --memory 8G --disk 10G\n查看\nmultipass list\n相关命令：\n 创建虚拟机： multipass launch --name k3s 启动虚拟机： multipass start k3s 停止虚拟机： multipass stop k3s 进入虚拟机： multipass shell k3s 执行命令： multipass exec k3s -- ls -l 查看虚拟机列表： multipass list 查看帮助： multipass help  k3s默认不允许远程登录的，如果想使用SSH登录虚拟机的话，可以按下步骤：\n  登录虚拟机： multipass shell k3s\n  安装 net-tools: sudo apt install net-tools\n  修改ssh配置： vi /etc/ssh/sshd_config\n(PassWordAuthentication no=\u0026gt;yes 和 PermitRootLogin yes 和 sudo service ssh restart)\n  设置密码：passwd\n  1 2  sudo passwd ubuntu 设置密码   退回主机测试登录：\n1  ssh ubuntu@192.168.105.10   生成秘钥：ssh-keygen  1 2 3  ssh-keygen -t rsa -b 4096 cd .ssh id_rsa.pub   配置免密登录：ssh-copy-id ubuntu@192.168.105.10 简化命令： alias k3s='ssh ubuntu@192.168.105.10'\n添加到bash各zsh的配置文件 中  安装k3s 进入到k3s虚拟机中进行安装 k3s:\n安装k3s的master节点 1  curl -sfL https://get.k3s.io | sh -   国内用户可以换成下面的命令，使用ranher的镜像源来安装：\n1 2 3 4 5  curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - # 查看 $ sudo kubectl get nodes NAME STATUS ROLES AGE VERSION k3s Ready control-plane,master 11s v1.29.3+k3s1   接下来需要在这个master节点上获取一个token，\n用来作为创建worker节点时的一个认证凭证，\n它保存在/var/lib/rancher/k3s/server/node-token这个文件里面，\n我们可以使用sudo cat命令来查看一下这个文件中的内容，\n1  sudo cat /var/lib/rancher/k3s/server/node-token   退出k3s虚拟主机：\n将TOKEN保存到一个环境变量中 1  TOKEN=$(multipass exec k3s sudo cat /var/lib/rancher/k3s/server/node-token)   保存master节点的IP地址 1  MASTER_IP=$(multipass info k3s | grep IPv4 | awk \u0026#39;{print $2}\u0026#39;)   确认\n1  echo $MASTER_IP   使用刚刚的TOKEN和MASTER_IP来创建两个worker节点\n并把它们加入到集群中\n创建两个worker节点的虚拟机 1 2  multipass launch --name worker1 --cpus 2 --memory 8G --disk 10G multipass launch --name worker2 --cpus 2 --memory 8G --disk 10G   在worker节点虚拟机上安装k3s 1 2 3  for f in 1 2; do multipass exec worker$f -- bash -c \u0026#34;curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=\\\u0026#34;https://$MASTER_IP:6443\\\u0026#34; K3S_TOKEN=\\\u0026#34;$TOKEN\\\u0026#34; sh -\u0026#34; done   这样就完成了一个多节点的kubernetes集群的搭建。\nk8s的常用命令 基础使用 1 2 3 4 5 6 7 8  # 查看帮助 kubectl --help # 查看API版本 kubectl api-versions # 查看集群信息 kubectl cluster-info   资源的创建和运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 创建并运行一个指定的镜像 kubectl run NAME --image=image [params...] # e.g. 创建并运行一个名字为nginx的Pod kubectl run nginx --image=nginx # 根据YAML配置文件或者标准输入创建资源 kubectl create RESOURCE # e.g. # 根据nginx.yaml配置文件创建资源 kubectl create -f nginx.yaml # 根据URL创建资源 kubectl create -f https://k8s.io/examples/application/deployment.yaml # 根据目录下的所有配置文件创建资源 kubectl create -f ./dir # 通过文件名或标准输入配置资源 kubectl apply -f (-k DIRECTORY | -f FILENAME | stdin) # e.g. # 根据nginx.yaml配置文件创建资源 kubectl apply -f nginx.yaml   查看资源信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # 查看集群中某一类型的资源 kubectl get RESOURCE # 其中，RESOURCE可以是以下类型： kubectl get pods / po # 查看Pod kubectl get svc # 查看Service kubectl get deploy # 查看Deployment kubectl get rs # 查看ReplicaSet kubectl get cm # 查看ConfigMap kubectl get secret # 查看Secret kubectl get ing # 查看Ingress kubectl get pv # 查看PersistentVolume kubectl get pvc # 查看PersistentVolumeClaim kubectl get ns # 查看Namespace kubectl get node # 查看Node kubectl get all # 查看所有资源 # 后面还可以加上 -o wide 参数来查看更多信息 kubectl get pods -o wide # 查看某一类型资源的详细信息 kubectl describe RESOURCE NAME # e.g. 查看名字为nginx的Pod的详细信息 kubectl describe pod nginx   资源的修改、删除和清理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # 更新某个资源的标签 kubectl label RESOURCE NAME KEY_1=VALUE_1 ... KEY_N=VALUE_N # e.g. 更新名字为nginx的Pod的标签 kubectl label pod nginx app=nginx # 删除某个资源 kubectl delete RESOURCE NAME # e.g. 删除名字为nginx的Pod kubectl delete pod nginx # 删除某个资源的所有实例 kubectl delete RESOURCE --all # e.g. 删除所有Pod kubectl delete pod --all #强制删除pod ,grace-period 是 延迟删除的意思 --grace-period=0 --force sudo kubectl delete pods portainer-6dd4dfd74-td7g6 -n portainer --grace-period=0 --force # 根据YAML配置文件删除资源 kubectl delete -f FILENAME # e.g. 根据nginx.yaml配置文件删除资源 kubectl delete -f nginx.yaml # 设置某个资源的副本数 kubectl scale --replicas=COUNT RESOURCE NAME # e.g. 设置名字为nginx的Deployment的副本数为3 kubectl scale --replicas=3 deployment/nginx # 根据配置文件或者标准输入替换某个资源 kubectl replace -f FILENAME # e.g. 根据nginx.yaml配置文件替换名字为nginx的Deployment kubectl replace -f nginx.yaml   调试和交互 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 进入某个Pod的容器中 kubectl exec [-it] POD [-c CONTAINER] -- COMMAND [args...] # e.g. 进入名字为nginx的Pod的容器中，并执行/bin/bash命令 kubectl exec -it nginx -- /bin/bash # 查看某个Pod的日志 kubectl logs [-f] [-p] [-c CONTAINER] POD [-n NAMESPACE] # e.g. 查看名字为nginx的Pod的日志 kubectl logs nginx # 将某个Pod的端口转发到本地 kubectl port-forward POD [LOCAL_PORT:]REMOTE_PORT [...[LOCAL_PORT_N:]REMOTE_PORT_N] # e.g. 将名字为nginx的Pod的80端口转发到本地的8080端口 kubectl port-forward nginx 8080:80 # 连接到现有的某个Pod（将某个Pod的标准输入输出转发到本地） kubectl attach POD -c CONTAINER # e.g. 将名字为nginx的Pod的标准输入输出转发到本地 kubectl attach nginx # 运行某个Pod的命令 kubectl run NAME --image=image -- COMMAND [args...] # e.g. 运行名字为nginx的Pod kubectl run nginx --image=nginx -- /bin/bash   minikube 要先开启服务\n1  minikube start   multipass 要先进入master节点\n1  multipass shell k3s   命令 查看节点：\nsudo kubectl get nodes\n查看service：\nsudo kubectl get svc\n查看pod：\nsudo kubectl get pod\n创建pod:\nsudo kubectl run nginx --image=nginx\n创建资源对象：\nsudo kubectl create ...\n创建deployment:\n1 2 3 4 5 6  sudo kubectl create deployment nginx-deployment --image=nginx $ sudo kubectl get pod NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 24m nginx-deployment-6d6565499c-lv4s4 1/1 Running 0 22m    PS : 名字中可以看出 deployment 和 pod 之间还有一个 replicaset (6d6565499c),\nnginx-deployment:代表 deployment 的名称\n6d6565499c：代表 replicaset 的随机数\nlv4s4：代表 pod 的随机数\n 1 2 3  $ sudo kubectl get replicaset NAME DESIRED CURRENT READY AGE nginx-deployment-6d6565499c 1 1 1 25m   编辑资源对象：\n1 2  sudo kubectl edit deployment nginx-deployment 进入 vim编辑器   查看日志：\n1 2 3 4  $ sudo kubectl logs nginx-deployment-6d6565499c-lv4s4 /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/ /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh   进入pod:\n1 2  $ sudo kubectl exec -it nginx-deployment-6d6565499c-lv4s4 -- /bin/bash root@nginx-deployment-6d6565499c-lv4s4:/#   删除资源对象(deployment)\n1 2  sudo kubectl delete deployment nginx-deployment 之后相就的replicaset 和 pod 都会被删除   yaml文件的配置和使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:3template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.25ports:- containerPort:80  通过yaml文件： 创建deployment资源对象\n1  sudo kubectl create -f nginx-deployment.yaml   删除deployment:\n1  sudo kubectl delete -f nginx-deployment.yaml    PS:create 和 apply 的区别：新增 和 更新或新增\n k8s配置项详解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  # 与APIserver交互指定 group/versionapiVersion:apps/v1 # 资源对象的类型：Deployment/ Service/ ConfigMapkind:Deployment# 定义资源对象的元数据：名称、标签、命令空间metadata:name:kibananamespace:logging# 规范，是specification的缩写，配置多个资源对象的信息：多副本、镜像、端口等# spec是一个嵌套的结构，第一个spec是deployment配置信息，第二个是pod的配置信息，spec:# 选择器 == Labels 标签selector:matchLabels:app:kibana# 副本的个数replicas:3# 定义了pod的配置信息template:metadata:labels:app:kibanaspec:containers:- name:kibana# 镜像地址image:docker.elastic.co/kibana/kibana:6.5.4# 环境变量env:- name:ELASTICSEARCH_URLvalue:http://elasticsearch:9200- name:XPACK_SECURITY_ENABLEDvalue:\u0026#34;true\u0026#34;ports:# 对外暴露的端口是 5601- containerPort:5601name:httpprotocol:TCP  创建 资源对象： 1  kubectl create apply -f kibana-deploment.yaml   删除 资源对象： 1  kubectl delete -f kibana-deploment.yaml   创建/更新 资源对象 1  kubectl apply -f kibana-deploment.yaml    PS : 生产遇到流量高峰，修改replicas数量，并执行apply -f 就可以迅速扩容\n  PS :Service 中没有 replicas 变量，configMap 中没有 selector 变量\n 查看Ip和节点 命令：\n1  kubectl get pod -o wide   创建服务 1 2 3 4 5 6 7 8 9 10 11  apiVersion:v1kind:Servicemetadata:name:nginx-servicespec:selector:app:nginxports:- protocol:TCPport:80targetPort:80  创建服务 命令：\n1  kubectl create service nginx-service   将已存在的 deployment 对外公开为一个服务 命令：\n(将deployment升级为一个service)\n1 2 3 4 5 6 7 8  kubectl expose deployment nginx-deployment ubuntu@k3s:~$ sudo kubectl get all ... NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 18h \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; service/nginx-deployment ClusterIP 10.43.7.225 \u0026lt;none\u0026gt; 80/TCP 10s ...   访问这个服务：\n1  curl 10.43.7.225   查看 服务 详细信息\n命令：\n1 2 3  sudo kubectl describe service nginx-deployment sudo kubectl describe deployment nginx-deployment sudo kubectl describe pod nginx-deployment-cd5968d5b-g94t2   查看 deployment 详细信息\n命令：\n1  sudo kubectl describe deployment nginx-deployment   删除服务 1  sudo kubectl delete service nginx-deployment   提供对外端口服务 端口号必须在 30000 到 32767 之间\n1 2 3 4 5 6 7 8  spec:# 指定类型type:NodePortports:...nodePort:30080  更新配置：\n1 2 3 4 5 6 7 8 9 10  sudo kubectl apply -f nginx-service.yaml service/nginx-service configured # 查看type变为NodePort $ sudo kubectl get all ... NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 18h service/nginx-service NodePort 10.43.133.154 \u0026lt;none\u0026gt; 80:30080/TCP 4m ...   查看节点的ip地址：\n1 2 3 4 5  $ sudo kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME worker2 Ready \u0026lt;none\u0026gt; 18h v1.29.3+k3s1 192.168.65.4 \u0026lt;none\u0026gt; Ubuntu 24.04 LTS 6.8.0-31-generic containerd://1.7.11-k3s2 k3s Ready control-plane,master 18h v1.29.3+k3s1 192.168.65.2 \u0026lt;none\u0026gt; Ubuntu 24.04 LTS 6.8.0-31-generic containerd://1.7.11-k3s2 worker1 Ready \u0026lt;none\u0026gt; 18h v1.29.3+k3s1 192.168.65.3 \u0026lt;none\u0026gt; Ubuntu 24.04 LTS 6.8.0-31-generic containerd://1.7.11-k3s2   浏览器访问：\n因为是集群访问哪个节点都可以：\n192.168.65.2:30080\n192.168.65.3:30080\n192.168.65.4:30080\nservice服务的种类   ClusterIP   默认类型，集群内部的服务\n  NodePort   节点端口类型，将服务公开到集群节点上\n  LoadBalancer   负载均衡类型，将服务公开到外部负载均衡器上\n  ExternalName   外部名称类型，将服务映射到一个外部域名上\n  Headless   无头类型，主要用于DNS解析和服务发现\nportainer可视化管理集群 安装Portainer 1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 下载yaml文件： wget https://downloads.portainer.io/ce2-19/portainer.yaml # 安装 $ sudo kubectl apply -n portainer -f portainer.yaml namespace/portainer created serviceaccount/portainer-sa-clusteradmin created persistentvolumeclaim/portainer created clusterrolebinding.rbac.authorization.k8s.io/portainer created service/portainer created deployment.apps/portainer created # --或者直接安装 # 在master节点上安装portainer，并将其暴露在NodePort 30777上 kubectl apply -n portainer -f https://downloads.portainer.io/ce2-19/portainer.yaml   查看：\n指定命名空间：-n\n1  sudo kubectl get all -n portainer   访问 http协议：\nhttp://192.168.65.2:30777/\nhttps协议：\nhttps://192.168.65.2:30779/\n前提要连VPN：不然会报错：\n New Portainer installation\nYour Portainer instance timed out for security purposes. To re-enable your Portainer instance, you will need to restart Portainer.\n 根据yaml配置文件 删除资源对象\n1  sudo kubectl delete -f portainer.yaml   首次设置admin密码：\nadmin\nwjb1234509876\n","description":"k8s的部署、使用、工具。","id":4,"section":"stack","tags":["k8s"],"title":"k3s+multipass实践k8s集群操作","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s2/"},{"content":"pod pause容器 pause容器的作用:\n最主要的作用：创建共享的网络名称空间，以便于其它容器以平等的关系加入此网络名称空间\npause进程 是pod中所有容器的 父进程（即第一个进程）；\n同一个pod内多个容器共享 pause(网络站)，直接用host即可\n同一个pod内多个容器，既 共享网络 ，又 共享存储挂载\n控制器 ReplicationController(RC) 用来 控制预期的副本数量 ，如果有容器异常退出，自动新建pod代替；如果异常多出，自动回收。\n新版本的k8s中建议用ReplicaSet 替代 ReplicationController\nReplicaSet(RS) RS 和 RC 没有本质的不同，只是名字不一样，并且RS支持集合式的selector\nDeployment RS 可以独立使用，但建议使用 Deployment 自动管理 RS，RS不支持 rolling-update ，Deployment 支持\n PS : RS 支持 pod的创建，结合 Deployment 支持 rolling-update 。\n  HPA （自动扩容缩）： HPA 适用于 Deployment 和 ReplicaSet ,CPU利用率扩缩容\n StatefullSet StatefullSet 是为了解决 有状态服务 问题(对应 Deployment 和 ReplicaSets 是 无状态服务)\n应用场景：\n 稳定的持久化存储：\n即pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现 稳定的网络标识：\n即pod重新调度后其podName和Hostname不变 有序部署，有序扩展：\npod是有顺序的，依据定义的顺序依次进行即 从0到N-1，基于init containers来实现。 有序收缩，有序删除：\n即从N-1到0  DaemonSet 确保全部（或一些）Node上运行 只有一个pod的副本。当有node加入集群时，也会为他们新增一个pod。当有node从集群移除时，这些\npod也会被回收。删除 DaemonSet 将会删除它创建的所有pod。\n典型场景：\n 运行集群存储daemon，例如在每个node运行glusterd、ceph。 在每个node上运行日志收集 daemon，例如 fluentd、logstash. 在每个node上运行监控 daemon，例如：prometheus node exporter  Job \u0026amp;\u0026amp; Cron Job Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个pod成功结束\nCron Job 管理基于时间的job，即：\n 定时只运行一次 用周期地定时运行  网络通讯 k8s设定了所有pod都在一个可以直接连通的扁平的网络空间中，\n网络应用场景：\n 同一个pod内的多个容器之间：io,local 各pod之间的通讯：Overlay Network pod与service之间的通讯：各节点的Iptables规则，（新版LVS）   PS: 不同物理机之间，Docker0 中分配不同的网段，\n OverlayNetwork: 原理：Flanneld 分配 Flannel0,Flannel0 收集 Docker0的网络数据报文，Flanneld的数据的二次封装和二次解封。\nETCD与Flannel关系  存储管理Flannel可分配的IP段 ETCD监控每个 pod的实际地址，并维护pod节点路由表  网络场景解决方法： 场景一：同一个pod内部通讯： 同个pod共享同一个网络命名空间，共享同一个linux协议栈\n场景二：pod1至pod2：  情况1：pod1与pod2不在同一台主机，pod的地址是与docker0在同一个网段，Flannel0 收集 Docker0的网络数据报文，二次解封，Flanneld通过ETCD中存储的IP网段，找到\n对应的Flanneld,Flannel0拉取到doker0的网段地址，找到对应的pod地址。 情况2：pod1与pod2在同一台机器，由Docker0网桥直接转发请求至pod2，不需要经过Flannel  场景三：pod至service的网络： iptables维护和转发，新版lvs\n场景四：外网访问pod： 通过service中的nodePort对外部提供访问服务\nk8s重要组件 API Server: API Server: 所有服务访问 统一入口\nControllerManager: ControllerManager: 维持 副本期望数目\nScheduler: Scheduler: 负责 调度任务 ，选择合适的节点进行分配任务\nETCD: ETCD: 键值对数据库 储存K8S集群所有信息，持久化\nKubelet: Kubelet: 直接与容器引擎交互实现 容器的生命周期管理\nKube-proxy: Kube-proxy: 负责写入规则至 IPTables 、 IPVS 实现 服务映射访问 的\nCore-DNS: 为集群中的SVC创建一个域名IP的对应关系解析\nDashboard: 给 K8S集群提供一个访问页面\n###Ingress Controller:\n实现四层代理，igress可实现七层代理\nPrometheus: k8s集群的监控能力\nELK: 提供K8S集群日志统一分析介入平台\n","description":"k8s实践与总结","id":5,"section":"stack","tags":["k8s"],"title":"k8s实践与总结-1(pod)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s3/"},{"content":"资源分类 名称空间级别： 如：kube-system、k3s\n1.工作负载型资源： pod 、replicaSet 、Deployment 、statefulSet 、daemonSet 、job 、cronJob\n2.服务发现及负载均衡型资源： Service 、Ingress、\n3.配置与存储型资源： volume（存储卷）、CSI（容器存储接口，可扩展各种三方存储卷）\n4.特殊类型的存储卷： configMap（当配置中心来使用的资源类型）、Secret（保存敏感数据）、DownwardAPI(把外部环境中的信息输出给容器)\n5.集群级资源： Namespace、Node、Role、ClusterRole、RoleBinding、ClusterRoleBinding\n6.元数据型资源： HPA 、PodTemplate 、 LimitRange\n集群级别： role\n元数据型： HPA(平滑扩展)\nyaml属性 version string 类型\n是K8S API的版本。基本为 v1 (可kubectl api-versions命令查看)\nkind string 类型\n是yaml文件定义的资源类型和角色，比如：Deployment，Pod,Service\nmetadata Object 类型\n元数据对象，固定值就写metadata\nmetadata.name string 类型\n元数据对象的名字，自由编写，如：pod的名字\nmetadata.namespace string 类型\n元数据对象的命名空间，自由编写\nspec Object 类型\n字义对象规则，固定值spec\nspec.containers[] list 类型\nspec对象的容器列表定义，是个列表\nspec.containers[].name string 类型\n容器的名字\nspec.containers[].image string 类型\n容器的镜像名称\nspec.containers[].imagePullPolicy string 类型\n镜像的拉取策略，有三个选项：\n Always: 每次都尝试重新拉取镜像 Never: 仅使用本地镜像 IfNotPresent: 如果本有则用，没有在线拉  spec.containers[].command[] list 类型\n容器启动命令，可以指定多个命令。\nspec.containers[].args[] list 类型\n容器启动命令参数，可以指定多个\nspec.containers[].workingDir string 类型\n容器的工作目录\nspec.containers[].volumeMounts[] list 类型\n容器内部的挂载存储卷配置\nspec.containers[].volumeMounts[].name string 类型\n指定存挂载储卷的名称\nspec.containers[].volumeMounts[].mountPath string 类型\n指定存挂载储卷的路径\nspec.containers[].volumeMounts[].readOnly string 类型\n指定存挂载储卷的路径的读写模式，ture 或 false，默认为读写模式\nspec.containers[].ports[] list 类型\n窗口需要用到的端口列表\nspec.containers[].ports[].name string 类型\n端口名称\nspec.containers[].ports[].containerPort string 类型\n容器需要监听的端口号\nspec.containers[].ports[].hostPort string 类型\n容器所在主机需要监听的端口号，默认与containerPort相同，如果设置了hostPort同一台主机无法启动该容器的相同副本，因为端口号相同冲突了\nspec.containers[].ports[].protocol string 类型\n端口协议，支持TCP和UDP，默认TCP\nspec.containers[].env[] list 类型\n容器运行前设置的环境变量列表\nspec.containers[].env[].name list 类型\n环境变量名称\nspec.containers[].env[].value list 类型\n环境变量值\nspec.containers[].resources Object 类型\n资源限制和资源请求的值\nspec.containers[].resources.limits Object 类型\n容器运行时资源的运行上限\nspec.containers[].resources.limits.cpu string 类型\nCPU的限制，单位为core个数\nspec.containers[].resources.limits.memory string 类型\nMEM内存的限制，单位为MIB/GIB\nspec.containers[].resources.requests Object 类型\n容器启动和调度时的限制设置\nspec.containers[].resources.requests.cpu string 类型\nCPU请求，单位为core数，容器启动时初始化可用数量\nspec.containers[].resources.requests.memory string 类型\n内存请求，单位为MIB/GIB，容器启动的初始化可用数量\nspec.restartPolicy string 类型\npod的重启策略，可选值为Always、OnFailure,默认值为Always。\n Always： 无论容器是如何终止的，都将重启 OnFailure: 只非0退出码终止时，才重启 Never: 终止后不重启  spec.nodeSelector Object 类型\n定义Node的Label过滤标签，以 key:value 格式指定\nspec.imagePullSecrets Object 类型\n定义pull镜像时使用secret名称，以 name:secretkey 格式指定\nspec.hostNetwork Boolean 类型\n定义是否使用主机网络模式，默认值为 false.设置true 使用宿主机网络，不使用docker网桥，同时无法启动第二个副本。\n","description":"k8s实践与总结(资源与属性)","id":6,"section":"stack","tags":["k8s"],"title":"k8s实践与总结-2(资源与属性)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s4/"},{"content":"生命周期 pause容器 基础网络容器\nInit C 初始化容器\nInit容器 与 变通容器的区别：\n Init容器总是运行到成功完成为止 每个Init容器必须在下一个Init容器启动之前成功完成  Init容器对与应用容器的优势：\n 可包含实用具工 与应用容器分离 在应用容器先完成，可实现延时或阻塞  例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  apiVersion:v1kind:Podmetadata:name:myapp-podlabels:app:myappspec:containers:- name:nginximage:nginx:1.25command:[\u0026#39;sh\u0026#39;,\u0026#39;-c\u0026#39;,\u0026#39;echo The app is running! \u0026amp;\u0026amp; sleep 3600\u0026#39;]initContainers:- name:init-myserviceimage:busyboxcommand:[\u0026#39;sh\u0026#39;,\u0026#39;-c\u0026#39;,\u0026#39;until nslookup myservice; do echo waiting for myservice; \u0026amp;\u0026amp; sleep 2;done;\u0026#39;]- name:init-mydbimage:busyboxcommand:[\u0026#39;sh\u0026#39;,\u0026#39;-c\u0026#39;,\u0026#39;until nslookup mydb; do echo waiting for mydb ; \u0026amp;\u0026amp; sleep 2;done;\u0026#39;]  myservice和mydb的服务 yaml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  apiVersion:v1kind:Servicemetadata:name:myservicespec:ports:- protocol:TCPport:80targetPort:9376---apiVersion:v1kind:Servicemetadata:name:mydbspec:ports:- protocol:TCPport:80targetPort:9376   PS: Init容器失败，k8s会不断地重启pod，直到成功为止。\nrestartPolicy 为 Never 则不重启\n init c特殊说明  init容器在网络(pause容器)和数据卷之后启动。每个容器必须在下一个容器启动之前成功退出 init容器失败会用restartPolicy策略 init容器没有成功之前，端口不会暴露在service中 初始化的pod为pending状态 pod重启，所有init容器必须重新执行 init容器spec被修改image字段，pod会重启 init容器没有readiness探针 pod中init容器与app容器名称必须唯一  容器探针 探针： 探针：由kubelet对容器进行的定期诊断。\n执行诊断，kubelet会调用由容器实现的handler.\n三种处理程序：\n ExecAction :\n容器内执行命令，退出码为0则诊断成功 TCPSocketAction:\n容器的TCP端口检查，端口打开则诊断成功 HTTPGetAction:\n容器的IP+端口进行HTTP 的Get请求，状态码\u0026gt;200且\u0026lt;400,诊断成功  每次探测都获得三种结果：\n 成功：容器通过诊断 失败：容器未通过诊断 未知：诊断失败，挂起\u0026hellip;  readiness就绪探针 如果就绪探测失败，删除pod的IP地址。\n如果不提供就绪探针，状态为success\n1 2 3 4 5 6 7 8  ...spec:containers:readinessProbe:httpGet:port:80path:/index1.html...   PS: pod启动失败，检查错误 kubectl describe pod XXX\n Liveness存活探针 如果存活探测失败，kubelet杀死容器并重启。\n如果不提供存活探针，状态为success\nexec 1 2 3 4 5 6 7 8 9  ...spec:containers:livenessProbe:exec:command:[\u0026#34;test\u0026#34;,\u0026#34;-e\u0026#34;,\u0026#34;/tmp/live\u0026#34;]initialDelaySeconds:1periodSeconds:3...  httpGet 1 2 3 4 5 6 7 8 9 10  ...spec:containers:livenessProbe:httpGet:port:httppath:/index.htmlperiodSeconds:3timeoutSeconds:10...  检测选项：-w\n1  kubectl get pod -w   tcp 1 2 3 4 5 6 7 8 9 10  ...spec:containers:livenessProbe:initialDelaySeconds:5tcpSocket:port:80periodSeconds:3timeoutSeconds:1...  Main C 主容器：启动start、结束end\n1 2 3 4 5 6 7 8 9 10 11 12  ...spec:containers:...lifecycle:postStart:exec:80command:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;echo Hello from the postStart handler \u0026gt; /tmp/message\u0026#34;]preStop:3exec:80command:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;echo Hello from the postStart handler \u0026gt; /tmp/message\u0026#34;]...  pod阶段(phase) 挂起-Pending pod已被k8s系统接受，但有一个或多个容器镜像 尚未创建。等待 调度Pod 、网络下载镜像\n运行-Running pod已经绑定到了一个节点上，pod中所有容器已经创建，至少一个容器正 在运行，或者 正在启动 或 重启 状态\n成功-Success pod中的 所有容器都被成功终止，并且不会再重启\n失败-Failed pod中的容器都已经终止了，并且至少有一个容器是 失败终止。\n未知-Unknown 因为某些原因无法取得pod的状态，主机通信失败\n","description":"k8s实践与总结(pod生命周期)","id":7,"section":"stack","tags":["k8s"],"title":"k8s实践与总结-3(pod生命周期)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s5/"},{"content":"k8s控制器 定义： k8s中内建了很多的controller(控制器)，相当于一个状态机，用来控制pod的具体状态和行为\n控制器类型  ReplicationController和ReplicaSet\n用来维持用户定义的副本数 Deployment\n声明式定义方法，用来替代RS更方便的管理应用\n场景：   定义Deployment来创建Pod和ReplicaSet(先创建rs，rs再管理pod) 滚动升级和回滚应用(通过rs的版本删除旧pod) 扩容和缩容 暂停和继续Deployment   PS:\n命令式编程：过程步骤一一步定义好 create\n声明式编程：不要过程，只要结果 apply\n  DaemonSet\n确保 全部 或 一些 Node上运行一个pod的副本。\n典型用法：   运行集群存储 daemon,如 每个Node上运行glusterd、ceph 在每个Node上运行日志收集daemon，如 fluentd、logstash 在每个Node上运行监控daemon，如 prometheus node exporter   Job/CronJob\n保证任务，成功结束，如： * * * * *。1 定时任务 2 周期任务 StateFulSet\n应用场景：   稳定的持久化存储 稳定的网络标识 有序部署，有序扩展   Horizontal Pod Autoscaling\n平滑更新  Deployment 1.创建 kubectl create -f xxx-deployment.yaml --record\n2.扩容 scale ... --replicas 10\n1  kubectl scale deployment nginx-deployment --replicas 10   3.如果集群支持HPV的话，可以为Deployment设置自动扩展 kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80\n4.更新镜像比较简单 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1\n查看更新过程的命令：\nkubectl rollout status XX \nkubectl rollout status deployment/nginx-deployment\n5.回滚 rollout undo\nkubectl rollout undo deployment/nginx-deployment\nDeployment的更新策略  Deployment 保证升级时只有一定数量的pod是down的。 确保至少有比期望的pod数量少一个是up状态（最多一个不可用） 确保最多比期望的pod数据多一个pod是up的 更新25%的pod  Rollver(多个并行) 假设要创建5个副本的Deployment，当还有3个没创建好里，更新了策略，Deployment会直接杀死已经创建好的pod，直接更新最新的5个pod\n回退(Deployment) 1 2 3 4 5 6 7 8 9  kubectl set image deployment/nginx-deployment nginx=nginx:1.91 kubectl rollout status deployment/nginx-deployment kubectl get pods kubectl rollout history deployment/nginx-deployment kubectl rollout undo deployment/nginx-deployment ## 指定 历史版本 kubectl rollout undo deployment/nginx-deployment --to-version=2 ## 暂停 deployment 的更新 kubectl rollout pause deployment/nginx-deployment   清理(Policy) 设置 spec.revisonHistoryLimit 项来指定 deployment 最多保留多少 revision 历史记录。\n默认的会保留所有的revsion;设置为0，不允许回退\nDaemonSet 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ...apiVersion:apps/v1kind:DaemonSetmetadata:name:daemonset-examplelabels:app:deamonsetspec:selector:matchLabels:name:deamonset-exapletemplate:metadata:labels:name:deamonset-exaplespec:containers:- name:deamonset-exampleimage:XXXmyapp:v1...  Job 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  apiVersion:batch/v1kind:Jobmetadata:name:pispec:template:metadata:name:pispec:containers:- name:piimage:perlcommand:[\u0026#34;perl\u0026#34;,\u0026#34;-Mbignum=bpi\u0026#34;,\u0026#34;-wle\u0026#34;,\u0026#34;print bpi(2000)\u0026#34;]restartPolicy:Never  ","description":"k8s实践与总结(控制器)","id":8,"section":"stack","tags":["k8s"],"title":"k8s实践与总结-4(控制器)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s6/"},{"content":"service服务 service的定义： 通过 label 和 selector 对外提供访问的一组pod，相当于微服务\nsvc只能提供 4层负载均衡 能力,没有7层负载均衡，\n也就是只能通过 IP + 端口 的方式访问，也就是不能通过 主机名 或 域名 方式访问\nservice的类型 4种类型：\n1. ClusterIP: 默认类型，自动分配一个仅ClusterIP内部可访问的 虚拟IP\n2. NodePort: 在ClusterIP的基础上，为service在每台机器上绑定一个端口，通过 NodeIP : NodePort来访问服务\n3. LoadBalancer: 在NodePort的基础上，cloud provider(云服务商)提供一个外部的负载均衡器，并把请求转发到 NodeIP : NodePort\n4. ExternalName: 把集群外部的服务引入到集群内部，在集群内部直接使用。\n说明：\n1-监听服务与端点：\n通过 kubeproxy 实现的，kubeproxy监听匹配到的pod中的信息并写入iptables中。\n2-客户端访问svc：\n通过 iptables 中的绑定信息，找到对应的pod\n代理模型的分类  PS : 为什么代理不使用 round-robin DNS?\n答：DNS更新不及时生效，会有缓存\n  userspace(k8s1.0版本) iptables(k8s1.2版本) ipvs(k8s1.14版本)  1 2  sudo vim svc-deployment.yaml sudo kubectl apply -f svc-deployment.yaml   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  apiVersion:apps/v1kind:Deploymentmetadata:name:myappspec:selector:matchLabels:app:myappreplicas:3template:metadata:labels:app:myapprelease:stabelspec:containers:- name:myappimage:nginx:1.25ports:- containerPort:80  1 2  sudo vim myapp-service.yaml sudo kubectl apply -f myapp-service.yaml   1 2 3 4 5 6 7 8 9 10 11 12  apiVersion:v1kind:Servicemetadata:name:myappspec:type:ClusterIPselector:app:myapprelease:stabelports:- port:80targetPort:80  Headless Service(特殊的clusterIP) 有时不需要或不想要负载均衡，以及单独的 Service IP。遇到这种情况，IP的值为 \u0026ldquo;None\u0026rdquo; 来创建 Headless Service，这类service服务，IP/kube-proxy不会处理它们，也不会负载均衡。\n1 2  sudo vim myapp-svc-headless.yaml sudo kubectl apply -f myapp-svc-headless.yaml   1 2 3 4 5 6 7 8 9 10 11 12  apiVersion:v1kind:Servicemetadata:name:myapp-headlessnamespace:defaultspec:selector:app:myappclusterIP:\u0026#34;None\u0026#34;ports:- port:80targetPort:80  查看\n1  $ kubectl get pod -n kube-system -o wide   1 2 3 4  # 安装dig $ yum install -y bind-utils $ dig -t A myapp-headless.default.svc.cluster.local. @10.96.0.10   ExternalName域名访问 1 2  sudo vim ex.yaml sudo kubectl apply -f ex.yaml   1 2 3 4 5 6 7 8  kind:ServiceapiVersion:v1metadata:name:my-service-1namespace:defaultspec:type:ExternalNameexternalName:i.jarvenwang.com  ","description":"k8s实践与总结(service)","id":9,"section":"stack","tags":["k8s"],"title":"k8s实践与总结-5(service)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s7/"},{"content":"ingress ingress概述 定义：提供外部访问内部集群的 访问入口，路由规则的集合，将外部的http或https请求转发到集群内部的service上。\ningress-nginx组成 三个组件：\n 反向代理负载均衡器\n通常以service的port方式运行，接收并按照ingress定义的规则进行转发，常用的有nginx，Haproxy，Traefik等，nginx 最常用 Ingress Controller\n监听APIServer，根据用户编写的ingress规则（编写ingress的yaml文件），动态地去更改nginx服务的配置文件，并且reload重载使其生效，此过程是自动化的（通过lua脚本来实现） Ingress\n将nginx的配置抽象成一个Ingress对象，当用户每添加一个新的服务，只需要编写一个新的ingress的yaml文件即可  ingress-nginx的工作原理 工作原理：\n ingress controller通过和k8s api交互，动态的去感知集群中ingress规则变化 然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段nginx配置 在写到nginx-ingress-controller的pod里，这个Ingress controller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中 然后reload一下使配置生效，以此达到分配和动态更新问题  ingress-nginx解决生产环境问题  动态配置服务：\n如果按照传统方式，当新增加一个服务时，我们可能需要在流量入口加一个反向代理指向我们新的服务，而使用ingress，只需要配置好ingress，当服务启动时，会自动注册到ingress当中，不需要额外的操作 减少不必要的Port暴露：\n我们知道部署k8s时，是需要关闭防火墙的，主要原因是k8s的很多服务会以nodeport方式映射出去，这样对于宿主机来说是非常的不安全的，而ingress可以避免这个问题，只需要将ingress自身服务映射出去，就可代理后端所有的服务，则后端服务不需要映射出去  部署Ingress-nginx 一、部署ingress-nginx前准备 创建namespace 1 2  sudo vim ns.yaml sudo kubectl apply -f ns.yaml   ns.yaml:\n1 2 3 4  apiVersion:v1kind:Namespacemetadata:name:ingress-test  查看：\n1 2 3 4 5 6 7  ubuntu@k3s:~/ingress_nginx$ sudo kubectl get ns NAME STATUS AGE kube-system Active 10d kube-public Active 10d kube-node-lease Active 10d default Active 10d ingress-test Active 13m \u0026lt;\u0026lt;\u0026lt;   创建nginx的deployment及service资源 1 2  sudo vim nginx.yaml sudo kubectl apply -f nginx.yaml   nginx.yaml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  apiVersion:apps/v1kind:Deploymentmetadata:name:nginxnamespace:ingress-testspec:selector:matchLabels:app:nginxreplicas:3template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.25ports:- containerPort:80---apiVersion:v1kind:Servicemetadata:name:nginx-svcnamespace:ingress-testspec:type:NodePortselector:app:nginxports:- protocol:TCPport:80targetPort:80nodePort:32133  查看：\n1 2 3 4 5 6 7 8 9 10  ubuntu@k3s:~/ingress_nginx$ sudo kubectl get svc -n ingress-test NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-svc NodePort 10.43.71.238 \u0026lt;none\u0026gt; 80:32133/TCP 18m # 查看 ubuntu@k3s:~/ingress_nginx$ curl 10.43.71.238 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; ...   测试外部通过nodeport方式能否访问到集群内部应用：\n1 2 3 4 5 6 7 8  multipass list Name State IPv4 Image primary Stopped -- Ubuntu 24.04 LTS k3s Running 192.168.74.2 Ubuntu 24.04 LTS 10.42.0.0 10.42.0.1 worker1 Stopped -- Ubuntu 24.04 LTS worker2 Stopped -- Ubuntu 24.04 LTS   访问 http://192.168.74.2:32133/ 成功显示OK\n二、创建ingress-nginx 网页上完整的命令是直接执行该yaml文件，我们先不要执行，先将该yaml文件下载到本地主机上\n1  wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.10.1/deploy/static/provider/cloud/deploy.yaml   deploy.yaml(国内的镜像)： deploy.yaml(国内的镜像)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650  apiVersion:v1kind:Namespacemetadata:name:ingress-nginxlabels:app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginx---apiVersion:v1kind:ServiceAccountmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginxnamespace:ingress-nginxautomountServiceAccountToken:true---apiVersion:v1kind:ConfigMapmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginx-controllernamespace:ingress-nginxdata:---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmname:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- configmaps- endpoints- nodes- pods- secretsverbs:- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- nodesverbs:- get- apiGroups:- \u0026#34;\u0026#34;resources:- servicesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingressesverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- eventsverbs:- create- patch- apiGroups:- networking.k8s.ioresources:- ingresses/statusverbs:- update- apiGroups:- networking.k8s.ioresources:- ingressclassesverbs:- get- list- watch---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmname:ingress-nginxroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:ingress-nginxsubjects:- kind:ServiceAccountname:ingress-nginxnamespace:ingress-nginx---apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginxnamespace:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- namespacesverbs:- get- apiGroups:- \u0026#34;\u0026#34;resources:- configmaps- pods- secrets- endpointsverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- servicesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingressesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingresses/statusverbs:- update- apiGroups:- networking.k8s.ioresources:- ingressclassesverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- configmapsresourceNames:- ingress-controller-leaderverbs:- get- update- apiGroups:- \u0026#34;\u0026#34;resources:- configmapsverbs:- create- apiGroups:- \u0026#34;\u0026#34;resources:- eventsverbs:- create- patch---apiVersion:rbac.authorization.k8s.io/v1kind:RoleBindingmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginxnamespace:ingress-nginxroleRef:apiGroup:rbac.authorization.k8s.iokind:Rolename:ingress-nginxsubjects:- kind:ServiceAccountname:ingress-nginxnamespace:ingress-nginx---apiVersion:v1kind:Servicemetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginx-controller-admissionnamespace:ingress-nginxspec:type:ClusterIPports:- name:https-webhookport:443targetPort:webhookappProtocol:httpsselector:app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/component:controller---apiVersion:v1kind:Servicemetadata:annotations:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginx-controllernamespace:ingress-nginxspec:type:NodePortports:- name:httpport:80protocol:TCPtargetPort:httpappProtocol:http- name:httpsport:443protocol:TCPtargetPort:httpsappProtocol:httpsselector:app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/component:controller---apiVersion:apps/v1kind:Deploymentmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginx-controllernamespace:ingress-nginxspec:selector:matchLabels:app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/component:controllerrevisionHistoryLimit:10minReadySeconds:0template:metadata:labels:app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/component:controllerspec:dnsPolicy:ClusterFirstcontainers:- name:controllerimage:registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.0.0imagePullPolicy:IfNotPresentlifecycle:preStop:exec:command:- /wait-shutdownargs:- /nginx-ingress-controller- --election-id=ingress-controller-leader- --controller-class=k8s.io/ingress-nginx- --configmap=$(POD_NAMESPACE)/ingress-nginx-controller- --validating-webhook=:8443- --validating-webhook-certificate=/usr/local/certificates/cert- --validating-webhook-key=/usr/local/certificates/keysecurityContext:capabilities:drop:- ALLadd:- NET_BIND_SERVICErunAsUser:101allowPrivilegeEscalation:trueenv:- name:POD_NAMEvalueFrom:fieldRef:fieldPath:metadata.name- name:POD_NAMESPACEvalueFrom:fieldRef:fieldPath:metadata.namespace- name:LD_PRELOADvalue:/usr/local/lib/libmimalloc.solivenessProbe:failureThreshold:5httpGet:path:/healthzport:10254scheme:HTTPinitialDelaySeconds:10periodSeconds:10successThreshold:1timeoutSeconds:1readinessProbe:failureThreshold:3httpGet:path:/healthzport:10254scheme:HTTPinitialDelaySeconds:10periodSeconds:10successThreshold:1timeoutSeconds:1ports:- name:httpcontainerPort:80protocol:TCP- name:httpscontainerPort:443protocol:TCP- name:webhookcontainerPort:8443protocol:TCPvolumeMounts:- name:webhook-certmountPath:/usr/local/certificates/readOnly:trueresources:requests:cpu:100mmemory:90MinodeSelector:kubernetes.io/os:linuxserviceAccountName:ingress-nginxterminationGracePeriodSeconds:300volumes:- name:webhook-certsecret:secretName:ingress-nginx-admission---apiVersion:networking.k8s.io/v1kind:IngressClassmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:nginxnamespace:ingress-nginxspec:controller:k8s.io/ingress-nginx---apiVersion:admissionregistration.k8s.io/v1kind:ValidatingWebhookConfigurationmetadata:labels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookname:ingress-nginx-admissionwebhooks:- name:validate.nginx.ingress.kubernetes.iomatchPolicy:Equivalentrules:- apiGroups:- networking.k8s.ioapiVersions:- v1operations:- CREATE- UPDATEresources:- ingressesfailurePolicy:FailsideEffects:NoneadmissionReviewVersions:- v1clientConfig:service:namespace:ingress-nginxname:ingress-nginx-controller-admissionpath:/networking/v1/ingresses---apiVersion:v1kind:ServiceAccountmetadata:name:ingress-nginx-admissionnamespace:ingress-nginxannotations:helm.sh/hook:pre-install,pre-upgrade,post-install,post-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhook---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:name:ingress-nginx-admissionannotations:helm.sh/hook:pre-install,pre-upgrade,post-install,post-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookrules:- apiGroups:- admissionregistration.k8s.ioresources:- validatingwebhookconfigurationsverbs:- get- update---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:ingress-nginx-admissionannotations:helm.sh/hook:pre-install,pre-upgrade,post-install,post-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:ingress-nginx-admissionsubjects:- kind:ServiceAccountname:ingress-nginx-admissionnamespace:ingress-nginx---apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:name:ingress-nginx-admissionnamespace:ingress-nginxannotations:helm.sh/hook:pre-install,pre-upgrade,post-install,post-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookrules:- apiGroups:- \u0026#34;\u0026#34;resources:- secretsverbs:- get- create---apiVersion:rbac.authorization.k8s.io/v1kind:RoleBindingmetadata:name:ingress-nginx-admissionnamespace:ingress-nginxannotations:helm.sh/hook:pre-install,pre-upgrade,post-install,post-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookroleRef:apiGroup:rbac.authorization.k8s.iokind:Rolename:ingress-nginx-admissionsubjects:- kind:ServiceAccountname:ingress-nginx-admissionnamespace:ingress-nginx---apiVersion:batch/v1kind:Jobmetadata:name:ingress-nginx-admission-createnamespace:ingress-nginxannotations:helm.sh/hook:pre-install,pre-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookspec:template:metadata:name:ingress-nginx-admission-createlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookspec:containers:- name:createimage:registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.0imagePullPolicy:IfNotPresentargs:- create- --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc- --namespace=$(POD_NAMESPACE)- --secret-name=ingress-nginx-admissionenv:- name:POD_NAMESPACEvalueFrom:fieldRef:fieldPath:metadata.namespacerestartPolicy:OnFailureserviceAccountName:ingress-nginx-admissionnodeSelector:kubernetes.io/os:linuxsecurityContext:runAsNonRoot:truerunAsUser:2000---apiVersion:batch/v1kind:Jobmetadata:name:ingress-nginx-admission-patchnamespace:ingress-nginxannotations:helm.sh/hook:post-install,post-upgradehelm.sh/hook-delete-policy:before-hook-creation,hook-succeededlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookspec:template:metadata:name:ingress-nginx-admission-patchlabels:helm.sh/chart:ingress-nginx-4.0.1app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:1.0.0app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:admission-webhookspec:containers:- name:patchimage:registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.0imagePullPolicy:IfNotPresentargs:- patch- --webhook-name=ingress-nginx-admission- --namespace=$(POD_NAMESPACE)- --patch-mutating=false- --secret-name=ingress-nginx-admission- --patch-failure-policy=Failenv:- name:POD_NAMESPACEvalueFrom:fieldRef:fieldPath:metadata.namespacerestartPolicy:OnFailureserviceAccountName:ingress-nginx-admissionnodeSelector:kubernetes.io/os:linuxsecurityContext:runAsNonRoot:truerunAsUser:2000  deploy.yaml(国外镜像)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662  apiVersion:v1kind:Namespacemetadata:labels:app.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxname:ingress-nginx---apiVersion:v1automountServiceAccountToken:truekind:ServiceAccountmetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginxnamespace:ingress-nginx---apiVersion:v1kind:ServiceAccountmetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admissionnamespace:ingress-nginx---apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginxnamespace:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- namespacesverbs:- get- apiGroups:- \u0026#34;\u0026#34;resources:- configmaps- pods- secrets- endpointsverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- servicesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingressesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingresses/statusverbs:- update- apiGroups:- networking.k8s.ioresources:- ingressclassesverbs:- get- list- watch- apiGroups:- coordination.k8s.ioresourceNames:- ingress-nginx-leaderresources:- leasesverbs:- get- update- apiGroups:- coordination.k8s.ioresources:- leasesverbs:- create- apiGroups:- \u0026#34;\u0026#34;resources:- eventsverbs:- create- patch- apiGroups:- discovery.k8s.ioresources:- endpointslicesverbs:- list- watch- get---apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admissionnamespace:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- secretsverbs:- get- create---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:labels:app.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- configmaps- endpoints- nodes- pods- secrets- namespacesverbs:- list- watch- apiGroups:- coordination.k8s.ioresources:- leasesverbs:- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- nodesverbs:- get- apiGroups:- \u0026#34;\u0026#34;resources:- servicesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingressesverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- eventsverbs:- create- patch- apiGroups:- networking.k8s.ioresources:- ingresses/statusverbs:- update- apiGroups:- networking.k8s.ioresources:- ingressclassesverbs:- get- list- watch- apiGroups:- discovery.k8s.ioresources:- endpointslicesverbs:- list- watch- get---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admissionrules:- apiGroups:- admissionregistration.k8s.ioresources:- validatingwebhookconfigurationsverbs:- get- update---apiVersion:rbac.authorization.k8s.io/v1kind:RoleBindingmetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginxnamespace:ingress-nginxroleRef:apiGroup:rbac.authorization.k8s.iokind:Rolename:ingress-nginxsubjects:- kind:ServiceAccountname:ingress-nginxnamespace:ingress-nginx---apiVersion:rbac.authorization.k8s.io/v1kind:RoleBindingmetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admissionnamespace:ingress-nginxroleRef:apiGroup:rbac.authorization.k8s.iokind:Rolename:ingress-nginx-admissionsubjects:- kind:ServiceAccountname:ingress-nginx-admissionnamespace:ingress-nginx---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:labels:app.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginxroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:ingress-nginxsubjects:- kind:ServiceAccountname:ingress-nginxnamespace:ingress-nginx---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admissionroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:ingress-nginx-admissionsubjects:- kind:ServiceAccountname:ingress-nginx-admissionnamespace:ingress-nginx---apiVersion:v1data:allow-snippet-annotations:\u0026#34;false\u0026#34;kind:ConfigMapmetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-controllernamespace:ingress-nginx---apiVersion:v1kind:Servicemetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-controllernamespace:ingress-nginxspec:externalTrafficPolicy:LocalipFamilies:- IPv4ipFamilyPolicy:SingleStackports:- appProtocol:httpname:httpport:80protocol:TCPtargetPort:http- appProtocol:httpsname:httpsport:443protocol:TCPtargetPort:httpsselector:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxtype:LoadBalancer---apiVersion:v1kind:Servicemetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-controller-admissionnamespace:ingress-nginxspec:ports:- appProtocol:httpsname:https-webhookport:443targetPort:webhookselector:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxtype:ClusterIP---apiVersion:apps/v1kind:Deploymentmetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-controllernamespace:ingress-nginxspec:minReadySeconds:0revisionHistoryLimit:10selector:matchLabels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxstrategy:rollingUpdate:maxUnavailable:1type:RollingUpdatetemplate:metadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1spec:containers:- args:- /nginx-ingress-controller- --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller- --election-id=ingress-nginx-leader- --controller-class=k8s.io/ingress-nginx- --ingress-class=nginx- --configmap=$(POD_NAMESPACE)/ingress-nginx-controller- --validating-webhook=:8443- --validating-webhook-certificate=/usr/local/certificates/cert- --validating-webhook-key=/usr/local/certificates/key- --enable-metrics=falseenv:- name:POD_NAMEvalueFrom:fieldRef:fieldPath:metadata.name- name:POD_NAMESPACEvalueFrom:fieldRef:fieldPath:metadata.namespace- name:LD_PRELOADvalue:/usr/local/lib/libmimalloc.soimage:registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29eimagePullPolicy:IfNotPresentlifecycle:preStop:exec:command:- /wait-shutdownlivenessProbe:failureThreshold:5httpGet:path:/healthzport:10254scheme:HTTPinitialDelaySeconds:10periodSeconds:10successThreshold:1timeoutSeconds:1name:controllerports:- containerPort:80name:httpprotocol:TCP- containerPort:443name:httpsprotocol:TCP- containerPort:8443name:webhookprotocol:TCPreadinessProbe:failureThreshold:3httpGet:path:/healthzport:10254scheme:HTTPinitialDelaySeconds:10periodSeconds:10successThreshold:1timeoutSeconds:1resources:requests:cpu:100mmemory:90MisecurityContext:allowPrivilegeEscalation:falsecapabilities:add:- NET_BIND_SERVICEdrop:- ALLreadOnlyRootFilesystem:falserunAsNonRoot:truerunAsUser:101seccompProfile:type:RuntimeDefaultvolumeMounts:- mountPath:/usr/local/certificates/name:webhook-certreadOnly:truednsPolicy:ClusterFirstnodeSelector:kubernetes.io/os:linuxserviceAccountName:ingress-nginxterminationGracePeriodSeconds:300volumes:- name:webhook-certsecret:secretName:ingress-nginx-admission---apiVersion:batch/v1kind:Jobmetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admission-createnamespace:ingress-nginxspec:template:metadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admission-createspec:containers:- args:- create- --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc- --namespace=$(POD_NAMESPACE)- --secret-name=ingress-nginx-admissionenv:- name:POD_NAMESPACEvalueFrom:fieldRef:fieldPath:metadata.namespaceimage:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366imagePullPolicy:IfNotPresentname:createsecurityContext:allowPrivilegeEscalation:falsecapabilities:drop:- ALLreadOnlyRootFilesystem:truerunAsNonRoot:truerunAsUser:65532seccompProfile:type:RuntimeDefaultnodeSelector:kubernetes.io/os:linuxrestartPolicy:OnFailureserviceAccountName:ingress-nginx-admission---apiVersion:batch/v1kind:Jobmetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admission-patchnamespace:ingress-nginxspec:template:metadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admission-patchspec:containers:- args:- patch- --webhook-name=ingress-nginx-admission- --namespace=$(POD_NAMESPACE)- --patch-mutating=false- --secret-name=ingress-nginx-admission- --patch-failure-policy=Failenv:- name:POD_NAMESPACEvalueFrom:fieldRef:fieldPath:metadata.namespaceimage:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366imagePullPolicy:IfNotPresentname:patchsecurityContext:allowPrivilegeEscalation:falsecapabilities:drop:- ALLreadOnlyRootFilesystem:truerunAsNonRoot:truerunAsUser:65532seccompProfile:type:RuntimeDefaultnodeSelector:kubernetes.io/os:linuxrestartPolicy:OnFailureserviceAccountName:ingress-nginx-admission---apiVersion:networking.k8s.io/v1kind:IngressClassmetadata:labels:app.kubernetes.io/component:controllerapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:nginxspec:controller:k8s.io/ingress-nginx---apiVersion:admissionregistration.k8s.io/v1kind:ValidatingWebhookConfigurationmetadata:labels:app.kubernetes.io/component:admission-webhookapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/name:ingress-nginxapp.kubernetes.io/part-of:ingress-nginxapp.kubernetes.io/version:1.10.1name:ingress-nginx-admissionwebhooks:- admissionReviewVersions:- v1clientConfig:service:name:ingress-nginx-controller-admissionnamespace:ingress-nginxpath:/networking/v1/ingressesfailurePolicy:FailmatchPolicy:Equivalentname:validate.nginx.ingress.kubernetes.iorules:- apiGroups:- networking.k8s.ioapiVersions:- v1operations:- CREATE- UPDATEresources:- ingressessideEffects:None   PS : 镜像拉取地址：\n1 2 3 4 5 6 7  ...nodeSelector:kubernetes.io/os:linuxcontainers:- name:nginx-ingress-controllerimage:quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.28.0 \u0026lt;\u0026lt;\u0026lt;(国外镜像地址)...  国内镜像可以使用：\n1  docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.28.0   导入镜像包-将nginx-ingress-controller.0.28.0镜像包导入集群中的各个节点\ndocker save -o nginx-xxx.tar nginx-ingress:latest\ndocker load -i nginx.tar\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  sudo vim deploy.yaml ubuntu@k3s:~/ingress_nginx$ sudo kubectl apply -f deploy.yaml namespace/ingress-nginx created serviceaccount/ingress-nginx created serviceaccount/ingress-nginx-admission created role.rbac.authorization.k8s.io/ingress-nginx created role.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrole.rbac.authorization.k8s.io/ingress-nginx created clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created rolebinding.rbac.authorization.k8s.io/ingress-nginx created rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created configmap/ingress-nginx-controller created service/ingress-nginx-controller created service/ingress-nginx-controller-admission created deployment.apps/ingress-nginx-controller created job.batch/ingress-nginx-admission-create created job.batch/ingress-nginx-admission-patch created ingressclass.networking.k8s.io/nginx created validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created   查看运行情况：\n1 2 3 4 5  ubuntu@k3s:~/ingress_nginx$ sudo kubectl get pod -n ingress-nginx -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES ingress-nginx-admission-create-pdwks 0/1 Completed 0 4m8s 10.42.0.175 k3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; ingress-nginx-admission-patch-rmp8g 0/1 Completed 1 4m8s 10.42.0.176 k3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; ingress-nginx-controller-57b7568757-kh42l 1/1 Running 0 4m8s 10.42.0.177 k3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;   ingress-rule.yaml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  apiVersion:networking.k8s.io/v1kind:Ingressmetadata:name:test-ingressnamespace:ingress-testannotations:nginx.ingress.kubernetes.io/rewrite-target:/spec:rules:- host:wangjinbao.netlify.apphttp:paths:- path:/pathType:Prefixbackend:service:name:nginx-svcport:number:80  1 2 3  sudo vim ingress-rule.yaml sudo kubectl apply -f ingress-rule.yaml   查看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ubuntu@k3s:~/ingress_nginx$ sudo kubectl get ingress -n ingress-test NAME CLASS HOSTS ADDRESS PORTS AGE test-ingress traefik wangjinbao.netlify.app 192.168.74.2 80 2m54s ubuntu@k3s:~/ingress_nginx$ sudo kubectl describe ingress -n ingress-test Name: test-ingress Labels: \u0026lt;none\u0026gt; Namespace: ingress-test Address: 192.168.74.2 Ingress Class: traefik Default backend: \u0026lt;default\u0026gt; Rules: Host Path Backends ---- ---- -------- wangjinbao.netlify.app / nginx-svc:80 (10.42.0.171:80,10.42.0.172:80,10.42.0.173:80) Annotations: nginx.ingress.kubernetes.io/rewrite-target: / Events: \u0026lt;none\u0026gt;   进入ingress容器查看：\n1 2 3 4 5 6 7 8 9  ubuntu@k3s:~/ingress_nginx$ sudo kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-pdwks 0/1 Completed 0 46m ingress-nginx-admission-patch-rmp8g 0/1 Completed 1 46m ingress-nginx-controller-57b7568757-kh42l 1/1 Running 0 46m # 进入容器 ubuntu@k3s:~/ingress_nginx$ sudo kubectl exec -it -n ingress-nginx ingress-nginx-controller-57b7568757-kh42l -- /bin/sh /etc/nginx $ cat nginx.conf   把之前通过svc的NodePort暴露端口去掉：\n1 2 3 4  ubuntu@k3s:~/ingress_nginx$ sudo vim nginx.yaml ubuntu@k3s:~/ingress_nginx$ sudo kubectl apply -f nginx.yaml deployment.apps/nginx unchanged service/nginx-svc configured   去掉svc中的：\n1 2 3 4 5 6  ...spec:type:NodePort...ports:nodePort:32133  绑定hosts：\n192.168.74.2 wangjinbao.netlify.app\n浏览器访问：\nhttp://wangjinbao.netlify.app/\n","description":"k8s实践与总结(ingress)","id":10,"section":"stack","tags":["k8s"],"title":"k8s实践与总结-6(ingress)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s8/"},{"content":" PS: 查看所有npm全局变量\nnpm list -global\n 1 2 3  npm cache clean --force //清除npm缓存 npm init vue@latest 或 npm create vue@latest ✔ Project name: … vue3-project   package.json中修改：\n1  \u0026#34;dev\u0026#34;: \u0026#34;vite --host 172.19.0.13\u0026#34;   总结关键点：\n vite.config.js - 项目的配置文件 基于vite的配置 package.json - 项目包文件 核心依赖变成了 vue3.x 和 vite main.js - 入口文件 createApp 函数创建应用实例 app.vue - 根组件 SFC单文件组件 script-template-style   变化一：脚本script和模板template顺序调整 变化二：模板template不再要求唯一根元素 变化三：脚本script添加setup标识支持组合式API  index.html - 单页入口 提供id为app的挂载点   报错信息\nnpm install 时报错：code ERESOLVE\n解决方法：\n清除npm缓存 npm cache clean \u0026ndash;force\n reactive 和 ref 生成响应式对象\nreactive() //只能传入对象返回对象\nref()//传入字符或对象\n总结关键点：\n reactive和ref函数的共同作用是什么？\n答：生成响应对象数据 reactive vs ref ？\n答：\n1.reactive 不能处理简单类型的数据\n2.ref参数类型支持更好但是必须通过.value访问修改\n3.ref函数的内部实现依赖于reactive函数 在实际工作中推荐使用哪个？\n答：推荐使用ref函数，更加灵活  computed计算属性函数 和vue2的完全一致，只是修改了写法\n核心步骤：\n 导入computed函数 执行函数在回调参数中return基于响应式数据做计算的值，用变量接收  1 2 3 4 5 6 7 8 9  \u0026lt;script setup\u0026gt; //导入 import { VueElement } from \u0026#39;vue\u0026#39;; import {computed} from VueElement //执行函数 变量接收 在回调参数中return计算值 const computedState=computed(()=\u0026gt;{ return \u0026#39;基于响应式数据做计算后的值\u0026#39; }) \u0026lt;/script\u0026gt;   filter 过滤数组\nlist.value.filter((item) =\u0026gt; item \u0026gt; 2);\n1 2 3  const computedState = computed(() =\u0026gt; { return list.value.filter((item) =\u0026gt; item \u0026gt; 2); });   setTimeout setTimeout(()=\u0026gt;{},3000)\n1 2 3  setTimeout(() =\u0026gt; { list.value.push(9, 10); }, 2000);   watch函数 作用：侦听一个或多个数据的变化，数据变化时执行回调函数\n2个参数：1. immediate (立即执行) 2.deep（深度侦听）\n1 2 3  watch(count, (newValue, oldValue) =\u0026gt; { console.log(\u0026#34;count发生了变化\u0026#34;, oldValue, newValue); });   侦听多个数据\n1 2 3  watch([count, name], ([newCount, newName], [oldCount, oldName]) =\u0026gt; { console.log(\u0026#34;count或者name变化\u0026#34;, [newCount, newName], [oldCount, oldName]); });   ** watch 立即执行\nimmediate: true,\n1 2 3 4 5 6 7 8 9  watch( count, () =\u0026gt; { console.log(\u0026#34;立即变化\u0026#34;); }, { immediate: true, } );   ** watch 深度侦听 deep侦听所有\n1 2 3 4 5 6 7 8 9  watch( count, () =\u0026gt; { console.log(\u0026#34;深度侦听\u0026#34;); }, { deep: true, } );   ** 针对侦听\n1 2 3 4 5 6  watch( () =\u0026gt; state.value.age, () =\u0026gt; { console.log(\u0026#34;深度侦听\u0026#34;); } );   生命周期 基本使用\n 导入生命周期函数 执行生命周期函数 传入回调  PS:可多次顺序执行\n1 2 3 4 5 6  \u0026lt;script setup\u0026gt; import { onMounted } from \u0026#34;vue\u0026#34;; onMounted(() =\u0026gt; { //自定义逻辑 }); \u0026lt;/script\u0026gt;   父传子参数 基本思想：\n 父组件中给子组件绑定属性 子组件内部通过props选项接收  子组件中宏函数：defineProps()\n1 2 3  defineProps({ message:String })   子传父参数 基本思想：\n 父组件中给子组件标签通过@绑定事件 子组件内部通过$emit方法触发事件  子组件中宏函数：defineEmits()\n1  defineEmits([\u0026#39;get-message\u0026#39;])   总结关键点：\n 父传子的过程中通过什么方式接收props？\ndefineProps({属性名：类型}) setup语法糖中如何使用父组件传过来的数据？\nconst props = defineProps({属性名：类型}) 子传父的过程中通过什么方式得到emit方法？\ndefineEmits([\u0026lsquo;事件名称\u0026rsquo;])  模板引用 通过 ref标识 获取真实的 dom对象或者组件实例对象\n基本思想：\n 调用ref函数生成一个ref对象(空对象ref(null)) const h1Ref=ref(null) 通过ref标识绑定ref对象到标签 \u0026lt;h1 ref=\u0026quot;\u0026quot;h1Ref\u0026quot;\u0026gt;我是dom标签h1\u0026lt;/h1\u0026gt;  PS:注意：组件挂载完成之后才能获取\n1 2 3  onMounted(()=\u0026gt;{ console.log(h1Ref.value) })   暴露宏函数defineExpose() 默认在\u0026lt;script setup\u0026gt;语法糖下组件内部的属性和方法是不开放给父组件访问的，可以通过 defineExpose() 宏函数指定哪些属性和方法允许访问\n1 2 3 4  const testMessage = ref(\u0026#39;this is test msg\u0026#39;) defineExpose({ testMessage })   总结关键点：\n 获取模板引用的时机是什么？\n组件挂载完毕 defineExpose 宏函数的作用是什么？\n显式暴露组件内部的属性和方法  组件通信 顶层组件向任意组件的底层组件传递数据和方法，实现跨层组件通信\n核心思想：\n 顶层组件通过 provide 函数提供数据  1  provide(\u0026#39;key\u0026#39;,顶层组件中的数据)   底层组件通过 inject 函数获取数据  1  const message = inject(\u0026#39;key\u0026#39;)   响应式数据：\n顶层组件中的数据 \u0026ndash;\u0026gt; ref()变量\nPS:跨层传递方法：和传递数据一样,(原则誰的数据谁负责修改)\n总结关键点：\n provide和inject的作用？\n跨层组件通信 如何在传递的过程中保持数据响应式？\n第二个参数传递ref对象 底层组件想要通知顶层组件做修改，如何做？\n传递方法，底层组件调用方法 一颗组件树中只有一个顶层或底层组件吗？\n相对概念，存在多个顶层和底层的关系  pinia 状态管理库\npinia的引入 main.js 使用方法：\n 导入 createPinia  1  import {createPinia} from \u0026#39;pinia\u0026#39;   执行方法得到实例  1  const pinia = createPinia()   把pinia实例加入到app应用中  1  createApp(App).use(pinia).mount(\u0026#39;#app\u0026#39;)   pinia的定义(state + action) 核心思想：\n 引入 defineStore  1  import {defineStore} from \u0026#39;pinia\u0026#39;   定义 defineStore别名实例的变量和方法,以对象形式返回\nexport : 表示 导出 的意思  1 2 3 4 5 6 7 8 9 10 11  export const useCounterStore = defineStore(\u0026#39;counter\u0026#39;,()=\u0026gt;{ //数据(state)  const count = ref(0) //修改数据的方法（action）  const increment = ()=\u0026gt;{ count.value++ } //以对象形式返回  return { count , increment } })   pinia的使用 核心思想：\n 导入 useCounterStore 方法  1  import { useCounterStore } from \u0026#39;@/stores/counter\u0026#39;   执行方法得到 useCounterStore对象  1 2  const useCounterStore = useCounterStore() //... useCounterStore.increment   getters pinia中的getters直接使用computed函数进行模拟\n1 2 3 4  //数据（state） const count = ref(0) //getter const doubleCount = computed(()=\u0026gt;count.value*2)   action 异步 核心思想：\n 定义变量 请求修改变量 挂载变量 使用变量  1 2 3 4 5  const list = ref([]) const getList = async ()=\u0026gt;{ const res = await axios.get(API_URL) list.value = res.data.data.channels }   storeToRefs 使用 storeToRefs 函数可以辅助保持数据 (state+getter) 的响应式解构\n场景：想使用解析赋值\n1 2  //响应式丢失 视图不更新 const { count , doubleCount } = counterStore   解决方法：\n1  const { count , doubleCount } = storeToRefs(counterStore)   PS:注意：storeToRefs 只修饰数据，不能修饰方便，方法还要从之前变量中解构赋值\n1 2 3 4  //数据 const { count , doubleCount } = storeToRefs(counterStore) //方法直接从原来的 counterStore 中解构赋值 const { increment } = counterStore   创建项目 1 2 3 4 5 6 7 8 9 10  npm init vue@latest ✔ Project name: … vue-rabbit ✔ Add Vue Router for Single Page Application development? … No / `Yes` ✔ Add Pinia for state management? … No / `Yes` ✔ Add ESLint for code quality? … No / `Yes` Done. Now run: cd vue-rabbit npm install npm run dev   PS:docker环境中增加外网访问：\n1 2 3 4  \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;vite --host 172.19.0.13\u0026#34;, ... }   添加几个文件夹 apis：API接口文件夹\ncomposables:组合函数文件夹\ndirectives:全局指令文件夹\nstyles:全局样式文件夹\nutils:工具函数文件夹\n配置联想提示  在根目录下新增 jsconfig.json文件 添加json格式的配置项目：如下：  1 2 3 4 5 6 7 8 9 10  { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;baseUrl\u0026#34;: \u0026#34;./\u0026#34;, \u0026#34;paths\u0026#34;: { \u0026#34;@/*\u0026#34;:[ \u0026#34;src/*\u0026#34; ] } } }   之后输入\u0026quot;@/\u0026ldquo;就会有提示当前目录了  安装element Plus  步骤一： npm install element-plus \u0026ndash;save  1 2 3 4  # 选择一个你喜欢的包管理器 # NPM $ npm install element-plus --save    步骤二：安装 unplugin-vue-components 和 unplugin-auto-import 这两款插件\n-D ： 代表只在开发环境安装  1  npm install -D unplugin-vue-components unplugin-auto-import    步骤三：修改 vite.config.js 按需导入  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //... //elementPlus 按需导入 import AutoImport from \u0026#39;unplugin-auto-import/vite\u0026#39; import Components from \u0026#39;unplugin-vue-components/vite\u0026#39; import { ElementPlusResolver } from \u0026#39;unplugin-vue-components/resolvers\u0026#39; //... plugins: [ //...  AutoImport({ resolvers: [ElementPlusResolver()], }), Components({ resolvers: [ElementPlusResolver()], }), ],    步骤四：验证element-plus  1  \u0026lt;el-button type=\u0026#34;primary\u0026#34;\u0026gt;Primary\u0026lt;/el-button\u0026gt;   主题定制 如何定制（scss变量替换方案）\n 安装scss\n==\u0026gt; npm i sass -D 准备定制样式文件\n==\u0026gt; styles/element/index.scss  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  //index.scss的内容如下： @forward \u0026#39;element-plus/theme-chalk/src/common/var.scss\u0026#39; with( $colors: ( \u0026#39;primary\u0026#39;:( //主色  \u0026#39;base\u0026#39;:#27ba9b, ), \u0026#39;success\u0026#39;:( //成功色  \u0026#39;base\u0026#39;:#1dc779, ), \u0026#39;warning\u0026#39;:( \u0026#39;base\u0026#39;:#ffb302, ), \u0026#39;danger\u0026#39;:( \u0026#39;base\u0026#39;:#e26237, ), \u0026#39;error\u0026#39;:( \u0026#39;base\u0026#39;:#cf4444, ) ) )   对elementPlus样式进行覆盖 ==\u0026gt; 通知 element 采用scss语言 -\u0026gt; 导入定制scss文件覆盖  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  //vite.config.js的内容如下： Components({ //1.配置elementPlus采用sass样式配色系统  resolvers: [ ElementPlusResolver({importStyle:\u0026#39;sass\u0026#39;}) ], } //... //vite样式自动导入及覆盖 css:{ preprocessorOptions:{ scss:{ //2.自动导入定制化样式文件进行样式覆盖  additionalData:` @use \u0026#34;@/styles/element/index.scss\u0026#34; as *; `, } } }   axios基本配置  安装axios  1  npm i axios   配置基础实例（统一接口配置）  1 2 3 4  1、接口基地址 2、接口超时时间 3、请求拦截器 4、响应拦截器    步骤一：添加http.js封装文件：\nsrc/utils/http.js  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  //axios基础的封装 import axios from \u0026#34;axios\u0026#34;; const httpInstance = axios.create({ baseURL: \u0026#39;http://pcapi-xiaotuxian-front-devtest.itheima.net\u0026#39;, timeout: 5000 }) //拦截器  //axios请求拦截器 httpInstance.interceptors.request.use(config =\u0026gt; { return config }, e =\u0026gt; Promise.rejecte) //axios响应式拦截器 httpInstance.interceptors.response.use(res =\u0026gt; res.data, e =\u0026gt; { return Promise.reject(e) }) export default httpInstance   步骤二：添加src/apis/testAPI.js文件  1 2 3 4 5 6 7  import httpInstance from \u0026#34;@/utils/http\u0026#34;; export function getCategory() { return httpInstance({ url: \u0026#39;home/category/head\u0026#39; }) }   步骤三：App.vue中添加请求  1 2 3 4  import { getCategory } from \u0026#34;@/apis/testAPI\u0026#34;; getCategory().then((res) =\u0026gt; { console.log(res); });   eslint使用  步骤一：下载 eslint包  1  npm i -D eslint   步骤二：初始化Eslint配置-\u0026gt;生成.eslintrc.js文件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  npx eslint --init 或者 \u0026#39;npm init @eslint/config\u0026#39; //回车如下： # npx eslint --init You can also run this command directly using \u0026#39;npm init @eslint/config\u0026#39;. ✔ How would you like to use ESLint? · problems ✔ What type of modules does your project use? · esm ✔ Which framework does your project use? · vue ✔ Does your project use TypeScript? · No / Yes ✔ Where does your code run? · browser, node ✔ What format do you want your config file to be in? · JavaScript The config that you\u0026#39;ve selected requires the following dependencies: @typescript-eslint/eslint-plugin@latest eslint-plugin-vue@latest @typescript-eslint/parser@latest ✔ Would you like to install them now? · No / Yes ✔ Which package manager do you want to use? · npm Installing @typescript-eslint/eslint-plugin@latest, eslint-plugin-vue@latest, @typescript-eslint/parser@latest   步骤三：若想配置 parser: \u0026lsquo;babel-eslint\u0026rsquo; 需要安装依赖如下：  1  npm install --save-dev babel-eslint   babel-eslint 解析器是一种使用频率很高的解析器，现在很多公司的很多项目目前都使用了es6，为了兼容性考虑基本都使用babel插件对代码进行编译。\n**PS: rules 一般是开发中关闭的一些报错规则 ，默认规则在 extends 中\nrules配置： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175  \u0026#34;no-alert\u0026#34;: 0,//禁止使用alert confirm prompt \u0026#34;no-array-constructor\u0026#34;: 2,//禁止使用数组构造器 \u0026#34;no-bitwise\u0026#34;: 0,//禁止使用按位运算符 \u0026#34;no-caller\u0026#34;: 1,//禁止使用arguments.caller或arguments.callee \u0026#34;no-catch-shadow\u0026#34;: 2,//禁止catch子句参数与外部作用域变量同名 \u0026#34;no-class-assign\u0026#34;: 2,//禁止给类赋值 \u0026#34;no-cond-assign\u0026#34;: 2,//禁止在条件表达式中使用赋值语句 \u0026#34;no-console\u0026#34;: 2,//禁止使用console \u0026#34;no-const-assign\u0026#34;: 2,//禁止修改const声明的变量 \u0026#34;no-constant-condition\u0026#34;: 2,//禁止在条件中使用常量表达式 if(true) if(1) \u0026#34;no-continue\u0026#34;: 0,//禁止使用continue \u0026#34;no-control-regex\u0026#34;: 2,//禁止在正则表达式中使用控制字符 \u0026#34;no-debugger\u0026#34;: 2,//禁止使用debugger \u0026#34;no-delete-var\u0026#34;: 2,//不能对var声明的变量使用delete操作符 \u0026#34;no-div-regex\u0026#34;: 1,//不能使用看起来像除法的正则表达式/=foo/ \u0026#34;no-dupe-keys\u0026#34;: 2,//在创建对象字面量时不允许键重复 {a:1,a:1} \u0026#34;no-dupe-args\u0026#34;: 2,//函数参数不能重复 \u0026#34;no-duplicate-case\u0026#34;: 2,//switch中的case标签不能重复 \u0026#34;no-else-return\u0026#34;: 2,//如果if语句里面有return,后面不能跟else语句 \u0026#34;no-empty\u0026#34;: 2,//块语句中的内容不能为空 \u0026#34;no-empty-character-class\u0026#34;: 2,//正则表达式中的[]内容不能为空 \u0026#34;no-empty-label\u0026#34;: 2,//禁止使用空label \u0026#34;no-eq-null\u0026#34;: 2,//禁止对null使用==或!=运算符 \u0026#34;no-eval\u0026#34;: 1,//禁止使用eval \u0026#34;no-ex-assign\u0026#34;: 2,//禁止给catch语句中的异常参数赋值 \u0026#34;no-extend-native\u0026#34;: 2,//禁止扩展native对象 \u0026#34;no-extra-bind\u0026#34;: 2,//禁止不必要的函数绑定 \u0026#34;no-extra-boolean-cast\u0026#34;: 2,//禁止不必要的bool转换 \u0026#34;no-extra-parens\u0026#34;: 2,//禁止非必要的括号 \u0026#34;no-extra-semi\u0026#34;: 2,//禁止多余的冒号 \u0026#34;no-fallthrough\u0026#34;: 1,//禁止switch穿透 \u0026#34;no-floating-decimal\u0026#34;: 2,//禁止省略浮点数中的0 .5 3. \u0026#34;no-func-assign\u0026#34;: 2,//禁止重复的函数声明 \u0026#34;no-implicit-coercion\u0026#34;: 1,//禁止隐式转换 \u0026#34;no-implied-eval\u0026#34;: 2,//禁止使用隐式eval \u0026#34;no-inline-comments\u0026#34;: 0,//禁止行内备注 \u0026#34;no-inner-declarations\u0026#34;: [2, \u0026#34;functions\u0026#34;],//禁止在块语句中使用声明（变量或函数） \u0026#34;no-invalid-regexp\u0026#34;: 2,//禁止无效的正则表达式 \u0026#34;no-invalid-this\u0026#34;: 2,//禁止无效的this，只能用在构造器，类，对象字面量 \u0026#34;no-irregular-whitespace\u0026#34;: 2,//不能有不规则的空格 \u0026#34;no-iterator\u0026#34;: 2,//禁止使用__iterator__ 属性 \u0026#34;no-label-var\u0026#34;: 2,//label名不能与var声明的变量名相同 \u0026#34;no-labels\u0026#34;: 2,//禁止标签声明 \u0026#34;no-lone-blocks\u0026#34;: 2,//禁止不必要的嵌套块 \u0026#34;no-lonely-if\u0026#34;: 2,//禁止else语句内只有if语句 \u0026#34;no-loop-func\u0026#34;: 1,//禁止在循环中使用函数（如果没有引用外部变量不形成闭包就可以） \u0026#34;no-mixed-requires\u0026#34;: [0, false],//声明时不能混用声明类型 \u0026#34;no-mixed-spaces-and-tabs\u0026#34;: [2, false],//禁止混用tab和空格 \u0026#34;linebreak-style\u0026#34;: [0, \u0026#34;windows\u0026#34;],//换行风格 \u0026#34;no-multi-spaces\u0026#34;: 0,//不能用多余的空格 \u0026#34;no-multi-str\u0026#34;: 2,//字符串不能用\\换行 \u0026#34;no-multiple-empty-lines\u0026#34;: [1, {\u0026#34;max\u0026#34;: 3}],//空行最多不能超过2行 \u0026#34;no-native-reassign\u0026#34;: 2,//不能重写native对象 \u0026#34;no-negated-in-lhs\u0026#34;: 2,//in 操作符的左边不能有! \u0026#34;no-nested-ternary\u0026#34;: 0,//禁止使用嵌套的三目运算 \u0026#34;no-new\u0026#34;: 1,//禁止在使用new构造一个实例后不赋值 \u0026#34;no-new-func\u0026#34;: 1,//禁止使用new Function \u0026#34;no-new-object\u0026#34;: 2,//禁止使用new Object() \u0026#34;no-new-require\u0026#34;: 2,//禁止使用new require \u0026#34;no-new-wrappers\u0026#34;: 2,//禁止使用new创建包装实例，new String new Boolean new Number \u0026#34;no-obj-calls\u0026#34;: 2,//不能调用内置的全局对象，比如Math() JSON() \u0026#34;no-octal\u0026#34;: 2,//禁止使用八进制数字 \u0026#34;no-octal-escape\u0026#34;: 2,//禁止使用八进制转义序列 \u0026#34;no-param-reassign\u0026#34;: 2,//禁止给参数重新赋值 \u0026#34;no-path-concat\u0026#34;: 0,//node中不能使用__dirname或__filename做路径拼接 \u0026#34;no-plusplus\u0026#34;: 0,//禁止使用++，-- \u0026#34;no-process-env\u0026#34;: 0,//禁止使用process.env \u0026#34;no-process-exit\u0026#34;: 0,//禁止使用process.exit() \u0026#34;no-proto\u0026#34;: 2,//禁止使用__proto__属性 \u0026#34;no-redeclare\u0026#34;: 2,//禁止重复声明变量 \u0026#34;no-regex-spaces\u0026#34;: 2,//禁止在正则表达式字面量中使用多个空格 /foo bar/ \u0026#34;no-restricted-modules\u0026#34;: 0,//如果禁用了指定模块，使用就会报错 \u0026#34;no-return-assign\u0026#34;: 1,//return 语句中不能有赋值表达式 \u0026#34;no-script-url\u0026#34;: 0,//禁止使用javascript:void(0) \u0026#34;no-self-compare\u0026#34;: 2,//不能比较自身 \u0026#34;no-sequences\u0026#34;: 0,//禁止使用逗号运算符 \u0026#34;no-shadow\u0026#34;: 2,//外部作用域中的变量不能与它所包含的作用域中的变量或参数同名 \u0026#34;no-shadow-restricted-names\u0026#34;: 2,//严格模式中规定的限制标识符不能作为声明时的变量名使用 \u0026#34;no-spaced-func\u0026#34;: 2,//函数调用时 函数名与()之间不能有空格 \u0026#34;no-sparse-arrays\u0026#34;: 2,//禁止稀疏数组， [1,,2] \u0026#34;no-sync\u0026#34;: 0,//nodejs 禁止同步方法 \u0026#34;no-ternary\u0026#34;: 0,//禁止使用三目运算符 \u0026#34;no-trailing-spaces\u0026#34;: 1,//一行结束后面不要有空格 \u0026#34;no-this-before-super\u0026#34;: 0,//在调用super()之前不能使用this或super \u0026#34;no-throw-literal\u0026#34;: 2,//禁止抛出字面量错误 throw \u0026#34;error\u0026#34;; \u0026#34;no-undef\u0026#34;: 2,//不能有未定义的变量 \u0026#34;no-undef-init\u0026#34;: 2,//变量初始化时不能直接给它赋值为undefined \u0026#34;no-undefined\u0026#34;: 2,//不能使用undefined \u0026#34;no-unexpected-multiline\u0026#34;: 2,//避免多行表达式 \u0026#34;no-underscore-dangle\u0026#34;: 1,//标识符不能以_开头或结尾 \u0026#34;no-unneeded-ternary\u0026#34;: 2,//禁止不必要的嵌套 var isYes = answer === 1 ? true : false; \u0026#34;no-unreachable\u0026#34;: 2,//不能有无法执行的代码 \u0026#34;no-unused-expressions\u0026#34;: 2,//禁止无用的表达式 \u0026#34;no-unused-vars\u0026#34;: [2, {\u0026#34;vars\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;args\u0026#34;: \u0026#34;after-used\u0026#34;}],//不能有声明后未被使用的变量或参数 \u0026#34;no-use-before-define\u0026#34;: 2,//未定义前不能使用 \u0026#34;no-useless-call\u0026#34;: 2,//禁止不必要的call和apply \u0026#34;no-void\u0026#34;: 2,//禁用void操作符 \u0026#34;no-var\u0026#34;: 0,//禁用var，用let和const代替 \u0026#34;no-warning-comments\u0026#34;: [1, { \u0026#34;terms\u0026#34;: [\u0026#34;todo\u0026#34;, \u0026#34;fixme\u0026#34;, \u0026#34;xxx\u0026#34;], \u0026#34;location\u0026#34;: \u0026#34;start\u0026#34; }],//不能有警告备注 \u0026#34;no-with\u0026#34;: 2,//禁用with  \u0026#34;array-bracket-spacing\u0026#34;: [2, \u0026#34;never\u0026#34;],//是否允许非空数组里面有多余的空格 \u0026#34;arrow-parens\u0026#34;: 0,//箭头函数用小括号括起来 \u0026#34;arrow-spacing\u0026#34;: 0,//=\u0026gt;的前/后括号 \u0026#34;accessor-pairs\u0026#34;: 0,//在对象中使用getter/setter \u0026#34;block-scoped-var\u0026#34;: 0,//块语句中使用var \u0026#34;brace-style\u0026#34;: [1, \u0026#34;1tbs\u0026#34;],//大括号风格 \u0026#34;callback-return\u0026#34;: 1,//避免多次调用回调什么的 \u0026#34;camelcase\u0026#34;: 2,//强制驼峰法命名 \u0026#34;comma-dangle\u0026#34;: [2, \u0026#34;never\u0026#34;],//对象字面量项尾不能有逗号 \u0026#34;comma-spacing\u0026#34;: 0,//逗号前后的空格 \u0026#34;comma-style\u0026#34;: [2, \u0026#34;last\u0026#34;],//逗号风格，换行时在行首还是行尾 \u0026#34;complexity\u0026#34;: [0, 11],//循环复杂度 \u0026#34;computed-property-spacing\u0026#34;: [0, \u0026#34;never\u0026#34;],//是否允许计算后的键名什么的 \u0026#34;consistent-return\u0026#34;: 0,//return 后面是否允许省略 \u0026#34;consistent-this\u0026#34;: [2, \u0026#34;that\u0026#34;],//this别名 \u0026#34;constructor-super\u0026#34;: 0,//非派生类不能调用super，派生类必须调用super \u0026#34;curly\u0026#34;: [2, \u0026#34;all\u0026#34;],//必须使用 if(){} 中的{} \u0026#34;default-case\u0026#34;: 2,//switch语句最后必须有default \u0026#34;dot-location\u0026#34;: 0,//对象访问符的位置，换行的时候在行首还是行尾 \u0026#34;dot-notation\u0026#34;: [0, { \u0026#34;allowKeywords\u0026#34;: true }],//避免不必要的方括号 \u0026#34;eol-last\u0026#34;: 0,//文件以单一的换行符结束 \u0026#34;eqeqeq\u0026#34;: 0,//必须使用全等 \u0026#34;func-names\u0026#34;: 0,//函数表达式必须有名字 \u0026#34;func-style\u0026#34;: [0, \u0026#34;declaration\u0026#34;],//函数风格，规定只能使用函数声明/函数表达式 \u0026#34;generator-star-spacing\u0026#34;: 0,//生成器函数*的前后空格 \u0026#34;guard-for-in\u0026#34;: 0,//for in循环要用if语句过滤 \u0026#34;handle-callback-err\u0026#34;: 0,//nodejs 处理错误 \u0026#34;id-length\u0026#34;: 0,//变量名长度 \u0026#34;indent\u0026#34;: [2, 2],//缩进风格 \u0026#34;init-declarations\u0026#34;: 0,//声明时必须赋初值 \u0026#34;key-spacing\u0026#34;: [0, { \u0026#34;beforeColon\u0026#34;: false, \u0026#34;afterColon\u0026#34;: true }],//对象字面量中冒号的前后空格 \u0026#34;lines-around-comment\u0026#34;: 0,//行前/行后备注 \u0026#34;max-depth\u0026#34;: [0, 4],//嵌套块深度 \u0026#34;max-len\u0026#34;: [0, 80, 4],//字符串最大长度 \u0026#34;max-nested-callbacks\u0026#34;: [0, 2],//回调嵌套深度 \u0026#34;max-params\u0026#34;: [0, 3],//函数最多只能有3个参数 \u0026#34;max-statements\u0026#34;: [0, 10],//函数内最多有几个声明 \u0026#34;new-cap\u0026#34;: 2,//函数名首行大写必须使用new方式调用，首行小写必须用不带new方式调用 \u0026#34;new-parens\u0026#34;: 2,//new时必须加小括号 \u0026#34;newline-after-var\u0026#34;: 2,//变量声明后是否需要空一行 \u0026#34;object-curly-spacing\u0026#34;: [0, \u0026#34;never\u0026#34;],//大括号内是否允许不必要的空格 \u0026#34;object-shorthand\u0026#34;: 0,//强制对象字面量缩写语法 \u0026#34;one-var\u0026#34;: 1,//连续声明 \u0026#34;operator-assignment\u0026#34;: [0, \u0026#34;always\u0026#34;],//赋值运算符 += -=什么的 \u0026#34;operator-linebreak\u0026#34;: [2, \u0026#34;after\u0026#34;],//换行时运算符在行尾还是行首 \u0026#34;padded-blocks\u0026#34;: 0,//块语句内行首行尾是否要空行 \u0026#34;prefer-const\u0026#34;: 0,//首选const \u0026#34;prefer-spread\u0026#34;: 0,//首选展开运算 \u0026#34;prefer-reflect\u0026#34;: 0,//首选Reflect的方法 \u0026#34;quotes\u0026#34;: [1, \u0026#34;single\u0026#34;],//引号类型 `` \u0026#34;\u0026#34; \u0026#39;\u0026#39; \u0026#34;quote-props\u0026#34;:[2, \u0026#34;always\u0026#34;],//对象字面量中的属性名是否强制双引号 \u0026#34;radix\u0026#34;: 2,//parseInt必须指定第二个参数 \u0026#34;id-match\u0026#34;: 0,//命名检测 \u0026#34;require-yield\u0026#34;: 0,//生成器函数必须有yield \u0026#34;semi\u0026#34;: [2, \u0026#34;always\u0026#34;],//语句强制分号结尾 \u0026#34;semi-spacing\u0026#34;: [0, {\u0026#34;before\u0026#34;: false, \u0026#34;after\u0026#34;: true}],//分号前后空格 \u0026#34;sort-vars\u0026#34;: 0,//变量声明时排序 \u0026#34;space-after-keywords\u0026#34;: [0, \u0026#34;always\u0026#34;],//关键字后面是否要空一格 \u0026#34;space-before-blocks\u0026#34;: [0, \u0026#34;always\u0026#34;],//不以新行开始的块{前面要不要有空格 \u0026#34;space-before-function-paren\u0026#34;: [0, \u0026#34;always\u0026#34;],//函数定义时括号前面要不要有空格 \u0026#34;space-in-parens\u0026#34;: [0, \u0026#34;never\u0026#34;],//小括号里面要不要有空格 \u0026#34;space-infix-ops\u0026#34;: 0,//中缀操作符周围要不要有空格 \u0026#34;space-return-throw-case\u0026#34;: 2,//return throw case后面要不要加空格 \u0026#34;space-unary-ops\u0026#34;: [0, { \u0026#34;words\u0026#34;: true, \u0026#34;nonwords\u0026#34;: false }],//一元运算符的前/后要不要加空格 \u0026#34;spaced-comment\u0026#34;: 0,//注释风格要不要有空格什么的 \u0026#34;strict\u0026#34;: 2,//使用严格模式 \u0026#34;use-isnan\u0026#34;: 2,//禁止比较时使用NaN，只能用isNaN() \u0026#34;valid-jsdoc\u0026#34;: 0,//jsdoc规则 \u0026#34;valid-typeof\u0026#34;: 2,//必须使用合法的typeof的值 \u0026#34;vars-on-top\u0026#34;: 2,//var必须放在作用域顶部 \u0026#34;wrap-iife\u0026#34;: [2, \u0026#34;inside\u0026#34;],//立即执行函数表达式的小括号风格 \u0026#34;wrap-regex\u0026#34;: 0,//正则表达式字面量用小括号包起来 \u0026#34;yoda\u0026#34;: [2, \u0026#34;never\u0026#34;]//禁止尤达条件    核心思想：\n 路由设计的依据是什么？\n答：内容切换的方式 默认二级路由如何进行设置？\n答：path配置项为空  scss自动导入  新建var.scss 文件\n目录：./styles/var.scss\n内容：  1 2 3 4 5 6  $xtxColor:#27ba9b; $helpColor:#e26237; $sucColor:#1dc779; $warnColor:#ffb302; $priceColor:#cf4444; ...   配置 vite.config.js 自动加载  1 2 3 4 5 6 7 8 9 10 11 12  //vite样式自动导入及覆盖  css:{ preprocessorOptions:{ scss:{ //2.自动导入定制化样式文件进行样式覆盖  additionalData:` @use \u0026#34;@/styles/element/index.scss\u0026#34; as *; @use \u0026#34;@/styles/var.scss\u0026#34; as *; `, } } }   使用 lang=\u0026ldquo;scss\u0026rdquo; 加载  1 2 3 4 5  \u0026lt;style scoped lang=\u0026#34;scss\u0026#34;\u0026gt; .test{ color:$priceColor } \u0026lt;/style\u0026gt;   Layout布局搭建  Nav区域  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;g-container\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;div\u0026gt;周杰伦\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;| 退出登录\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;| 我的订单\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;| 会员中心\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; .g-container { width: 100%; height: 45px; margin: 0 auto; line-height: 3; color: white; background-color: #4d4a4a; // position: relative;  overflow: hidden; div { float: right; display: flex; width: 400px; // padding-right: 100px;  div { justify-content: center; display: flex; width: 80px; } } \u0026amp; \u0026gt; div { // margin-bottom: 50px;  } } \u0026lt;/style\u0026gt;    Header区域  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  \u0026lt;script setup\u0026gt; import { useCategoryStore } from \u0026#34;@/stores/category\u0026#34;; const categoryStore = useCategoryStore(); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;h-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;d-logo\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;https://static.canva.cn/web/images/e1787d84651689b6f20de2ebd8d86baf.svg\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;d-nav\u0026#34; v-for=\u0026#34;item in categoryStore.categoryList\u0026#34; :key=\u0026#34;item.id\u0026#34; \u0026gt; {{ item.name }} \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;d-search\u0026#34;\u0026gt;搜索\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; .h-container { width: 100%; height: 130px; margin: 0 auto; line-height: 2; color: black; background-color: white; // position: relative; overflow: hidden; .d-logo { height: 130px; width: 300px; float: left; display: flex; margin-left: 200px; img { width: 100%; height: 100%; } } .d-nav { margin-left: 50px; height: 130px; float: left; display: flex; width: 50px; justify-content: center; align-items: center; } .d-search { margin-right: 200px; justify-content: center; align-items: center; height: 130px; float: right; display: flex; width: 100px; } } \u0026lt;/style\u0026gt;    二级路由出口区域  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  const router = createRouter({ history: createWebHistory(import.meta.env.BASE_URL), routes: [ { path: \u0026#39;/\u0026#39;, component: Layout, children: [ { path: \u0026#39;\u0026#39;, component: Home }, { path: \u0026#39;category\u0026#39;, component: Category } ] }, { path: \u0026#39;/login\u0026#39;, component: Login } ] })    Footer区域\n使用阿里的图标：\n地址：https://www.iconfont.cn/   帮助 -\u0026gt; 代码应用 -\u0026gt; font-class 引用 首页 -\u0026gt; 搜索 -\u0026gt; 要的图标 -\u0026gt; 添加购物车 index.html -\u0026gt; link -\u0026gt; iconfont  1 2 3 4  //index.html \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//at.alicdn.com/t/font_8d5l8fzk5b87iudi.css\u0026#34;\u0026gt; //vue \u0026lt;i class=\u0026#34;iconfont icon-weixin\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;   吸顶导航  关键样式  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; .hd-container { //关键样式：上平移自身高度+透明  transform: translateY(-100%); opacity: 0; position: fixed; z-index: 10; overflow: hidden; //移除平移+完全不透明  \u0026amp;.show { transition: all 0.3s linear; transform: none; opacity: 1; } } \u0026lt;/style\u0026gt;   插件@vueuse/core的useScroll  1 2 3  import { useScroll } from \u0026#34;@vueuse/core\u0026#34;; const { y } = useScroll(window);   绑定show类，判断y\u0026gt;130显示  1  \u0026lt;div class=\u0026#34;hd-container\u0026#34; :class=\u0026#34;{ show: y \u0026gt; 130 }\u0026#34;\u0026gt;   pinia重复请求优化  layout组件请求接口\n在apis/layout.js中：  1 2 3 4 5 6 7  import httpInstance from \u0026#34;@/utils/http\u0026#34;; export function getCategoryAPI() { return httpInstance({ url: \u0026#39;home/category/head\u0026#39; }) }   利用pinia的store存储和action\n在stores/category.js中：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import { ref } from \u0026#39;vue\u0026#39; import { defineStore } from \u0026#39;pinia\u0026#39; import { getCategoryAPI } from \u0026#39;@/apis/layout\u0026#39;; export const useCategoryStore = defineStore(\u0026#39;category\u0026#39;, () =\u0026gt; { //state  const categoryList = ref([]); //action  const getCategory = async () =\u0026gt; { const res = await getCategoryAPI(); categoryList.value = res.result; }; return { categoryList, getCategory } })   各模块组件的父类渲染\n在Layout/index.vue中：  1 2 3 4 5  import { useCategoryStore } from \u0026#34;@/stores/category\u0026#34;; import { onMounted } from \u0026#34;vue\u0026#34;; const categoryStore = useCategoryStore(); onMounted(() =\u0026gt; categoryStore.getCategory());   各模块组件中获取state\n在Layout/compoments/LayoutHeader.vue中  1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;script setup\u0026gt; import { useCategoryStore } from \u0026#34;@/stores/category\u0026#34;; const categoryStore = useCategoryStore(); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;d-nav\u0026#34; v-for=\u0026#34;item in categoryStore.categoryList\u0026#34; :key=\u0026#34;item.id\u0026#34; \u0026gt; {{ item.name }} \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt;   ElementPlus插件的使用  安装  1  npm install element-plus --save   加载\nmain.js中：  1 2 3 4 5 6  import ElementPlus from \u0026#39;element-plus\u0026#39; import \u0026#39;element-plus/dist/index.css\u0026#39; ... app.use(ElementPlus) app.mount(\u0026#39;#app\u0026#39;)   使用  1  \u0026lt;el-button\u0026gt;message\u0026lt;/el-button\u0026gt;   左导航+轮播图 element的 menu 菜单(el-menu) + Carousel 走马灯(el-carousel)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100  \u0026lt;script lang=\u0026#34;ts\u0026#34; setup\u0026gt; import { useCategoryStore } from \u0026#34;@/stores/category\u0026#34;; const categoryStore = useCategoryStore(); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;c-left\u0026#34;\u0026gt; \u0026lt;!-- 侧边导航 --\u0026gt; \u0026lt;el-col :span=\u0026#34;12\u0026#34; style=\u0026#34;position: absolute; top: 0px; z-index: 10; width: 300px\u0026#34; \u0026gt; \u0026lt;el-menu default-active=\u0026#34;2\u0026#34; class=\u0026#34;el-menu-vertical-demo\u0026#34; style=\u0026#34;background-color: black; opacity: 0.8\u0026#34; background-color=\u0026#34;rgb(21, 249, 195)\u0026#34; \u0026gt; \u0026lt;el-menu-item v-for=\u0026#34;i in categoryStore.categoryList\u0026#34; :key=\u0026#34;i\u0026#34;\u0026gt; \u0026lt;!-- \u0026lt;el-icon\u0026gt;\u0026lt;setting /\u0026gt;\u0026lt;/el-icon\u0026gt; --\u0026gt; \u0026lt;span class=\u0026#34;s-parent\u0026#34;\u0026gt;{{ i.name }} \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;s-children\u0026#34; v-for=\u0026#34;ic in i.children.slice(0, 2)\u0026#34;\u0026gt;{{ ic.name }}\u0026lt;/span\u0026gt; \u0026lt;/el-menu-item\u0026gt; \u0026lt;/el-menu\u0026gt; \u0026lt;/el-col\u0026gt; \u0026lt;!-- 轮播图 --\u0026gt; \u0026lt;div class=\u0026#34;block text-center\u0026#34;\u0026gt; \u0026lt;el-carousel height=\u0026#34;500px\u0026#34;\u0026gt; \u0026lt;el-carousel-item v-for=\u0026#34;item in 4\u0026#34; :key=\u0026#34;item\u0026#34; style=\u0026#34;position: absolute; top: 0px; z-index: 9\u0026#34; \u0026gt; \u0026lt;img src=\u0026#34;https://m.360buyimg.com/babel/jfs/t20260925/7569/37/22520/40263/65122aa8F7db4b1cc/4690718474f0e4b7.jpg\u0026#34; /\u0026gt; \u0026lt;/el-carousel-item\u0026gt; \u0026lt;/el-carousel\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; .c-left { z-index: 8; position: relative; width: 1480px; height: 500px; // background: #000; margin: auto; .el-menu-vertical-demo { border: 0; .s-parent { font-size: 20px; color: white; margin-left: 40px; } .s-children { color: white; font-size: 15px; margin-left: 10px; } } .block { img { width: 100%; height: 500px; } } .text-center { } h3 { } img { width: 100%; height: 500px; } } .demonstration { color: var(--el-text-color-secondary); } .el-carousel__item h3 { color: #475669; opacity: 0.75; line-height: 150px; margin: 0; text-align: center; } .el-carousel__item:nth-child(2n) { background-color: #99a9bf; } .el-carousel__item:nth-child(2n + 1) { background-color: #d3dce6; } \u0026lt;/style\u0026gt;   组件封装 组件参数：\n props 插槽  实现步骤  不做任何抽象，准备静态模板   定义属性 defineProps，占位模板 加入\u0026lt;slot / \u0026gt;  抽象可变的部分   主标题和副标题是纯文本，可以抽象成prop传入 主体内容是复杂的模版，抽象成插槽  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  \u0026lt;script setup\u0026gt; //定义props defineProps({ //主标题  title: { type: String, }, //副标题  subTitle: { type: String, }, }); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;panel-item\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;panel-head\u0026#34;\u0026gt; \u0026lt;!-- 主标题和副标题 --\u0026gt; \u0026lt;h3\u0026gt; {{ title }}\u0026lt;small\u0026gt;{{ subTitle }}\u0026lt;/small\u0026gt; \u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- 主体内容 --\u0026gt; \u0026lt;slot /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; //其它面板加载组件 \u0026lt;HomePanel title=\u0026#34;新鲜好物\u0026#34; sub-title=\u0026#34;新鲜好物 好多商品\u0026#34;\u0026gt; ...复杂的静态文件 \u0026lt;/HomePanel\u0026gt;   图片懒加载 实现步骤：\n 定义全局指令，并绑定图片\n在main.js中：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  //定义全局指令 app.directive(\u0026#39;img-lazy\u0026#39;, { mounted(el, binding) { //el : 指令绑定的那个元素  //binding: binding.value 指令等于号后面绑定的表达式的值 图片url  // console.log(el, binding.value)  useIntersectionObserver( el, ([{ isIntersecting }]) =\u0026gt; { if (isIntersecting) { //进入视口区域  el.src = binding.value } console.log(isIntersecting) }, ) } })   在图片组件中：\n1  \u0026lt;img v-img-lazy=\u0026#34;item.picture\u0026#34; /\u0026gt;   useIntersectionObserver 监听视口区\n判断isIntersecting=true  1 2 3 4  if (isIntersecting) { //进入视口区域  el.src = binding.value }   进入视口区域 图片src绑定\n监听对象的src=binding.value\n//el : 指令绑定的那个元素\n//binding: binding.value 指令等于号后面绑定的表达式的值 图片url  封装指定插件 实现步骤：\n directives/index.js中加插件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  //定义懒加载插件 import { useIntersectionObserver } from \u0026#39;@vueuse/core\u0026#39; export const lazyPlugin = { install(app) { //懒加载指令逻辑  //定义全局指令  app.directive(\u0026#39;img-lazy\u0026#39;, { mounted(el, binding) { //el : 指令绑定的那个元素  //binding: binding.value 指令等于号后面绑定的表达式的值 图片url  // console.log(el, binding.value)  const { stop } = useIntersectionObserver( el, ([{ isIntersecting }]) =\u0026gt; { if (isIntersecting) { //进入视口区域  el.src = binding.value stop() } // console.log(isIntersecting)  }, ) } }) } }   main.js中加载  1 2 3 4 5 6  // 引入懒加载指令插件并且注册 import { lazyPlugin } from \u0026#39;@/directives\u0026#39; app.use(lazyPlugin) app.mount(\u0026#39;#app\u0026#39;)   路由配置RouterLink :to=\u0026quot;\u0026quot; 中加 `` 符号，和变量${参数}\n1 2 3 4 5 6  \u0026lt;div class=\u0026#34;dd-nav\u0026#34;\u0026gt; \u0026lt;RouterLink to=\u0026#34;/\u0026#34; \u0026gt;首页\u0026lt;/RouterLink\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;RouterLink :to=\u0026#34;`/category/${item.id}`\u0026#34;\u0026gt;{{ item.name }}\u0026lt;/RouterLink\u0026gt;   获取url参数 useRoute 插件\n1 2 3  import { useRoute } from \u0026#34;vue-router\u0026#34;; //（params.id 来至 API请求接收的参数设置） route.params.id   激活元素显示 1 2 3 4 5 6  active-class=\u0026#34;active\u0026#34; .active { counter-reset: $xtxColor; border-bottom: 1px solid $xtxColor; }   路由缓存问题处理  方式一：添加key  1 2  \u0026lt;!-- 添加key 破坏复用机制 强制销毁重建--\u0026gt; \u0026lt;RouterView :key=\u0026#34;$route.fullPath\u0026#34; /\u0026gt;    方式二：onBeforeRouteUpdate  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;script setup\u0026gt; //默认id = route.params.id const getCategory = async (id = route.params.id) =\u0026gt; { const res = await getCategoryAPI(id); cateGoryData.value = res.result; }; onMounted(() =\u0026gt; getCategory()); //目录：路由参数变化的时候，可以把分类数据接口重新发送 onBeforeRouteUpdate((to) =\u0026gt; { console.log(\u0026#34;路由变化了\u0026#34;); //存在问题：使用最新的路由参数请求最新的分类数据  console.log(to); getCategory(to.params.id); }); \u0026lt;/script\u0026gt;   函数封闭，拆分业务，利于维护 基于逻辑函数拆分业务是把同一个组件中独立的业务代码通过函数做封装处理，提升代码的可维护性\n实现步骤：\n 把代码集中放于composables中并命名 方法中最后return对象结果 在模板中引用该引用  无限加载数据 实现步骤：\n 容器的div中添加v-infinite-scroll=\u0026ldquo;load\u0026rdquo;  1  \u0026lt;div class=\u0026#34;sub-body\u0026#34; v-infinite-scroll=\u0026#34;load\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;   为load添加方法获取数据  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;script\u0026gt; //加载更多 const disabled = ref(false); const load = async () =\u0026gt; { console.log(\u0026#34;加载更多数据\u0026#34;); //获取下一页数据  reqData.value.page++; const resNew = await getSubCategoryAPI(reqData.value); goodList.value = [...goodList.value, ...resNew.result.items]; //加载完毕 停止监听  if (res.result.items.length === 0) { disabled.value = true; } }; \u0026lt;/script\u0026gt;   拼接第二页的数据  1 2 3  \u0026lt;script\u0026gt; goodList.value = [...goodList.value, ...resNew.result.items] \u0026lt;/script\u0026gt;   路由切换滚动条置顶 在router/index.js中：\n1 2 3 4 5 6 7  routes:[ ... ], //路由滚动顶部  scrollBehavior() { return { top: 0 } }   渲染模板遇到对象的多层属性访问为空 good.details.pictures\nTypeError:Cannot read properties of undefined (reading 'properties')\n解决方法：\n 可选链 ?.  1 2  //？号前端有值，才继续运算 ${goods.categories?.[1].id}   v-if控制渲染  1 2 3  \u0026lt;div class=\u0026#34;container\u0026#34; v-if=\u0026#34;goods.details\u0026#34;\u0026gt; \u0026lt;/div\u0026gt;   tab类样式切换 绑定class，判断当前元素的id和激动状态activeInde是不是相等\n1 2  .active 是样式 :class=\u0026#34;{ active: i === activeIndex }\u0026#34;   扩大镜 注册全局组件  在目录components目录下新建文件index.js 内容如下：  1 2 3 4 5 6 7 8 9 10 11 12  //把components中的所有组件都进行全局化注册 //通过插件的方式 import ImageView from \u0026#39;./ImageView/index.vue\u0026#39; import Sku from \u0026#39;./XtxSku/index.vue\u0026#39; export const componentPlugin = { install(app) { // app.component(\u0026#39;组件名字\u0026#39;,组件配置对象)  app.component(\u0026#39;XtxImageView\u0026#39;, ImageView) app.component(\u0026#39;XtxSku\u0026#39;, Sku) } }   main.js 增加内容如下：  1 2 3 4 5  //引入全局组件插件 import { componentPlugin } from \u0026#39;@/components\u0026#39; app.use(componentPlugin) app.mount(\u0026#39;#app\u0026#39;)   之后就可以把一些引入加载的组件去掉之后直接使用XtxImageView 和 XtxSku  静态跳转 1  \u0026lt;a href=\u0026#34;javascript:;\u0026#34; @click=\u0026#34;$router.push(`/login`)\u0026#34;\u0026gt;请先登录\u0026lt;/a\u0026gt;   验证功能 el-form =\u0026gt; 绑定表单对象和规则对象\nel-form-item =\u0026gt; 绑定使用的规则字段\nel-input =\u0026gt; 双向绑定表单数据\n步骤：\n 准备表单对象  1 2 3 4  const form = ref({ account: \u0026#34;\u0026#34;, password: \u0026#34;\u0026#34;, });   准备规则对象  1 2 3 4 5 6 7  const rules = { account: [{ required: true, message: \u0026#34;用户名不能为空\u0026#34;, trigger: \u0026#34;blur\u0026#34; }], password: [ { required: true, message: \u0026#34;密码不能为空\u0026#34;, trigger: \u0026#34;blur\u0026#34; }, { min: 6, max: 14, message: \u0026#34;密码长度6-14\u0026#34;, trigger: \u0026#34;blur\u0026#34; }, ], };   指定表单域的检验字段名 双向绑定输入对象  1 2 3 4 5 6 7 8 9  \u0026lt;el-form :model=\u0026#34;form\u0026#34; :rules=\u0026#34;rules\u0026#34;\u0026gt; \u0026lt;el-form-item prop=\u0026#34;account\u0026#34; label=\u0026#34;账户\u0026#34;\u0026gt; \u0026lt;el-input v-model=\u0026#34;form.account\u0026#34; /\u0026gt; \u0026lt;/el-form-item\u0026gt; \u0026lt;el-form-item prop=\u0026#34;password\u0026#34; label=\u0026#34;密码\u0026#34;\u0026gt; \u0026lt;el-input v-model=\u0026#34;form.password\u0026#34; /\u0026gt; \u0026lt;/el-form-item\u0026gt; \u0026lt;el-button\u0026gt;点击登录\u0026lt;/el-button\u0026gt; \u0026lt;/el-form\u0026gt;   *** PS:vue处理复杂功能 ***\n思想：当功能很复杂时，通过 多个组件各自负责某个小功能，再组合成一个大功能是组件设计中的常用方法\n自定义验证规则 方法：\n1 2 3 4 5 6 7  { validator:(rule,val,callback) = \u0026gt;{ //自定义检验逻辑  //value：当前输入的数据  //callback:检验处理函数 校验通过调用  } }   添加内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  agree: [ { validator: (rule, value, callback) =\u0026gt; { console.log(value); //自定义梳校验逻辑  //勾选就通过 不勾选就不通过  if (value) { callback(); } else { callback(new Error(\u0026#34;请勾选协议\u0026#34;)); } }, }, ], . . . \u0026lt;el-form-item prop=\u0026#34;agree\u0026#34; label=\u0026#34;协议\u0026#34;\u0026gt; \u0026lt;el-input v-model=\u0026#34;form.agree\u0026#34; /\u0026gt; \u0026lt;/el-form-item\u0026gt;   整个表单的内容验证 对所有需要检验的表单进行统一梳校验\n1 2 3 4 5 6 7 8  formEl.validator((valid) =\u0026gt; { if (valid) { console.log(\u0026#34;submit\u0026#34;); } else { console.log(\u0026#34;error submit\u0026#34;); return false; } });   增加内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //获取form实例做统一校验 const formRef=ref(null) const doLogin=()=\u0026gt;{ //调用实例方法  formRef.value.validator(()=\u0026gt;{ //valid:所有表单都通过校验 才为true  console.log(valid) //以valid做为判断条件 如果通过校验才执行登录逻辑  if(valid){ //TODO LOGIN  } }) } //vue 获取实例 :ref=\u0026#34;\u0026#34; \u0026lt;el-form :ref=\u0026#34;formRef\u0026#34; :model=\u0026#34;form\u0026#34; :rules=\u0026#34;rules\u0026#34;\u0026gt;   vue获取实例：  先定义空变量\nconst formRef=ref(null) 再用:ref绑定空变量\n:ref=\u0026quot;formRef\u0026quot;  结构赋值 有三个变量，但现在只取2个\n1 2 3 4 5 6  const form = ref({ account: \u0026#34;\u0026#34;, password: \u0026#34;\u0026#34;, agree: true, }); const { account , password } =form.value   登录操作 1 2 3 4 5 6 7 8  import { useRouter } from \u0026#34;vue-router\u0026#34;; const res = await loginAPI({account,password}) //1.提示用户 ElMessage({type:\u0026#39;success\u0026#39;,message:\u0026#39;登录成功\u0026#39;}) //2.跳转首页 const router=useRouter() router.replace({path:\u0026#39;/\u0026#39;})   存储localStorage 挺久化存储插件：pinia-plugin-persistedstate\n 安装插件  1  npm i pinia-plugin-persistedstate   2.注册插件\n在main.js中，添加：\n1 2 3  const pinia = createPinia() //注册持久化插件 pinia.use(PiniaPluginPersistedstate)   使用插件\n创建store时，将 persistent 选项设置为 true  1 2 3 4 5 6 7  import { defineStore } from \u0026#39;pinia\u0026#39; export const useStore = defineStore(\u0026#39;main\u0026#39;, () =\u0026gt; { const someState = ref(\u0026#39;你好token\u0026#39;) return { someState } }, { persist: true } )   登录和非登录状态的模版乱配 核心思想：v-if=\u0026quot;false v-else\n1 2 3 4 5 6  \u0026lt;template v-if=\u0026#34;userStore.userInfo.token\u0026#34;\u0026gt; //登录时显示第一块 \u0026lt;/template\u0026gt; \u0026lt;template v-else\u0026gt; //非登录时显示第二块 \u0026lt;/template\u0026gt;   请求拦截器携带token 核心思想：\n1 2 3 4 5 6 7 8  httpInstance.interceptors.request.use(config =\u0026gt; { const userStore = userUserStore() const token = userStore.userInfo.token if (token) { config.headers.Authorization = `Bearer ${token}` } return config }, e =\u0026gt; Promise.rejecte)   退出登录  步骤一：pinia中写清除方法  1 2 3 4  //退出时清除用户信息  const clearUserInfo = () =\u0026gt; { clearUserInfo.value = {} }   步骤二：登录页面处理逻辑  1 2 3 4 5 6 7 8  const confirm = () =\u0026gt; { console.log(\u0026#34;用户要退出登录了\u0026#34;); //退出登录逻辑  //1 清除用户信息 触发action  useCounterStore.clearUserInfo(); //2 跳转路由地址  router.push(\u0026#34;/login\u0026#34;); };   统一错误提示 1 2 3 4 5 6 7 8 9 10  //axios响应式拦截器 httpInstance.interceptors.response.use(res =\u0026gt; res.data, e =\u0026gt; { //统一错误提示  ElMessage({ type:\u0026#39;warning\u0026#39;, message:e.response.data.message }) return Promise.reject(e) })   token失效401 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  //axios响应式拦截器 httpInstance.interceptors.response.use(res =\u0026gt; res.data, e =\u0026gt; { //统一错误提示  ElMessage({ type: \u0026#39;warning\u0026#39;, message: e.response.data.message }) //401 token失效处理  //1 清除本地用户数据  //2 跳转登录页  if(e.response.status==401){ userStore.clearUserInfo() router.push(\u0026#39;/login\u0026#39;) } return Promise.reject(e) })   添加本地购物车 stores/cartStore.js 的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  //封装财物车模块 import { defineStore } from \u0026#39;pinia\u0026#39; import { ref } from \u0026#39;vue\u0026#39; export const useCartStore=defineStore(\u0026#39;cart\u0026#39;,()=\u0026gt;{ //1 定义state - cartList  const cartList = ref([]) //2 定义action - addCart  const addCart=(goods)=\u0026gt;{ //添加购物车逻辑  //思路：通过匹配传递过来的商品对象中的skuId能不能在cartList中找到，找到了就是添加过 cosnt item = cartList.value.find((item)=\u0026gt;goods.skuId === item.skuId ) //已添加过 count+1  if(item){ //找到了  item.count++ }else{ //没找到  cartList.value.push(goods) } //没有添加过 直接push  } return { cartList, addCart } },{ persist:true, })   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  //sku规格被操作时 let skuObj={} const skuChange=()=\u0026gt;{ console.log(sku) skuObj=sku } const count=ref(1) const countChange = (count)=\u0026gt;{ console.log(count) } //添加财物车 const cartStore = useCartStore() const addCart = ()=\u0026gt;{ if(skuObj.skuId){ //规则已经选择 触发action  cartStore.addCart({ id:goods.value.id, name:goods.value.name, picture:goods.value.picture, price:goods.value.price, count:count.value, skuId:skuObj.skuId, attrsText:skuObj.attrsText, selected:true }) }else{ //规则没有选择 提示用户  ElMessage.warning(\u0026#39;请选择规则\u0026#39;) } }   删除购物车 思路：\n 找到要删除项的下标值 - splice 使用数组的过滤方法 - filter  1 2 3 4 5 6  \u0026lt;script\u0026gt; const delCart = (skuId)=\u0026gt;{ const idx=cartList.value.findIndex((item)=\u0026gt; skuId === item.skuId) cartList.value.splice(idx,1) } \u0026lt;/script\u0026gt;   计算属性  总的数量 所有项的count之和  1  const allCount = computed( ()=\u0026gt;cartList.value.reduce( (a,c)=\u0026gt;a + c.count,0))   总价 所有项的count * price 之和  1  const allPrice = computed( ()=\u0026gt;cartList.value.reduce( (a,c)=\u0026gt;a + c.count * c.price ,0))   //保留两位小数\ncartStore.allPrice.toFixed(2)\n列表购物车-单选功能 核心思路：单选的核心思路就是始终把 单行框的状态和Pinia中store对应的状态保持同步\n注意事项：v-model 双向绑定指令不方便进行命令式的操作（因为后续还要调用接口），所以把 v-model 回退到一般模式，也就是: model-value 和 @change 的配合实现\n步骤：\n 步骤一：pinia（store）\u0026ndash; (使用store渲染单行框) \u0026ndash;\u0026gt; :model-value 步骤二：@change \u0026ndash; 单选框切换时修改store中对应的状态 \u0026ndash;\u0026gt; pinia（store）  全选  是否全选：\n方法: every  1 2 3  const isAll=computed(()=\u0026gt;cartList.value.every((item) =\u0026gt; item.selected )) ... :model-value=\u0026#34;cartStore.isAll\u0026#34;   全选功能\n方法： forEach  1 2 3 4  const allCheck = (selected)=\u0026gt;{ //把cartLst中的每一项的selected都设置为当前的全选框状态 cartList.value.forEach(item =\u0026gt; item.selected = selected) }   列表购物车-统计数据实现 核心方法： filter 和 reduce\n 已选择数量 = cartList中所有selected字段为true项的count之和 商品合计 = cartList中所有selected字段为true项的count*price之和  1 2 3 4  //已选择数量: const selectedCount = computed( ()=\u0026gt;cartList.value.filter(item=\u0026gt;item.selected).reduce( (a,c)=\u0026gt;a + c.count,0)) //已选择商品价钱合计: const selectedPrice = computed( ()=\u0026gt;cartList.value.filter(item=\u0026gt;item.selected).reduce( (a,c)=\u0026gt;a + c.count*c.price,0))   tab切换类 核心思想：\n 点击时记录一个当前激活地址对象activeAddress，点击哪个地址就把哪个地址对象记录下来 通过 动态类名 :class 控制激活样式类型 active 是否存在，判断条件为：激活地址对象的id === 当前项id  1 2 3  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;text item\u0026#34; :class=\u0026#34;{active: activeAddress.id === item.id }\u0026#34;\u0026gt; TAB \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt;   倒计时函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  export const useCountDown = ()=\u0026gt;{ //1 响应式的数据  let timer = null const time = ref(0) //格式化时间为 XX分XX秒  const formatTime = computed(()=\u0026gt;dayjs.unix(time.value).format(\u0026#39;mm分ss秒\u0026#39;)) //2 开启倒计时的函数  const start= (currentTime)=\u0026gt;{ //开始倒计时的逻辑  //核心逻辑的编写：每隔1s就--  time.value = currentTime timer = setInterval(()=\u0026gt;{ time.value-- },1000) } //组件销毁时清除定时器  onUnmounted(()=\u0026gt;{ timer \u0026amp;\u0026amp; clearInterval(timer) }) return { formatTime, start } }   使用如下：\n1 2 3  const { formatTime,start } = useCountDown() {{ formatTime }} start(60)   分页逻辑实现  使用列表数据生成分页（页数=总条数/每页条数）  1 2 3  \u0026lt;template\u0026gt; \u0026lt;el-pagination :total=\u0026#34;total\u0026#34; :page-size=\u0026#34;params.pageSize\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt;   切换分页修改page参数，再次获取订单列表数据  1 2 3 4 5 6 7 8 9 10 11 12  ```vue \u0026lt;script\u0026gt; const pageChange = (page)=\u0026gt;{ console.lgo(page) params.value.page=page //发送请求 getOrderList() } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;el-pagination :total=\u0026#34;total\u0026#34; :page-size=\u0026#34;params.pageSize\u0026#34; @current-change=\u0026#34;pageChange\u0026#34;/\u0026gt; \u0026lt;/template\u0026gt;   ","description":"Vue.js是一种流行的JavaScript前端框架，用于构建用户界面。它是一种渐进式框架，可以逐步应用到项目中，也可以与其他库或现有项目进行整合。","id":11,"section":"stack","tags":["javascript",""],"title":"vue3实战项目","uri":"http://wangjinbao.netlify.app/en/stack/javascript/project/"},{"content":"前期准备 插件  VScode + Vue Language Features (Volar) \u0026ndash; 高亮 edge 浏览器插件 vue devtools  创建项目 1 2 3 4 5  npm init vue@latest # 一路回车 npm install npm run dev npm run build    docker外网访问，解决方法  1 2 3 4 5 6 7  # package.json 中修改 dev --host \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;vite --host 172.19.0.13\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;vite build\u0026#34;, \u0026#34;preview\u0026#34;: \u0026#34;vite preview\u0026#34; },   package.json\nindex.html\nmain.js\napp.vue\nMVVM的演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;!--脚本--\u0026gt; \u0026lt;script\u0026gt; export default{ data:()=\u0026gt;({ account:\u0026#39;abc\u0026#39; }) } \u0026lt;/script\u0026gt; \u0026lt;!--视图--\u0026gt; \u0026lt;template\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;account\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;这是我的第一个vue\u0026lt;/h1\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;!--样式--\u0026gt; \u0026lt;style scoped\u0026gt; \u0026lt;/style\u0026gt;   vue的组件风格 vue的组件可以按两种不同的风格书写\n 选项式API 组合式API  选项式API 可以用包含多个选项的 对象 来描述组件的逻辑，如： data 、 methods 和 mounted\n选项所定义的属性都会暴露在函数内部的 this 上，它会指向当前的组件实例\n1 2 3 4 5 6 7 8  \u0026lt;script\u0026gt; export default{ data:()=\u0026gt;({ account:\u0026#39;abc\u0026#39; }) } \u0026lt;/script\u0026gt;    响应式数据的声明  1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;script\u0026gt; export default { //data选项是一个函数返回的对象  data: () =\u0026gt; ({ account: \u0026#34;ABc\u0026#34;, student: { name: \u0026#34;jack\u0026#34;, age: 30, }, }), \u0026lt;/script\u0026gt; {{ account }}   组合式API 可以使用导入的API函数来描述组件逻辑\n在单文件组件中，组合式API通常会与\u0026lt;script setup\u0026gt;搭配使用\nsetup 属性是一个标识，告诉vue需要在编译时进行一些处理，可以更简洁地使用组合式API\n\u0026lt;script setup\u0026gt;可以直接使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;script setup\u0026gt; //引入API函数 import { ref } from \u0026#34;vue\u0026#34;; //数据源 let account = ref(\u0026#34;afdsaf\u0026#34;); //方法 function changeAccount() { account.value += \u0026#34;??????\u0026#34;; } \u0026lt;/script\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;account\u0026#34; /\u0026gt; \u0026lt;button @click=\u0026#34;changeAccount\u0026#34;\u0026gt;点我更改account\u0026lt;/button\u0026gt;    响应式数据的声明   普通变量的数据源，不具备响应式对象 普通变量使用ref函数后的数据源，具备响应式对象  1 2  let account = ref(\u0026#34;xyz\u0026#34;); account.value //获取    使用reactive函数声明原始类型的数据源，不具备响应式对象 使用reactive函数声明对象类型的数据源，具备响应式对象  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  //reactive把对象类型数据源，变为响应式对象 \u0026lt;script setup\u0026gt; import { reactive } from \u0026#34;vue\u0026#34;; import { ref } from \u0026#34;vue\u0026#34;; //普通对象类型的数据源，具备响应式对象 let emp = reactive({ salary: 88000, name: \u0026#34;wjb\u0026#34;, }); function changeEmpSalary() { emp.salary += 100; console.log(emp); } //ref把变通变量数据源，变为响式对旬，要用.value来获取值 let account = ref(\u0026#34;xyz\u0026#34;); function changeAccount() { account.value += \u0026#34;+\u0026#34;; console.info(account); } \u0026lt;/script\u0026gt;   vue的常用指令 v-text 指令 1.采用纯文字的方式填充数据\n2.加在空元素上\nv-html 指令 1.以html语法显示数据\n2.加在空元素上\n{{ }}插值表达式 1.可以放任意元素中\nv-model 指令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  \u0026lt;script\u0026gt; \u0026lt;div\u0026gt;账号：{{ student.name }}\u0026lt;/div\u0026gt; \u0026lt;!-- 单行文本框 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;student.name\u0026#34; /\u0026gt; \u0026lt;!-- 多行 --\u0026gt; \u0026lt;textarea v-model=\u0026#34;student.name\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;!-- 复选 框true/false --\u0026gt; \u0026lt;input type=\u0026#34;checkbox\u0026#34; v-model=\u0026#34;student.open\u0026#34; /\u0026gt;灯 \u0026lt;!-- 复选 框true-value/false-value --\u0026gt; \u0026lt;input type=\u0026#34;checkbox\u0026#34; true-value=\u0026#34;确定\u0026#34; false-value=\u0026#34;不确定\u0026#34; v-model=\u0026#34;student.open\u0026#34; /\u0026gt;选择 \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;zq\u0026#34; v-model=\u0026#34;student.likes\u0026#34; /\u0026gt;足球 \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;lq\u0026#34; v-model=\u0026#34;student.likes\u0026#34; /\u0026gt;篮球 \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;ymq\u0026#34; v-model=\u0026#34;student.likes\u0026#34; /\u0026gt;羽毛球 \u0026lt;!-- 单选框 --\u0026gt; \u0026lt;input type=\u0026#34;radio\u0026#34; value=\u0026#34;man\u0026#34; v-model=\u0026#34;student.sex\u0026#34; /\u0026gt;男 \u0026lt;input type=\u0026#34;radio\u0026#34; value=\u0026#34;woman\u0026#34; v-model=\u0026#34;student.sex\u0026#34; /\u0026gt;女 \u0026lt;!-- 下拉框 --\u0026gt; \u0026lt;select v-model=\u0026#34;student.level\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;C\u0026#34;\u0026gt;初级\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;B\u0026#34;\u0026gt;中级\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;A\u0026#34;\u0026gt;高级\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;!-- 多选下拉框 --\u0026gt; \u0026lt;select multiple v-model=\u0026#34;student.city\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;吉C\u0026#34;\u0026gt;通化\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;吉B\u0026#34;\u0026gt;吉林\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;吉A\u0026#34;\u0026gt;长春\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/script\u0026gt;   转换数据类型 v-model.number\nv-model.trim\nv-model.lazy\n1 2 3 4 5 6 7 8  \u0026lt;!-- 用户输入的值自动转成数值 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model.number=\u0026#34;student.age\u0026#34; /\u0026gt; \u0026lt;!-- 用户输入的值自动过滤空白字符--\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model.trim=\u0026#34;student.nickname\u0026#34; /\u0026gt; \u0026lt;!-- 懒、用户输入的值change后自动转成数值 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model.lazy.number=\u0026#34;student.age\u0026#34; /\u0026gt;   v-bind 绑定指令 1.绑定class类 PS ： 如果将属性绑定的值为null值，会直接迁移掉这个属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026lt;script\u0026gt; import { reactive } from \u0026#34;vue\u0026#34;; export default { data: () =\u0026gt; ({ picture: { with: 200, src: \u0026#34;http://localhost:1313/images/whoami/avatar.jpg\u0026#34;, }, }), }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;!-- v-bind --\u0026gt; \u0026lt;img v-bind:src=\u0026#34;picture.src\u0026#34; v-bind:width=\u0026#34;picture.with\u0026#34; /\u0026gt; \u0026lt;!-- 精简 :--\u0026gt; \u0026lt;img :src=\u0026#34;picture.src\u0026#34; :width=\u0026#34;picture.with\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;picture.with\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt;   绑定多个属性/值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;script setup\u0026gt; import { reactive } from \u0026#34;vue\u0026#34;; let attrs = reactive({ class: \u0026#34;error\u0026#34;, id: \u0026#34;borderBlue\u0026#34;, }); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;!-- 绑定多个属性及值 --\u0026gt; \u0026lt;button v-bind=\u0026#34;attrs\u0026#34;\u0026gt;我是一个普通按钮\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; .error { background-color: red; color: white; } #borderBlue { border: 2px solid rgb(44, 67, 167); } \u0026lt;/style\u0026gt;   class数组\n1 2 3 4 5 6 7 8  let btnTheme=ref([]) \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;error\u0026#34; v-model=\u0026#34;btnTheme\u0026#34;\u0026gt; error \u0026lt;input type=\u0026#34;checkbox\u0026#34; value=\u0026#34;flat\u0026#34; v-model=\u0026#34;btnTheme\u0026#34;\u0026gt; flat \u0026lt;button :class=\u0026#34;btnTheme\u0026#34;\u0026gt;按钮\u0026lt;/button\u0026gt; \u0026lt;!-- 数组和对象可以一起使用 --\u0026gt; \u0026lt;button :class=\u0026#34;[{\u0026#39;rounded\u0026#39;:capsule},widthTheme]\u0026#34;\u0026gt;按钮\u0026lt;/button\u0026gt;   2.绑定style样式  绑定数据源对象  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026lt;script\u0026gt; export default { data: () =\u0026gt; ({ btnTheme: { backgroundColor: \u0026#34;#FF0000\u0026#34;, color: \u0026#34;#000000\u0026#34;, }, backColor: \u0026#34;#0000FF\u0026#34;, textColor: \u0026#34;#FFFFFF\u0026#34;, borRadius: 20, }), }; \u0026lt;/script\u0026gt; 背景色：\u0026lt;input type=\u0026#34;color\u0026#34; v-model=\u0026#34;btnTheme.backgroundColor\u0026#34; /\u0026gt;error 字体色：\u0026lt;input type=\u0026#34;color\u0026#34; v-model=\u0026#34;btnTheme.color\u0026#34; /\u0026gt;flat \u0026lt;br /\u0026gt; \u0026lt;br /\u0026gt; \u0026lt;!-- style 可以直接绑定对象数据源，但是对象数据源的属性名称不能随便写，(驼峰命名法替代\u0026#39;-\u0026#39;) --\u0026gt; \u0026lt;button :style=\u0026#34;btnTheme\u0026#34;\u0026gt;普通按钮\u0026lt;/button\u0026gt;   直接传属性对象  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;!-- style可以传对象 --\u0026gt; 背景色：\u0026lt;input type=\u0026#34;color\u0026#34; v-model=\u0026#34;backColor\u0026#34; /\u0026gt; 字体色：\u0026lt;input type=\u0026#34;color\u0026#34; v-model=\u0026#34;textColor\u0026#34; /\u0026gt; 边框圆角：\u0026lt;input type=\u0026#34;range\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;20\u0026#34; v-model=\u0026#34;borRadius\u0026#34; /\u0026gt; \u0026lt;button :style=\u0026#34;{ backgroundColor: backColor, color: textColor, \u0026#39;border-radius\u0026#39;: borRadius + \u0026#39;px\u0026#39;, }\u0026#34; \u0026gt; 普通按钮 \u0026lt;/button\u0026gt;   v-if/v-else-if/v-else 判断指令 1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;script\u0026gt; export default { data: () =\u0026gt; ({ isShow: false, }), }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; 是否显示：\u0026lt;input type=\u0026#34;checkbox\u0026#34; v-model=\u0026#34;isShow\u0026#34; /\u0026gt; \u0026lt;h3 v-if=\u0026#34;isShow\u0026#34;\u0026gt;这是一个标签\u0026lt;/h3\u0026gt; \u0026lt;/template\u0026gt;   v-show 是否显示 1 2 3 4 5 6 7 8 9 10 11 12 13  export default { data: () =\u0026gt; ({ isShow: false, show: true, }), }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; 是否显示：\u0026lt;input type=\u0026#34;checkbox\u0026#34; v-model=\u0026#34;isShow\u0026#34; /\u0026gt; \u0026lt;h3 v-if=\u0026#34;isShow\u0026#34;\u0026gt;这是一个标签\u0026lt;/h3\u0026gt; \u0026lt;h3 v-show=\u0026#34;show\u0026#34;\u0026gt;显示\u0026lt;/h3\u0026gt; \u0026lt;/template\u0026gt;   v-on 事件绑定指令(缩写：@) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;script\u0026gt; export default { data: () =\u0026gt; ({ volume: 5, }), methods: { addVolume() { if (this.volume !== 10) { this.volume++; } }, }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h3\u0026gt;当前音量：{{ volume }}\u0026lt;/h3\u0026gt; \u0026lt;button v-on:click=\u0026#34;addVolume\u0026#34;\u0026gt;添加音量\u0026lt;/button\u0026gt; \u0026lt;button @:click=\u0026#34;addVolume\u0026#34;\u0026gt;添加音量\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   事件的修饰符  .prevent 阻止默认行为  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;script\u0026gt; export default { data: () =\u0026gt; ({ volume: 5, }), methods: { say() { window.alert(\u0026#34;hi\u0026#34;); }, }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;a href=\u0026#34;www.baidu.com\u0026#34; @click.prevent=\u0026#34;say\u0026#34;\u0026gt;百度\u0026lt;/a\u0026gt; \u0026lt;/template\u0026gt;   .stop阻止事件冒泡  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;script\u0026gt; export default { data: () =\u0026gt; ({ volume: 5, }), methods: { say(name) { console.log(\u0026#34;hi\u0026#34; + name); }, }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;divArea\u0026#34; @click=\u0026#34;say(\u0026#39;DIV\u0026#39;)\u0026#34;\u0026gt; \u0026lt;button @click.stop=\u0026#34;say(\u0026#39;BUTTON\u0026#39;)\u0026#34;\u0026gt;按钮\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt;   .capture 以捕获模式触发当前的事件处理函数\n给该元素添加了一个监听器\n先触发该元素的事件，都有修饰符，由外向内触发 .once绑定事件只触发1次 .self只有在event.target是当前元素自身时触发事件处理函数\n对只该元素上触发事件有效 .passive 向浏览器表明了不想阻止事件的默认行为  按键的修饰符 .enter / .tab / .shift / .exact\n1 2 3 4 5 6 7 8  按键的键盘中包含enter事件\u0026lt;input type=\u0026#34;text\u0026#34; @keydown.enter=\u0026#34;showMessage(\u0026#39;按下了enter键\u0026#39;)\u0026#34; /\u0026gt; 按键的键盘中包含enter+shift事件\u0026lt;input type=\u0026#34;text\u0026#34; @keydown.enter.shift=\u0026#34;showMessage(\u0026#39;按下了enter+shift键\u0026#39;)\u0026#34; /\u0026gt;   鼠标按键的修饰符 .left / .right / .middle\nv-for渲染数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;script setup\u0026gt; import { ref } from \u0026#34;vue\u0026#34;; let subject = ref([ { id: 1, name: \u0026#34;vue\u0026#34; }, { id: 2, name: \u0026#34;python\u0026#34; }, { id: 3, name: \u0026#34;java\u0026#34; }, { id: 4, name: \u0026#34;php\u0026#34; }, ]); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;!-- 对象 --\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;sub in subject\u0026#34;\u0026gt;编号：{{ sub.id }} -- 名称：{{ sub.name }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;!-- 解构 --\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;{ id, name } in subject\u0026#34;\u0026gt;编号：{{ id }} -- 名称：{{ name }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;!-- 索引 --\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;(sub, index) in subject\u0026#34;\u0026gt; 编号：{{ sub.id }} -- 名称：{{ sub.name }} -- 索引：{{ index }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/template\u0026gt;   v-for渲染对象 1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;value in student\u0026#34;\u0026gt;{{ value }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;(value, name) in student\u0026#34;\u0026gt; 属性名：{{ name }}--属性值：{{ value }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;(value, name, index) in student\u0026#34;\u0026gt; 属性名：{{ name }}--属性值：{{ value }}--索引：{{ index }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;   key管理状态 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;script setup\u0026gt; import { ref } from \u0026#34;vue\u0026#34;; let subject = ref([ { id: 1, name: \u0026#34;java\u0026#34; }, { id: 2, name: \u0026#34;python\u0026#34; }, { id: 3, name: \u0026#34;php\u0026#34; }, { id: 4, name: \u0026#34;go\u0026#34; }, ]); function addSub() { subject.value.unshift({ id: 5, name: \u0026#34;hadoop\u0026#34; }); } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click.once=\u0026#34;addSub\u0026#34;\u0026gt;添加课程\u0026lt;/button\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;sub in subject\u0026#34; :key=\u0026#34;sub.id\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;checkbox\u0026#34; /\u0026gt; 课程：{{ sub }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/template\u0026gt;   侦听器 选项式API中的侦听器 选项式API中使用 watch 选项在每次响应式属性发生变化是触发一个函数\n 函数式侦听器  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026lt;script\u0026gt; export default { data: () =\u0026gt; ({ age: 30, emp: { name: \u0026#34;jack\u0026#34;, sex: 1, }, }), watch: { /** * 侦听age数据源是否变化 * @param {*} newData * @param {*} oldData */ age(newData, oldData) { console.log(\u0026#34;oldData:\u0026#34; + oldData); console.log(\u0026#34;newData:\u0026#34; + newData); }, \u0026#34;emp.name\u0026#34;(newData, oldData) { console.log(\u0026#34;oldData:\u0026#34; + oldData); console.log(\u0026#34;newData:\u0026#34; + newData); }, }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;age\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;emp.name\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt;   对象式侦听器   deep 深度侦听  1  deep:true    immediate 创建时立即触发  1  immediate:true    flush 改回调机制(DOM更新后)  1  flush:\u0026#39;post\u0026#39;   this.$watch 侦听器\n允许提交停止该侦听器\n语法：this.$watch(data,method,object)\ndata:侦听数据源，类型为string\nmethod:回调函数，参数一新值，参数二旧值\nobject:配置\na. deep:深度侦听\nb. immediate:创建时立即触发\nc. flush:\u0026lsquo;post\u0026rsquo;：要改回调机制(DOM更新后) 停止侦听器  1 2 3 4 5 6 7 8 9 10 11  accountStop: null, ... this.accountStop = this.$watch( \u0026#34;age\u0026#34;, (newData, oldData) =\u0026gt; { console.log(\u0026#34;年龄的新旧值1\u0026#34;); console.log(newData); console.log(oldData); }, { immediate: true } );   组合式API中的侦听器 watch函数 1 2 3 4 5 6 7 8 9  //侦听对象的某个属性，要以对象的方式 watch( () =\u0026gt; emp.salary, (newData, oldData) =\u0026gt; { console.log(\u0026#34;=== 员工薪资新旧值 ===\u0026#34;); console.log(newData); console.log(oldData); } )   watchEffect函数 立即回调\n1 2 3 4 5 6 7 8 9  \u0026lt;script setup\u0026gt; import { reactive, ref, watch, watchEffect } from \u0026#34;vue\u0026#34;; let account = ref(\u0026#34;Abc\u0026#34;); watchEffect(() =\u0026gt; { console.log(account.value); }); \u0026lt;/script\u0026gt;    默认情况下，回调触发机制，在DOM更新之前 flush:\u0026lsquo;post\u0026rsquo; 在DOM更新之后  watchPostEffect函数 在DOM更新之后\nwatchEffect函数 + flush:\u0026lsquo;post\u0026rsquo;\n计算属性 computed(()=\u0026gt;{})\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026lt;script setup\u0026gt; import { computed, ref } from \u0026#34;vue\u0026#34;; let age = ref(20); //计算属性 let ageState = computed(() =\u0026gt; { if (age.value \u0026lt; 18) { return \u0026#34;未成年\u0026#34;; } else if (age.value \u0026lt; 60) { return \u0026#34;中年\u0026#34;; } else { return \u0026#34;老年\u0026#34;; } }); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; 年龄：\u0026lt;input type=\u0026#34;number\u0026#34; v-model=\u0026#34;age\u0026#34; /\u0026gt; \u0026lt;p\u0026gt;年龄阶段：{{ ageState }}\u0026lt;/p\u0026gt; \u0026lt;/template\u0026gt;    计算属性与方法的区别：\n1.两种方式的结果确实是完全相同的，不同之处在于计算属性值会基于响应式依赖被缓存。\n2.计算属性：仅会在响应式依赖数据更新时才会重新计算\n3.方法：总是会在页面渲染发生时再次执行函数  组件 一个vue组件在使用前需要先被\u0026rsquo;注册'，这样vue才能在渲染模板时找到其对应的实现；组件注册有两种方式：全局注册 局部注册\n全局注册组件 可使用app.component(name,Component) 注册组件的方法，在此应用的任意组件的模板中使用\n name:注册的名字 Component:需要注册的组件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //在main.js中 ... import App from \u0026#39;./App.vue\u0026#39; //1、引入需要注册的组件 import LoginVue from \u0026#39;./components/Login.vue\u0026#39; // let app = createApp(App) //-- //2.全局注册组件 app.component(\u0026#39;MLogin\u0026#39;,LoginVue) //--  app.mount(\u0026#39;#app\u0026#39;) ...   1 2 3 4 5 6 7  //App.vue中 \u0026lt;script\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;!-- 使用全局注册的组件 --\u0026gt; \u0026lt;MLogin/\u0026gt; \u0026lt;/template\u0026gt;   局部注册组件 局部注册的组件需要在使用它的父组件中显式导入，并且只能在该父组件中使用。\n 在选项式API中，可以使用components选项来局部注册组件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;script\u0026gt; //1、引入需要注册的组件 import LoginVue from \u0026#39;./components/Login.vue\u0026#39; export default { //2.注册组件选项  components:{ \u0026#34;MLogin\u0026#34;:LoginVue //名字一样的话，直接写组件名即可LoginVue  } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;!-- 使用局部注册的组件 --\u0026gt; \u0026lt;MLogin/\u0026gt; \u0026lt;/template\u0026gt;   在组合式API中的\u0026lt;script setup\u0026gt;内，直接导入的组件就可以在模板中直接可用，无需注册  1 2 3 4 5 6 7  \u0026lt;script setup\u0026gt; //1、引入需要注册的组件 import LoginVue from \u0026#39;./components/Login.vue\u0026#39; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;LoginVue/\u0026gt; \u0026lt;/template\u0026gt;   数据传递 如果父组件向子组件进行传递数据，那么我们需要在子组件中声明props来接收传递数据的属性，可采用\n1、字符串数组式 或\n2、对象式来声明props\n方式一：字符串数组式  定义 defineProps  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026lt;script setup\u0026gt; defineProps([\u0026#39;title\u0026#39;,\u0026#39;\u0026#39;error\u0026#39;,\u0026#39;flat\u0026#39;]) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button :class=\u0026#34;{error,flat}\u0026#34;\u0026gt; {{title}} \u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; button { border:none; padding:12px 25px; } .error { background-color:rgb(197,75,75); color:white; } .flat { box-shadow:0 0 10px grey; }    使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;script setup\u0026gt; import { ref } from \u0026#39;vue\u0026#39;; import ButtonVue from \u0026#39;./components/Button.vue\u0026#39; let isError =ref(false) let isFlat = ref(false) let btnText = ref(\u0026#39;普通按钮\u0026#39;) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; 主题：\u0026lt;input type=\u0026#34;checkbox\u0026#34; v-model=\u0026#34;isError\u0026#34;\u0026gt; 阴影：\u0026lt;input type=\u0026#34;checkbox\u0026#34; v-model=\u0026#34;isFlat\u0026#34;\u0026gt; 按钮文本：\u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;btnText\u0026#34;\u0026gt; \u0026lt;ButtonVue title=\u0026#34;提交\u0026#34; :error=\u0026#34;true\u0026#34; :flat=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt;   注意不能直接修改 props 的数据，因为是只读的，只能父组件修改\n方式二：对象式来声明 注意：\n 所有prop默认都是可选的，除非声明了required:true 除Boolean外的传递的可选prop将会有一个默认值undefined Boolean类型的未传递prop将被转换为false 当prop的校验失败后，Vue会抛出一个控制台警告 注意prop的校验是在组件实例被创建之前\na.在选项式API中，实例的属性（比如 data 、 computed 等）将在 default 或 validator 函数中不可用\nb.在组合式API中，defineProps宏中的参数不可以访问\u0026lt;script setup\u0026gt;中定义的其他变量。  1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;script setup\u0026gt; let propsData = defineProps({ title:{ type:String, required:true }, error:Boolean, flat:Boolean, tips:{ type:String, default:\u0026#39;我是一个普通的按钮\u0026#39; } }) \u0026lt;/script\u0026gt;   对象中的属性：\n type:类型，如 String,Number,Boolean,Array,Object,Date default:默认值：对象或者数组应当用工厂函数返回 required:是否必填，布尔值 validator:自定义校验，函数类型  注意：\n1 2 3 4 5 6  关于Boolean类型转换： 为了更贴近原生 boolean attributes 行为，声明为 Boolean 类型的 props 有特别的类型转换规则 如声明时： defineProps{{ error:Boolean}} 传递数据时： \u0026lt;MyComponent error/\u0026gt; 相当于 \u0026lt;MyComponent :error=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;MyComponent /\u0026gt; 相当于 \u0026lt;MyComponent :error=\u0026#34;false\u0026#34; /\u0026gt;   自定义事件 emits 子组件中如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;script\u0026gt; export default { //自定义事件选项  emits:[\u0026#39;changeAge\u0026#39;,\u0026#39;changeAgeAndName\u0026#39;], methods:{ emitEventAge(){ //选项式通过 this.$emit 触发自定义事件  this.$emit(\u0026#39;changeAge\u0026#39;,30) } } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;emitEventAge\u0026#34;\u0026gt;更改年龄\u0026lt;/button\u0026gt; \u0026lt;br\u0026gt; \u0026lt;button @click=\u0026#34;$emit(\u0026#39;changeAgeAndName\u0026#39;,10,\u0026#39;Annie\u0026#39;)\u0026#34;\u0026gt;更改年龄\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   父组件中如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;script\u0026gt; import StudentVue from \u0026#39;./compoments/Student.vue\u0026#39; export default { components:{StudentVue}, data:()=\u0026gt;({ student:{ name:\u0026#39;Jack\u0026#39;, age:18, sex:\u0026#39;男\u0026#39;, } }), methods:{ getNewAge(newAge){ console.log((\u0026#39;年龄的新值：\u0026#39;+newAge)) this.student.age=newAge } } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; {{student}} \u0026lt;hr\u0026gt; \u0026lt;StudentVue @change-age=\u0026#34;getNewAge\u0026#34;/\u0026gt; \u0026lt;/template\u0026gt;   触发自定义组件事件：\n 在选项式API中，可通过组件当前实例 this.$emit(event,...args) 来触发当前组件自定义的事件 在组合式API中，可调用 defineEmits 宏返回的 emit(event,...args) 函数来触发当前组件自定义的事件\n其中上方两个参数分别为：\nevent：触发事件名，字符串类型\n...args：传递参数，可没有，可多个  *注意事项：\n 模板上可以用$event变量  1  $event.target.checked    组合式API中变量的值.value  1  shopCar.value   透传属性和事件 父组件在使用子组件的时候：\n 透传属性和事件并没有在子组件中用 props 和 emits 声明 透传属性和事件最常见的如 @click 和 class 、 id 、style 当子组件只有一个元素时，透传属性和事件会自动添加到该根元素上；如果根元素已有 class或style属性，它会自动合并  组止透传属性和事件自动透传给唯一的根组件\n在子组件中添加\n  在选项式API中，可以在组件选项中设置 inheritAttrs:false 来组上\n  在组合式API中，\u0026lt;script setup\u0026gt; 中，你需要一个额外的\u0026lt;script\u0026gt;块来写inheritAttrs:false 选项声明禁止\n  1 2 3 4 5  \u0026lt;script\u0026gt; export default{ inheritAttrs:false } \u0026lt;/script\u0026gt;   多根元素的透传属性和事件\n在子组件中元素添加 v-bind=\u0026quot;$attrs\u0026quot;以说明接受透传属性和事件\n1  \u0026lt;button v-bind=\u0026#34;$attrs\u0026#34;\u0026gt;\u0026lt;/button\u0026gt;   访问透传属性和事件\n 在选项式API中，可以用 this.$attrs 或 $attrs  1 2 3 4 5 6 7  this.$attrs this.$attrs.onClick() \u0026lt;template\u0026gt; //在模板中可以直接使用 $attrs  \u0026lt;h6\u0026gt;{{ $attrs }}\u0026lt;/h6\u0026gt; \u0026lt;h6\u0026gt;{{ $attrs.title }}\u0026lt;/h6\u0026gt; \u0026lt;/template\u0026gt;   在组合式API中，可以用 useAttrs() 来获取  1 2 3 4 5 6 7 8  \u0026lt;script setup\u0026gt; let attrs = useAttrs() \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; //在模板中可以直接使用 attrs  \u0026lt;h6\u0026gt;{{ attrs }}\u0026lt;/h6\u0026gt; \u0026lt;h6\u0026gt;{{ attrs.title }}\u0026lt;/h6\u0026gt; \u0026lt;/template\u0026gt;   插糟 在封装组件时，可以使用 \u0026lt;slot\u0026gt; 元素把不确定的、希望由用户指定的部分定义为插槽；插槽可以理解为给\n预留的内容提供点位符，插槽也可以提供默认内容，如果组件的使用者没有为插槽提供任何内容，则插槽的\n默认内容会生效。\n1 2 3 4 5 6 7 8 9 10 11  //父组件中 \u0026lt;template\u0026gt; \u0026lt;CardVue\u0026gt; \u0026lt;button\u0026gt;关闭\u0026lt;/button\u0026gt; \u0026lt;/CardVue\u0026gt; \u0026lt;/template\u0026gt; //子组件中 \u0026lt;template\u0026gt; \u0026lt;slot\u0026gt;卡片功能区域\u0026lt;/slot\u0026gt; \u0026lt;/template\u0026gt;   插槽的默认内容只有父组件没有提供内容时才会显示\n具名插槽 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  //父组件 \u0026lt;template v-solt:test\u0026gt; 指定name \u0026lt;/template\u0026gt; \u0026lt;template #test\u0026gt; #号 \u0026lt;/template\u0026gt; \u0026lt;template #default\u0026gt; 默认 \u0026lt;/template\u0026gt; //子组件 \u0026lt;template\u0026gt; \u0026lt;!-- 具名插槽 --\u0026gt; \u0026lt;solt name=\u0026#34;test\u0026#34;\u0026gt;\u0026lt;/solt\u0026gt; \u0026lt;!-- 默认插槽 --\u0026gt; \u0026lt;solt\u0026gt;卡片功能区域\u0026lt;/solt\u0026gt; \u0026lt;/template\u0026gt;   作用域插槽 带有数据的插槽称为作用域插槽\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  //子组件中 \u0026lt;script\u0026gt; let blog = reactive({ title:\u0026#39;Java实现上传\u0026#39;, time:\u0026#39;2020-10-10 15:33:33\u0026#39;, }) let author = ref(\u0026#39;爱思考的飞飞\u0026#39;) \u0026lt;/script\u0026gt; \u0026lt;slot name=\u0026#34;cardContent\u0026#34; :cardBlog=\u0026#34;blog\u0026#34; :cardAuthor=\u0026#34;author\u0026#34;\u0026gt;\u0026lt;/slot\u0026gt; //父组件中 \u0026lt;template #cardContent=\u0026#34;dataProps\u0026#34;\u0026gt; \u0026lt;li\u0026gt;{{ dataProps }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;博客的标题：{{ dataProps.cardBlog.title }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;博客的时间：{{ dataProps.cardBlog.time }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;博客的作者：{{ dataProps.cardAuthor }}\u0026lt;/li\u0026gt; \u0026lt;/template\u0026gt;   默认插槽使用属性值\n1 2 3 4 5 6 7  //如果使用子组件时用到了 `v-slot` ，则该子组件标签中将无法向其他具名插槽中提供内容 \u0026lt;CardVue v-slot=\u0026#34;dataProps\u0026#34;\u0026gt; //错误 \u0026lt;button #XXX=\u0026#34;XXX\u0026#34;\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;{{ dataProps.close }}\u0026lt;/button\u0026gt; \u0026lt;button\u0026gt;{{ dataProps.sure }}\u0026lt;/button\u0026gt; \u0026lt;/CardVue\u0026gt;   scoped 属性 **默认情况下，写在.vue组件中的样式会全局生效，很容易造成多个组件之间的样式冲突问题导致\n组件之间样式冲突的根本原因是：\n 单页面应用程序中，所有组件的DOM结构，都是基于唯一的index.html页面进行呈现的 每个组件中的样式，都会影响整个index.html页面中的DOM元素  scoped 属性\n让下方的样式只作用在该组件中，或者子组件的根元素上\n该组件中的所有元素及子组件中的根元素会加上固定的属性(data-v-1a2j3i6)\n该css选择器都自动添加固定的属性选择器[data-v-1a2j3i6]\n1 2 3 4 5 6 7 8 9 10  \u0026lt;style\u0026gt; //可以作用在当前页面元素上 h3{ border:1px solid red; } //可以作用在子组件的根元素上 .error{ border:1px solid black;; } \u0026lt;/style\u0026gt;   :deep()深度选择器 1 2 3  .error.deep(button){ }   css中的v-bind() 1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;script setup\u0026gt; let btnTheme = reactive({ backColor:\u0026#39;#000000\u0026#39;, textColor:\u0026#39;#FFFFFF\u0026#39;, }) \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; button{ //v-bind() 数据源值变化，样式也变化  background-color:v-bind(\u0026#39;btnTheme.backColor\u0026#39;); color:v-bind(\u0026#39;btnTheme.textColor\u0026#39;); } \u0026lt;/style\u0026gt;   注入inject main.js中引入提供数据\n1  app.provice(\u0026#39;message\u0026#39;,\u0026#39;登录成功\u0026#39;)   在子组件中\n1 2 3 4 5 6 7 8  \u0026lt;script\u0026gt; export default{ inject:[\u0026#39;message\u0026#39;,\u0026#39;title\u0026#39;,\u0026#39;subtitle\u0026#39;,\u0026#39;changeSubtitle\u0026#39;] } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h2\u0026gt;应用层提供的数据 {{ message }}\u0026lt;/h2\u0026gt; \u0026lt;/template\u0026gt;   **选项式API中，访问组件实例this，provide必须采用函数的方式（不能用箭头函数）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;script\u0026gt; export default{ data:()=\u0026gt;({ title:\u0026#39;博客\u0026#39;, subtitle:\u0026#39;百万博主分享经验\u0026#39; }), methods:{ changeSubtitle(sub){ this.subtitle = sub } } //provide:{title:this.title} //无法访问组件实例 this  //如果想访问组件实例 this，必须采用函数的方式  provicde(){ return { title:this.title, //这种并注入方 与 提供方 没有响应式连接  subtitle:computed(()=\u0026gt;this.subtitle), changeSubtitle:this.changeSubtitle } } } \u0026lt;/script\u0026gt;    title:this.title, //这种并注入方 与 提供方 没有响应式连接 subtitle:computed(()=\u0026gt;this.subtitle) //响应式连接借助组合式API中的 computed() 函数提供计算属性  生命周期 beforeCreate  beforeCreate 选项式声明周期函数,可以访问props的数据 在组件实例初始化之前调用（props 解析已解析、data 和computed等选项还未处理） 不能访问组件的实例 this 中的数据源和函数等 不能访问组件中的视图DOM元素 组合式API中的setup()钩子会在所有选项式API钩子之前调用  1 2 3 4  beforeCreate(){ console.log(\u0026#39;beforeCreate 组件实例话之前\u0026#39;) console.log(this.$props.subtitle) }   created 组件实例初始化之后\n1 2 3 4 5 6  created(){ console.log(\u0026#39;created 组件实例话之后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() }   beforeMount（onBeforeMount） 组件视图渲染之前\n1 2 3 4 5 6  beforeMount(){ console.log(\u0026#39;beforeMount 组件视图渲染之前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() },   组合式API\n1 2 3 4 5 6  onBeforeMount(()=\u0026gt;{ console.log(\u0026#39;beforeMount 组件视图渲染之前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() })   mounted 组件视图渲染之后\n1 2 3 4 5 6 7  mounted(){ console.log(\u0026#39;mounted 组件视图渲染之后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }   组合式API：\n1 2 3 4 5 6 7  onMounted(()=\u0026gt;{ console.log(\u0026#39;mounted 组件视图渲染之后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) })   beforeUpdate 数据源发生改变，视图重新渲染前\n1 2 3 4 5 6 7  beforeUpdate(){ console.log(\u0026#39;beforeUpdate 数据源发生改变，视图重新渲染前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }   在组合式API：\n1 2 3 4 5 6 7  onBeforeUpdate(()=\u0026gt;{ console.log(\u0026#39;beforeUpdate 数据源发生改变，视图重新渲染前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) })   update 数据源发生改变，视图重新渲染后\n1 2 3 4 5 6 7  updated(){ console.log(\u0026#39;updated 数据源发生改变，视图重新渲染后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }   在组合式API：\n1 2 3 4 5 6 7  onUpdated(()=\u0026gt;{ console.log(\u0026#39;updated 数据源发生改变，视图重新渲染后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) })   beforeUnmount 组件在卸载之前\n1 2 3 4 5 6 7  beforeUnmount(){ console.log(\u0026#39;beforeUnmount 组件在卸载之前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }   在组合式API:\n1 2 3 4 5 6 7  onBeforeUnmount(()=\u0026gt;{ console.log(\u0026#39;beforeUnmount 组件在卸载之前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) })   unmounted 组件在卸载之后\n1 2 3 4 5 6 7  unmounted(){ console.log(\u0026#39;unmounted 组件已卸载\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() // console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }   在组合式API：\n1 2 3 4 5 6 7  onUnmounted(()=\u0026gt;{ console.log(\u0026#39;unmounted 组件已卸载\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() // console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) })   完整如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  \u0026lt;script\u0026gt; export default { props:[\u0026#39;subtitle\u0026#39;], data:()=\u0026gt;({ age:30 }), methods:{ showMessage(){ console.log(\u0026#39;函数 Hello\u0026#39;) } }, beforeCreate(){ console.log(\u0026#39;beforeCreate 组件实例话之前\u0026#39;) console.log(this.$props.subtitle) }, created(){ console.log(\u0026#39;created 组件实例话之后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() }, beforeMount(){ console.log(\u0026#39;beforeMount 组件视图渲染之前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() }, mounted(){ console.log(\u0026#39;mounted 组件视图渲染之后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }, beforeUpdate(){ console.log(\u0026#39;beforeUpdate 数据源发生改变，视图重新渲染前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }, updated(){ console.log(\u0026#39;updated 数据源发生改变，视图重新渲染后\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }, beforeUnmount(){ console.log(\u0026#39;beforeUnmount 组件在卸载之前\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML) }, unmounted(){ console.log(\u0026#39;unmounted 组件已卸载\u0026#39;) console.log(this.$props.subtitle) console.log(this.age) this.showMessage() // console.log(document.getElementById(\u0026#39;title\u0026#39;).innerHTML)  }, } \u0026lt;/script\u0026gt;   访问DOM元素模板引用 如果想访问组件中的底层 DOM 元素，可使用 vue 提供特殊的 ref 属性来访问\n选项式API中ref  字符声明的：\nref=\u0026ldquo;account\u0026rdquo; 字符串，获取 this.$refs.account  1  this.$refs.account   函数声明的：\n:ref=\u0026ldquo;passwordRef\u0026rdquo; ，获取 passwordRef(el){}  1 2 3 4 5  //注意函数式声明的ref，不会在 this.$refs 中获取 passwordRef(el){ this.passwordEl = el }   *注意： 函数式声明的ref，不会在 this.$refs 中获取\n组合API中ref 字符声明的：\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;script settup\u0026gt; let account = ref(null) //ref变量名一定要和输入框中的ref属性值一样 function changeAccount(){ console.log(account.value) account.value.style=\u0026#39;padding:10px\u0026#39; account.value.className=\u0026#39;rounded\u0026#39; account.value.focus() } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; ref=\u0026#34;account\u0026#34;\u0026gt;\u0026lt;button @click=\u0026#34;changeAccount\u0026#34;\u0026gt;改变账号\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   函数声明的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;script settup\u0026gt; let password = ref(null) //ref变量名一定要和输入框中的ref属性值一样 function passwordRef(el){ password.value=el } function changePassword(){ console.log(password.value) password.value.style=\u0026#39;padding:10px\u0026#39; password.value.className=\u0026#39;rounded\u0026#39; password.value.focus() } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; :ref=\u0026#34;passwordRef\u0026#34;\u0026gt;\u0026lt;button @click=\u0026#34;changePassword\u0026#34;\u0026gt;改变p密码\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   v-for 中的模板引用 前提条件：\n注意：vue的版本在3.2.25及以上版本\nvue版本查看：在项目根目录中的 package.json\n1 2 3  \u0026#34;dependencies\u0026#34;: { \u0026#34;vue\u0026#34;: \u0026#34;^3.3.4\u0026#34; }   引用方法：\n 如果 ref 值是字符串形式，在元素被渲染后包含对应整个列表的所有元素【数组】 如果 ref 值是函数形式，则会每渲染一个列表元素则会执行对应的函数【不推荐使用，影响性能】  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  \u0026lt;script\u0026gt; import { url } from \u0026#34;inspector\u0026#34;; export default { data: () =\u0026gt; ({ books: [ { id: 1, name: \u0026#34;红楼梦\u0026#34; }, { id: 2, name: \u0026#34;三国演义\u0026#34; }, { id: 3, name: \u0026#34;水浒传\u0026#34; }, { id: 4, name: \u0026#34;西游记\u0026#34; }, ], }), methods: { changeBookListStyle() { console.log(this.$refs.booklist); this.$refs.booklist[2].style = \u0026#34;color:red\u0026#34;; }, }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;b in books\u0026#34; :key=\u0026#34;b.id\u0026#34; ref=\u0026#34;booklist\u0026#34;\u0026gt; {{ b.name }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;button @click=\u0026#34;\u0026#34;\u0026gt;点击查看 booklist\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   组合式API：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026lt;script setup\u0026gt; import { VueElement } from \u0026#39;vue\u0026#39;; import {ref} from VueElement import { Script } from \u0026#39;vm\u0026#39;; let students = ref([ {id:1,name:\u0026#39;Jack\u0026#39;}, {id:2,name:\u0026#39;Annie\u0026#39;}, {id:3,name:\u0026#39;Tom\u0026#39;}, ]) function changeStyle(){ console.log(students.value) students.value[2].style=\u0026#39;color:red\u0026#39; } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;s in students\u0026#34; :key=\u0026#34;s.id\u0026#34; ref=\u0026#34;students\u0026#34;\u0026gt; {{ s.name }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;button @click=\u0026#34;changeStyle\u0026#34;\u0026gt;点击查看 students\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   组件上的ref 模板引用也可以被用在一个子组件上；这种情况下引用中获得的值是组件实例\n 如果子组件使用的是 选项式API，默认情况下父组件可以随意访问子组件的数据和函数， 除非在子组件使用 expose 选项来暴露特定的数据或函数\n例子：\n\u0026mdash;- 子组件中：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  \u0026lt;script\u0026gt; //选项式API，默认情况父组件可以随意访问该子组件的数据和函数 export default { data: () =\u0026gt; ({ account: \u0026#34;abc123\u0026#34;, password: \u0026#34;123321\u0026#34;, }), methods: { toLogin() { console.log(\u0026#34;登录中...\u0026#34;); }, }, //只暴露指定的数据、函数等  expose: [\u0026#34;account\u0026#34;, \u0026#34;toLogin\u0026#34;], }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; 账号：\u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;account\u0026#34; /\u0026gt; 密码：\u0026lt;input type=\u0026#34;password\u0026#34; v-model=\u0026#34;password\u0026#34; /\u0026gt; \u0026lt;button @click=\u0026#34;toLogin\u0026#34;\u0026gt;登录\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt;\u0026lt;/style\u0026gt;   \u0026mdash;- 父组件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  \u0026lt;script\u0026gt; import LoginVue from \u0026#34;./components/Login.vue\u0026#34;; export default { components: { LoginVue }, data: () =\u0026gt; ({ login_vue: null, }), methods: { showSonData() { console.log(\u0026#34;页面渲染后的方法\u0026#34;); console.log(this.login_vue.account); console.log(this.login_vue.password); }, }, mounted() { this.login_vue = this.$refs.loginView; }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h3\u0026gt;登陆界面\u0026lt;/h3\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;!-- 组件上的ref值为该组件的实例 --\u0026gt; \u0026lt;LoginVue ref=\u0026#34;loginView\u0026#34; /\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;button @click=\u0026#34;showSonData\u0026#34;\u0026gt;查看子组件中的信息\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   如果子组件使用的是组合式API\u0026lt;script setup\u0026gt; ，那么该子组件默认是私有的，则父组件无法访问该子组件，除非子组件在其中通过defineExpose宏显式暴露特定的数据或函数\n组合式API的例子：\n\u0026mdash;- 子组件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026lt;script setup\u0026gt; import { ref } from \u0026#34;vue\u0026#34;; let account = ref(\u0026#34;abc123\u0026#34;); let password = ref(\u0026#34;123321\u0026#34;); function toLogin() { console.log(\u0026#34;登录中...\u0026#34;); } defineExpose({ account, toLogin, }); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; 账号：\u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;account\u0026#34; /\u0026gt; 密码：\u0026lt;input type=\u0026#34;password\u0026#34; v-model=\u0026#34;password\u0026#34; /\u0026gt; \u0026lt;button @click=\u0026#34;toLogin\u0026#34;\u0026gt;登录\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   \u0026mdash;- 父组件中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026lt;script setup\u0026gt; import { ref } from \u0026#34;vue\u0026#34;; import LoginVue from \u0026#34;./components/Login.vue\u0026#34;; let loginView = ref(null); function showSonData() { console.log(\u0026#34;页面渲染后的方法\u0026#34;); console.log(loginView.value.account); console.log(loginView.value.password); } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h3\u0026gt;登陆界面\u0026lt;/h3\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;!-- 组件上的ref值为该组件的实例 --\u0026gt; \u0026lt;LoginVue ref=\u0026#34;loginView\u0026#34; /\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;button @click=\u0026#34;showSonData\u0026#34;\u0026gt;查看子组件中的信息\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   路由 Vue Rounter vue-router 是 vue.js 官方给出的路由解决方案，能名轻松的管理 SPA 项目中组件的切换\n安装：\n1  npm install vue-router@4    src下面创建views目录，用于放置视图页面\n//src/views/HomeViews.vue 内容  1 2 3 4 5 6 7 8 9  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;home\u0026#34;\u0026gt;网站首页界面\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; div.home { background-color: cyan; } \u0026lt;/style\u0026gt;   //src/views/BlogHomeView.vue 内容\n1 2 3 4 5 6 7 8  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;blog\u0026#34;\u0026gt;网站首页界面\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; div.blog { background-color: yellow; } \u0026lt;/style\u0026gt;   创建路由模块  在项目中的src文件夹中创建一个router 文件夹，在其中创建 index.js 模块 采用 createRouter() 创建路由，并暴露出去 在main.js文件中初始化路由模块 app.use(routerin)  router/index.js内容如下：\n1 2 3 4 5 6 7  import { createRouter } from \u0026#34;vue-router\u0026#34;; //创建路由对象 const router=createRouter({}) //将路由对象暴露出去 export default router   main.js内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  import \u0026#39;./assets/main.css\u0026#39; import { createApp } from \u0026#39;vue\u0026#39; import App from \u0026#39;./App.vue\u0026#39; //引入路由模块(如果文件名字为index. 则默认只需要写在目录地址即可) import router from \u0026#39;./router\u0026#39; const app=createApp(App) //初始化路由模块 app.use(router) app.mount(\u0026#39;#app\u0026#39;)   规定路由模式 history路由模式可采用：\n createWebHashHistory() ：Hash模式\na. 它在内部传递的实际URL之前使用了一个哈希字符 # ,如 https://example.com/#/user/id\nb. 由于这部分URL从未被发送到服务器，所以它不需要在服务器层面上进行任何特殊处理 createWebHistory()：html5模式（推荐）\na. 当使用这种历史模式时,URL会看起来很\u0026rsquo;正常'，如 https://example.com/user/id\nb. 由于我们的应用是一个单面的客户端应用，如果没有适当的服务器配置，用户浏览https://example.com/user/id就会404；\n解决这个问题：在服务器上添加 一个简单的回退路由 try_files $uri $uri/ /index.html;（二级目录用：try_files $uri $uri/ /report/index.html;），如果URL不匹配任何资源，应提供与你的应用程序中的index.html相同的页面  使用路由规则 routes 配置路由规则\n path :路由分配的 URL name :当路由指向此页面时显示的名字 component ：路由调用这个页面时加载的组件  router/index.js中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import { createRouter, createWebHistory } from \u0026#34;vue-router\u0026#34;; import BlogHomeView from \u0026#39;@/views/BlogHomeView.vue\u0026#39; //路由规则 const routes=[ { path:\u0026#39;/home\u0026#39;,//路由地址 name:\u0026#39;home\u0026#39;,//路由名称 component:()=\u0026gt;import(\u0026#39;@/views/HomeView.vue\u0026#39;) //切换路由地址时展示的组件  }, { path:\u0026#39;/blog\u0026#39;,//路由地址 name:\u0026#39;blog\u0026#39;,//路由名称 component:BlogHomeView } ] //创建路由对象 const router=createRouter({ history:createWebHistory(), //采用html5路由模式 routes }) //将路由对象暴露出去 export default router   App.vue 中：\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;script setup\u0026gt; import { ref } from \u0026#34;vue\u0026#34;; import router from \u0026#34;./router\u0026#34;; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;router-link to=\u0026#34;/home\u0026#34;\u0026gt;首页\u0026lt;/router-link\u0026gt; | \u0026lt;router-link to=\u0026#34;/blog\u0026#34;\u0026gt;博客\u0026lt;/router-link\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;router-view /\u0026gt; \u0026lt;/template\u0026gt;   重定向 可采用 redirect 重定向\n1 2 3 4 5 6  const routes=[ { path:\u0026#39;/\u0026#39;, redirect:\u0026#39;/home\u0026#39;//重定向地址  }, 】   嵌套路由(二级目录) 三点：\n 父级页面添加 \u0026lt;router-view /\u0026gt; 父级页面连接地址 /school/math 路由配置children=\u0026gt;path、name、component\n例子如下：\nSchoolHomeView.vue 中内容：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;school\u0026#34;\u0026gt; 学堂首页界面 \u0026lt;router-link to=\u0026#34;/school/english\u0026#34;\u0026gt;英文\u0026lt;/router-link\u0026gt; | \u0026lt;router-link to=\u0026#34;/school/math\u0026#34;\u0026gt;数学\u0026lt;/router-link\u0026gt; \u0026lt;router-view /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; div.school { padding: 20px; background-color: orange; } \u0026lt;/style\u0026gt;   路由配置文件 router/index.js地址的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import { createRouter, createWebHistory } from \u0026#34;vue-router\u0026#34;; import BlogHomeView from \u0026#39;@/views/BlogHomeView.vue\u0026#39; import SchoolHomeView from \u0026#39;@/views/SchoolHomeView.vue\u0026#39; import EnglishView from \u0026#39;@/views/school/EnglishView.vue\u0026#39; import MathView from \u0026#39;@/views/school/MathView.vue\u0026#39; //路由规则 const routes=[ { path:\u0026#39;/school\u0026#39;,//路由地址  name:\u0026#39;school\u0026#39;,//路由名称  component:SchoolHomeView, //嵌套路由，下面要展示的组件需要在父级路由的组件中(router-view)进行展示  children:[ { path:\u0026#39;english\u0026#39;,//注意：嵌套路由中的path不能以“/”开头  name:\u0026#39;school-english\u0026#39;, component:EnglishView }, { path:\u0026#39;math\u0026#39;,//注意：嵌套路由中的path不能以“/”开头  name:\u0026#39;school-math\u0026#39;, component:MathView }, ] } ] //创建路由对象 const router=createRouter({ history:createWebHistory(), //采用html5路由模式  routes }) //将路由对象暴露出去 export default router   获取url路由的参数 路由index.js中，路由加 `:id：\n1 2 3 4 5  { path:\u0026#39;/blog-content/:id\u0026#39;,//获取参数  name:\u0026#39;blog-content\u0026#39;, component:BlogContent }    在选项式API JS中采用 this.$route.params 来访问，试图模板上采用 $route.params来访问  1 2 3 4 5 6 7  \u0026lt;script\u0026gt; console.log(this.$route.params) console.log(this.$route.params.id) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; {{ $route.params }} \u0026lt;/template\u0026gt;   在组合式API中，需要 import { useRoute } from 'vue-router' ，JS和视图模板上通过userRoute().params 来访问  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  \u0026lt;script setup\u0026gt; import { useRoute } from \u0026#34;vue-router\u0026#34;; const routObj = useRoute(); const paramsData = defineProps([\u0026#34;id\u0026#34;]); function getParams() { console.log(routObj.params); console.log(routObj.params.id); console.log(paramsData.id); } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;home\u0026#34;\u0026gt;博客的详情\u0026lt;/div\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;{{ routObj.params }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;{{ routObj.params.id }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;{{ id }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;button @click=\u0026#34;getParams\u0026#34;\u0026gt;获取js中的内容\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; div.home { padding: 20px; background-color: cyan; } \u0026lt;/style\u0026gt;   还可以通过在路由规则上添加 props:true，将路由参数传递给组件的 props 中  1 2 3 4 5 6 7 8 9  //props:true, { path:\u0026#39;/blog-content/:id\u0026#39;,//路由地址  name:\u0026#39;blog-content\u0026#39;,//路由名称  props:true, //将路由参数动态传给组件的 `props`选项  component:BlogContent } //在模板中直接可以用id {{ id }}   声明式和编程式导航  声明式：  1  \u0026lt;router-link to=\u0026#34;/school/math\u0026#34;\u0026gt;数学\u0026lt;/router-link\u0026gt;    编程式：push   选项式API：this.router.push(\u0026hellip;) 或者模板中 $router.push(\u0026hellip;)  1 2 3 4 5 6 7  \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;$router.push(\u0026#39;/school/math\u0026#39;)\u0026#34;\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;$router.push({ path:\u0026#39;/blog\u0026#39; })\u0026#34;)\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;$router.push({ name:\u0026#39;school\u0026#39;})\u0026#34;)\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;$router.push({ name:\u0026#39;school\u0026#39; , params:{ id:119 } })\u0026#34;\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   组合式API：  1 2 3 4 5 6 7  \u0026lt;script setup\u0026gt; import { useRouter } from \u0026#34;vue-router\u0026#34;; const routerObj = useRouter(); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;routerObj.push(\u0026#39;/school\u0026#39;)\u0026#34;\u0026gt;学堂\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   声明式和编程式 替换  声明式：\n返回上一页是当前页面\n  1  \u0026lt;router-link to=\u0026#34;/school/math\u0026#34; replace\u0026gt;数学\u0026lt;/router-link\u0026gt;    编程式：replace   选项式API：this.router.push(\u0026hellip;) 或者模板中 $router.push(\u0026hellip;)  1 2 3 4 5 6 7 8  \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;$router.replace(\u0026#39;/school/math\u0026#39;)\u0026#34;\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;$router.replace({ path:\u0026#39;/blog\u0026#39; }\u0026#34;)\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;$router.replace({ name:\u0026#39;school\u0026#39;}\u0026#34;)\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;$router.replace({ name:\u0026#39;school\u0026#39; , params:{ id:119} })\u0026#34;\u0026gt;\u0026lt;/button\u0026gt; //replace:true  \u0026lt;button @click=\u0026#34;$router.push({ name:\u0026#39;school\u0026#39; , params:{ id:119 }, replace:true})\u0026#34;\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   组合式API：  1 2 3 4 5 6 7  \u0026lt;script setup\u0026gt; import { useRouter } from \u0026#34;vue-router\u0026#34;; const routerObj = useRouter(); \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;routerObj.replace(\u0026#39;/school\u0026#39;)\u0026#34;\u0026gt;学堂\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt;   路由历史 参数 n 表示前进或后退步数\nn :\nrouter.go(1) 前进一步 ，相当于 router.forward()\nrouter.go(-1) 后退一步 ，相当于 router.back()\n如果没有历史记录，什么都不发生\n 选项式API  1  this.$router.go(n)   组合式API  1  useRouter().go(n)   导航守卫 种类：\n 全局前置守卫 全局解析守卫 全局后置守卫 路由独享守卫 组件内的守卫  全局前置守卫 注册全局 前置守卫\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026lt;script\u0026gt; //创建路由对象 const router=createRouter({ history:createWebHistory(), //采用html5路由模式  routes }) //..........  //注册全局 前置守卫 //to :将要访问的路由信息对象 //from :将要离开的路由信息对象 router.beforeEach((to,from,next)=\u0026gt;{ //判断要访问的路由是否需要用户登录  if(to.meta.isLogin){ //获取存储对象  let userLogin=localStorage.getItem(\u0026#39;loginUser\u0026#39;) //判断用户是否已经登录了  if(userLogin==null){ //未登录 --\u0026gt; 跳转至登录页  return next({path:\u0026#39;/login\u0026#39;}) } } return next() }) //将路由对象暴露出去 export default router //.......... \u0026lt;/script\u0026gt;   存储对象到本地\n1 2 3 4 5  \u0026lt;script\u0026gt; localStorage.setItem(\u0026#39;loginUser\u0026#39;,JSON.stringify(user)) localStorage.getItem(\u0026#39;loginUser\u0026#39;) localStorage.removeItem(\u0026#39;loginUser\u0026#39;) \u0026lt;/script\u0026gt;   1 2 3  \u0026lt;script\u0026gt; localStorage.setItem(\u0026#39;user\u0026#39;,JSON.stringify(user)) \u0026lt;/script\u0026gt;   是不是登录判断跳转\u0026raquo;\u0026gt;\nsrc/views/LoginView.vue 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  \u0026lt;script setup\u0026gt; import { reactive } from \u0026#34;vue\u0026#34;; const user = reactive({ account: \u0026#34;\u0026#34;, password: \u0026#34;\u0026#34;, }); function toLogin() { localStorage.setItem(\u0026#34;loginUser\u0026#34;, JSON.stringify(user)); alert(\u0026#34;登录成功\u0026#34;); } function loginOut() { localStorage.removeItem(\u0026#34;loginUser\u0026#34;); alert(\u0026#34;注销成功\u0026#34;); } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;login\u0026#34;\u0026gt;登录界面\u0026lt;/div\u0026gt; \u0026lt;hr /\u0026gt; 账号：\u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;user.account\u0026#34; /\u0026gt;\u0026lt;br /\u0026gt; 密码:\u0026lt;input type=\u0026#34;text\u0026#34; v-model=\u0026#34;user.password\u0026#34; /\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;button @click=\u0026#34;toLogin\u0026#34;\u0026gt;登录\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026#34;loginOut\u0026#34;\u0026gt;注销\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; div.login { padding: 20px; background-color: rgb(138, 112, 242); } \u0026lt;/style\u0026gt;   src/router/index.js 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  \u0026lt;script\u0026gt; import { createRouter, createWebHistory } from \u0026#34;vue-router\u0026#34;; import BlogHomeView from \u0026#39;@/views/BlogHomeView.vue\u0026#39; import SchoolHomeView from \u0026#39;@/views/SchoolHomeView.vue\u0026#39; import EnglishView from \u0026#39;@/views/school/EnglishView.vue\u0026#39; import MathView from \u0026#39;@/views/school/MathView.vue\u0026#39; import BlogContent from \u0026#39;@/views/BlogContentView.vue\u0026#39; import LoginView from \u0026#39;@/views/LoginView.vue\u0026#39; //路由规则 const routes=[ { path:\u0026#39;/\u0026#39;, redirect:\u0026#39;/home\u0026#39;//重定向地址  }, { path:\u0026#39;/home\u0026#39;,//路由地址  name:\u0026#39;home\u0026#39;,//路由名称  component:()=\u0026gt;import(\u0026#39;@/views/HomeView.vue\u0026#39;) //切换路由地址时展示的组件  }, { path:\u0026#39;/blog\u0026#39;,//路由地址  name:\u0026#39;blog\u0026#39;,//路由名称  meta:{isLogin:true}, component:BlogHomeView }, { path:\u0026#39;/school\u0026#39;,//路由地址  name:\u0026#39;school\u0026#39;,//路由名称  meta:{isLogin:true}, component:SchoolHomeView, //嵌套路由，下面要展示的组件需要在父级路由的组件中(router-view)进行展示  children:[ { path:\u0026#39;english\u0026#39;,//注意：嵌套路由中的path不能以“/”开头  name:\u0026#39;school-english\u0026#39;, component:EnglishView }, { path:\u0026#39;math\u0026#39;,//注意：嵌套路由中的path不能以“/”开头  name:\u0026#39;school-math\u0026#39;, component:MathView }, ] }, { path:\u0026#39;/blog-content/:id\u0026#39;,//路由地址  name:\u0026#39;blog-content\u0026#39;,//路由名称  props:true, meta:{isLogin:true}, component:BlogContent }, { path:\u0026#39;/login\u0026#39;,//路由地址  name:\u0026#39;login\u0026#39;,//路由名称  component:LoginView }, ] //创建路由对象 const router=createRouter({ history:createWebHistory(), //采用html5路由模式  routes }) //注册全局 前置守卫 //to :将要访问的路由信息对象 //from :将要离开的路由信息对象 router.beforeEach((to,from,next)=\u0026gt;{ console.log(to) console.log(to.path) //判断要访问的路由是否需要用户登录  if(to.meta.isLogin){ //获取存储对象  let userLogin=localStorage.getItem(\u0026#39;loginUser\u0026#39;) //判断用户是否已经登录了  if(userLogin==null){ //未登录 --\u0026gt; 跳转至登录页  return next({path:\u0026#39;/login\u0026#39;}) } } return next() }) //将路由对象暴露出去 export default router \u0026lt;/script\u0026gt;   状态管理库Pinia 安装与使用 安装：\n1  npm install pinia   使用：\n在src/main.js中：\n1 2 3  import {createPinia} from \u0026#39;pinia\u0026#39; //创建pinia(根存储)，并且应用到整个应用中 app.use(createPinia())   Store  store 是一个保存状态和业务逻辑的实体，它并不与组件树绑定，它承载着全局状态；它永远存在，每个组件都可以读取和写入它 store 有三个概念，state、getters 和 actions ，我们可以理解成组件中的 data、computed 和 methods 在项目中的 src\\store 文件夹下不同的 store.js 文件  语法：\ndefineStore(name,function|options) 定义的，建议其函数返回的值命名为 use\u0026hellip;Store 方便理解\n选项式API写法：\n1 2 3 4 5 6 7 8 9 10  import { defineStore } from \u0026#39;pinia\u0026#39; //创建一个store，并暴露出去 //参数 1：名称，保证唯一 //参数 2：对象形式（选项式） export const useStor=defineStore(\u0026#39;main\u0026#39;,{ state:()=\u0026gt;({}), //共享的数据  getters:{}, //通过计算得到的共享数据  actions:{} //共享的函数 })   组件式API写法：\n1 2 3 4 5 6 7 8 9  export const useStore=defineStore(\u0026#39;main\u0026#39;,()=\u0026gt;{ //ref 变量 --\u0026gt; 共享的数据  //computed() --\u0026gt;通过计算得到的共享数据  //function() --\u0026gt; 共享的函数  return { //返回组件需要的：变量、计算属性、函数  } })   state 语法：\nmapState( storeObj , array | object )\n获取state中的值：mapState\n思路整理:\n 步骤一：在xxxStore.js中设置一些共享数据 export const useUserStore = defineStore(\u0026lsquo;user\u0026rsquo;,{xxx}) 步骤二：vue页面引入 useUserStore , 动态获取 const u = useUserStore(); 步骤三：使用 computed 获取对象中的变量值  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  //--步骤一-- export const useUserStore = defineStore(\u0026#39;user\u0026#39;,{ state:()=\u0026gt;({ age:10, level:5, nickname:\u0026#39;wjb\u0026#39;, account:\u0026#39;SCD273\u0026#39; }), //通过计算得到的新的共享的数据，只读  //如果依赖的数据发生变化，则会重新计算  getters:{ month(){ return this.birthday.split(\u0026#39;-\u0026#39;) }, ageStage:(state)=\u0026gt;{ } } }) //--步骤二-- \u0026lt;script\u0026gt; import { mapState, mapWritableState } from \u0026#34;pinia\u0026#34;; import { useUserStore } from \u0026#34;./store/useUserStore\u0026#34;; import { computed } from \u0026#34;vue\u0026#34;; const u = useUserStore(); const u_age = computed(() =\u0026gt; { u.age; }); const u_level = computed(() =\u0026gt; { u.level; }); const u_nickname = computed(() =\u0026gt; { u.nickname; }); const { age, level } = storeToRefs(u); \u0026lt;/script\u0026gt;   demo例子如下：\nsrc/store/useUserStore.js内容：\n1 2 3 4 5 6 7 8 9 10  import {defineStore} from \u0026#39;pinia\u0026#39; export const useUserStore = defineStore(\u0026#39;user\u0026#39;,{ state:()=\u0026gt;({ age:10, level:5, nickname:\u0026#39;wjb\u0026#39;, account:\u0026#39;SCD273\u0026#39; }) })   src/App.vue内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026lt;script\u0026gt; import { mapState } from \u0026#34;pinia\u0026#34;; import { useUserStore } from \u0026#34;./store/useUserStore\u0026#34;; export default { computed: { ...mapState(useUserStore, [\u0026#34;age\u0026#34;, \u0026#34;level\u0026#34;]), ...mapState(useUserStore, { user_account: \u0026#34;account\u0026#34;, user_nickname: \u0026#34;nickname\u0026#34;, }), }, }; \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;{{ this.age }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;{{ level }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;{{ user_account }}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;{{ user_nickname }}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/template\u0026gt;   修改state 映射的值 mapWritableState \u0026hellip;mapWritableState(useUserStore, [\u0026ldquo;account\u0026rdquo;, \u0026ldquo;nickname\u0026rdquo;]),`\ncomputed: { //mapState：将store的state映射成当前组件的计算属性 //具有响应式，但是是只读 //字符串数组形式，不能自定义计算属性名 //对象形式：可以自定义计算属性名 ...mapState(useUserStore, [\u0026quot;age\u0026quot;, \u0026quot;level\u0026quot;]), ...mapState(useUserStore, { user_account: \u0026quot;account\u0026quot;, user_nickname: \u0026quot;nickname\u0026quot;, }), ...mapWritableState(useUserStore, [\u0026quot;account\u0026quot;, \u0026quot;nickname\u0026quot;]), }, }; 从 store 解构想要的 state:\nstoreToRefs : 既有自己的属性，又是响应式\n1  const { age, level,account:userAccount } = storeToRefs(u);   getters 思路整理:\n 步骤一：在xxxStore.js中设置一些共享计算的数据  1 2 3 4 5 6 7 8 9  getters:{ month(){ return this.birthday.split(\u0026#39;-\u0026#39;) }, ageStage:(state)=\u0026gt;{ } }   步骤二：vue页面引入 useUserStore , 动态获取  1 2 3 4 5 6 7 8 9 10 11 12 13 14  export default { computed: { //mapState：将store的state映射成当前组件的计算属性  //具有响应式，但是是只读  //字符串数组形式，不能自定义计算属性名  //对象形式：可以自定义计算属性名  ...mapState(useUserStore, [\u0026#34;age\u0026#34;, \u0026#34;level\u0026#34;]), ...mapState(useUserStore, { user_account: \u0026#34;account\u0026#34;, user_nickname: \u0026#34;nickname\u0026#34;, }), ...mapWritableState(useUserStore, [\u0026#34;account\u0026#34;, \u0026#34;nickname\u0026#34;]), }, };   步骤三：使用 computed 获取对象中的变量值  js中内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;script\u0026gt; //通过计算得到的新的共享的数据，只读 //如果依赖的数据发生变化，则会重新计算 getters:{ month(){ return this.birthday.split(\u0026#39;-\u0026#39;) }, ageStage:(state)=\u0026gt;{ } } \u0026lt;/script\u0026gt;   vue中内容：\n从 store 取getters 和 取 state 用法相同，都可以使用 mapState\n具有响应式\n1  ..mapState(useUserStore, [\u0026#34;month\u0026#34;, \u0026#34;ageStage\u0026#34;]),   actions 思路整理:\n 定义共享数据 设置actions修改共享数据  1 2 3 4 5 6 7 8 9 10 11 12 13  export const useUserStore = defineStore(\u0026#39;user\u0026#39;,{ state:()=\u0026gt;({ age:10, nickname:\u0026#39;wjb\u0026#39;, }), actions:{ setUserStore(nickname,age){ //当前state中的数据  this.nickname=nickname this.age=age } } })    选项式API中访问js中的共享数据actions   使用 mapActions 将 store 中的 actions 映射为自己的函数 字符串数组模式，不可以自定义函数名 对象模式，可以自定义函数名  1 2 3 4 5 6 7 8 9  methods:{ //使用 mapActions 将 store 中的 actions 映射为自己的函数  //字符串数组模式，不可以自定义函数名  //对象模式，可以自定义函数名  ...mapActions(useUserStore,[\u0026#39;setUserInfo\u0026#39;], ...mapActions(useUserStore,{ set_user_object:\u0026#39;setUserInfoByObject\u0026#39; }) }    组合式API中访问js中的共享数据actions\n将 store 中的 actions 解构成自己的函数 可自定义函数(不得使用storeToRefs)  1 2 3 4 5 6 7  //store 实例 const user_store = useUserStore(); const { nickname, age } = storeToRefs(user_store); //将 store 中的 actions 解构成自己的函数 可自定义函数(不得使用storeToRefs) const { setUserStore } = useUserStore;   请求库Axios  Axios 是一个基于 promise 网络请求库，作用于 node.js 和 浏览器 中 Axios 在服务端它使用原生 node.js http 模块，而在客户端(浏览端) 则使用 XMLHttpRequests Axios 可以拦截请求和响应、转换请求和响应数据、取消请求、自动转换 JSON 数据 Axios 安装方式： npm install axios  Axios配置项 这些是创建请求时最常用的配置选项； 详细的配置项请前往 Axios 官网\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  { url: \u0026#34;/user\u0026#34;, //请求的服务器地址URL  method: \u0026#34;GET\u0026#34;, //请求方式，默认值GET  baseURL: \u0026#34;https://some-domain.com/api\u0026#34;, //如果url不是绝对地址，则会发送  headers: { \u0026#34;X-Requested-With\u0026#34;: \u0026#34;XMLHttpRequest\u0026#34; }, //自定义请求头  params: { ID: 12345 }, //与请求一起发送的URL参数  data: { firstName: \u0026#34;Fred\u0026#34; }, //作为请求体被发送的数据，仅适用\u0026#39;PUT\u0026#39;,\u0026#39;POST\u0026#39;,\u0026#39;DELETE\u0026#39;和\u0026#39;PATCH\u0026#39;请求方法  timeout: 1000, //请求超时的毫秒数，默认为0（永不超时）  responseType: \u0026#34;json\u0026#34;, //期望服务器返回的数据类型，选项包括：\u0026#39;arraybuffer\u0026#39;,\u0026#39;document\u0026#39;,\u0026#39;json\u0026#39;,\u0026#39;text\u0026#39;,\u0026#39;stream\u0026#39;,浏览器专属：\u0026#39;blob\u0026#39;,默认\u0026#39;json\u0026#39;  //允许在向服务器发送前，修改请求数据，它只能用于\u0026#39;PUT\u0026#39;,\u0026#39;POST\u0026#39;,\u0026#39;PATCH\u0026#39;这几个请求方法  transformRequest: [ function (data, headers) { return data; //对发送的 data 进行任意转换处理  }, ], //在传递给 then/catch 前，允许修改响应数据  transformResponse: [ function (data) { return data; //对接收的data进行任意转换处理  }, ], }   跨域问题 同源策略：是指协议，域名，端口都要相同，其中有一个不同都会产生跨域\nvite.config.js中配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  export default defineConfig({ plugins: [ vue(), ], resolve: { alias: { \u0026#39;@\u0026#39;: fileURLToPath(new URL(\u0026#39;./src\u0026#39;, import.meta.url)) } }, server:{ proxy:{ \u0026#39;/apisace\u0026#39;:{ target:\u0026#39;https://eolink.o.apispace.com/history-weather/query\u0026#39;, changeOrigin:true, rewrite:path=\u0026gt;path.replace(/^\\/apispace/,\u0026#39;\u0026#39;) } } } })   使用方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;script setup\u0026gt; import { axios } from \u0026#34;axios\u0026#34;; function getCityWeather() { axios({ method: \u0026#34;GET\u0026#34;, url: \u0026#34;/apisace\u0026#34;, }) .then((response) =\u0026gt; { console.log(); }) .catch((error) =\u0026gt; { alert(\u0026#34;服务器异常\u0026#34;); }); } \u0026lt;/script\u0026gt;   ","description":"Vue.js是一种流行的JavaScript前端框架，用于构建用户界面。它是一种渐进式框架，可以逐步应用到项目中，也可以与其他库或现有项目进行整合。","id":12,"section":"stack","tags":["javascript",""],"title":"vue3框架","uri":"http://wangjinbao.netlify.app/en/stack/javascript/vue1/"},{"content":"例子1 自定义属性、事件 src/App.vue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  \u0026lt;script setup\u0026gt; import Product from \u0026#34;./components/Product.vue\u0026#34;; import { ref } from \u0026#34;vue\u0026#34;; let shopCar = ref([ { id: 89, title: \u0026#34;ROG幻16 2023 第13代英特尔酷睿i9 16英寸 星云屏\u0026#34;, subtitle: \u0026#34;设计师轻薄高性能游戏本笔记本电脑(i9-13900H 16G 1T RTX4060 2.5K 240HzP3广色域)灰\u0026#34;, image: \u0026#34;https://img10.360buyimg.com/n1/jfs/t1/191391/18/41888/113687/64e5711cF1c35de3a/d15c1c04d114b810.jpg\u0026#34;, price: 1000, count: 1, selected: false, }, { id: 102, title: \u0026#34;机械革命无界14Pro\u0026#34;, subtitle: \u0026#34;(R7-7840HS 16G 1T 120Hz 2.8K 高色域)轻薄本办公商务本游戏本笔记本电脑\u0026#34;, image: \u0026#34;https://img11.360buyimg.com/n7/jfs/t1/88945/40/31886/150051/64f68461Ffa336065/b4b16f0597a24d21.jpg\u0026#34;, price: 2000, count: 1, selected: false, }, { id: 108, title: \u0026#34;联想（Lenovo）拯救者Y7000P\u0026#34;, subtitle: \u0026#34;13代酷睿i7 2023游戏笔记本电脑 16英寸(13代i7-13620H 16G 1T RTX4050 2.5K 165Hz高色域屏)灰\u0026#34;, image: \u0026#34;https://img12.360buyimg.com/n1/s450x450_jfs/t1/180461/29/38082/115800/650188f9Fab57feb5/dba4651979f21c8a.jpg\u0026#34;, price: 3000, count: 1, selected: true, }, ]); //产品的状态发生改变 function changeShopCarProductChecked(checked, id) { console.log(checked); console.log(id); shopCar.value.some((product) =\u0026gt; { if (id === product.id) { console.log(product); product.selected = checked; return true; } }); } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;Product v-for=\u0026#34;product in shopCar\u0026#34; :key=\u0026#34;product.id\u0026#34; :id=\u0026#34;product.id\u0026#34; :pictrue=\u0026#34;product.image\u0026#34; :title=\u0026#34;product.title\u0026#34; :subtitle=\u0026#34;product.subtitle\u0026#34; :price=\u0026#34;product.price\u0026#34; :count=\u0026#34;product.count\u0026#34; :is-checked=\u0026#34;product.selected\u0026#34; @change-product-checked=\u0026#34;changeShopCarProductChecked\u0026#34; /\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; } * { margin: 0; padding: 0; } \u0026lt;/style\u0026gt;   components/Product.vue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91  \u0026lt;script setup\u0026gt; //自定义属性 let propsData = defineProps({ id: { type: Number, required: true }, isChecked: Boolean, //是否被选中  pictrue: { type: String, required: true }, title: { type: String, required: true }, subtitle: { type: String, required: true }, price: { type: Number, default: 0 }, count: { type: Number, default: 0 }, }); //自定义事件 let emits = defineEmits([ \u0026#34;changeProductChecked\u0026#34;, //改变复选框的状态事件 ]); //改变产品选中的状态 function changeCheckedState(e) { // console.log(e.target.checked);  let newCheckedState = e.target.checked; emits(\u0026#34;changeProductChecked\u0026#34;, newCheckedState, propsData.id); } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;!-- 产品容器 --\u0026gt; \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt; \u0026lt;!-- 选项框 --\u0026gt; \u0026lt;input type=\u0026#34;checkbox\u0026#34; class=\u0026#34;p_checkbox\u0026#34; :checked=\u0026#34;isChecked\u0026#34; @change=\u0026#34;changeCheckedState\u0026#34; /\u0026gt; \u0026lt;!-- 产品图片 --\u0026gt; \u0026lt;img class=\u0026#34;p_image\u0026#34; :src=\u0026#34;pictrue\u0026#34; /\u0026gt; \u0026lt;!-- 产品内容 --\u0026gt; \u0026lt;div class=\u0026#34;p_content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{{ title }}\u0026lt;/h3\u0026gt; \u0026lt;span class=\u0026#34;p_title\u0026#34;\u0026gt;{{ subtitle }}\u0026lt;/span\u0026gt; \u0026lt;h2 style=\u0026#34;color: red\u0026#34;\u0026gt;￥ {{ price }}\u0026lt;/h2\u0026gt; \u0026lt;div class=\u0026#34;p_area\u0026#34;\u0026gt; \u0026lt;button\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;span\u0026gt;{{ count }}\u0026lt;/span\u0026gt; \u0026lt;button\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style\u0026gt; #app { width: 100%; } .box { box-shadow: 0 0 8px gray; /* width: 100%; */ padding: 20px; margin: 15px; display: flex; align-items: center; position: relative; } .p_checkbox { width: 25px; height: 25px; margin-right: 20px; } .p_image { width: 120px; height: 120px; margin: 0 auto; } .p_content { align-self: start; } .p_title { margin: 10px 10px; } .p_area { position: absolute; bottom: 5px; right: 5px; } .p_area button { width: 20px; height: 20px; } \u0026lt;/style\u0026gt;   ","description":"Vue.js是一种流行的JavaScript前端框架，用于构建用户界面。它是一种渐进式框架，可以逐步应用到项目中，也可以与其他库或现有项目进行整合。","id":13,"section":"stack","tags":["javascript",""],"title":"vue3简单例子","uri":"http://wangjinbao.netlify.app/en/stack/javascript/demo/"},{"content":"常用方式如下三种： 1.源代码中增加debugger 或 console.log 2.在Chrome浏览器Source中加断点 3.vscode中直接调试，对源码定位准确直观 Vscode的Debug配置 1.安装拓展插件 Debugger for Chrome（停更）\n所以安的 JavaScript Debugger\n生成模板debug配置，后面会再重新配置：\n点击debug按钮 -\u0026gt; Run and Debug -\u0026gt; Chrome\n2.在配置文件中添加：devtool: \u0026lsquo;source-map\u0026rsquo; 找到项目的配置文件，把devtool改为\u0026rsquo;source-map\u0026rsquo;配置\nvue2:\n1 2 3 4 5  module.exports = { dev: { devtool: \u0026#39;source-map\u0026#39;, } }   vue3\n1 2 3 4 5 6 7  module.exports = { chainWebpack: (config) =\u0026gt; { if (isDev) { config.devtool(\u0026#39;source-map\u0026#39;) } } }   也可以通过 configureWebpack: { devtool: \u0026lsquo;source-map\u0026rsquo; }进行配置，方式多种\n3.配置vscode\\launch.json文件 在项目根目录下配置.vscode/launch.json 文件，具体配置 vscode-chrome-debug 插件有详细描述，我的配置如下：vscode\n默认生成的 launch.json 是没有 ：\u0026ldquo;webpack:///./src/\u0026quot;: \u0026ldquo;${webRoot}/\u0026quot;，我的打断点是灰色就是这里导致的。\n通过修改配置让vscode 知道 webpack 调试的文件对应项目的本地文件。问题解决。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  { // 使用 IntelliSense 了解相关属性。  // 悬停以查看现有属性的描述。  // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387  \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;chrome\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;vuejs: chrome\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:8028\u0026#34;, \u0026#34;webRoot\u0026#34;: \u0026#34;${workspaceFolder}/src\u0026#34;, \u0026#34;sourceMapPathOverrides\u0026#34;: { \u0026#34;webpack:///src/*\u0026#34;: \u0026#34;${webRoot}/*\u0026#34;, \u0026#34;webpack:///./src/*\u0026#34;: \u0026#34;${webRoot}/*\u0026#34; } } ] }   4.添加断点后，启动项目，然后开启debug模式 ","description":"Vue.js是一种流行的JavaScript前端框架，用于构建用户界面。它是一种渐进式框架，可以逐步应用到项目中，也可以与其他库或现有项目进行整合。","id":14,"section":"stack","tags":["javascript",""],"title":"Vue的debug调试","uri":"http://wangjinbao.netlify.app/en/stack/javascript/debugger/"},{"content":"常用样式   vue中默认样式位置   1 2 3  src/assets/main.css src/assets/base.css 如不需要可以注释     清除所有的外边距和内边距   1 2 3 4  *{ margin:0; padding:0; }     并排排列   1 2 3  .box{ display:flex; }     垂直排部   1 2 3  .box{ align-items:center; }     div 竖 排列   设置div的父元素的display为flex，再设置flex-direction为column，即可将div竖排列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026lt;style\u0026gt; .container { display: flex; flex-direction: column; } \u0026lt;br\u0026gt; .box { width: 200px; height: 100px; margin-bottom: 10px; background-color: #f1f1f1; } \u0026lt;/style\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;     自已顶端对齐   1 2 3  .box{ align-self:start; }     左右对称对齐   1 2 3  .container{ justify-content: space-between; }     div中flex文字左右上下居中   1 2 3 4  .container{ justify-content: center; align-items: center; }     div圆角   1  border-radius:8px;     div阴影   1  box-shadow:0 0 5px red;     vscode中添加自动样式   1  插件搜索 AutoScssStruct4Vue     走马灯   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  \u0026lt;!-- 轮播图 --\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;block text-center\u0026#34;\u0026gt; \u0026lt;el-carousel height=\u0026#34;500px\u0026#34;\u0026gt; \u0026lt;el-carousel-item v-for=\u0026#34;item in 4\u0026#34; :key=\u0026#34;item\u0026#34; style=\u0026#34;position: absolute; top: 0px; z-index: 9\u0026#34; \u0026gt; \u0026lt;img src=\u0026#34;https://m.360buyimg.com/babel/jfs/t20260925/7569/37/22520/40263/65122aa8F7db4b1cc/4690718474f0e4b7.jpg\u0026#34; /\u0026gt; \u0026lt;/el-carousel-item\u0026gt; \u0026lt;/el-carousel\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; .c-left { z-index: 8; position: relative; width: 1480px; height: 500px; background: #000; margin: auto; .block { img { width: 100%; height: 500px; } } .text-center { } h3 { } img { width: 100%; height: 500px; } } .demonstration { color: var(--el-text-color-secondary); } .el-carousel__item h3 { color: #475669; opacity: 0.75; line-height: 150px; margin: 0; text-align: center; } .el-carousel__item:nth-child(2n) { background-color: #99a9bf; } .el-carousel__item:nth-child(2n + 1) { background-color: #d3dce6; } \u0026lt;/style\u0026gt;     多div层叠   1 2 3 4 5 6  父类div position: relative; 子类div1 position: absolute; top: 0px; z-index: 10; 子类div2 position: absolute; top: 0px; z-index: 9;     div居中最简单方法   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;pro-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;pro-middle\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; .pro-container { padding: 2vmin; display: flex; .pro-middle { width: 1480px; height: 500px; background: rgb(213, 216, 248); margin: auto; } } \u0026lt;/style\u0026gt;     图片懒加载   自定义命令：v-img-lazy\n1  v-img-lazy     ul li横向排列   1 2 3 4 5 6 7 8 9  \u0026lt;style\u0026gt; ul { list-style: none; } li { display: inline-block; margin-right: 20px; } \u0026lt;/style\u0026gt;     div鼠标悬停阴影   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  .div { width: 240px; height: 240px; /* 设置相对移动 */ position: relative; } .div:hover { /* 移动 */ top: -10px; left: -10px; /* 图片变大 */ transform: scale(1.1); /* 阴影 */ box-shadow: 10px 5px 5px #888888; /* 鼠标变化 */ cursor: pointer; }     动态 div鼠标悬停阴影   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  \u0026lt;style\u0026gt; .goods-item-img { width: 240px; height: 240px; position: relative; box-shadow: 0 8px 12px rgba(0, 0, 0, 0.5); transition: all 0.6s cubic-bezier(0.165, 0.84, 0.44, 1); transform: scale(1); } .goods-item-img::after { border-radius: 5px; position: absolute; z-index: -1; top: 0; left: 0; width: 100%; height: 100%; box-shadow: 0 16px 24px rgba(0, 0, 0, 0.7); opacity: 0; transition: all 0.3s cubic-bezier(0.165, 0.94, 0.94, 1); } .goods-item-img:hover { transform: scale(1.05, 1.05); } .goods-item-img:hover::after { opacity: 1; } \u0026lt;/style\u0026gt;     背景图片充满div   1 2 3 4 5  \u0026lt;style\u0026gt; background: url(\u0026#34;../assets/bg3.webp\u0026#34;) center no-repeat; background-attachment: fixed; background-size: cover; \u0026lt;/style\u0026gt;     element插件中的label样式   1 2 3 4 5 6 7 8  \u0026lt;el-form-item label=\u0026#34;用户名\u0026#34; prop=\u0026#34;username\u0026#34;\u0026gt; \u0026lt;/el-form-item\u0026gt; \u0026lt;style\u0026gt; .el-form-item__label { color: white; } \u0026lt;/style\u0026gt;     element插件中的左对齐   1 2 3 4 5  \u0026lt;style\u0026gt; .demo-form-inline { text-align: left; } \u0026lt;/style\u0026gt;   ","description":"Vue.js是一种流行的JavaScript前端框架，用于构建用户界面。它是一种渐进式框架，可以逐步应用到项目中，也可以与其他库或现有项目进行整合。","id":15,"section":"stack","tags":["javascript",""],"title":"样式技巧","uri":"http://wangjinbao.netlify.app/en/stack/javascript/style/"},{"content":"Airflow概念 Apache Airflow是一个开源的任务调度和工作流管理平台，它使用Python编写。Airflow调度器是Airflow的一个核心组件，负责管理和调度任务的执行。\n1.Airflow调度器的主要功能   任务调度：\nAirflow调度器根据预定义的任务调度依赖关系和时间表，确定何时执行每个任务。它可以处理复杂的工作流调度需求，如依赖关系、并发性和重试策略等。\n  任务执行：\nAirflow调度器将任务分配给可用的执行器（如本地执行器、Celery执行器或Kubernetes执行器），并跟踪任务的状态和执行结果。\n  任务监控和日志记录：\nAirflow调度器监控任务的执行状态，并将任务的日志和元数据存储在后端数据库中，以便后续查询和分析。\n  任务重试和错误处理：\n如果任务执行失败，Airflow调度器可以根据预定义的重试策略自动重试任务。它还提供了一套灵活的错误处理机制，可以定义任务失败时的行为。\n  调度器高可用：\nAirflow调度器支持多个调度器实例之间的高可用性配置，以确保调度器的可用性和容错性。\n  核心概念：\n Dynamic：Airflow配置需要使用Python，允许动态生产管道。这允许编写可动态、实例化管道的代码。 Extensible：轻松定义自己的运算符，执行程序并扩展库，使其适合于您的环境 Elegant：Airflow是精简的，使用功能强大的Jinjia模板引擎，将脚本参数化内置于airflow的核心中 Scalable：Airflow具有模板块架构，并使用消息队列来安排任意数量的工作任务。  2.安装Miniconda conda概念：\n一个开源的包、环境管理器，可用于在同一个机器上切换不同的Python版本的软件包及其依赖，并能在不同的python环境之间切换。\nAnaconda包括Conda、Python 以及一大堆安装好的工具包，比如：numpy、pandas等，Miniconda包括Conda、Python。此外没有如此多的工具包，所以选择Miniconda\n2.1下载 anaconda官网： https://repo.anaconda.com/\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n2.2安装 1  bash Miniconda3-latest-Linux-x86_64.sh   安装过程中，指定安装路径\n2.3加载环境变量配置文件，使之生效 1 2 3  source ~/.bashrc # 退出环境 (base) $conda deactivate   2.4取消激活base环境 miniconda安装完成后，每次打开终端都会激活其默认的base环境，用以下命令，禁止激活默认base环境\n1  conda config --set auto_activate_base false   2.5创建环境 1 2 3  $conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free $conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main $conda config --set show_channel_urls yes   创建python3.8环境\n1  conda create --name airflow python=3.8   说明：conda环境管理常用命令\n创建环境：\n1  conda create -n env_name   查看所有环境：\n1  conda info --envs   删除一个环境：\n1  conda remove -n env_name --all   激活airflow环境：\n1  conda activate airflow   退出airflow环境：\n1 2  conda deactivate python -V   ","description":"Apache Airflow是一个开源的任务调度和工作流管理平台，它使用Python编写，是一个以编程方式编写，安排和监视工作流的平台。","id":16,"section":"stack","tags":["db",""],"title":"airflow调度系统","uri":"http://wangjinbao.netlify.app/en/stack/db/airflow/"},{"content":"简介 Apache DolphinScheduler 旨在解决复杂的大数据任务依赖关系，并为应用程序提供数据和各种 OPS 编排中的关系。 解决数据研发ETL依赖错综复杂，无法监控任务健康状态的问题。 DolphinScheduler 以 DAG（Directed Acyclic Graph，DAG）流式方式组装任务，可以及时监控任务的执行状态，支持重试、指定节点恢复失败、暂停、恢复、终止任务等操作。\n官方地址：\n https://dolphinscheduler.apache.org/zh-cn/\n 常见问题  问题：   Statement.executeQuery() cannot issue statements that do not produ\n  解决:   dolphinscheduler -\u0026gt; SQL类型 \u0026ldquo;非查询\u0026rdquo; \u0026amp;\u0026amp; 分段执行符号 \u0026ldquo;;\u0026rdquo;\n ","description":"Apache DolphinScheduler 是一个分布式易扩展的可视化DAG工作流任务调度开源系统。适用于企业级场景，提供了一个可视化操作任务、工作流和全生命周期数据处理过程的解决方案。","id":17,"section":"stack","tags":["db",""],"title":"dolphinscheduler","uri":"http://wangjinbao.netlify.app/en/stack/db/dolphinscheduler/"},{"content":"窗口函数 窗口函数表达式：\n1 2 3  function(args)OVER([PARTITIONBYexpression][ORDERBYexpression[ASC|DESC]][frame])rank()over(partitionbyxxx分组orderbyxxx排序)  1.排序函数 1.1 row_number() 序号不重复，序号连续\n形如：1,2,3...\n1.2 rank() 序号可以重复，序号不连续\n形如：1,2,2,4...\n1.3 dense_rank() 序号可以重复，序号连续\n形如：1,2,2,3...\n2.聚合函数  sum,avg,min,max,count \u0026hellip;  1 2 3 4 5 6 7 8  selectname,deptno,salary,SUM(salary)over(partitionbydeptno)astotal_costfromemployees;selectname,deptno,salary,AVG(salary)over(partitionbydeptno)astotal_costfromemployees;selectname,deptno,salary,MIN(salary)over(partitionbydeptno)astotal_costfromemployees;selectname,deptno,salary,MAX(salary)over(partitionbydeptno)astotal_costfromemployees;   加上 order by 会累积计算上一条数据结果  1 2 3  selectname,deptno,salary,SUM(salary)over(partitionbydeptnoorderbysalarydesc)astotal_costfromemployees;selectname,deptno,salary,AVG(salary)over(partitionbydeptnoorderbysalarydesc)astotal_costfromemployees;   没有分区字段  1 2  selectname,deptno,salary,SUM(salary)over()astotal_costfromemployees;   分区字段可以为 多个  1 2  selectname,deptno,salary,SUM(salary)over(partitionbydeptno,salary)astotal_costfromemployees;  3.字段头部值、尾部值函数 first_value,last_value over partition by\n1 2 3 4 5 6  selectname,deptno,hiredate,first_value(hiredate)over(partitionbydeptnoorderbyhiredate)as`first`,last_value(hiredate)over(partitionbydeptnoorderbyhiredate)as`last`fromemployees;  4.字段上一个、下一个值函数 lag, over partition by (lag上一个)\nlag(col,n,default) n 表上n个\nlead, over partition by (lead下一个)\nlead(col,n,default) n 表下n个\n1 2 3 4 5 6  selectname,deptno,hiredate,lead(hiredate)over(partitionbydeptnoorderbyhiredate)as`lead`,lag(hiredate)over(partitionbydeptnoorderbyhiredate)as`lag`fromemployees;  5.滑动时间窗口(frame)  rows模式：\n按物理行来进行划分 range模式：\n按数值逻辑来进行划分  滑动行范围的常用表达；\n1 2  {RANGE|ROWS}frame_start{RANGE|ROWS}BETWEENframe_startANDframe_end  常用的五种表达式：\n UNBOUNDED PRECEDING expression PRECEDING \u0026ndash; only allowed in ROWS mode CURRENT ROW expression FOLLOWING \u0026ndash; only allowed in ROWS mode UNBOUNDED FOLLOWING  默认：BETWEEN unbounded preceding AND CURRENT ROW\n例子：滚动3个月平均值：\n1 2 3 4 5  selectproduct,year_month,gmv,avg(gmv)over(partitionbydepartment,productorderbyyear_monthROWS2PRECEDING)ASavg_gmvfromproduct  ","description":"在大数据开发中，窗口函数是一种强大的功能，用于在查询结果中计算聚合、排序和排名等操作","id":18,"section":"stack","tags":["db",""],"title":"SQL窗口函数","uri":"http://wangjinbao.netlify.app/en/stack/db/sql_func/"},{"content":"1.自定义排序 (ORDER BY FIELD) 在MySQL中ORDER BY 排序除了 ASC 和 DESC 之外，还可以用自定义排序方式实现\n1  select*frommoviesORDERBYFIELD(movie_name,\u0026#39;神话\u0026#39;,\u0026#39;警察故事\u0026#39;...)  2.空值NULL排序 (ORDER BY IF(ISNULL)) 在MySQL中ORDER BY排序字段名，如果字段中存在NULL值就会对我们的排序结果造成影响。\n这时候可用使用 ORDER BY IF(ISNULL(字段),0,1) 语法将NULL值转换成 0 或 1 ，实现NULL值数据排序到数据集前面或后面\n1 2  select*frommoviesORDERBYactors,pricedesc;select*frommoviesORDERBYIF(ISNULL(actors),0,1),actors,pricedesc;  3.CASE表达式 (CASE\u0026hellip;WHEN) 在开发中经常用if\u0026hellip;else if\u0026hellip;else，这时用CASE\u0026hellip;WHEN表达式解决这个问题。\n如：学生90分以上为优秀，分数80-90评为良好，分数60-80评为一般，分数低于60评为较差。查询方式如下：\n1 2 3 4 5  select*,casewhenscore\u0026gt;90then\u0026#39;优秀\u0026#39;whenscore\u0026gt;80then\u0026#39;良好\u0026#39;whenscore\u0026gt;60then\u0026#39;一般\u0026#39;else\u0026#39;较差\u0026#39;endlevelfromstudent;  4.分组连接函数 (GROUP_CONCAT) 分组连接函数 可以在分组后指定字段的 字符串连接方式 ，并且还可以 指定排序逻辑 ；连接字符串默认为英文逗号。\n1 2 3 4 5 6 7 8  selectactors,GROUP_CONCAT(movie_name),GROUP_CONCAT(price)frommoviesGROUPBYactors;selectactors,GROUP_CONCAT(movie_nameorderbypricedescSEPARATOR\u0026#39;_\u0026#39;),GROUP_CONCAT(priceorderbypricedescSEPARATOR\u0026#39;_\u0026#39;)frommoviesGROUPBYactors;  5.分组统计数据后再进行统计汇总 (with rollup) 在mysql中用 whth rollup在分组统计数据的基础上再进行数据统计汇总，即将分组后的数据进行汇总。\n1 2 3  selectactors,SUM(price)FROMmoviesGROUPBYactors;selectactors,SUM(price)FROMmoviesGROUPBYactorsWITHROLLUP;  6.子查询提取 (with as) 如果一整句查询中多个子查询都需要使用同一个子查询的结果，就可以用with as 将共用的子查询提取出来并取一个别名。\n例子：\n获取演员刘亦菲票价大于50且小于65的数据。\n1 2 3 4  withm1as(select*frommovieswhereprice\u0026gt;50),m2as(select*frommovieswhereprice\u0026gt;=65)select*fromm1wherem1.idnotin(selectm2.idfromm2)andm1.actors=\u0026#39;刘亦菲\u0026#39;;  `\n7.优雅处理数据插入、更新时主键、唯一键重复 7.1 有则忽略，无则插入(IGNORE) 1 2 3 4  select*frommovieswhereid\u0026gt;=13;INSERTIGNOREINTOmovies(id,movie_name,actors,price,release_date)VALUES(13,\u0026#39;神话\u0026#39;,\u0026#39;成龙\u0026#39;,100,\u0026#39;2005-12-22\u0026#39;);  7.2 有则删除+插入，无则插入(REPLACE) 1 2  REPLACEINSERTINTOmovies(id,movie_name,actors,price,release_date)VALUES(13,\u0026#39;神话\u0026#39;,\u0026#39;成龙\u0026#39;,100,\u0026#39;2005-12-22\u0026#39;);  7.1 有则更新，无则插入(on duplicate key update) 1 2 3  INSERTINTOmovies(id,movie_name,actors,price,release_date)VALUES(13,\u0026#39;神话\u0026#39;,\u0026#39;成龙\u0026#39;,100,\u0026#39;2005-12-22\u0026#39;)onduplicatekeyupdateprice=price+10;  ","description":"几种好用的SQL高级用法。","id":19,"section":"stack","tags":["db",""],"title":"SQL高级用法","uri":"http://wangjinbao.netlify.app/en/stack/db/sql_high/"},{"content":"1.Join背景 1.1Join 类型 上图列举了常见的 Join 类型：\n  Cross Join：左表和右表的一个笛卡尔积。\n  Full / Left / Right Outer Join：Outer Join 需要根据语义，对两表/左表/右表上没有匹配上的行进行补 Null。\n  Anti Join：反连接，输出连接关系上 没有匹配上 的数据行，通常 Anti Join 出现在not in 或者not exists 子查询的规划中。\n  Semi Join：与 Anti Join 相反，只输出在连接关系上匹配的数据行即可，一般是一行数据结果。\n  Inner Join：输出左表和右表的交集，根据连接条件产生一对多的结果行。\n  1.2Join 优化的难点 Join 的执行效率通常分成两部分来优化，一是 提高单机上 Join 算子的效率，二是 规划一个合理的 Join 计划，尽可能地减少 Join 的输入/执行成本。本文主要集中在后者的介绍上，那么接下来就从 Join 优化的难点开始讲起。\n  难点一，Join 的实现方式多。\n如上图所示，不同 Join 的实现方式在不同场景下效率不同，如 Sort-Merge Join 在 Join 有序数据时，效率可能远高于 Hash Join，但是在数据 Hash 分布的分布式数据库里，Hash Join 的效率可能远比 Sort-Merge 高。而数据库则需要针对不同的场景，选择合适的 Join 方式。\nstarrocks中还是使用的Hash Join。\n  难点二，多表 Join 的执行顺序。\n  在多表 Join 的场景下，选择度高的 Join 先执行，会提高整个 SQL 的效率，但是怎么判断出 Join 的执行顺序呢？这却是十分困难的。\n如上图所示，在 Left-Deep 模型下，N 个表 Join 可能的排列个数有2^n-1个，但是在 Bushy 模型下，排列个数高达2^(n-1) * C(n-1)个，对于数据库而言，查找一个最佳 Join 顺序的耗时和成本是指数级的增长。\n 难点三，数据的基数/行数/相关度难以评估\n  在执行 SQL 之前，数据库难以准确评估一个 Join 实际的执行效果，通常我们都认为小表 Join 大表的选择度高于大表 Join 大表。但是实际情况下呢？显然并不是这样的，还有很多一对多的场景，甚至在更复杂的 SQL 中，存在各种聚合、过滤的算子，在数据经过一系列运算后，数据库系统对于 Join 的输入都会难以评估准确。\n 难点四，单机最优的计划不等于分布式最优\n在分布式系统中，会通过 Re-Shuffle 或者广播数据的方式，将需要的数据发送到目的端参与计算，分布式数据库中 Join 也是如此。但这也带来了另外一个问题，一个单机数据库上最优的执行计划，因为没有考虑数据的分布 \u0026amp; 网络传输的开销，放在分布式数据库上未必是最优的执行计划。分布式数据库在规划 Join 的执行计划和执行方式时，需要考虑数据的分布和网络成本。  1.3SQL的优化流程 StarRocks 对于 SQL 的优化主要通过 优化器 完成，主要集中在 Rewrite 和 Optimize 阶段。\n1.4 Join 优化的原则 StarRocks 目前 Join 的算法主要是一个 Hash Join，默认使用右表去构建 Hash 表，在这个前提下，我们总结了五个优化方向：\n  不同 Join 类型的算子，性能是不同的，尽可能使用性能高的 Join 类型，避免使用性能差的 Join 类型。根据 Join 输出的数据量，大致上的性能排序：Semi-Join/Anti-Join \u0026gt; Inner Join \u0026gt; Outer Join \u0026gt; Full Outer Join \u0026gt; Cross Join。\n  Hash Join 实现时，使用小表做 Hash 表，远比用一个大表做 Hash 表高效。\n  多表 Join 时，优先执行选择度高的 Join，能大幅减少后续 Join 的开销。\n  尽可能减少参与 Join 的数据量。\n  尽可能减少分布式 Join 产生的网络成本。\n  PS:谓词的概念：\n 谓词 ： 用于过滤和比较数据的条件。它们用于在查询中指定需要返回的数据行。 常见的SQL谓词包括： + 比较谓词：用于比较两个值之间的关系，例如 等于（=），不等于（\u0026lt;\u0026gt;），大于（\u0026gt;），小于（\u0026lt;），大于等于（\u0026gt;=），小于等于（\u0026lt;=）等。 + 逻辑谓词：用于将多个条件组合在一起进行逻辑操作，例如 AND，OR，NOT等。 + 范围谓词：用于指定一个范围，例如 BETWEEN 和 IN 。 + 空值谓词：用于检查是否为NULL值，例如 IS NULL 和 IS NOT NULL。 + 模糊匹配谓词：用于在字符串中进行模式匹配，例如 LIKE 和 NOT LIKE。 + 子查询谓词：用于在查询中嵌套另一个查询，例如 EXISTS 和 IN。 2.Join 逻辑优化 介绍一些 Join 上的启发式规则。\n2.1 类型转换 低效率的 Join 类型转为高效的 Join 类型，主要包括以下三个转换规则：\n 转换规则一：Cross Join 转换为 Inner Join\n当 Cross Join 满足某个约束时，可以将 Cross Join 转为 Inner Join。\n该约束为：Join 上至少存在一个表示连接关系的 谓词。\n例如：  -- 转换前 Select * From t1, t2 Where t1.v1 = t2.v1; -- 转换后, Where t1.v1 = t2.v1是连接关系谓词 Select * From t1 Inner Join t2 On t1.v1 = t2.v1;  转换规则二：Outer Join 转换为 Inner Join  当满足以下约束时，可以将 Outer Join 转为 Inner Join：\n  Left / Right Outer Join 上存在一个 Right / Left 表的相关谓词；\n  该相关谓词是一个严格（Restrick Null）谓词。\n例如：\n   -- 转换前 Select * From t1 Left Outer Join t2 On t1.v1 = t2.v1 Where t2.v1 \u0026gt; 0; -- 转换后， t2.v1 \u0026gt; 0 是一个 t2 表上的严格谓词 Select * From t1 Inner Join t2 On t1.v1 = t2.v1 Where t2.v1 \u0026gt; 0; 需要注意的是，在 Outer Join 中，需要根据 On 子句的连接谓词进行 补 Null  操作，\n而不是过滤 ，所以该转换规则不适用 On 子句中的连接谓词。\n例如：\n1 2 3  Select * From t1 Left Outer Join t2 On t1.v1 = t2.v1 And t2.v1 \u0026gt; 1; -- 显然，上面的SQL和下面SQL的语义并不等价 Select * From t1 Inner Join t2 On t1.v1 = t2.v1 And t2.v1 \u0026gt; 1;   这里需要提到一个概念，即 严格（Restrick Null）谓词 .\nStarRocks 把一个可以过滤掉 Null 值的谓词叫做 严格谓词 ，例如a \u0026gt; 0；\n而不能过滤 Null 的谓词，叫做 非严格谓词 ，例如：a IS Null;\n大部分谓词都是严格谓词，非严格谓词主要是 IS Null 、IF、 CASE WHEN 或 函数构成的谓词\nStarRocks 对于严格谓词的判断，用了一个简单的方法：\n将需要检测的列全部替换成 Null，然后进行表达式化简。如果结果是 True，意味着输入为 Null 时，Where 子句无法过滤数据，那么该谓词是一个非严格谓词；反之，如果结果是 False 或 Null，那么是一个严格谓词。\n 转换规则三：Full Outer Join 转为 Left / Right Outer Join  同样，当满足该约束时，Full Outer Join 可以转为 Left / Right Outer Join：存在一个可以 bind 到 Left / Right 表的严格谓词。\n例如：\n-- 转换前 Select * From t1 Full Outer Join t2 On t1.v1 = t2.v1 Where t1.v1 \u0026gt; 0; -- 转换后， t1.v1 \u0026gt; 0 是一个左表上的谓词，且是一个严格谓词 Select * From t1 Left Outer Join t2 On t1.v1 = t2.v1 Where t1.v1 \u0026gt; 0; 2.2 谓词下推 谓词下推 是一个 Join 上非常重要，也是很常用的一个优化规则，其主要目的是 提前过滤 Join 的输入 ，从而提升 Join 的性能。\n对于 Where 子句，当满足以下约束时，我们可以进行谓词下推，并且伴随着谓词下推，我们可以做 Join 类型转换：\n 任意 Join 类型； Where 谓词可以 bind 到其中一个输入上。\n例如：  Select * From t1 Left Outer Join t2 On t1.v1 = t2.v1 Left Outer Join t3 On t2.v2 = t3.v2 Where t1.v1 = 1 And t2.v1 = 2 And t3.v2 = 3; 其谓词下推的流程如下。\n第一步，分别下推 (t1.v1 = 1 And t2.v1 = 2) 和 (t3.v2 = 3)，由于满足类型转换规则(t1 Left Outer Join t2) Left Outer Join t3 转换为 (t1 Left Outer Join t2) Inner Join t3。\n第二步，继续下推 (t1.v1 = 1) 和 (t2.v1 = 2)，且 t1 Left Outer Join t2 转换为 t1 Inner Join t2。\n需要注意的是\n对于 On 子句上的连接谓词，其下推的规则和 Where 子句有所不同，这里我们分为\nInner Join 和其他 Join 类型两种情况。\n第一种情况是，对于 Inner Join，On 子句上的连接谓词下推，和 Where 子句相同，上面已经叙述过，这里不再重复。\n第二种情况是，对于 Outer / Semi / Anti Join 的连接谓词下推，需要满足以下约束，且下推过程中无法进行类型转换：\n必须为 [Left/Right] Outer/Semi/Anti Join；\n连接谓词\u0026rsquo;只能' bind 到 [Right/Left] 输入上。\n例如：\nSelect * From t1 Left Outer Join t2 On t1.v1 = t2.v1 And t1.v1 = 1 And t2.v1 = 2 Left Outer Join t3 On t2.v2 = t3.v2 And t3.v2 = 3; 其 On 连接谓词下推的流程如下。\n第一步，下推 t1 Left Join t2 Left Join t3 上可以 bind 到右表的连接谓词 (t3.v2 = 3)，此时无法将 Left Outer Join 转换为 Inner Join。\n第二步，下推 t1 Left Join t2 上可以 bind 到右表的连接谓词 (t2.v1 = 2)。由于t1.v1 = 1是 bind 到左表的，下推以后会过滤 t1 的数据，所以该行为与 Left Outer Join 语义不符，无法下推该谓词。\n2.3 谓词提取 在之前的谓词下推的规则中，只能下推满足 合取 语义的谓词，例如 t1.v1 = 1 And t2.v1 = 2 And t3.v2 = 3 中，三个子谓词都是通过合取谓词连接，而无法下推 析取 语义的谓词，例如t1.v1 = 1 Or t2.v1 = 2 Or t3.v2 = 3。\n但是在实际场景中，析取谓词也十分常见，对此 StarRocks 做了一个提取谓词（列值推导）的优化。通过一系列的交并集操作，将析取谓词中的列值范围提取出合取谓词，继而下推合取谓词。例如：\n-- 谓词提取前 Select * From t1 Join t2 On t1.v1 = t2.v1 Where (t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4) -- 利用(t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4)进行列值推导，推导出（t2.v1 \u0026gt;= 2），（t1.v2 IN (3, 4)）两个谓词 Select * From t1 Join t2 On t1.v1 = t2.v1 Where (t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4) AND t2.v1 \u0026gt;= 2 AND t1.v2 IN (3, 4); 这里需要注意的是，提取出来的谓词范围可能是原始谓词范围的超集，所以不一定能直接替换原始谓词。\n2.4 等价推导 在谓词上，除了上述的谓词提取，还有另一个重要的优化，叫 等价推导 。等价推导主要利用了 Join 的连接关系，从左表/右表列的取值范围，推导出右表/左表对应列的取值范围。例如：\n-- 原始SQL Select * From t1 Join t2 On t1.v1 = t2.v1 Where (t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4) -- 利用(t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4)进行列值推导，推导出（t2.v1 \u0026gt;= 2），（t1.v2 IN (3, 4)）两个谓词 Select * From t1 Join t2 On t1.v1 = t2.v1 Where (t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4) AND t2.v1 \u0026gt;= 2 AND t1.v2 IN (3, 4); -- 利用连接谓词(t1.v1 = t2.v1)和(t2.v1 \u0026gt;= 2)进行等价推导，推导出（t1.v1 \u0026gt;= 2）谓词 Select * From t1 Join t2 On t1.v1 = t2.v1 Where (t2.v1 = 2 AND t1.v2 = 3) OR (t2.v1 \u0026gt; 5 AND t1.v2 = 4) AND t2.v1 \u0026gt;= 2 AND t1.v2 IN (3, 4) AND t1.v1 \u0026gt;= 2; 当然，等价推导的作用范围并不像谓词提取一样广泛，谓词提取可以在任意谓词上进行，但等价推导和谓词下推类似，在不同的 Join 上有不同的条件约束，这里同样分为 Where 谓词和 On 连接谓词来解析。\nWhere 谓词：\n几乎没有约束，可以从左表的谓词推导出右表，反之亦可。\nOn 连接谓词：\n在 Inner Join 上和 Where 谓词相同，没有条件约束；\n除 Inner Join 外，仅支持 Semi Join 和 Outer Join，且仅支持与 Join 方向相反的单向推导。例如，Left Outer Join 可以从左表的谓词推导出右表的谓词，Right Outer Join 可以从右表的谓词推导出左表的谓词。\n为什么在 Outer / Semi Join 上存在单向的限制呢？原因也很简单，以 Left Outer Join 为例，在谓词下推的规则中有提到，Left Outer Join 只能下推右表的谓词，而左表的谓词则由于违法语义导致无法下推。所以执行等价推导时，从右表谓词推导出的左表谓词，同样需要满足该约束。\n那么在这个前提下，推导出来的左表谓词并不能起到提前过滤数据的作用，而且还会带来执行额外谓词的开销，所以 Outer / Semi Join 只支持单向推导。\n关于等价推导的实现，StarRocks 是通过维护了两个 Map 实现的。一个 Map 用于维护 Column 和 Column 之间的等价关系，另一个 Map 则用来维护 Column 到 Value 或者表达式的等值关系，通过这两个 Map 相互查找，实现等价推导\n2.5 Limit 下推 除了谓词可以下推，Join 上也支持 Limit 的下推。当 SQL 是一个 Outer Join 或 Cross Join 时，可以将 Limit 下推到输出行数稳定的孩子上。其中，Left Outer Join 输出行数至少和左孩子一致，那么 Limit 可以下推到左表上，Right Outer Join 反之。\n-- 下推前 Select * From t1 Left Outer Join t2 On t1.v1 = t2.v1 Limit 100; -- 下推后 Select * From (Select * From t1 Limit 100) t Left Outer Join t2 On t.v1 = t2.v1 Limit 100; 比较特殊的是 Cross Join 和 Full Outer Join、Cross Join 的输出是一个笛卡尔积，行数是左表 x 右表；而 Full Outer Join 的输出行数，则至少是左表 + 右表，所以这两种 Join 可以在左表和右表上各下推一个 Limit。例如：\n-- 下推前 Select * From t1 Join t2 Limit 100; -- 下推后 Select * From (Select * From t1 Limit 100) x1 Join (Select * From t2 Limit 100) Limit 100; ","description":"介绍 StarRocks 在 Join 查询规划上的经验和探索。文章主要分为四个部分：Join 背景，Join 逻辑优化，Join Reorder，分布式 Join 规划。","id":20,"section":"stack","tags":["db",""],"title":"StarRocks的Join 查询优化","uri":"http://wangjinbao.netlify.app/en/stack/db/select/"},{"content":"1.基本概念 FE FE: 负责 查询解析 ， 查询优化 ， 查询调度 和 元数据管理\nBE BE： 负责 查询执行 和 数据存储\n2.完整处理一条查询 SQL 2.1 从 SQL 文本到执行计划 口诀：解析-分析-逻辑计划-优化器-物理计划碎片\n从 SQL 文本到分布式物理执行计划, 在 StarRocks 中，需要经过以下 5 个步骤:\n SQL Parse：将 SQL 文本转换成一个 AST（抽象语法树） SQL Analyze：基于 AST 进行语法和语义分析 SQL Logical Plan：将 AST 转换成逻辑计划 SQL Optimize：基于关系代数、统计信息、Cost 模型，对逻辑计划进行重写、转换，选择出 Cost “最低” 的物理执行计划 生成 Plan Fragment：将 Optimizer 选择的物理执行计划转换为 BE 可以直接执行的 Plan Fragment  SQL Parse： Query Parse 的输入是 SQL 的 String 字符串，Query Parse 的输出是 Abstract Syntax Tree，每个节点都是一个 ParseNode 。\n一个查询 SQL Parse 后生成一个 QueryStmt， 由 SelectList, FromClause, wherePredicate, GroupByClause, havingPredicate, OrderByElement, LimitElement 等组成，基本和 SQL 文本一一对应。\nStarRocks 目前使用的 Parser 是 ANTLR4，语法规则定义的文件可在 GitHub 搜索 StarRocks g4 获取。\nSQL Analyze： StarRocks 获取到 AST 后，接着会进行语法分析和语义分析，完成下面的工作：\n检查并绑定 Database, Table, Column 等元信息\nSQL 的合法性检查：Where 中不能有 Grouping 操作， HLL 和 Bitmap 列不能 Sum 等\nTable 和 Column 的别名处理\n函数参数的合法性检测: Sum 的参数类型必须是数值类型，Lead 和 Lag 窗口函数第 2 和第 3 个参数必须常量等\n类型检查和类型转换：BIGINT 和 DECIMAL 比较，BIGINT 类型需要 Cast 成 DECIMAL\nSQL Analyze 的结果是一个有层级结构的 Relation，如图 2 所示，比如一个 From 子句对应一个 TableRelation， 一个子查询对应一个 SubqueryRelation。\nSQL Logical Plan 接下来，StarRocks 会将 Relations 转化成一棵 Logical Plan Tree， 如图 所示，可以简单理解为每个集合操作都会对应一个 Logical Node\nSQL Optimize StarRocks Optimizer 的输入是一棵逻辑计划树，输出是一棵 Cost “最低” 的分布式物理计划树。\n一般 SQL 越复杂，Join 的表越多，数据量越大，Optimizer 的意义就越大，因为不同执行方式的性能差别可能有成百上千倍。StarRocks 优化器完全自研，主要基于 Cascades 和 ORCA 论文实现，并结合 StarRocks 执行器和调度器进行了深度定制，优化和创新。\n它完整支持了 TPC-DS 99 条 SQL，实现了公共表达式复用，相关子查询重写，Lateral Join， CTE 复用，Join Rorder，Join 分布式执行策略选择，Global Runtime Filter 下推，低基数字典优化等重要功能和优化。\n（1）Logical Plan Rewrite 在正式进入 CBO 之前，StarRocks 会首先进行一系列 Logical Plan 的 Rewrite，Rewrite 阶段的 Rule 我们认为都会生成更优的 Logical Plan，主要的 Rewrite Rule 有下面这些：\n 各种表达式的重写和化简 列裁剪 谓词下推 Limit Merge, Limit 下推 聚合 Merge 等价谓词推导（常量传播） Outer Join 转 Inner Join 常量折叠 公共表达式复用 子查询重写 Lateral Join 化简 分区分桶裁剪 Empty Node 优化 Empty Union, Intersect, Except 裁剪 Intersect Reorder Count Distinct 相关聚合函数重写  （2）CBO Transform 我们在 Logical Plan Rewrite 完成后，正式基于 Columbia 论文进行 CBO 优化，主要包括下面的优化：\n 多阶段聚合优化：普通聚合（count, sum, max, min 等）会拆分成两阶段，单个 Count Distinct 查询会拆分成三阶段或是四阶段。 Join 左右表调整：StarRocks 始终用右表构建 Hash 表，所以右表应该是小表，StarRocks 可以基于 cost 自动调整左右表顺序，也会自动把 Left Join 转 Right Join。 Join 多表 Reorder：多表 Join 如何选择出正确的 Join 顺序，是 CBO 优化器的核心。当 Join 表的数量小于等于 5 时，StarRocks 会基于 Join 交换律和结合律进行 Join Reorder，大于 5 时，StarRocks 会基于贪心算法和动态规划进行 Join Reorder。 Join 分布式执行选择：StarRocks 支持的分布式 Join 方式有 Broadcast、Shuffle、单边 Shuffle、Colocate、Replicated。StarRocks 会基于 Cost 估算和 Property Enforce 机制选择出 “最佳” 的 Join 分布式执行方式。 Push Down Aggregate to Join 物化视图选择与重写  如图 5 所示， 在 CBO 优化中，Logical Plan 会先转成 Memo 的数据结构。Memo 的中文含义是备忘录，所有的逻辑计划和物理计划都会记录在 Memo 中， Memo 就构成了整个搜索空间 。\n然后如图 6 所示，StarRocks 应用各种 Rule 扩展搜索空间，并生成对应的物理执行计划，再基于统计信息和 Cost 估计从 Memo 中选择一组 Cost 最低的物理执行计划。\n（3）统计信息 和 Cost 估计 CBO 优化器好坏的 关键 之一是 Cost 估计是否准确，而 Cost 估计是否准确的关键点之一是 统计信息是否收集及时准确。\nStarRocks 目前支持表级别和列级别的统计信息，支持自动收集和手动收集两种方式。无论自动还是手动，都支持全量和抽样收集两种方式。\n有了统计信息之后， StarRocks 就会基于统计信息进行 Cost 估算。StarRocks 估算 Cost 时会考虑 CPU、内存、网络、IO 等资源因子，每个资源因子会有不同的权重，每个执行算子的 Cost 计算公式都不太一样。\n当你使用 StarRocks 发现 Join 左右表不合理、Join 分布式执行策略不合理时，可以参考 StarRocks CBO 使用文档收集统计信息。\n生成 Plan fragment StarRocks Optimizer 的输出是一棵 分布式物理执行计划树 ，但并不能直接被 BE 节点执行，所以需要转换成 BE 可以直接执行的 PlanFragment。转换过程基本是个一一映射的过程。\n3.执行计划的调度 在生成查询的分布式 Plan 之后，FE 调度模块会负责 PlanFragment 的执行实例生成、 PlanFragment 的调度、 每个 BE 执行状态的管理、 查询结果的接收。\n有了分布式执行计划之后，我们需要解决下面的问题：\n 哪个 BE 执行哪个 PlanFragment 每个 Tablet 选择哪个副本去查询 多个 PlanFragment 如何调度  StarRocks 会首先确认 Scan Operator 所在的 Fragment 在哪些 BE 节点执行，每个 Scan Operator 有需要访问的 Tablet 列表。然后对于每个 Tablet，StarRocks 会先选择版本匹配的、健康的、所在的 BE 状态正常的副本进行查询。在最终决定每个 Tablet 选择哪个副本查询时，采用的是随机方式，不过 StarRocks 会尽可能保证每个 BE 的请求均衡。假如我们有 10 个 BE、10 个 Tablet，最终调度的结果理论上就是每个 BE 负责 1 个 Tablet 的 Scan。\n当确定包含 Scan 的 PlanFragment 由哪些 BE 节点执行后，其他的 PlanFragment 实例也会在 Scan 的 BE 节点上执行 （也可以通过参数选择其他 BE 节点），不过具体选择哪个 BE 是随机选取的。\n当 FE 确定每个 PlanFragment 由哪个 BE 执行，每个 Tablet 查询哪个副本后，FE 就会将 PlanFragment 执行相关的参数通过 Thrift 的方式发送给 BE。\n目前 FE 对多个 PlanFragment 调度的方式是 All At Once 的方式，是按照自顶向下的方式遍历 PlanFragment 树，将每个 PlanFragment 的执行信息发送给对应的 BE。\n4.执行计划的执行 StarRocks 是通过 MPP 多机并行机制来充分利用多机的资源，通过 Pipeline 并行机制来充分利用单机上多核的资源，通过向量化执行来充分利用单核的资源，进而达到极致的查询性能。\nMPP 多机并行执行 MPP 是大规模并行计算 的简称，核心做法是将查询 Plan 拆分成很多可在单个节点上执行的计算实例，然后多个节点并行执行。每个节点不共享 CPU、内存、磁盘资源。MPP 数据库的查询性能可以随着集群的水平扩展而不断提升。\n如图 所示，StarRocks 会将一个查询在逻辑上切分为多个 Query Fragment（查询片段），每个 Query Fragment 可以有一个或者多个 Fragment 执行实例，每个 Fragment 执行实例会被调度到集群某个 BE 上执行。一个 Fragment 可以包括一个或者多个 Operator（执行算子），图中的 Fragment 包括了 Scan、Filter、Aggregate。每个 Fragment 可以有不同的并行度。\n多个 Fragment 之间会以 Pipeline 的方式在内存中并行执行，而不是像批处理引擎那样 Stage By Stage 执行。Shuffle （数据重分布）操作是 MPP 数据库查询性能可以随着集群的水平扩展而不断提升的关键，也是实现高基数聚合和大表 Join 的关键。\nPipeline 单机并行执行 StarRocks 在 Fragment 和 Operator 之间引入了 Pipeline 的概念，一个 Pipeline 内的数据没有到达终点前不需要 Materialize(实现)，遇到需要 Materialize 的算子（Agg, Sort, Join)，则需要拆分出一个新的 Pipeline，所以 1 个 Fragment 会对应多个 Pipeline。\n如图 所示，一个 Pipeline 由多个 Operator 组成。第一个 Operator 是 Source Operator，负责产生数据，一般是 Scan 节点 和 Exchange 节点。最后一个 Operator 是 Sink Operator，负责物化或者消费数据。中间的 Operator 负责对数据进行 Transform。\n那么 Pipeline 如何并行呢？答案是 Pipeline 和 Fragment 一样，可以生成多个实例，每个实例称为一个 Pipeline Driver。当一个 Pipeline 需要 N 个并行度去执行时，一个 Pipeline 就会生成 N 个 Pipeline Driver，如图 12 所示，并行度是 3，一个 Pipeline 就产生了 3 个 Pipeline Driver。\n如图 13 所示，一个 Pipeline 执行中，当前一个 Operator 可以产生数据，且后一个 Operator 可以消费数据时，Pipeline 的执行线程就会从前一个 Operator Pull 出数据，然后 Push 到后一个 Operator。每个 Pipeline 的执行状态是很清晰的，简单可以理解为有 Ready、Running、Blocked 等 3 种状态。当前面的 Operator 无法产生数据，或者后面的 Operator 不需要消费数据时，Pipeline 就会处于 Blocked 的状态。\n如图 14 所示， Pipeline 并行执行框架的核心是实现一个用户态的协程调度，不再依赖操作系统的内核态线程调度，减少线程创建、线程销毁、线程上下文切换的成本。\n在 Pipeline 并行执行框架中，StarRocks 会启动机器 CPU 核数个执行线程，每个执行线程会从一个多级反馈就绪队列中获取 Ready 状态的 Pipeline 去执行，同时会有一个全局 Poller 线程不断检查 Blocked 队列中的 Pipeline 是否解除了阻塞，可以变为 Ready 状态。如果可以变为了 Ready 状态，就可以把 Pipeline 从 阻塞队列移到多级反馈就绪队列中。\n向量化执行 随着数据库执行的瓶颈逐渐从 IO 转移到 CPU，为了充分发挥 CPU 的执行性能，StarRocks 基于向量化技术重新实现了整个执行引擎，向量化执行引擎是为了充分利用单核 CPU 的能力。\n向量化在实现上主要是算子和表达式的向量化，图 15 是算子向量化的示例，图 16 是表达式向量化的示例，算子和表达式向量化执行的核心是批量按列执行。相比于单行执行，批量执行可以有更少的虚函数调用，更少的分支判断；相比于按行执行，按列执行对 CPU Cache 更友好，更易于 SIMD 优化。\n向量化执行不仅仅是数据库所有算子的向量化和表达式的向量化，而是一项巨大和复杂的性能优化工程，包括数据在磁盘、内存、网络中的按列组织，数据结构和算法的重新设计，内存管理的重新设计，SIMD 指令优化，CPU Cache 优化，C++ Level 优化等。经过努力，StarRocks 向量化执行引擎相比之前的按行执行，取得了整体 5 到 10 倍的性能提升。\n总结 StarRocks 如何完成一条查询 SQL 的处理：\n 通过高效强大的 CBO 优化器生成最佳的分布式物理执行计划； 通过查询调度器选择合适的数据副本，并将分布式物理执行计划调度到合适的计算节点进行计算； 通过 MPP 分布式执行框架充分利用多机的资源，做到查询性能可以随着机器数量近似线性扩展； 通过 Pipeline 并行执行框架充分利用多核资源，做到查询性能可以随着机器核数近似线性扩展； 通过向量化执行引擎充分利用 CPU 单核资源，将单核执行性能做到极致。  ","description":"StarRocks是一个分布式的列式存储和分析数据库，它的执行计划是指数据库在执行查询时的操作顺序和方式。","id":21,"section":"stack","tags":["db",""],"title":"StarRocks的执行计划","uri":"http://wangjinbao.netlify.app/en/stack/db/plan/"},{"content":"概述 Jaeger 是 Uber 开发并开源的一款 分布式链路追踪系统 ，兼容 OpenTracing API。\n适用场景：  分布式跟踪信息传递 分布式事务监控 问题分析 依赖分析 性能优化  特性 高扩展性 Jaeger后端的设计没有单点故障，可以根据业务需求进行扩展。\n原生支持 OpenTracing Jaeger后端，Web UI和工具库已完全设计为支持OpenTracing标准:\n 通过跨度引用将迹线表示为 有向无环图（不仅是树）； 支持强类型的跨度 标签 和 结构化日志 baggage 支持通用的分布式 上下文传播机制  多存储后端  Jaeger支持两个流行的开源 NoSQL数据库 作为跟踪存储后端：Cassandra 3.4+ 和 Elasticsearch 5.x / 6.x / 7.x。 Jaeger还附带了一个简单的内存存储区，用于测试设置。  现代化的UI  Jaeger Web UI是使用流行的开源框架（如React）以Javascript实现的。 v1.0中发布了几项性能改进，以允许UI有效处理大量数据，并显示具有成千上万个跨度的跟踪  云原生部署  Jaeger后端作为Docker映像的集合进行分发。 这些二进制文件支持各种配置方法，包括命令行选项，环境变量和多种格式（yaml，toml等）的配置文件。 Kubernetes模板和Helm图表有助于将其部署到Kubernetes集群。  可观察性  所有Jaeger后端组件都公开Prometheus指标（也支持其他指标后端）。 使用结构化日志库zap将日志写到标准输出。  系统架构   Jaeger Client\n为不同语言实现了符合 OpenTracing 标准的 SDK。应用程序通过 API 写入数据，client library 把 trace 信息按照应用程序指定的采样策略 传递给 jaeger-agent。\n  Agent\n是一个监听在 UDP 端口上 接收 span 数据的网络守护进程，它会将数据批量发送给 collector。它被设计成一个基础组件，推荐部署到所有的宿主机上。Agent 将 client library 和 collector 解耦，为 client library 屏蔽了路由和发现 collector 的细节。\n  Collector\n接收 jaeger-agent 发送来的数据，然后将数据写入后端存储。Collector 被设计成无状态的组件，因此您可以同时运行任意数量的 jaeger-collector。\n  Data Store\n后端存储被设计成一个可插拔的组件，支持将数据写入 cassandra、elastic search。\n  Query\n接收查询请求，然后从后端存储系统中检索 trace 并通过 UI 进行展示。Query 是无状态的，您可以启动多个实例，把它们部署在 nginx 这样的负载均衡器后面。\n  采样速率 如果所有的请求都开启 Trace 显然会带来比较大的压力，另外，大量的数据也会带来很大存储压力。为此，jaeger 支持设置采样速率，根据系统实际情况设置合适的采样频率。\nJaeger 官方提供了 多种采集策略:\n const - 全量采集，采样率设置 0,1 分别对应打开和关闭 probabilistic - 概率采集，默认万份之一，0~1之间取值， rateLimiting - 限速采集，每秒只能采集一定量的数据 remote - 动态采集策略，根据当前系统的访问量调节采集策略  安装 为方便演示，使用官方推荐的Docker快速启动方式：\n1  docker run -d --name=jaeger -p6831:6831/udp -p16686:16686 jaegertracing/all-in-one:latest   浏览器Web UI： http://localhost:16686/\n PS:注意：这个docker镜像封装的jaeger是把数据放在内存中 的，仅用于测试，正式使用需指定后端存储\n docker-compose部署如下：\ndocker-compose.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  version:\u0026#34;3\u0026#34;services:jeager:build:./jeagercontainer_name:jeagerenvironment:- COLLECTOR_ZIPKIN_HTTP_PORT=9411ports:- \u0026#34;5775:5775/udp\u0026#34;- \u0026#34;6831:6831/udp\u0026#34;- \u0026#34;6832:6832/udp\u0026#34;- \u0026#34;5778:5778\u0026#34;- \u0026#34;16686:16686\u0026#34;- \u0026#34;14268:14268\u0026#34;- \u0026#34;9411:9411\u0026#34;volumes:- /Users/wangdante/D/kugou/:/var/www/html/restart:alwaysnetworks:jarven:ipv4_address:172.19.0.20...  使用 现在需要一点数据让我们把页面操作起来。\n启动一个应用 这个应用是Jaeger仓库中的一个示例\n这里我通过源码启动:\n1 2 3  git clone git@github.com:jaegertracing/jaeger.git jaeger cd jaeger/examples/hotrod go run ./main.go all   同样提供了docker镜像启动方式，参考示例链接。\n访问hotrod的webUI：http://127.0.0.1:8080\n发送请求 点击一个按钮，发送下单请求，效果见下图\n分别是 车牌号，预计到达时间，请求序列号，请求耗时。\nJaeger查看服务架构 切换到Jaeger webUI，点击上面的System Architecture \u0026ndash;\u0026gt; DAG （directed acyclic graph，有向无环图）\n这就是我们启动的hotrod的微服务架构图，可以看到有几个服务，依赖关系如何。\n首先，这里有四个服务（真实的），两个存储(组件模拟的)，其中的数字就是请求调用次数，图中展示了redis调用的次数最多，有点纳闷，回到Jaeger 主页面看看。\n查看一个trace 通过前面的架构图可以指定，frontend是最上层服务，通过它应该可以查询到所有的调用记录。\n上面的查询结果就是点击了查询按钮之后的效果，在第一个记录中，可以看到3个Errors，后面是一次请求经历的几个服务或阶段。\n点进去看详细\n这里提到一个词 Span，这里先介绍什么是Trace，一个 trace 代表了一个事务或者流程在（分布式）系统中的执行过程；\n一个 span 代表在分布式系统中完成的单个工作单元，也包含其他 span 的 “引用”，这允许将多个 spans 组合成一个完整的 Trace。\n比如说，调用一次查询用户信息的请求 /get_user?uid=1，这里分几步：\n 第一步，请求到达路由服务，路由服务根据路径调用handler 第二步，handler内部调用service服务 第三步，service根据路由调用其handler 第四步，service-handler内调用数据库  这里就有四个耗时阶段，每个阶段都要耗时，将每个阶段称作是一个span，但其实你会发现上一个阶段会包含下面的所有阶段，这里解释了前面提到的span引用问题；\n每个span都有一些元信息：\n span-id 操作名 开始时间和结束时间，以及耗时 tag，用户自定义标签便于查询过滤和理解数据 log，记录 Span 内特定时间或事件的日志信息，以及应用程序本身的其他调试或信息输出 span context，跨越进程边界，传递到子级 Span 的状态。常在追踪示意图中创建上下文时使用  这里通过上面的图解释一下调用过程：\n frontend服务接收到外部HTTP GET请求，路由是/dispatch frontend服务调用customer服务的/customer接口 customer服务内执行mysql查询，结果返回再返回frontend服务 然后frontend服务向driver服务发起RPC调用，接口是Driver::findNearest driver服务内再调用多次redis，并且可以看到发生错误 然后frontend服务又向route服务发起了多次HTTP GET调用，路由是/route 最后frontend服务返回结果。  点开每个span都可以看到一些细节，包含tag和log；比如发送错误的redis调用，在log部分可以看到更多细节，这都是我们在代码中打的\nContextualized logging（情景化日志） 简单说就是，每个span下的log部分都是针对这一次调用产生的记录，这对我们的帮助简直不要太大；以往我们都是直接去tail -f x.log，如果一秒有多个并发请求，我们很难从那么多日志记录中找出问题。\nSpan Tags \u0026amp; Logs 这个前面也说了，tag自己定义，kv格式，jaeger中可以用来筛选trace，而log则是记录与这个span这次请求密切相关的事件，一般会带有时间戳，比如redis timeout\n 注意：OpenTracing的规范仓库中的semantic data conventions(语义数据约定)描述了一些能够应对多数情况的tag名和log字段，因此我们还是应该参考一下这个约定，少搞特殊\n 链路拆解分析 现在以frontend服务为主角，把以它为root的span都折叠，得到下图\n此图可以让我们更清晰的这个trace过程，哪些span是顺序执行的，哪些是并行的。\n顺序执行的span：\n /customer /driver.DriverService/FindNearest  并行的span:\n route (每次并发3个请求，图中显示的蓝条在时间线上重合)   PS:这有多方便不用我多说了，代码中的并发调用看的一清二楚。\n 筛选\u0026amp;排序 查询时筛选是通过service, tag, min/max duration；\n这里说一下排序功能，我们可以对搜索结果排序，有几种方式，见下图:\n比较多个Trace 在搜索结果中选中至少两个trace，点击右上角的比较按钮\n下图是比较的页面\n下面介绍怎么看对比图；\n首先，忽略方块颜色，这些箭头连起来的方块图就是一个trace的调用链，一个方块就是一个span。\n一般我们只会选择 两个相同的请求来比较，上图其实就是两个trace重合之后的图；\n如果你选择 两个不同 的请求比较，看到的是下图\n顺便就讲一下这图，很明显，两个不同路由的请求trace无法重合，其实没有比较意义，但可以解释一下这个颜色，我们放大来看；\n 深绿色，表示这个span在只存在于trace-B中，A没有这个span 深红色，表示这个span在只存在于trace-A中，B没有这个span  不过这不是绝对的，因为我看到了这种比较情况\n同样是深绿色，但是两个trace种都有这个span，只是B多于A，我想可以通过数值+8%得出结论，B的span数是14，A是13，算起来就是多了大约8%，看来我们更应该关注这个数值，不过我想颜色的深浅仍然可以代表差距的大小。\n下面看另一张图：\n这里还有两种颜色;\n 浅绿色，表示这个span在trace-B（右边这个）的数量多余trace-A 浅红色，表示这个span在trace-A（左边这个）的数量多于trace-B  最后就是看到的更多的灰色，表示两个trace中都有这个span，且数量一致。\n那么到底如何根据比较得出结论？ 看下面这张图\n推断： 首先A和B在靠近root span的部分有重合，但大量的child span显示深红色表示 trace-B缺少这些深红色的span，一般表示在灰色span处发生了调用失败事件，导致一连串的span消失。\n这样的比较可以在调查事件时提供非常及时和细致的线索。我们可以快速而自信地缩小搜索范围。\n如果发生上图这样的事件，我们不应该直接去看深红色的span细节，而应该查看靠近它们的灰色span的log信息，以快速定位问题。\nkratos集成jeager 前提docker下已经部署了jeager，之后开放了端口 http://localhost:14268\n下载安装包 1 2  # 主要是otel ==\u0026gt; go get -u go.opentelemetry.io/otel $ go get -u go.opentelemetry.io/otel/exporters/jaeger   添加jeager到grpc服务 文件地址：balance/internal/server/grpc.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  package server import ( ... \u0026#34;go.opentelemetry.io/otel\u0026#34; \u0026#34;go.opentelemetry.io/otel/attribute\u0026#34; \u0026#34;go.opentelemetry.io/otel/exporters/jaeger\u0026#34; \u0026#34;go.opentelemetry.io/otel/sdk/resource\u0026#34; \u0026#34;go.opentelemetry.io/otel/sdk/trace\u0026#34; semconv \u0026#34;go.opentelemetry.io/otel/semconv/v1.4.0\u0026#34; ... ) // 设置全局trace func initTracer(url string) error { // 创建 Jaeger exporter \texp, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(url))) if err != nil { return err } tp := trace.NewTracerProvider( // 将基于父span的采样率设置为100% \ttrace.WithSampler(trace.ParentBased(trace.TraceIDRatioBased(1.0))), // 始终确保再生成中批量处理 \ttrace.WithBatcher(exp), // 在资源中记录有关此应用程序的信息 \ttrace.WithResource(resource.NewSchemaless( semconv.ServiceNameKey.String(\u0026#34;kratos-balance\u0026#34;), attribute.String(\u0026#34;exporter\u0026#34;, \u0026#34;wjb\u0026#34;), attribute.Float64(\u0026#34;float\u0026#34;, 388.66), )), ) otel.SetTracerProvider(tp) return nil } // NewGRPCServer new a gRPC server. func NewGRPCServer(c *conf.Server, balanceService *service.BalanceService, logger log.Logger) *grpc.Server { ... err := initTracer(\u0026#34;http://localhost:14268/api/traces\u0026#34;) if err != nil { panic(err) } ... }   ","description":"Jaeger是一个开源的分布式追踪系统，用于监控和诊断微服务架构中的应用程序。","id":22,"section":"stack","tags":["knowledge"],"title":"Jeager链路追踪系统","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/jeager/"},{"content":"OpenTracing概念 OpenTracing 分布式调用链标准（OpenTracing）\n为了让分布式链路追踪技术有一个行业标准，CNCF（云原生计算基金会） 推出了 OpenTracing 项目\nOpenTracing 项目是 与平台厂商无关的链路解决方案，它不提供具体的实现代码，只制定规范，让接入它的系统能有个一致的协议。\nJaeger 、 Skywalking 等分布式链路追踪产品都是根据这个标准实现的。\nOpenTracing 是一个中立的分布式追踪的 API 规范，提供了统一接口方便开发者在自己的服务中集成一种或者多种分布式追踪的实现，使得开发人员能够方便的添加或更换追踪系统的实现。\nOpenTracing 可以解决 不同的分布式追踪系统 API 不兼容的问题 ，各个分布式追踪系统都来实现这套接口。\nOpenTracing数据模型 OpenTracing 的数据模型，主要有三个：\n1.Trace： 可以理解为 一个完整请求链路 ，也可以认为是由 多个 span 组成的有向无环图(DAG) \n2.Span： span 代表系统中具有开始时间和执行时长的逻辑运行单元，只要是 一个完整生命周期的程序访问 都可以认为是一个 span，比如一次数据库访问，一次方法的调用，一次 MQ 消息的发送等；\n每个 span 包含: 操作名称 、起始时间、结束时间、阶段标签集合（Span Tag）、阶段日志（Span Logs）、阶段上下文（SpanContext）、引用关系（Reference）；\n3.SpanContext Trace 的全局上下文信息，span 的状态通过 SpanContext 跨越进程边界进行传递，比如包含 trace id，span id，Baggage Items（一个键值对集合）\nTraceId 是这个请求的全局标识。内部的每一次调用就称为一个 Span，每个 Span 都要带上全局的 TraceId，这样才可把全局 TraceId 与每个调用关联起来。\n这个 TraceId 是通过 SpanContext 传输的，既然要传输，显然都要遵循协议来调用。\n 如果我们把传输协议比作车，把 SpanContext 比作货，把 Span 比作路应该会更好理解一些。\n 设计方案 OpenTracing的设计方案包括以下几个核心组件：\nTracer: 跟踪器是OpenTracing的核心组件，用于创建和管理跟踪span。它还提供了一组标准API，用于在应用程序中嵌入跟踪代码\nAPI: API是一组标准化的接口，用于跨语言和跨平台地记录和传递跟踪数据\nSpan： Span是跟踪中的基本单位，用于描述操作的开始和结束。它可以包含事件、标签和日志，并可以与上下文关联。\nContext: Context是OpenTracing中用于传递上下文信息的关键组件.它可以包含操作ID、Span和其他跟踪数据，用于跨越不同服务和调用之间的信息传递。Context通常需要与RPC系统和HTTP框架进行集成，以便在不同的服务之间传递跟踪信息。\nCarrier: Carrier是OpenTracing中用于传递跟踪数据的载体。它可以是HTTP请求头、RPC参数、日志文件等等。通过使用标准化的Carrier格式，不同的跟踪系统可以互相兼容并集成。\n在设计OpenTracing时，还考虑了可扩展性和可插拔性。跟踪器和跟踪系统可以根据需要进行定制和更改，而不会影响应用程序中的跟踪代码\n底层原理: 在实现OpenTracing时，通常会使用两个核心组件：Tracer和Span\nTracer Tracer是OpenTracing中的核心组件之一，它充当了跟踪系统和应用程序之间的桥梁。\nTracer主要负责管理和创建Span和Trace。Span是代表代码执行时间和相关上下文信息的对象，而Trace是包含所有Span的集合。Tracer可以通过将跟踪数据发送到跟踪系统进行存储和分析，以便开发人员能够更好地了解应用程序的行为和性能。\n在OpenTracing中，Tracer对象是 线程安全的，因此可以在多个线程中使用。通常，Tracer应该在应用程序中只有一个实例。创建Tracer实例时，通常需要提供一些配置选项，例如 跟踪系统的地址、采样率等。\nSpan Span是OpenTracing中的另一个核心组件，它代表了一段代码的执行时间和相关的上下文信息。Span通常被嵌套在Trace中，并且可以包含其他Span。\nSpan通常由以下几个部分组成：\nSpanContext： 包含Span的元数据，例如Span的唯一标识符、父Span的标识符等\nOperation Name： Span的名称，用于描述Span代表的操作\nStart Time： Span的开始时间，用于记录Span开始执行的时间\nEnd Time： Span的结束时间，用于记录Span执行结束的时间\nTags： 用于添加Span的标签，例如Span的名称、开始时间、结束时间等\nLogs： 用于向Span中添加日志和事件信息，例如请求开始和结束的时间、传输的数据等\nSpan通常由以下几个操作组成：\nStartSpan： 用于开始一个新的Span，并返回一个Span对象\nSetTag： 用于添加Span的标签\nLog： 用于向Span中添加日志和事件信息\n使用Tracer和Span可以帮助开发人员更好地了解应用程序的行为和性能。Tracer可以帮助开发人员将应用程序的跟踪数据发送到跟踪系统进行存储和分析，而Span则可以用来描述整个请求的跟踪信息\n一个Span可以和一个或者多个Span间存在因果关系。\nOpen Tracing定义了两种关系：ChildOf (子节点) 和 FollowsFrom (父节点)\n在使用OpenTracing时，开发人员需要在代码中创建Span，并通过Tracer将Span与跟踪操作相关联。\n下面是一些使用OpenTracing的python示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  import opentracing # 创建一个新的Tracer对象 tracer = opentracing.Tracer() # 开始一个新的Spanwith  tracer.start_active_span(\u0026#39;my_operation\u0026#39;) as scope: span = scope.span # 在Span中添加一些标签  span.set_tag(\u0026#39;key\u0026#39;, \u0026#39;value\u0026#39;) # 记录一些日志  span.log_kv({\u0026#39;event\u0026#39;: \u0026#39;my_event\u0026#39;, \u0026#39;data\u0026#39;: \u0026#39;my_data\u0026#39;}) # 执行一些操作  do_something() # 结束Span  scope.close()   上面的代码使用Python的OpenTracing库创建了一个新的Tracer对象，并使用start_active_span方法开始一个新的Span。在Span中，开发人员可以添加标签、记录日志、执行操作等。当跟踪操作完成后，Span会被自动关闭并提交给Trace。\nLog的概念 每个Span可以进行多次Logs操作，每一个Logs操作，都需要一个带时间戳的时间名称、以及可选的任意大小的存储结果。\nTags的概念 每个Span可以有多个键值对（key:value）形式的Tags，Tags是没有时间戳的，支持简单的对Span进行注解和补充。\nOpenTracing理论的开源项目 Jaeger Jaeger是一个开源的分布式追踪系统，支持OpenTracing规范，并提供了一个用于收集、存储和查询 跟踪数据的平台。\n并支持多种语言和平台。Jaeger可以帮助用户了解服务之间的依赖关系，找到性能瓶颈，进行故障排除等。在Jaeger中，开发人员可以使用OpenTracing API创建Span，并将它们与Jaeger进行交互。\nJaeger的设计与OpenTracing的原则非常一致。\nJaeger的架构包括以下组件：\nAgent： 运行在每个主机上的进程，用于 接收Span数据并将其发送到Collector\nCollector： 收集Agent发送的Span数据 ，并存储在数据库中\nQuery： 提供一个Web界面，用于查询和分析 存储在数据库中的Span数据\nStorage： 用于 存储Span数据的后端存储，支持Cassandra、Elasticsearch和Memory三种存储方式\nZipkin Zipkin是Twitter开源的分布式跟踪系统，它也实现了OpenTracing规范，并支持多种语言和平台。Zipkin可以帮助用户追踪请求的路径，分析服务之间的依赖关系，以及找到性能瓶颈。\nSkyWalking SkyWalking是Apache基金会孵化的分布式APM系统，它也支持OpenTracing规范。SkyWalking可以帮助用户追踪分布式系统中的请求，分析服务之间的依赖关系，以及监控服务的性能指标。\n方案对比 ","description":"分布式调用链标准 OpenTracing","id":23,"section":"stack","tags":["knowledge"],"title":"OpenTracing","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/opentracing/"},{"content":"概述 prometheus 是一个 时间序列 数据库\nprometheus特点  多维度数据模型\nPrometheus 使用多维度的数据模型来存储时间序列数据 强大的查询语言\nPromQL 是 Prometheus 的查询语言，支持丰富的操作符和函数，可以实现复杂的数据分析和统计 灵活的警报机制\nPrometheus 支持基于查询语言的警报规则，可以实现灵活的警报策略和通知方式 易于扩展和集成\nPrometheus 提供了丰富的客户端库和插件，可以轻松地集成到各种应用和系统中，并支持水平扩展和高可用部署  prometheus整体架构图：\n组件介绍 三台服务器\n prometheus服务器 被监控的服务器 grafana服务器  Prometheus 负责数据收集处理，Grafana 负责前台展示数据。其中采用 Prometheus 中对接的各 Exporter 包含：\n Node Exporter（核心组件），负责收集所属节点的硬件和操作系统数据，可外挂客制化收集数据文件。它将以容器方式运行在所有节点上; 其他各专属类型Exporter，例如上篇介绍的HPC高性能计算环境下，有针对调度系统专用的Exporter； Alertmanager（可选组件），负责告警，它将以容器方式运行在所有节点上; 其他组件，如cadvisor监控容器等  Prometheus Node-exporter Grafana docker和docker-compose安装 安装docker 1 2 3 4 5 6 7 8 9 10 11 12  # 安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加Docker软件包源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 安装Docker CE yum install docker-ce -y # 启动 systemctl start docker # 开机启动 systemctl enable docker # 查看Docker信息 docker info   安装docker-compose 1 2 3 4  # 直接下载到/usr/local/bin/下即可 curl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose # 这是一个基于python编写的可执行脚本文件，下载后需要赋予可执行权限，运行需要依赖python环境 chmod +x /usr/local/bin/docker-compose   添加配置文件 1 2  mkdir -p D/mydocker/prometheus/config cd D/mydocker/prometheus/config   添加 prometheus.yml 配置文件 1 2  # 添加 prometheus.yml 配置文件 vim prometheus.yml   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  # my global configglobal:scrape_interval:15s# Set the scrape interval to every 15 seconds. Default is every 1 minute.evaluation_interval:15s# Evaluate rules every 15 seconds. The default is every 1 minute.scrape_timeout:10s# scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting:alertmanagers:- static_configs:- targets:[\u0026#34;172.19.0.22:9093\u0026#34;]# - alertmanager:9093# Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;.rule_files:- \u0026#34;node_down.yml\u0026#34;# - \u0026#34;first_rules.yml\u0026#34;# - \u0026#34;second_rules.yml\u0026#34;# A scrape configuration containing exactly one endpoint to scrape:# Here it\u0026#39;s Prometheus itself.scrape_configs:# The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config.- job_name:\u0026#34;prometheus\u0026#34;static_configs:- targets:[\u0026#34;172.19.0.21:9090\u0026#34;]- job_name:\u0026#34;cadvisor\u0026#34;static_configs:- targets:[\u0026#34;172.19.0.24:8080\u0026#34;]# 以下为各节点类型分组# 管理节点组- job_name:\u0026#34;mgt\u0026#34;scrape_interval:8sstatic_configs:- targets:[\u0026#34;172.19.0.25:9100\u0026#34;]- job_name:\u0026#34;io\u0026#34;scrape_interval:8sstatic_configs:- targets:[\u0026#34;172.19.0.25:9100\u0026#34;]- job_name:\u0026#34;login\u0026#34;scrape_interval:8sstatic_configs:- targets:[\u0026#34;172.19.0.25:9100\u0026#34;]  添加邮件告警配置文件 添加配置文件 alertmanager.yml，配置收发邮件邮箱\nvim alertmanager.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  global:smtp_smarthost:\u0026#39;smtp.163.com:25\u0026#39;#163服务器smtp_from:\u0026#39;xxxxxx@163.com\u0026#39;#你的发邮件的邮箱smtp_auth_username:\u0026#39;xxxxxx@163.com\u0026#39;#你的发邮件的邮箱用户名，也就是你的邮箱smtp_auth_password:\u0026#39;*********\u0026#39;#发邮件的邮箱密码smtp_require_tls:false#不进行tls验证route:group_by:[\u0026#39;alertname\u0026#39;]group_wait:10sgroup_interval:10srepeat_interval:10mreceiver:live-monitoringreceivers:- name:\u0026#39;live-monitoring\u0026#39;email_configs:- to:\u0026#39;xxxxxxxxxx@qq.com\u0026#39;#收邮件的邮箱  添加报警规则 添加一个 node_down.yml 为 prometheus targets 监控\nvim node_down.yml\n1 2 3 4 5 6 7 8 9 10 11  groups: - name: node_down rules: - alert: InstanceDown expr: up == 0 for: 1m labels: user: test annotations: summary: \u0026#39;Instance {{ $labels.instance }} down\u0026#39; description: \u0026#39;{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minutes.\u0026#39;   编写 docker-compose vim docker-compose-monitor.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  ...prometheus:build:./prometheuscontainer_name:prometheushostname:prometheusports:- \u0026#34;9090:9090\u0026#34;volumes:- /Users/wangdante/D/kugou/:/var/www/html/- /Users/wangdante/D/mydocker/prometheus/config/prometheus.yml:/etc/prometheus/prometheus.yml- /Users/wangdante/D/mydocker/prometheus/config/node_down.yml:/etc/prometheus/node_down.ymlrestart:alwaysnetworks:jarven:ipv4_address:172.19.0.21alertmanager:build:./alertmanagercontainer_name:alertmanagerhostname:alertmanagerports:- \u0026#34;9093:9093\u0026#34;volumes:- /Users/wangdante/D/mydocker/prometheus/config/alertmanager.yml:/etc/alertmanager/alertmanager.ymlrestart:alwaysnetworks:jarven:ipv4_address:172.19.0.22grafana:build:./grafanacontainer_name:grafanahostname:grafanaports:- \u0026#34;3000:3000\u0026#34;restart:alwaysnetworks:jarven:ipv4_address:172.19.0.23cadvisor:build:./cadvisorcontainer_name:cadvisorhostname:cadvisorports:- \u0026#34;8080:8080\u0026#34;# volumes:# - /:/rootfs:ro# - /var/run:/var/run:rw# - /sys:/sys:ro# - /var/lib/docker/:/var/lib/docker:rorestart:alwaysnetworks:jarven:ipv4_address:172.19.0.24node-exporter:build:./node-exportercontainer_name:node-exporterhostname:node-exporterports:- \u0026#34;9100:9100\u0026#34;restart:alwaysnetworks:jarven:ipv4_address:172.19.0.25...  启动 docker-compose 1 2 3 4 5 6 7  # 使用docker-composer命令启动yml里配置好的各容器 docker-compose -f /usr/local/src/config/docker-compose-monitor.yml up -d # 删除容器： docker-compose -f /usr/local/src/config/docker-compose-monitor.yml down #重启容器： docker restart id   实际场景示例：\n服务器节点列表及资源监控 用户登录情况监控 ","description":"Prometheus是由go语言开发的一套开源的监控\u0026报警\u0026时间序列数 据库的组合。","id":24,"section":"stack","tags":["knowledge"],"title":"prometheus","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/prometheus/"},{"content":"1、引言 1.1目标与范围 介绍企业IT数仓建设体系、架构和数据仓库开发规范，并附上实际案例加以说明，为数据仓库建设工作提供规范标准和指导建议。\n1.2适用对象 1)数据仓库设计人员\n2)数据仓库开发人员\n3)数据仓库运维人员\n4)数据需求对接人\n1.3相关参考 【1】【腾讯视频】离线数仓建设规范化流程实践\nhttps://km.woa.com/group/47744/articles/show/441043?sessionKey=TE746fC4fhrE7zhbRc1QrvdYxWOT7MT0\n【2】滴滴数据仓库指标体系建设实践\nhttps://km.woa.com/group/44229/articles/show/441343\n【3】维度建模和指标体系构建\nhttps://km.woa.com/group/47744/articles/show/444548\n【4】《大数据之路-阿里巴巴大数据实践》《数据仓库工具箱-维度建模权威指南》\n1.4数仓建设准则 （1）规范性 保证数据架构分层规范性、数据接入规范性、数据仓库开发规范性。\n（2）一致性 通过领域驱动和一数一源理念保证数据的一致性，统一数据语言，从而进一步保证数据的可信性和数仓建设的灵活性。\n（3）扩展性 模型建设要具备可扩展性，保证能灵活支持元数据变更、数据迁移、数据需求变更等需求。\n（4）时效性 数据采集、处理、查询要具备满足业务需求的高时效保障。\n（5）灵活性 支持多场景的报表新增需求，支持报表的灵活变更需求。\n（6）安全性 保证全生命周期的数据安全，包括但不限于数据采集、传输、处理、存储、消费、共享过程中的安全。\n2数仓体系整体设计  业务视角：依照公司管理职能和数据领域划分业务板块，如企业集团的IT数据管理领域等；其中，IT业务板块又可以根据业务职能划分为相对独立的业务域，如HR、财务等；一个完整的业务域一般由三类数据构成，分别是：基础数据（又叫参考数据）、交易数据、主数据。 交易数据区：一般根据业务事项产生，具有事务发生日期属性，属于事务性数据，也是具体的业务过程数据存储区。 基础数据区：基础数据存储的是时间周期或者修饰词信息，是描述业务数据的数据，一般引用外部标准或者战略业务等的配置数据，如管理架构、平台产品、业务渠道等具备管理视角的数据，未来可形成维表或衍生指标。 业务主数据区：一般来源于业务系统，结构及内容与业务系统完全一致，如人员信息表、组织架构、财务科目等。  3数仓库架构设计 3.1 架构图 3.2架构分区说明 数据仓库模型建设的核心内容是DW和ADS数据层建设，且遵循Kimball模型建设理论，其他层的数据逻辑模型可参照上层数据的模型进行迁移转化。\n3.2.1 ODS    中文名 数据预处理区     英文全名 Operational Data Store   模型设计说明 主要包含业务数据库快照数据、运营埋点数据、其他业务等数据   数据类型 交易数据、基础数据、业务主数据   表类型 事务事实表（增量表）   ETL工作 1）同步：结构化数据增量或全量同步到数据仓库；\u000b2）结构化：非结构化数据结构化处理后同步到数据仓库；\u000b3）保存历史\u000b4）数据预处理：根据数据业务需求校验数据、过滤数据，进行基础的数据预处理工作   备注 业务覆盖度要恰当，尽量覆盖关键核心的业务数据    3.2.2 TMP    中文名 临时数据区     英文全名 Tempare Data Store   模型设计说明 临时层， 数据处理的辅助处理层，服务DWD、DWS 层，主要是一些临时存储的数据   数据类型 业务数据、基础数据、主数据   表类型 全量事实表   ETL工作 数据抽取加载，不涉及数据处理   备注 根据自定义需求、尽量不要占用资源、需及时清除数据    3.2.3 DW  BMD     中文名 业务主数据区     英文全名 Business Master Data   模型设计说明 核心业务对象，自动定期从业务源系统同步   数据类型 主数据   表类型 拉链表   ETL工作 主数据集成（主数据也可以被直接统计为数据指标、也可以作为分析维度）   备注 业务主数据区数据模型相对交易数据区的数据模型会稳定很多     DWD     中文名 数据仓库明细层     英文全名 Data Warehouse Detail   模型设计说明 存储经过标准规范化处理(即数据清洗)后的运营数据，是基础事实数据明细层。实例:行为事件明细表、MySQL 各业务数据经过 ETL 处理后的实体表   数据类型 业务数据   表类型 事务事实表   ETL工作 参考数据资产目录数据业务域划分标准，按业务域聚合交   备注 数据模型能满足指标建设需求，模型中各个事务的维度粒度要保持一致，且要求维度的最细粒度，覆盖度越高完善度越好     DIM     中文名 数据仓库维度表层     英文全名 Dimension data   模型设计说明 维度数据层，主要包含一些业务维度数据。实例：地区表，订单状态，支付方式，审批状态，商品分类，商品型号，渠道类型、终端类型、广告位、红包计划等   数据类型 基础数据   表类型 拉链表   ETL工作 建立一致数据分析维表，降低数据计算口径、算法不统一的风险   备注 模型是所有数据类型中最稳定的，能支持对指标分析维度进行灵活的下钻与聚合分析     DWS     中文名 数据公共汇总层     英文全名 Data Warehouse Summery   模型设计说明 按数据业务域进行划分，支持 OLAP 分析、数据分发等，其信息主要来源于 DWD 层汇总后的数据。实例:财务损益明细汇总表   数据类型 主题域OLAP数据模型数据分析区   表类型 累计快照表   ETL工作 本数据区域根据依据指标矩阵负责从技术加工、业务一致性等共性方向将生成公共数据，为下游数据提供单一的数据口径输出，最大化实现一次加工多次使用   备注 该区域模型一般采用的星花模型，支持对多项同粒度的业务过程进行多维度的分析，分析的指标粒度具有通用性，是报表分析较其他数据区引用度最高的数据区     DM(数据集市)     中文名 数据集市     英文全名 Data Mart   模型设计说明 数据集市就是满足特定的部门或者用户的需求，按照多维的方式进行存储，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体，一般是一个存储衍生指标的指标库   数据类型 主题域星型模型数据区，大宽表物化视图区   表类型 累计快照表   ETL工作 在数据仓库领域，该层根据业务需求从DWS抽取加工数据，建立汇总宽表、支持报表分析   备注 属于高粒度多维度聚合的数据模型区，也称为立方体（cube），往往直接支持决策层和管理层的报表需求，场景简单时，此层可省略    3.2.4 MDW    中文名 元数据信息层     英文全名 Meta Data Warehouse   模型设计说明 元数据机制主要支持以下五类系统管理功能：1、描述哪些数据在数据仓库中; 2、定义要进入数据仓库中的数据和从数据仓库中产生的数据; 3、记录根据业务事件发生而随之进行的数据抽取工作时间安排; 4、记录并检测系统数据一致性的要求和执行情况; 5、衡量数据质量。   数据类型 元数据   表类型 拉链表   ETL工作 本数据区，直接集成数据库的元数据信息   备注 根据数据资产管理、数据资产分析需求进行建模    3.2.5 ADS    中文名 应用数据层     英文全名 Application Database Service   模型设计说明 面向具体应用的表，要创建在这层，一般一些特定应用的个性化处理的复杂指标或者数据表会放在这层   数据类型 应用主题数据   表类型 全量表   ETL工作 在数据仓库领域，该层根据业务需求从ods/dwd/dws/dm抽取加工数据，对数据做如下处理：1）个性化指标加工：不公用性、复杂性指标（指数型、排名型，比值型）；2）对应用数据进行组装：大宽表、行转列表、趋势指标串、画像分析等   备注     4数据仓库开发规范 4.1 指标管理规范 4.1.1 指标分析流程说明 指标建设首先需要确定数据的业务板块（一般对应数据资产目录的数据域分组），在将指标需求根据其业务定义拆解成为业务过程和业务对象，将业务过程拆解出分析维度和原子指标，最终进一步生成派生指标，其中业务对象及其属性以及派生指标中的修饰词和时间周期也可以作为事实表的维度属性，业务过程将被作为事实表。具体关系及示例如下图：\n4.1.2 指标命名规范 （1）命名原则\n●统一性：保持全局一致、唯一\n●可读性：遵循指标分析流程、英文简写清晰易懂、不易产生歧义\n●易维护性：具有明确的规则\n●可扩展性：长度限制以及组合规则可支持业务指标扩展\n（2） 规则定义\n原子指标：[动作]+[业务对象]+度量\n【示例】打卡员工数：cki_emp_cnt\n衍生指标：[时间周期] +[修饰词]+原子指标([动作]+[业务对象]+度量)\n【示例】上周迟到打卡的女员工数：lw_late_cki_emp_f_cnt\n复合指标：[时间周期] +[修饰词]+原子指标([动作]+[业务对象]+度量)\n【示例】上周迟到打卡的女员工占比：lw_late_cki_emp_f_rat\n（3） 组成规则说明\n●常见统计时间周期列表\n中文名\t英文名\t中文名\t英文名\n最近1天\t1d\t当前月\tcm\n最近7天\t7d\t当前季度\tcq\n最近1个月\t1m\t截止当日\ttd\n最近1小时\t1h\t年初累计到当日\tytd\n未来7天\tf1w\t月初累计到当日\tmtd\n本周\tcw\t上周\tlw\n●常见业务对象列表\n业务主体\t英文全称\t英文简称\n组织\torganization\torg\n项目\tproject\tproj\n合同\tcontract\tcontr\n产品\tproduct\tprod\n渠道\tchannel\tchnnl\n订单\torder\torder\n……\t……\t……\n●常见度量列表\n度量类型\t英文名\t英文缩写\n计数\tcount\tcnt\n计金额\tamount\tamt\n占比\trate\trat\n4.2 数据模型开发规范 4.2.1 数据模型开发指引 （1）表级开发指引说明\n   表类型 说明 开发指引     拉链缓慢变化表 保存一个业务对象全生命周期的数据，通过对业务对象代理键更新插入的方式加载数据 必须增加业务主键级别的start_dt,end_dt，另外要有数据接入时间，对象生成时间，数据来源信息   快照表-缓慢变化表 按照更新时间分区保持当前状态的全部对象数据，业务过程或对象当前状态和前一天状态没有关系，增量方式加载数据，通过日期限制查询对象当前状态，通过业务代理键查询业务全生命周期数据 必须按当前更新时间dt作为分区字段，另外要有数据接入时间，事务生成时间，数据来源信息   快照表-周期变化表 按照更新时间分区保持当前状态的全量数据，业务过程或者对象当前状态与之前的状态相关，采用增量加载 必须按当前更新时间dt作为分区字段，另外要有数据接入时间，事务生成时间，数据来源信息   快照表-事务增量表 日志型或者事务型数据，当前数据和历史数据业务主键完全不相关，增量加载就行 需具备数据接入时间，事务生成时间，数据来源信息    （2）字段开发指引说明\n   字段类型 说明 开发指引     ID字段 表自生成的自然键 流水号，长度最好不要超过21位   关联维度 对应维度信息的代理键和名称，或者只有代理键或名称 维度管理最好具备外键ID或者外键编码，同时具备维度Id 值对应的name值   日期字段 业务元数据日期或者管理元数据日期 Hive、clickhouse中的日期字段统一采用字符串类型存储，时间戳除外   时间字段 业务元数据时间或者管理元数据时间 Hive、clickhouse中的日期字段统一采用字符串类型存储，时间戳除外   指标字段  只能为数值型，控制精度   编码字段 外部唯一标识，代理键 编码字段，必须保证编码的可读性、可扩展性和一致性    （3）表间开发指引说明\n   关系类型 说明 开发指引     业务对象各个业务过程关联 业务过程按照最细粒度进行对象关联 通过一致性最细粒度业务对象编码关联   桥接表关联 具有映射关系的三个表关联，一般是跨系统编码映射，标准对齐等    父子表关联 具有层级关系的维度表 表需具备上级的编码或者ID    4.2.2 数据模型命名规范 （1）命名原则\n●统一性：全局唯一，统一使用小写字母，表名统一由字母和下划线（_）组成\n●可读性：标准化管理规则，英文简称清晰易懂，避免歧义\n●易维护性：具有明确的规则\n●可扩展性：长度限制支持对象新增和迁移可扩展；\n●稳定性：名称一旦确定，全生命周期保持不变\n4.2.2.1 表命名规范 (1)公式及样例\n（3）规则说明\n●更新方式\n   更新方式 编码 编码说明     全量 f full的缩写   增量 i increase的缩写    ●存储方式\n   存储方式 编码 编码说明     拉链表 z zip的缩写   快照表 s snapshot的缩写    ●时间粒度\n   时间粒度 编码 编码说明     每天更新 1d day   每周更新 1w week   每月更新 1m month   每2小时更新 2h hour   每5分钟更新 5min minute    ●分区信息\n   分区 编码 编码说明     分区表 p partition   非分区表 /     4.2.2.2 字段命名规范 对字段进行标准命名需遵循两个过程：\n●确定标准字段（原子字段）\n标准字段一般由实体+字段属性组成\n●遵循继承关系\n对衍生字段确定其所继承的原子字段，从而保障字段的属性一直，例如：“投保人号”、“被保人号”，本质为“客户号”。在设计表字段时，它们都将从标准字段（客户号）继承，具有与标准字段相同的数据类型（长度/精度）、数据格式、校验规则、默认值。\n（1）规则定义\n   公式 [修饰词]_ [业务主体]_ [业务过程]属性字段[标识主体]     公式说明 []表示可有字段，‘标识字段’是属于主体的标签字段，一般是主体的属性的具体属性值，或者业务过程的状态                   基本信息字段 字段中文名称 修饰词 业务主体 业务过程 属性字段 标识主体 字段名称   基本信息字段 组织名 / org  name / org_name   基本信息字段 合同审批状态 / cntrct approval status / cntrct_approval_status   指标字段 QQ音乐下载 qqmusic user down cn / qqmusic_user_down_cn   日期字段 注册日期 /  reg date / reg_date   时间字段 修改时间 /  upd time / upd_time   判断字段 是否完成 /   is finish is_finish   判断字段 是否新员工 / / / is new_emp is_new_emp    4.3 其他规范  所有层 ：ds字段，date类型，格式2023-04-05，取跑任务的当前时间；但是ODS层例外，ODS层沿用之前的逻辑，写的是跑任务的当前时间的前一天；query_effdt字段，varchar类型，格式2023-04-05；在Starrocks里面，如果需要用到这个字段来做分区，可以做成date类型；DWD以上的层，对null字段都需要处理为''，也就是空字符串 ODS：\n1.ds字段：日期分区字段，date类型，格式2023-04-05，每天凌晨跑数时取跑数时-1的日期作为该字段的值（虽然更好的是去跑数当天的日期，但是以前的逻辑都已经取T-1，所以就沿用过去的逻辑）。\n2.bs_flag字段：是否补跑标记\n3.加密方式：跟原敏感仓一致，使用别名“HR_CRYPTIC_DW”对需要加密的字段进行加密；加密盐为emplid字段，如果没有emplid字段，则使用deptid，如果也没有则根据业务系统特点选字段，但是要在“数据备注”中注明。  5、样例说明 为了更清晰的说明数据仓库各个核心数据区具体的模型和数据关系，初步以HR域的HR门户和集音社两个系统的订单相关表和员工信息表为例，进行数仓建设和相关的指标分析，具体模型关系图如下：\n","description":"介绍企业IT数仓建设体系、架构和数据仓库开发规范，并附上实际案例加以说明，为数据仓库建设工作提供规范标准和指导建议。","id":25,"section":"stack","tags":["db",""],"title":"数仓建设规范","uri":"http://wangjinbao.netlify.app/en/stack/db/tips/"},{"content":"介绍 是一个可读性高，用来表达数据序列的格式。\nYAML 的意思其实：仍是一种 标记语言，但为是强调这种语言 以数据做为中心，而不是以标记语言为重点\n基本语法  缩进时不允许使用Tab键，只允许使用空格 缩进的 空格数目不重要，只要相同层级的元素左侧对齐即可 '#\u0026lsquo;标识注释，从这个字符一直到行尾，都会被忽略  YAML支持的数据结构  对象：键值对的集合，对称为映射(mapping)/哈希(hashes)/字典(dictionary) 数组：一组按次序排列的值，又称为序列(sequence)/列表(list) 纯量：单个的、不可再分的值  对象类型： 对象的一组键值对，使用冒号结构\n1 2  name: Steve age: 18   YAML也允许另一种写法，将所有键值对写成一个行内对象\n1  hash: {name: Steve, age: 18}   数组类型： 一组连词线开头的行，构成一个数组\n1 2 3  animal - Cat - Dog   数组也可采用行内表示法：\n1  animal: [Cat, Dog]   复合结构： 对象和数组可以结合使用，形成复合结构\n1 2 3 4 5 6  languages: - Ruby - Python websites: Ruby: ruby-lang.org Python: python.org   纯量： 纯量是最基本的、不可再分的值。以下数据类型都属纯量\n 字符串 布尔值 整数 浮点数 Null 时间 日期  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  数值直接以字面量的形式表示： number: 12.30 布尔值用true和false表示： isSet: true null用 ~ 表示： parent: ~ 时间采用 ISO8601 形式 iso8601: 2001-12-15t21:01:01.10-05:00 日期采用复合 iso8601 格式的年、月、日表示 date: 1976-07-31 YAML 使用两个感叹号，强制转换数据类型 e: !!str 123 f: !!str true   字符串 字符串默认不使用引号：\n1  str: 这是一行字符串   如果字符串之中包含空格或特殊字符，需要放在引号之中\n1  str: \u0026#39;内容： 字符串\u0026#39;   单引号和双引号都可以使用，双引号不会对特殊字符转义\n1 2  s1: \u0026#39;内容\\n字符串\u0026#39; s2: \u0026#34;内容\\n字符串\u0026#34;   单引号中如果还有单引号，必须连续使用两个单引号转义\n1  str: \u0026#39;Tom\u0026#39;\u0026#39;s day\u0026#39;   字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为 空格\n1 2 3  str: 这是一段 多行 字符串   多行字符串可以使用|保留换行符，也可以使用\u0026gt;折叠换行\n1 2 3 4 5 6  this:| Foo Bar this:\u0026gt; Foo Bar   +表示保留文字块末尾的换行，-表示删除字符串末尾的换行：\n1 2 3 4 5 6  s1:| Foo s2:|+ Foo s3:|- Foo   ","description":"yaml格式、语法","id":26,"section":"stack","tags":["knowledge"],"title":"浅谈yaml","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/yaml/"},{"content":"介绍 市面上常用的嗠注册中心有：\n Eureka Nacos Consul ZooKeeper Etcd CoreDNS   Eureka2.X版本官方已经停止更新了。\n Consul是HashiCorp公司推出使用go语言开发的开源工具,，用于实现分布式系统的服务发现与配置。 Consul是 分布式的 、高可用的 、 可横向扩展的。\nconsul特性  Raft算法：   PS:Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题：Leader选举（Leader election）、日志同步（Log replication）、安全性（Safety）、日志压缩（Log compaction）、成员变更（Membership change）等\n  服务发现：\nconsul通过DNS或者HTTP接口使服务注册和服务发现变的很容易，一些外部服务，例如saas提供的也可以一样注册。 健康检查 ：\n健康检测使consul可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面。 Key/Value存储 ：\n一个用来存储动态配置的系统。提供简单的HTTP接口，可以在任何地方操作。 多数据中心 ：\n无需复杂的配置，即可支持任意数量的区域。 支持http和dns协议接口 官方提供web管理界面  consul角色 client:客户端 无状态，将 HTTP和DNS接口 请求转发给局域网的服务端集群。\nserver:服务端 保存配置信息，高可用集群，每个数据中心的server数量推荐为3个或5个\nconsul工作原理 1.服务发现以及注册 当服务 Producer 启动时，会将自己的 IP/host 等信息通过发送请求告知 Consul 、 Consul 接收到 Producer 的注册信息后，每隔10s(默认)会向 Producer 发送一个健康检查的请求，检验 Producer 是否健康。\n2.服务调用 当 Consumer 请求 Producer 时，会先从 Consul 中拿到存储 Producer 服务的 IP和Port 的临时表（temp table）,从temp table 表中任选一个 Producer 的IP和Port,然后根据这个IP和Port，发送访问请求；temp table表只包含通过了健康检查的 Producer 信息，并且每隔10s（默认）更新。\nconsul安装(本地) 官方网站：\nhttps://consul.io/\n安装consul  方式一：macOS系统：  1 2 3 4  brew tap hashicorp/tap brew install hashicorp/tap/consul //检查版本号 consul version   验证启动 1 2 3 4 5 6 7  //启动consul consul agent -dev ... 2023-11-17T16:25:34.985+0800 [INFO] agent: Starting server: address=127.0.0.1:8500 network=tcp protocol=http 2023-11-17T16:25:35.025+0800 [INFO] agent: Started gRPC listeners: port_name=grpc_tls address=127.0.0.1:8503 network=tcp 2023-11-17T16:25:35.025+0800 [INFO] agent: Started gRPC listeners: port_name=grpc address=127.0.0.1:8502 network=tcp   访问浏览器：\nhttp://127.0.0.1:8500/\nconsul安装(docker-compose) vim docker-compose.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  version:\u0026#39;3.5\u0026#39;services:consul1:image:consul:latestcontainer_name:consul1restart:alwayscommand:agent -server -client=0.0.0.0 -bootstrap-expect=3 -node=consul1volumes:- /usr/local/docker_my/consul/consul1/data:/consul/data- /usr/local/docker_my/consul/consul1/config:/consul/configconsul2:image:consul:latestcontainer_name:consul2restart:alwayscommand:agent -server -client=0.0.0.0 -retry-join=consul1 -node=consul2volumes:- /usr/local/docker_my/consul/consul2/data:/consul/data- /usr/local/docker_my/consul/consul2/config:/consul/configconsul3:image:consul:latestcontainer_name:consul3restart:alwayscommand:agent -server -client=0.0.0.0 -retry-join=consul1 -node=consul3volumes:- /usr/local/docker_my/consul/consul3/data:/consul/data- /usr/local/docker_my/consul/consul3/config:/consul/configconsul4:image:consul:latestcontainer_name:consul4restart:alwaysports:- 8500:8500command:agent -client=0.0.0.0 -retry-join=consul1 -ui -node=client1volumes:- /usr/local/docker_my/consul/consul4/data:/consul/data- /usr/local/docker_my/consul/consul4/config:/consul/config  说明：\n启动了4个consul，其中consul1 是主节点，consul2、consul3 是子节点。consul4是提供ui服务的。\n启动：\ndocker-compose up -d\n参数说明：\nserver模式启动的命令行参数说明：\n -server：表示当前使用的server模式；如果没有指定，则表示是client模式。 -node：指定当前节点在集群中的名称。 -config-dir：指定配置文件路径，定义服务的；路径下面的所有.json结尾的文件都被访问；缺省值为：/consul/config。 -data-dir： consul存储数据的目录；缺省值为：/consul/data。 -datacenter：数据中心名称，缺省值为dc1。 -ui：使用consul自带的web UI界面 。 -join：加入到已有的集群中。 -enable-script-checks： 检查服务是否处于活动状态，类似开启心跳。 -bind： 绑定服务器的ip地址。 -client： 客户端可访问ip，缺省值为：“127.0.0.1”，即仅允许环回连接。 -bootstrap-expect：在一个datacenter中期望的server节点数目，consul启动时会一直等待直到达到这个数目的server才会引导整个集群。这个参数的值在同一个datacenter的所有server节点上必须保持一致。  consul安装(集群) 首先准备三个节点node1、node2、node3：\n 10.25.84.163 10.25.84.164 10.25.84.165  下载安装包 以linux下安装为例，首先下载安装包，下载地址：https://www.consul.io/downloads.html\n下载后上传到linux服务器，或者直接在linux上下载，版本可自行替换\n1 2  wget https://releases.hashicorp.com/consul/1.7.0/consul_1.7.0_linux_amd64.zip unzip consul_1.7.0_linux_amd64.zip -d /usr/local/bin   设置环境变量 1 2 3 4 5  $ vi /etc/profile export CONSUL_HOME=/usr/local/bin/consul export PATH=$PATH:CONSUL_HOME $ source /etc/profile   验证（三台机） 1 2 3  $ consul version Consul v1.7.0 Protocol 2 spoken by default, understands 2 to 3   启动agent 分别在三台服务器输入以下对应的命令：\n1 2 3 4 5 6 7 8 9  // 启动10.25.84.163 consul agent -server -ui -bootstrap-expect=3 -data-dir=/data/consul -node=server-1 -client=0.0.0.0 -bind=10.25.84.163 -datacenter=dc1 // 启动10.25.84.164，并加入10.25.84.163节点 consul agent -server -ui -bootstrap-expect=3 -data-dir=/data/consul -node=server-2 -client=0.0.0.0 -bind=10.25.84.164 -datacenter=dc1 -join 10.25.84.163 // 启动10.25.84.165，并加入10.25.84.163节点 consul agent -server -ui -bootstrap-expect=3 -data-dir=/data/consul -node=server-3 -client=0.0.0.0 -bind=10.25.84.165 -datacenter=dc1 -join 10.25.84.163   启动日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  [root@localhost ~]# consul agent -server -ui -bootstrap-expect=3 -data-dir=/data/consul -node=server-1 -client=0.0.0.0 -bind=10.25.84.163 -datacenter=dc1 bootstrap_expect \u0026gt; 0: expecting 3 servers ==\u0026gt; Starting Consul agent... Version: \u0026#39;v1.7.0\u0026#39; Node ID: \u0026#39;4a60c9bd-472b-01a3-57f4-c74b8ba4d3df\u0026#39; Node name: \u0026#39;server-1\u0026#39; Datacenter: \u0026#39;dc1\u0026#39; (Segment: \u0026#39;\u0026lt;all\u0026gt;\u0026#39;) Server: true (Bootstrap: false) Client Addr: [0.0.0.0] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600) Cluster Addr: 10.25.84.163 (LAN: 8301, WAN: 8302) Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false ==\u0026gt; Log data will now stream in as it occurs: 2020-02-21T11:28:20.323+0800 [INFO] agent.server.raft: initial configuration: index=0 servers=[] 2020-02-21T11:28:20.324+0800 [INFO] agent.server.raft: entering follower state: follower=\u0026#34;Node at 10.25.84.163:8300 [Follower]\u0026#34; leader= 2020-02-21T11:28:20.325+0800 [INFO] agent.server.serf.wan: serf: EventMemberJoin: server-1.dc1 10.25.84.163 2020-02-21T11:28:20.326+0800 [INFO] agent.server.serf.lan: serf: EventMemberJoin: server-1 10.25.84.163 2020-02-21T11:28:20.326+0800 [INFO] agent.server: Adding LAN server: server=\u0026#34;server-1 (Addr: tcp/10.25.84.163:8300) (DC: dc1)\u0026#34; 2020-02-21T11:28:20.326+0800 [INFO] agent.server: Handled event for server in area: event=member-join server=server-1.dc1 area=wan 2020-02-21T11:28:20.327+0800 [INFO] agent: Started DNS server: address=0.0.0.0:8600 network=tcp 2020-02-21T11:28:20.327+0800 [INFO] agent: Started DNS server: address=0.0.0.0:8600 network=udp 2020-02-21T11:28:20.328+0800 [INFO] agent: Started HTTP server: address=[::]:8500 network=tcp 2020-02-21T11:28:20.328+0800 [INFO] agent: started state syncer ==\u0026gt; Consul agent running! ... 2020-02-21T11:29:27.352+0800 [INFO] agent.server.raft: pipelining replication: peer=\u0026#34;{Voter 31174405-571f-f598-ef74-0a9aba59a6a8 10.25.84.165:8300}\u0026#34; 2020-02-21T11:29:27.352+0800 [WARN] agent.server.raft: appendEntries rejected, sending older logs: peer=\u0026#34;{Voter b3d84299-a458-19bf-2b98-ca9031e6aea4 10.25.84.164:8300}\u0026#34; next=1 2020-02-21T11:29:27.356+0800 [INFO] agent.server.raft: pipelining replication: peer=\u0026#34;{Voter b3d84299-a458-19bf-2b98-ca9031e6aea4 10.25.84.164:8300}\u0026#34; 2020-02-21T11:29:27.368+0800 [INFO] agent.leader: started routine: routine=\u0026#34;CA root pruning\u0026#34; 2020-02-21T11:29:27.368+0800 [INFO] agent.server: member joined, marking health alive: member=server-1 2020-02-21T11:29:27.381+0800 [INFO] agent.server: member joined, marking health alive: member=server-2 2020-02-21T11:29:27.396+0800 [INFO] agent.server: member joined, marking health alive: member=server-3 2020-02-21T11:29:28.609+0800 [INFO] agent: Synced node info   查看集群成员： 1 2 3 4 5 6  [root@localhost ~]# consul members Node Address Status Type Build Protocol DC Segment server-1 10.25.84.163:8301 alive server 1.7.0 2 dc1 \u0026lt;all\u0026gt; server-2 10.25.84.164:8301 alive server 1.7.0 2 dc1 \u0026lt;all\u0026gt; server-3 10.25.84.165:8301 alive server 1.7.0 2 dc1 \u0026lt;all\u0026gt;   命令输出显示了集群节点名称、IP端口、健康状态、启动模式、所在数据中心和版本信息。\n通过HTTP API查看 1  curl 10.25.84.163:8500/v1/catalog/nodes   返回数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  [ { \u0026#34;ID\u0026#34;:\u0026#34;99f8e10c-edda-bb40-21b4-8719ba851308\u0026#34;, \u0026#34;Node\u0026#34;:\u0026#34;agent-1\u0026#34;, \u0026#34;Address\u0026#34;:\u0026#34;10.25.84.163\u0026#34;, \u0026#34;Datacenter\u0026#34;:\u0026#34;dc1\u0026#34;, \u0026#34;TaggedAddresses\u0026#34;:{ \u0026#34;lan\u0026#34;:\u0026#34;10.25.84.163\u0026#34;, \u0026#34;lan_ipv4\u0026#34;:\u0026#34;10.25.84.163\u0026#34;, \u0026#34;wan\u0026#34;:\u0026#34;10.25.84.163\u0026#34;, \u0026#34;wan_ipv4\u0026#34;:\u0026#34;10.25.84.163\u0026#34; }, \u0026#34;Meta\u0026#34;:{ \u0026#34;consul-network-segment\u0026#34;:\u0026#34;\u0026#34; }, \u0026#34;CreateIndex\u0026#34;:5, \u0026#34;ModifyIndex\u0026#34;:11 }, { \u0026#34;ID\u0026#34;:\u0026#34;824a86e6-9713-a136-8037-c489222a88e1\u0026#34;, \u0026#34;Node\u0026#34;:\u0026#34;agent-2\u0026#34;, \u0026#34;Address\u0026#34;:\u0026#34;10.25.84.164\u0026#34;, \u0026#34;Datacenter\u0026#34;:\u0026#34;dc1\u0026#34;, \u0026#34;TaggedAddresses\u0026#34;:{ \u0026#34;lan\u0026#34;:\u0026#34;10.25.84.164\u0026#34;, \u0026#34;lan_ipv4\u0026#34;:\u0026#34;10.25.84.164\u0026#34;, \u0026#34;wan\u0026#34;:\u0026#34;10.25.84.164\u0026#34;, \u0026#34;wan_ipv4\u0026#34;:\u0026#34;10.25.84.164\u0026#34; }, \u0026#34;Meta\u0026#34;:{ ...   通过DNS接口查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  [root@localhost ~]$ dig @10.25.84.163 -p 8600 server-1.node.consul ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 \u0026lt;\u0026lt;\u0026gt;\u0026gt; @10.25.84.163 -p 8600 server-1.node.consul ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 64004 ;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;server-1.node.consul.\tIN\tA ;; ANSWER SECTION: server-1.node.consul.\t0\tIN\tA\t10.25.84.163 ;; ADDITIONAL SECTION: server-1.node.consul.\t0\tIN\tTXT\t\u0026#34;consul-network-segment=\u0026#34; ;; Query time: 1 msec ;; SERVER: 10.25.84.163#8600(10.25.84.163) ;; WHEN: Fri Feb 21 12:47:15 CST 2020 ;; MSG SIZE rcvd: 101   其中server-1.node.consul中第一部分需要替换成自己的agent节点名\ndig命令如果不存在需要安装下，命令：\nyum -y install bind-utils\n停止agent服务 通过consul leave命令优雅停止服务，我们再打开一个从节点机器终端，运行该命令\n1 2  $ consul leave Graceful leave complete   kratos微服务注册consul 步骤一：引入依赖包 1 2 3  $go get -u github.com/hashicorp/consul/api $go get -u github.com/go-kratos/kratos/contrib/registry/consul/v2 $go mod tidy   步骤二：添加配置config.proto 文件：website/internal/conf/conf.proto\n添加\n1 2 3 4 5 6 7  message Registry { message Consul { string address = 1; string scheme = 2; } Consul consul = 1;}  当前目录下重置pb.go文件：\n1 2  $ protoc --proto_path=./internal --go_out=paths=source_relative:./internal ./internal/conf/conf.proto   步骤三：添加consul 配置信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14  server:http:addr:0.0.0.0:8902timeout:1sgrpc:addr:0.0.0.0:9902timeout:1senv:logsystem:\u0026#34;/Users/wangdante/D/kugou/hl/hl_service/backendapi/logs/system/\u0026#34;loginfo:\u0026#34;/Users/wangdante/D/kugou/hl/hl_service/backendapi/logs/info/\u0026#34;#consul 配置信息consul:address:127.0.0.1:8500scheme:http  步骤四：添加consul服务 目录：\nwebsite/internal/server/consul.go\n内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package server import ( \u0026#34;github.com/go-kratos/kratos/contrib/registry/consul/v2\u0026#34; \u0026#34;github.com/go-kratos/kratos/v2/log\u0026#34; \u0026#34;github.com/go-kratos/kratos/v2/registry\u0026#34; consulAPI \u0026#34;github.com/hashicorp/consul/api\u0026#34; \u0026#34;github.com/spf13/viper\u0026#34; \u0026#34;website/internal/conf\u0026#34; ) // NewRegistrar new an Consul server. func NewRegistrar(conf *conf.Registry, logger log.Logger) registry.Registrar { c := consulAPI.DefaultConfig() c.Address = viper.GetString(\u0026#34;server.consul.address\u0026#34;) //c.Address = \u0026#34;127.0.0.1:8500\u0026#34; \tc.Scheme = viper.GetString(\u0026#34;server.consul.scheme\u0026#34;) //c.Scheme = \u0026#34;http\u0026#34;  cli, err := consulAPI.NewClient(c) if err != nil { panic(err) } r := consul.New(cli, consul.WithHealthCheck(false)) return r }   步骤五：依赖注入consul 目录：website/internal/server/server.go\n1  var ProviderSet = wire.NewSet(NewGRPCServer, NewHTTPServer, NewRegistrar) //添加服务NewRegistrar   步骤六：main.go入口文件引入consul 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  ... //添加 rr registry.Registrar //并注册kratos.Registrar func newApp(logger log.Logger, gs *grpc.Server, hs *http.Server, rr registry.Registrar) *kratos.App { return kratos.New( kratos.ID(id), kratos.Name(Name), kratos.Version(Version), kratos.Metadata(map[string]string{}), kratos.Logger(logger), kratos.Server( gs, hs, ), kratos.Registrar(rr), ) } ... func main() { ... //读取配置信息 \tvar rc conf.Registry if err := c.Scan(\u0026amp;rc); err != nil { panic(err) } ... //注入 \u0026amp;rc \tapp, cleanup, err := wireApp(bc.Server, \u0026amp;rc, bc.Data, logger) ...   步骤七：初始化应用registrar 目录：\nwebsite/cmd/website/wire_gen.go\n1 2 3 4 5 6 7 8 9 10  ... // wireApp init kratos application. // 添加 registry *conf.Registry //添加newApp应用 func wireApp(confServer *conf.Server, registry *conf.Registry, confData *conf.Data, logger log.Logger) (*kratos.App, func(), error) { ... registrarServer := server.NewRegistrar(registry, logger) app := newApp(logger, grpcServer, httpServer, registrarServer) ... }   目录：\nwebsite/cmd/website/wire.go\n1 2 3 4 5 6  ... // wireApp init kratos application. // 添加*conf.Registry func wireApp(*conf.Server, *conf.Registry, *conf.Data, log.Logger) (*kratos.App, func(), error) { panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, newApp)) }   步骤八：启动 1 2 3 4 5  go mod tidy go get github.com/google/wire/cmd/wire@latest go generate ./... kratos run    PS:可能报错：服务名称重复\nmain.go ==\u0026gt; id = Name + \u0026ldquo;-\u0026rdquo; + uuid.NewString()\n 验证成功 去浏览器查看：\n","description":"consul服务注册中心","id":27,"section":"stack","tags":["knowledge"],"title":"consul服务注册中心","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/consul_center/"},{"content":"理论基础 CAP定理 1998年，加州大学，Eric Brewer提出，分布式系统有三个指标：\n Consistency(一致性) Availability(可用性) Partition tolerance(分区容错性)  分布式系统无法同时满足这三个指标，这个结论就叫CAP定理。\n PS:分布式系统中一定会出现不避免的问题：分区问题（P）\n当分区出现时，系统的 一致性（C）和 可用性（A）就无法同时满足，要么是CP，要么是AP\nES集群是CP？还是AP？ ==\u0026gt; 是CP\n BASE理论 BASE理论是对CAP的一种解决思路，包含三个思想：\n Basically Available(基本可用)：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用 Soft State(软件状态)：在一定时间内，允许出现中间状态，比如临时的不一致状态 Eventually Consistent(最终一致性)：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致  解决方案：\n AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致 。 CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成 强一致 。但事务等待过程，处理弱可用状态。  \u0026ldquo;事务协调者\u0026rdquo; 非常重要 解决分布式事务的思想和模型 概念：\n 全局事务：整个分布式事务 分支事务：分布式事务中包含的每个子系统的事务 最终一致思想：各分支事务分别执行并提交，如果有不一致的情况，再想办法恢复数据 强一致思想：各分支事务执行完业务不要提交，等待彼此结果，而后统一提交或回滚  Seata架构 Seata事务管理中有三个重要角色：\n TC（Transaction Coordinator）- 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚 TM（Transaction Manager）- 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务 RM（Resource Manager ）- 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚  Seata提供了四种事务模式： 四种不同的分布式事务解决方案：\n XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入 TCC模式：最终一致的分阶段事务模式，有业务侵入 AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式 SAGA模式：长事务模式，有业务侵入  \u0026ndash;XA模式\u0026ndash; XA规范 是X/Open 组织定义的分布式事务处理（DTP,Distributed Transaction Processing）标准，XA 规范 描述了全局的TM 与局部的RM 之间的接口，几乎所有主流的数据库都对XA规范 提供了支持。\nseata的XA模式 RM一阶段的工作：\n 注册分支事务到 TC 执行分支事务sql但不提交 报告状态到 TC  TC二阶段的工作：\nTC检测各分支事务执行状态：\na. 如果都成功，通知所有RM提交事务\nb. 如果有失败，通知所有RM回滚事务\nRM二阶段的工作：\n接口TC指令，提交或回滚事务\nXA模式优/缺点 优点：\n 事务强一致性，满足ACID原则 没有代码侵入，实现简单\n缺点： 耗时，性能较差 依赖关系型数据库  \u0026ndash;AT模式\u0026ndash; 优化了XA模型中锁定周期过长的问题\n阶段一RM的工作：\n 注册分支事务 记录undo-log(数据快照) 执行业务sql并提交 报告事务状态\n阶段二提交时RM的工作：\na. 删除undo-log即可\n阶段二回滚时RM的工作：\na. 根据undo-log恢复数据到更新前  AT模式与XA模式的 区别：  XA模式不提交；AT模式提交 XA模式利用数据库机制实现回滚；AT模式利用数据快照实现回滚 XA模式强一致；AT模式最终一致  AT模式的脏写问题 全局锁：由TC记录当前正在操作某行数据的事务，该事务持有全局锁，具备执行权。 xid/table/pk\n全局锁与DB锁互相等待可能死锁\nAT模式优/缺点 优点：\n 一阶段完成直接提交事务，释放数据库资源，性能比较好 全局锁实现读写隔离 无代码侵入，框架自动完成回滚和提交\n缺点：   最终一致性，两阶段之间软状态 快照功能会影响性能，但比XA模式要好很多  \u0026ndash;TCC模式(强性能)\u0026ndash; TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码实现数据恢复。需要实现三个方法：\n Try：资源的检测和预留； Confirm：完成资源操作业务；要求Try 成功 Confirm 一定要能成功。 Cancel：预留资源释放，可以理解为try的反向操作  TCC模式优/缺点 优点：\n 性能好，一阶段完成直接提交事务，释放数据库资源 无快照，无全局锁，性能最强 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库  缺点：\n 代码侵入，要人为编写try/confirm/cancel接口，太麻烦 软状态，事务是最终一致 要考虑confirm和cancel的失败情况，做好 幂等性 处理  空回滚 当某分支事务的try阶段 阻塞 时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是 空回滚。\n业务悬挂 对于已经空回滚的业务，如果以后继续执行try，就永远不可能 confirm 或 cancel ，这就是 业务悬挂 。\n设计一张记录事务状态的表：\n1 2 3 4 5 6 7  CREATETABLE`account_freeze_tbl`(`xid`varchar(255)NOTNULLCOMMENT\u0026#39;事务id\u0026#39;,`user_id`varchar(255)DEFAULTNULLCOMMENT\u0026#39;用户id\u0026#39;,`freeze_money`intunsignedDEFAULT\u0026#39;0\u0026#39;COMMENT\u0026#39;冻结金额\u0026#39;,`state`tinyint(1)DEFAULTNULLCOMMENT\u0026#39;事务状态0:try1:confirm2:cancel\u0026#39;,PRIMARYKEY(`xid`))ENGINE=InnoDBDEFAULTCHARSET=utf8mb3COMMENT=\u0026#39;冻结金额事务表\u0026#39;;  TCC实现步骤： Try业务：  记录冻结金额和事务状态到 account_freeze 表 扣减account表可用金额  Confirm业务：  根据xid删除account_freeze表的冻结记录  Cancel业务：  修改account_freeze表，冻结金额为0，state为2 修改account表，恢复可用金额  如何判断是否空回滚：  cancel业务中，根据xid查询account_freeze，如果为null则说明try还没做，需要空回滚  如何避免业务悬挂：  try业务中，根据xid查询account_freeze，如果已经存在则证明cancel已经执行，则拒绝执行try业务  \u0026ndash;Saga模式\u0026ndash; saga柜式是Seata 提供的长事务解决方案：\n分两个阶段：\n 一阶段：直接提交本地事务 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚  saga模式优点：\n 事务参与者异步调用，高吞吐 一阶段直接提交事务，无锁，性能好 不用编写TCC中的三个阶段，实现简单  缺点：\n 时效性差，软状态持续时间不确实 没有锁，没有事务隔离，会有脏写  四种模式对比     XA AT TCC SAGA     一致性 强一致 弱一致 弱一致 最终一致   隔离性 完全隔离 基于全局锁隔离 基于资源预留隔离 无隔离   代码侵入 无 无 有，要编写三个接口 有，要编写状态机和补偿业务   性能 差 好 非常好 非常好   场景 对一致性、隔离性有高要求的业务 基于关系型数据库的大多数分布式事务场景 对性能要求较高的事务、有非关系型数据库要参与的事务 业务流程长、业务流程多、参与者包含其它公司或遗留系统服务，无法提供TCC模式要求的三个接口    TC服务的高可用和异地容灾 TC服务作为Seata的核心服务，一定要保证 高可用 和 异地容灾。\nTC的异地多机房容灾架构：\n","description":"Seata 开源的、高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案","id":28,"section":"stack","tags":["knowledge"],"title":"分布式事务框架 seata","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/seata/"},{"content":"仓库礼物概览  1.普通送礼\n充值星币 2.仓库送礼\n活动赢星币  需求：   存储要求：\n 数量 礼物种类 过期属性 绑定属性    送礼功能\n  入/出仓库功能\n  目标：  实现基本功能条件下，符合资金安全规范标准 实现弹性和灵活扩展的机制，能够随时根据需求进行横向或纵向的扩展 酷狗直播S级业务，保证高性能、高可用，5个9的级别(99.999%)  仓库礼物基础设计 实现基本功能条件下，在数据层面上兼顾 性能、可扩展性\n1.库存表 2.订单表 避免多发、少扣 从三个方面处理：从数据结构、编码、监控 多种方面，保障资金安全\n一、DB(数据结构)  数据库关键字段 unsigned ,避免扣穿 订单流水表 记录操作数据，支持 平衡对账 余额表增加更新时间与流水表一致，支持 期初期末对账  二、编码  幂等，重复请求，返回一致结果 DB乐观锁 ，避免并发扣错 预算SDK对接 ，避免业务多发   扩展：数据库架构常见架构设计：\n一、主备架构（Master-Slave Architecture）：\n主备架构是指数据库系统中有一个主节点（Master）和一个或多个备节点（Slave），主节点负责处理所有的写入操作，而备节点负责复制主节点上的数据。当主节点出现故障时，备节点可以接管主节点的工作，以保证数据库的可用性\n二、双主架构（Master-Master Architecture）：\n双主架构是指数据库系统中有两个主节点，每个主节点都可以处理读写操作。当一个主节点出现故障时，另一个主节点可以接管其工作，以保证数据库的可用性\n三、主从架构（Master-Slave Architecture）：\n主从架构和主备架构类似，但是备节点可以被配置为只读节点，主节点处理所有的写入操作，而从节点负责处理读取操作。当主节点出现故障时，备节点可以接管主节点的工作，并成为新的主节点。\n四、一致性解决方案（Consistency Solution）：\n在分布式数据库系统中，一致性解决方案是指确保不同节点之间数据的一致性。常见的一致性解决方案包括 基于时间戳的复制、 基于多版本并发控制（MVCC）的复制 、基于Paxos协议的一致性算法 、基于Raft协议的一致性算法 等。这些算法都旨在保证不同节点之间数据的一致性和可靠性\n 数据库架构设计原则(扩展) 一、数据库的范式化设计： 通过范式化的设计，可以减少数据冗余和数据不一致的问题。常见的范式包括第一范式（1NF）、第二范式（2NF）和第三范式（3NF）等\n二、数据库的反范式化设计： 有些情况下，反范式化的设计可以提高数据库的性能。反范式化的设计包括将数据冗余存储、增加冗余索引、分区表、分片等技术\n三、合理分配数据和索引： 合理的数据和索引分配可以提高数据库的查询性能。通常建议将索引分配到较小的表中，同时将数据均匀分配到各个节点中\n四、优化数据库查询： 通过对查询进行优化，可以提高数据库的查询性能。包括对查询进行优化，例如使用索引、避免全表扫描、使用优化的SQL语句等\n五、合理的分区和分片： 分区和分片是分布式数据库中常用的技术，可以提高数据库的可扩展性。合理的分区和分片可以减少网络开销、提高查询性能、降低数据库负载等\n六、安全性和可靠性： 在数据库架构设计中，安全性和可靠性是非常重要的。包括对数据库进行备份、数据加密、访问控制、防火墙等技术的应用。\n七、监控和调优： 在数据库架构设计中，监控和调优也是非常重要的。包括实时监控数据库的性能、调整数据库配置参数、调整应用程序、优化数据库查询等。\n服务部署 部署架构：同城主备 模型\n双机房缓存一致性问题 问题：备用机房有 1%的流量 ，可能会导致双边机房缓存 数据不一致\n方案：扣款逻辑读主库，业务操作成功后，双删两机房Redis\n三、监控 仓库礼物过期属性设计 仓库过期需求介绍 需求背景：大量僵尸账户仓库库存 堆积， 金额庞大，对平台而言存在资金隐患\n 增加礼物过期时间 同一礼物聚合在一起 显示最近过期的礼物数量 优先扣除最近过期  支持过期属性面临的挑战 用户体量 大、礼物种类 多、且每个礼物需要支持 过期属性\n技术挑战：存储压力 大 、 S级服务性能要求 高\n过期属性方案选型 目的：性能优化\n方案：聚合 同一个用户、同一礼物、按月分桶，过期时间以json存储\n版本1：增加过期列\n问题：如果用户大量送礼，可能导致大事务\n版本2：聚合一个用户、同一礼物过期列、以json存储\n问题：大字段存储、会影响到查询性能\n版本3：聚合同一个用户、同一礼物、按月分桶，过期时间以json存储\n性能测试 结论：可满足当前性能要求\n限制过期时间为3个月，\n出仓接口最大QPS: 2000+ ，\n入仓：3000+，\n查询最大支持：8000+\n仓库礼物指定房间设计 指定房间送礼介绍 需求：农场产出的礼物，只能在 当前直播间 送出\n目标：\n 实现指定房间送礼 隔离性：不影响现有繁星仓库业务 扩展性：业务全面铺开后无性能压力  支持指定房间面临的挑战 存在 无限膨胀 的可能性\n需要在原有的仓库的基础上增加 toKugouId字段 ，以仓库目前的体量估算，对仓库db性能有 很大影响 。\n解决性能问题 如何解决活动仓库数量级 无限膨胀 的问题？\n业务维度  控制活动专属礼物种类 限制过期时间不超过3个月 限制只能绑定主播  技术维度  按kugouId分表 后续按toKugouId分库 独立服务部署，不影响现有仓库  整体架构设计 目的：不影响当前繁星仓库\n方案：新增活动仓库服务，独立部署，送礼服务聚合数据\n仓库列表设计 问题：如何实现仓库列表的统计、明细功能 方案：空间换时间，增加 冗余统计表\n需求：查询 kugouId = 1 和 toKugouId = 2 的仓库列表统计信息与明细\ntoKugouId可能会无限膨胀，如果按kugouId为条件查，可能会导致慢查询\n方案：增加冗余表，避免慢查询出现\n缺点：入仓 + 出仓 多一次写入\n问题：按kugouId查询仓库列表，如何实现 分页查询 方案：前端内存分页，一次性取3000条数据\n","description":"酷狗直播中亿级仓库礼物的建设与演进。","id":29,"section":"posts","tags":["db"],"title":"亿级仓库礼物的建设与演进","uri":"http://wangjinbao.netlify.app/en/posts/gift/"},{"content":"仓库礼物概览  1.普通送礼\n充值星币 2.仓库送礼\n活动赢星币  需求：   存储要求：\n 数量 礼物种类 过期属性 绑定属性    送礼功能\n  入/出仓库功能\n  目标：  实现基本功能条件下，符合资金安全规范标准 实现弹性和灵活扩展的机制，能够随时根据需求进行横向或纵向的扩展 酷狗直播S级业务，保证高性能、高可用，5个9的级别(99.999%)  仓库礼物基础设计 实现基本功能条件下，在数据层面上兼顾 性能、可扩展性\n1.库存表 2.订单表 避免多发、少扣 从三个方面处理：从数据结构、编码、监控 多种方面，保障资金安全\n一、DB(数据结构)  数据库关键字段 unsigned ,避免扣穿 订单流水表 记录操作数据，支持 平衡对账 余额表增加更新时间与流水表一致，支持 期初期末对账  二、编码  幂等，重复请求，返回一致结果 DB乐观锁 ，避免并发扣错 预算SDK对接 ，避免业务多发   扩展：数据库架构常见架构设计：\n一、主备架构（Master-Slave Architecture）：\n主备架构是指数据库系统中有一个主节点（Master）和一个或多个备节点（Slave），主节点负责处理所有的写入操作，而备节点负责复制主节点上的数据。当主节点出现故障时，备节点可以接管主节点的工作，以保证数据库的可用性\n二、双主架构（Master-Master Architecture）：\n双主架构是指数据库系统中有两个主节点，每个主节点都可以处理读写操作。当一个主节点出现故障时，另一个主节点可以接管其工作，以保证数据库的可用性\n三、主从架构（Master-Slave Architecture）：\n主从架构和主备架构类似，但是备节点可以被配置为只读节点，主节点处理所有的写入操作，而从节点负责处理读取操作。当主节点出现故障时，备节点可以接管主节点的工作，并成为新的主节点。\n四、一致性解决方案（Consistency Solution）：\n在分布式数据库系统中，一致性解决方案是指确保不同节点之间数据的一致性。常见的一致性解决方案包括 基于时间戳的复制、 基于多版本并发控制（MVCC）的复制 、基于Paxos协议的一致性算法 、基于Raft协议的一致性算法 等。这些算法都旨在保证不同节点之间数据的一致性和可靠性\n 数据库架构设计原则(扩展) 一、数据库的范式化设计： 通过范式化的设计，可以减少数据冗余和数据不一致的问题。常见的范式包括第一范式（1NF）、第二范式（2NF）和第三范式（3NF）等\n二、数据库的反范式化设计： 有些情况下，反范式化的设计可以提高数据库的性能。反范式化的设计包括将数据冗余存储、增加冗余索引、分区表、分片等技术\n三、合理分配数据和索引： 合理的数据和索引分配可以提高数据库的查询性能。通常建议将索引分配到较小的表中，同时将数据均匀分配到各个节点中\n四、优化数据库查询： 通过对查询进行优化，可以提高数据库的查询性能。包括对查询进行优化，例如使用索引、避免全表扫描、使用优化的SQL语句等\n五、合理的分区和分片： 分区和分片是分布式数据库中常用的技术，可以提高数据库的可扩展性。合理的分区和分片可以减少网络开销、提高查询性能、降低数据库负载等\n六、安全性和可靠性： 在数据库架构设计中，安全性和可靠性是非常重要的。包括对数据库进行备份、数据加密、访问控制、防火墙等技术的应用。\n七、监控和调优： 在数据库架构设计中，监控和调优也是非常重要的。包括实时监控数据库的性能、调整数据库配置参数、调整应用程序、优化数据库查询等。\n服务部署 部署架构：同城主备 模型\n双机房缓存一致性问题 问题：备用机房有 1%的流量 ，可能会导致双边机房缓存 数据不一致\n方案：扣款逻辑读主库，业务操作成功后，双删两机房Redis\n三、监控 仓库礼物过期属性设计 仓库过期需求介绍 需求背景：大量僵尸账户仓库库存 堆积， 金额庞大，对平台而言存在资金隐患\n 增加礼物过期时间 同一礼物聚合在一起 显示最近过期的礼物数量 优先扣除最近过期  支持过期属性面临的挑战 用户体量 大、礼物种类 多、且每个礼物需要支持 过期属性\n技术挑战：存储压力 大 、 S级服务性能要求 高\n过期属性方案选型 目的：性能优化\n方案：聚合 同一个用户、同一礼物、按月分桶，过期时间以json存储\n版本1：增加过期列\n问题：如果用户大量送礼，可能导致大事务\n版本2：聚合一个用户、同一礼物过期列、以json存储\n问题：大字段存储、会影响到查询性能\n版本3：聚合同一个用户、同一礼物、按月分桶，过期时间以json存储\n性能测试 结论：可满足当前性能要求\n限制过期时间为3个月，\n出仓接口最大QPS: 2000+ ，\n入仓：3000+，\n查询最大支持：8000+\n仓库礼物指定房间设计 指定房间送礼介绍 需求：农场产出的礼物，只能在 当前直播间 送出\n目标：\n 实现指定房间送礼 隔离性：不影响现有繁星仓库业务 扩展性：业务全面铺开后无性能压力  支持指定房间面临的挑战 存在 无限膨胀 的可能性\n需要在原有的仓库的基础上增加 toKugouId字段 ，以仓库目前的体量估算，对仓库db性能有 很大影响 。\n解决性能问题 如何解决活动仓库数量级 无限膨胀 的问题？\n业务维度  控制活动专属礼物种类 限制过期时间不超过3个月 限制只能绑定主播  技术维度  按kugouId分表 后续按toKugouId分库 独立服务部署，不影响现有仓库  整体架构设计 目的：不影响当前繁星仓库\n方案：新增活动仓库服务，独立部署，送礼服务聚合数据\n仓库列表设计 问题：如何实现仓库列表的统计、明细功能 方案：空间换时间，增加 冗余统计表\n需求：查询 kugouId = 1 和 toKugouId = 2 的仓库列表统计信息与明细\ntoKugouId可能会无限膨胀，如果按kugouId为条件查，可能会导致慢查询\n方案：增加冗余表，避免慢查询出现\n缺点：入仓 + 出仓 多一次写入\n问题：按kugouId查询仓库列表，如何实现 分页查询 方案：前端内存分页，一次性取3000条数据\n","description":"酷狗直播中亿级仓库礼物的建设与演进。","id":30,"section":"stack","tags":["db"],"title":"亿级仓库礼物的建设与演进","uri":"http://wangjinbao.netlify.app/en/stack/db/gift/"},{"content":"基础知识 webSocket是什么  websocket是一种在单个tcp上进行 全双工通信 的协议，长连接，双向传输 第三方包：go get -u -v github.com/gorilla/websocket websocket协议实现起来相对简单。HTTP协议初始握手建立连接，websocket实质上使用原始TCP 读取/写入数据 http有良好的兼容性，ws和http的默认端口都是80，wss和https的默认端口都是443  websocket握手协议 客户端请求 Request Header 1 2 3 4 5 6 7 8  GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket // 指明使用WebSocket协议 Connection: Upgrade\t// 指明使用WebSocket协议 Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== // Bse64 encode的值，是浏览器随机生成的 Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 //指定Websocket协议版本 Origin: http://example.com   说明：\n服务端收到Sec-WebSocket-Key后拼接上一个固定的GUID，进行一次SHA-1摘要，再转成Base64编码，得到Sec-WebSocket-Accept返回给客户端。\n客户端对本地的Sec-WebSocket-Key执行同样的操作跟服务端返回的结果进行对比，如果不一致会返回错误关闭连接。如此操作是为了把websocket header 跟http header区分开\n服务器响应 Response Header 1 2 3 4 5  HTTP/1.1 111 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: HSmrc1sMlYUkAGmm5OPpG2HaGWk= Sec-WebSocket-Protocol: chat   websocket发送的消息类型 5种：TextMessag、BinaryMessage、CloseMessag、PingMessage、PongMessage\n TextMessag和BinaryMessage分别表示发送文本消息和二进制消息 CloseMessage关闭帧，接收方收到这个消息就关闭连接 PingMessage和PongMessage是保持心跳的帧，服务器发ping给浏览器，浏览器返回pong消息  控制类消息 Websocket协议定义了三种控制消息：Close、Ping和Pong。\n通过调用Conn的WriteControl、WriteMessage或NextWriter方法向对端发送控制消息\nConn收到了Close消息之后，调用由SetCloseHandler方法设置的handler函数，然后从NextReader 、ReadMessage或消息的Read 方法返回一个*CloseError。缺省的close handler会发送一个Close消息到对端。\nConn收到了Ping消息之后，调用由SetPingHandler 方法设置的handler函数。缺省的ping handler会发送一个Pong消息到对象。\nConn收到了Pong消息之后，调用由SetPongHandler 设置的handler函数。缺省的pong handler什么也不做。\n控制消息的handler函数是从NextReader、ReadMessage和消息的Read方法中调用的。缺省的close handler和ping handler向对端写数据时可能会短暂阻塞这些方法。\n应用程序必须读取Conn，使得对端发送的close、ping、和pong消息能够得到处理。即使应用程序不关心对端发送的消息，也应该启动一个goroutine来读取对端的消息并丢弃。例如：\ngorilla/websocket websocket由http升级而来，首先发送附带Upgrade请求头的Http请求，所以我们需要在处理Http请求时拦截请求并判断其是否为websocket升级请求，如果是则调用gorilla/websocket库相应函数处理升级请求\nUpgrader Upgrader发送附带Upgrade请求头的Http请求,把 http 请求升级为长连接的 WebSocket,结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  type Upgrader struct { // 升级 websocket 握手完成的超时时间  HandshakeTimeout time.Duration // io 操作的缓存大小，如果不指定就会自动分配。  ReadBufferSize, WriteBufferSize int // 写数据操作的缓存池，如果没有设置值，write buffers 将会分配到链接生命周期里。  WriteBufferPool BufferPool //按顺序指定服务支持的协议，如值存在，则服务会从第一个开始匹配客户端的协议。  Subprotocols []string // http 的错误响应函数，如果没有设置 Error 则，会生成 http.Error 的错误响应。  Error func(w http.ResponseWriter, r *http.Request, status int, reason error) // 如果请求Origin标头可以接受，CheckOrigin将返回true。 如果CheckOrigin为nil，则使用安全默认值：如果Origin请求头存在且原始主机不等于请求主机头，则返回false。  // 请求检查函数，用于统一的链接检查，以防止跨站点请求伪造。如果不检查，就设置一个返回值为true的函数  CheckOrigin func(r *http.Request) bool // EnableCompression 指定服务器是否应尝试协商每个邮件压缩（RFC 7692）。 将此值设置为true并不能保证将支持压缩。 目前仅支持“无上下文接管”模式  EnableCompression bool }   创建Upgrader实例 该实例用于升级请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  var upgrader = websocket.Upgrader{ ReadBufferSize: 1124, //指定读缓存大小  WriteBufferSize: 1124, //指定写缓存大小  CheckOrigin: checkOrigin, } // 检测请求来源 func checkOrigin(r *http.Request) bool { if r.Method != \u0026#34;GET\u0026#34; { fmt.Println(\u0026#34;method is not GET\u0026#34;) return false } if r.URL.Path != \u0026#34;/ws\u0026#34; { fmt.Println(\u0026#34;path error\u0026#34;) return false } return true }   升级协议 func (*Upgrader) Upgrade 函数将 http 升级到 WebSocket 协议。\n1 2 3 4 5  // responseHeader包含在对客户端升级请求的响应中。 // 使用responseHeader指定cookie（Set-Cookie）和应用程序协商的子协议（Sec-WebSocket-Protocol）。 // 如果升级失败，则升级将使用HTTP错误响应回复客户端 // 返回一个 Conn 指针，使用 Conn 读写数据与客户端通信。 func (u *Upgrader) Upgrade(w http.ResponseWriter, r *http.Request, responseHeader http.Header) (*Conn, error)   升级为websocket连接并获得一个conn实例，之后的发送接收操作皆有conn，其类型为websocket.Conn。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  //Http入口 func (e *Engine) ServeHTTP(w http.ResponseWriter, r *http.Request) { //判断请求是否为websocket升级请求。  if websocket.IsWebSocketUpgrade(r) { // 收到 http 请求后升级协议  conn, err := upgrader.Upgrade(w, r, w.Header()) // 向客户端发送消息使用 WriteMessage(messageType int, data []byte),参数1为消息类型，参数2消息内容  conn.WriteMessage(websocket.TextMessage, []byte(\u0026#34;升级成功\u0026#34;)) // 接受客户端消息使用 ReadMessage(),该操作阻塞线程所以建议运行在其他协程上。  //返回值(接收消息类型、接收消息内容、发生的错误)当然正常执行时错误为 nil。一旦连接关闭返回值类型为-1可用来终止读操作。  go func() { for { t, c, _ := conn.ReadMessage() fmt.Println(t, string(c)) if t == -1 { return } } }() } else { //处理普通请求  c := newContext(w, r) e.router.handle(c) } }   设置关闭连接监听 函数为SetCloseHandler(h func(code int, text string) error)函数接收一个函数为参数，参数为nil时有一个默认实现，其源码为：\n1 2 3 4 5 6 7 8 9 10  func (c *Conn) SetCloseHandler(h func(code int, text string) error) { if h == nil { h = func(code int, text string) error { message := FormatCloseMessage(code, \u0026#34;\u0026#34;) c.WriteControl(CloseMessage, message, time.Now().Add(writeWait)) return nil } } c.handleClose = h }   可以看到作为参数的函数的参数为int和string类型正好和前端的close(long string)对应即前端调用close(long string)关闭连接后两个参数会被发送给后端并最终被func(code int, text string) error所使用。\n1 2 3 4 5  // 设置关闭连接监听 conn.SetCloseHandler(func(code int, text string) error { fmt.Println(code, text) // 断开连接时将打印code和text  return nil })   总览 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  type WsServer struct { ...... // 定义一个 upgrade 类型用于升级 http 为 websocket  upgrade *websocket.Upgrader } func NewWsServer() *WsServer { ws.upgrade = \u0026amp;websocket.Upgrader{ ReadBufferSize: 4196,//指定读缓存区大小  WriteBufferSize: 1124,// 指定写缓存区大小  // 检测请求来源  CheckOrigin: func(r *http.Request) bool { if r.Method != \u0026#34;GET\u0026#34; { fmt.Println(\u0026#34;method is not GET\u0026#34;) return false } if r.URL.Path != \u0026#34;/ws\u0026#34; { fmt.Println(\u0026#34;path error\u0026#34;) return false } return true },upgrade } return ws } func (self *WsServer) ServeHTTP(w http.ResponseWriter, r *http.Request) { ...... // 收到 http 请求后 升级 协议  conn, err := self.upgrade.Upgrade(w, r, nil) if err != nil { fmt.Println(\u0026#34;websocket error:\u0026#34;, err) return } fmt.Println(\u0026#34;client connect :\u0026#34;, conn.RemoteAddr()) go self.connHandle(conn) }   Demo 复杂版本 服务端： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var upgrader = websocket.Upgrader{ ReadBufferSize: 4196, WriteBufferSize: 1124, CheckOrigin: func(r *http.Request) bool { //if r.Method != \u0026#34;GET\u0026#34; { \t//\tfmt.Println(\u0026#34;method is not GET\u0026#34;) \t//\treturn false \t//} \t//if r.URL.Path != \u0026#34;/ws\u0026#34; { \t//\tfmt.Println(\u0026#34;path error\u0026#34;) \t//\treturn false \t//} \treturn true }, } // ServerHTTP 用于升级协议 func ServerHTTP(w http.ResponseWriter, r *http.Request) { // 收到http请求之后升级协议 \tconn, err := upgrader.Upgrade(w, r, nil) if err != nil { log.Println(\u0026#34;Error during connection upgrade:\u0026#34;, err) return } defer conn.Close() for { // 服务端读取客户端请求 \tmessageType, message, err := conn.ReadMessage() if err != nil { log.Println(\u0026#34;Error during message reading:\u0026#34;, err) break } log.Printf(\u0026#34;Received:%s\u0026#34;, message) // 开启关闭连接监听 \tconn.SetCloseHandler(func(code int, text string) error { fmt.Println(code, text) // 断开连接时将打印code和text \treturn nil }) //服务端给客户端返回请求 \terr = conn.WriteMessage(messageType, message) if err != nil { log.Println(\u0026#34;Error during message writing:\u0026#34;, err) return } } } func home(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Index Page\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/socket\u0026#34;, ServerHTTP) http.HandleFunc(\u0026#34;/\u0026#34;, home) log.Fatal(http.ListenAndServe(\u0026#34;localhost:8181\u0026#34;, nil)) }   客户端： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  // client.go package main import ( \u0026#34;github.com/gorilla/websocket\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;time\u0026#34; ) var done chan interface{} var interrupt chan os.Signal func receiveHandler(connection *websocket.Conn) { defer close(done) for { _, msg, err := connection.ReadMessage() if err != nil { log.Println(\u0026#34;Error in receive:\u0026#34;, err) return } log.Printf(\u0026#34;Received: %s\\n\u0026#34;, msg) } } func main() { done = make(chan interface{}) // Channel to indicate that the receiverHandler is done \tinterrupt = make(chan os.Signal) // Channel to listen for interrupt signal to terminate gracefully  signal.Notify(interrupt, os.Interrupt) // Notify the interrupt channel for SIGINT  socketUrl := \u0026#34;ws://localhost:8181\u0026#34; + \u0026#34;/socket\u0026#34; conn, _, err := websocket.DefaultDialer.Dial(socketUrl, nil) if err != nil { log.Fatal(\u0026#34;Error connecting to Websocket Server:\u0026#34;, err) } defer conn.Close() go receiveHandler(conn) // 无限循环使用select来通过通道监听事件 \tfor { select { case \u0026lt;-time.After(time.Duration(1) * time.Millisecond * 1111): //conn.WriteMessage()每秒钟写一条消息 \terr := conn.WriteMessage(websocket.TextMessage, []byte(\u0026#34;Hello from GolangDocs!\u0026#34;)) if err != nil { log.Println(\u0026#34;Error during writing to websocket:\u0026#34;, err) return } //如果激活了中断信号，则所有未决的连接都将关闭 \tcase \u0026lt;-interrupt: // We received a SIGINT (Ctrl + C). Terminate gracefully... \tlog.Println(\u0026#34;Received SIGINT interrupt signal. Closing all pending connections\u0026#34;) // Close our websocket connection \terr := conn.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, \u0026#34;\u0026#34;)) if err != nil { log.Println(\u0026#34;Error during closing websocket:\u0026#34;, err) return } select { // 如果receiveHandler通道退出，则通道\u0026#39;done\u0026#39;将关闭 \tcase \u0026lt;-done: log.Println(\u0026#34;Receiver Channel Closed! Exiting....\u0026#34;) //如果\u0026#39;done\u0026#39;通道未关闭，则在1秒钟后会有超时，因此程序将在1秒钟超时后退出 \tcase \u0026lt;-time.After(time.Duration(1) * time.Second): log.Println(\u0026#34;Timeout in closing receiving channel. Exiting....\u0026#34;) } return } } }   简单版 服务端： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  package main import ( \u0026#34;github.com/gorilla/websocket\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var upgrade = websocket.Upgrader{ ReadBufferSize: 1124, WriteBufferSize: 1124, CheckOrigin: func(r *http.Request) bool { return true }, } func HelloHTTP(w http.ResponseWriter, r *http.Request) { //1.升级协议，并返回升级后的长连接 \tconn, err := upgrade.Upgrade(w, r, nil) if err != nil { log.Println(\u0026#34;Error during connection upgrade:\u0026#34;, err) return } defer conn.Close() for { // 2.读取客户端的请求信息 \tmessageType, message, err := conn.ReadMessage() if err != nil { log.Println(\u0026#34;Error during message writing:\u0026#34;, err) return } log.Printf(\u0026#34;Recive message:%s\u0026#34;, message) //\t3.返回给客户端信息 \terr = conn.WriteMessage(messageType, message) if err != nil { log.Println(\u0026#34;Error during message writing:\u0026#34;, err) return } } } func main() { http.HandleFunc(\u0026#34;/socket\u0026#34;, HelloHTTP) http.ListenAndServe(\u0026#34;:8181\u0026#34;, nil) }   客户端： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  package main import ( \u0026#34;github.com/gorilla/websocket\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) func ReceiveHandler(con *websocket.Conn) { for { _, message, err := con.ReadMessage() if err != nil { log.Println(\u0026#34;Error during Receive:\u0026#34;, err) return } log.Printf(\u0026#34;Receive:%s\\n\u0026#34;, message) } } func main() { socketUrl := \u0026#34;ws://localhost:8181\u0026#34; + \u0026#34;/socket\u0026#34; // 使用 net.Dialer Dialer.Dial 函数建立 TCP 连接,建立成功后，取得了 net.Conn 对象，  conn, _, err := websocket.DefaultDialer.Dial(socketUrl, nil) if err != nil { log.Fatal(\u0026#34;Error connecting to websocket Server:\u0026#34;, err) } defer conn.Close() ticker := time.Tick(time.Second) for range ticker { err = conn.WriteMessage(websocket.TextMessage, []byte(\u0026#34;Hello World!\u0026#34;)) if err != nil { log.Println(\u0026#34;Error during writing to websocket:\u0026#34;, err) return } // 接受客户端消息使用ReadMessage()该操作会阻塞线程所以建议运行在其他协程上  go ReceiveHandler(conn) } }   Gin框架结合gorilla 安装Gin和gorilla 1 2  go get -u github.com/gin-gonic/gin #如果下载慢看看是否用代理 或 go mod init 模块名 go get -u github.com/gorilla/websocket   demo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var upgrader = websocket.Upgrader{ CheckOrigin: func(r *http.Request) bool { // 在这里进行权限验证，返回true表示验证通过，允许连接 \t// 你可以根据需要实现自己的验证逻辑 \treturn true }, } func main() { r := gin.Default() // 提供一个HTTP端点用于升级连接为WebSocket \tr.GET(\u0026#34;/ws\u0026#34;, func(c *gin.Context) { serveWebSocket(c.Writer, c.Request) }) r.Run(\u0026#34;:8085\u0026#34;) } func serveWebSocket(w http.ResponseWriter, r *http.Request) { conn, err := upgrader.Upgrade(w, r, nil) if err != nil { log.Println(err) return } defer conn.Close() for { // 读取客户端发送的消息 \tmessageType, p, err := conn.ReadMessage() if err != nil { log.Println(err) return } log.Println(\u0026#34;来自客户端的信息：\u0026#34;) log.Println(string(p)) // 将消息原样发送回客户端 \terr = conn.WriteMessage(messageType, []byte(\u0026#34;我收到你的信息了\u0026#34;)) if err != nil { log.Println(err) return } } }   调试 1  go run main.go   使用Apifox -\u0026gt; websocket\nnginx ssl证书进行升级 1 2 3 4 5 6 7 8 9 10 11 12 13 14  server { listen 443 ssl; server_name your_domain.com ssl_certificate /path/to/your_cert.crt; ssl_certificate_key /path/to/your_private_key.key; location / { proxy_pass http://127.0.0.1:8080; # 这里是你的Gin应用的地址和端口 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_set_header Host $host; } }   ","description":"Golang官方认可的websocket库","id":31,"section":"stack","tags":["golang",""],"title":"gorilla/websocket","uri":"http://wangjinbao.netlify.app/en/stack/golang/gin_gorilla/"},{"content":"1.在项目根目录下新建models目录： 2.下载gorm包 1 2 3 4 5 6 7 8 9 10 11 12 13  $ go get -u gorm.io/gorm go: downloading gorm.io/gorm v1.25.5 go: downloading github.com/jinzhu/now v1.1.5 go: added github.com/jinzhu/inflection v1.0.0 go: added github.com/jinzhu/now v1.1.5 go: added gorm.io/gorm v1.25.5 $ go get -u gorm.io/driver/mysql go: downloading gorm.io/driver/mysql v1.5.2 go: downloading github.com/go-sql-driver/mysql v1.7.0 go: added github.com/go-sql-driver/mysql v1.7.1 go: added gorm.io/driver/mysql v1.5.2   3.新增数据表结构体 models/repo_basic.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11  package models import \u0026#34;gorm.io/gorm\u0026#34; type RepoBasic struct { gorm.Model Identity string `gorm:\u0026#34;column:identity;type:varchar(36);\u0026#34; json:\u0026#34;identity\u0026#34;` //唯一标识 \tName string `gorm:\u0026#34;column:name;type:varchar(255);\u0026#34; json:\u0026#34;name\u0026#34;` //Name \tDesc string `gorm:\u0026#34;column:desc;type:varchar(255);\u0026#34; json:\u0026#34;desc\u0026#34;` //desc \tStar int `gorm:\u0026#34;column:star;type:int(11);default:0;\u0026#34; json:\u0026#34;star\u0026#34;` //star }   models/user_basic.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  package models import \u0026#34;gorm.io/gorm\u0026#34; type UserBasic struct { gorm.Model Identity string `gorm:\u0026#34;column:identity;type:varchar(36);\u0026#34; json:\u0026#34;identity\u0026#34;` //唯一标识 \tUsername string `gorm:\u0026#34;column:username;type:varchar(255);\u0026#34; json:\u0026#34;username\u0026#34;` // 用户名 \tPassword string `gorm:\u0026#34;column:password;type:varchar(36);\u0026#34; json:\u0026#34;password\u0026#34;` //密码 } func (table *UserBasic) TableName() string { return \u0026#34;user_basic\u0026#34; }   models/repo_user.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package models import \u0026#34;gorm.io/gorm\u0026#34; type RepoUser struct { gorm.Model Rid int `gorm:\u0026#34;column:rid;type:int(11);\u0026#34; json:\u0026#34;rid\u0026#34;` //仓库ID \tUid int `gorm:\u0026#34;column:uid;type:int(11);\u0026#34; json:\u0026#34;uid\u0026#34;` //用户ID \tType int `gorm:\u0026#34;column:type;type:tinyint(1);\u0026#34; json:\u0026#34;type\u0026#34;` //类型{1所有者2被授权者} } func (table *RepoUser) TableName() string { return \u0026#34;repo_user\u0026#34; }   models/repo_star.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  package models import \u0026#34;gorm.io/gorm\u0026#34; type RepoStar struct { gorm.Model Rid int `gorm:\u0026#34;column:rid;type:int(11);\u0026#34; json:\u0026#34;rid\u0026#34;` //仓库ID \tUid int `gorm:\u0026#34;column:uid;type:int(11);\u0026#34; json:\u0026#34;uid\u0026#34;` //用户ID } func (table *RepoStar) TableName() string { return \u0026#34;repo_star\u0026#34; }   4创建 user.proto 并修改 根目录下执行：\n1  kratos proto add api/git/user.proto   user.proto 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  syntax = \u0026#34;proto3\u0026#34;;package api.git;import \u0026#34;google/api/annotations.proto\u0026#34;;option go_package = \u0026#34;customer/api/git;git\u0026#34;;option java_multiple_files = true;option java_package = \u0026#34;api.git\u0026#34;;service User {\trpc Login (LoginRequest) returns (LoginReply){\toption (google.api.http) = {\tget: \u0026#34;/login\u0026#34;\t};\t};}message LoginRequest {\tstring username = 1; //用户名 \tstring password = 2;//密码 }message LoginReply {\tstring token = 1; //token }  5 创建 PB 1  kratos proto client api/git/user.proto   6 创建 Service 1  kratos proto server api/git/user.proto -t internal/service   在cmd -\u0026gt; main.go -\u0026gt; wireApp -\u0026gt; NewHTTPServer 中注册服务\ncustomer/internal/server/http.go 修改内容：\n1  git.RegisterUserHTTPServer(srv, service.NewUserService())   7 初始化DB 新增 models/init.go文件 内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package models import ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) var DB *gorm.DB func NewDB(dsn string) error { db, err := gorm.Open(mysql.Open(dsn)) if err != nil { return err } err = db.AutoMigrate(\u0026amp;UserBasic{}) if err != nil { return err } err = db.AutoMigrate(\u0026amp;RepoBasic{}) if err != nil { return err } err = db.AutoMigrate(\u0026amp;RepoUser{}) if err != nil { return err } err = db.AutoMigrate(\u0026amp;RepoStar{}) if err != nil { return err } DB = db return nil }   加载 init.go cmd/main.go文件加载 init.go文件：\n1 2 3 4 5 6  # wireApp 关键字前加 //init db \terr := models.NewDB(bc.Data.Database.Source) if err != nil { panic(err) }   修改config参数 修改config.yaml 数据库配置参数：\n1 2 3 4  data:database:driver:mysqlsource:root:654321@tcp(127.0.0.1:3306)/up-git?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local   PS: proto 文件只要修改就重新执行：\nkratos proto client api/git/user.proto\n 8用迁移文件生数据表： 1  db.AutoMigrate(\u0026amp;RepoUser{})   9修改service/user.go文件： 1 2 3 4 5 6 7 8 9 10 11  func (s *UserService) Login(ctx context.Context, req *pb.LoginRequest) (*pb.LoginReply, error) { ub := new(models.UserBasic) err := models.DB.Where(\u0026#34;username = ? AND password = ?\u0026#34;, req.Username, req.Password).First(ub).Error if err != nil { return nil, err } return \u0026amp;pb.LoginReply{ Token: \u0026#34;token\u0026#34;, }, nil }   10验证接口 POST http://127.0.0.1:8600/login\n{\n\u0026ldquo;username\u0026rdquo;:\u0026ldquo;admin\u0026rdquo;,\n\u0026ldquo;password\u0026rdquo;:\u0026ldquo;123321\u0026rdquo;\n}\n{\n\u0026ldquo;token\u0026rdquo;: \u0026ldquo;token\u0026rdquo;\n}\n","description":"一套轻量级 Go 微服务框架，包含大量微服务相关框架及工具","id":32,"section":"stack","tags":["golang",""],"title":"kratos框架项目实践","uri":"http://wangjinbao.netlify.app/en/stack/golang/kratos_project/"},{"content":"对称加密算法 特点 加密和解密使用的是同一个密钥，数据私密性双向保证，也就是加密和解密都不能泄露密码\n优缺点  优点：加密效率高，适合大些的数据加密 缺点：安全性相对非对称低  go语言实现对称加密算法 AES AES-128：key长度16 字节\nAES-192：key长度24 字节\nAES-256：key长度32 字节\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  var key []byte = []byte(\u0026#34;hallenhallenhall\u0026#34;) // 填充密码长度 func PadPwd(srcByte []byte,blockSize int) []byte { // 16 13 13-3 = 10 \tpadNum := blockSize - len(srcByte)%blockSize ret := bytes.Repeat([]byte{byte(padNum)}, padNum) srcByte = append(srcByte, ret...) return srcByte } // 加密 func AesEncoding(src string) (string,error) { srcByte := []byte(src) fmt.Println(srcByte) // safer \tblock, err := aes.NewCipher(key) if err != nil { return src, err } // 密码填充 \tNewSrcByte := PadPwd(srcByte, block.BlockSize()) //由于字节长度不够，所以要进行字节的填充 \tfmt.Println(NewSrcByte) dst := make([]byte, len(NewSrcByte)) block.Encrypt(dst, NewSrcByte) fmt.Println(dst) // base64编码 \tpwd := base64.StdEncoding.EncodeToString(dst) return pwd, nil } // 去掉填充的部分 func UnPadPwd(dst []byte) ([]byte,error) { if len(dst) \u0026lt;= 0 { return dst, errors.New(\u0026#34;长度有误\u0026#34;) } // 去掉的长度 \tunpadNum := int(dst[len(dst)-1]) return dst[:(len(dst) - unpadNum)], nil } // 解密 func AesDecoding(pwd string) (string,error) { pwdByte := []byte(pwd) pwdByte, err := base64.StdEncoding.DecodeString(pwd) if err != nil { return pwd, err } block, errBlock := aes.NewCipher(key) if errBlock != nil { return pwd, errBlock } dst := make([]byte, len(pwdByte)) block.Decrypt(dst, pwdByte) dst, _ = UnPadPwd(dst)\t// 填充的要去掉 \treturn string(dst), nil }   DES DES：支持字节长度是8\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  // 只支持8字节的长度 var desKey = []byte(\u0026#34;hallenha\u0026#34;) // 加密 func DesEncoding(src string) (string,error) { srcByte := []byte(src) block, err := des.NewCipher(desKey) if err != nil { return src, err } // 密码填充 \tnewSrcByte := PadPwd(srcByte, block.BlockSize()) dst := make([]byte, len(newSrcByte)) block.Encrypt(dst, newSrcByte) // base64编码 \tpwd := base64.StdEncoding.EncodeToString(dst) return pwd, nil } // 解密 func DesDecoding(pwd string) (string,error) { pwdByte, err := base64.StdEncoding.DecodeString(pwd) if err != nil { return pwd, err } block, errBlock := des.NewCipher(desKey) if errBlock != nil { return pwd, errBlock } dst := make([]byte, len(pwdByte)) block.Decrypt(dst, pwdByte) // 填充的要去掉 \tdst, _ = UnPadPwd(dst) return string(dst), nil }   DES(CBC模式) des——CBC模式，key长度必须为24\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  // 3des的key，长度是24 var tdesKey = []byte(\u0026#34;hallenhallenhallenhallen\u0026#34;) // 3des加密 func TDesEncoding(src string) (string,error) { srcByte := []byte(src) block, err := des.NewTripleDESCipher(tdesKey) // 和des的区别 \tif err != nil { return src, err } // 密码填充 \tnewSrcByte := PadPwd(srcByte, block.BlockSize()) dst := make([]byte, len(newSrcByte)) block.Encrypt(dst, newSrcByte) // base64编码 \tpwd := base64.StdEncoding.EncodeToString(dst) return pwd, nil } // 3des解密 func TDesDecoding(pwd string) (string,error) { pwdByte, err := base64.StdEncoding.DecodeString(pwd) if err != nil { return pwd, err } block, errBlock := des.NewTripleDESCipher(tdesKey) // 和des的区别 \tif errBlock != nil { return pwd, errBlock } dst := make([]byte, len(pwdByte)) block.Decrypt(dst, pwdByte) // 填充的要去掉 \tdst, _ = UnPadPwd(dst) return string(dst), nil }   非对称加密算法 特点  加密和解密的密钥不同，有两个密钥（公钥和私钥） 公钥：可以公开的密钥；公钥加密，私钥解密 私钥：私密的密钥；私钥加密，公钥解密 私密单方向保证，只要有一方不泄露就没问题  优缺点  优点：安全性相对对称加密高 缺点：加密效率低，适合小数据加密  go语言实现非对称加密算法 消息发送方利用对方的公钥进行加密，消息接受方收到密文时使用自己的私钥进行解密\n对哪一方更重要，哪一方就拿私钥\n注意：\n 公钥和密钥生成的时候要有一种关联，要把密钥和公钥保存起来。\n RSA 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141  package main import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/rsa\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) // 保存生成的公钥和密钥 func SaveRsaKey(bits int) error { privateKey,err := rsa.GenerateKey(rand.Reader,bits) if err != nil { fmt.Println(err) return err } publicKey := privateKey.PublicKey // 使用x509标准对私钥进行编码，AsN.1编码字符串 \tx509Privete := x509.MarshalPKCS1PrivateKey(privateKey) // 使用x509标准对公钥进行编码，AsN.1编码字符串 \tx509Public := x509.MarshalPKCS1PublicKey(\u0026amp;publicKey) // 对私钥封装block 结构数据 \tblockPrivate := pem.Block{Type: \u0026#34;private key\u0026#34;,Bytes: x509Privete} // 对公钥封装block 结构数据 \tblockPublic := pem.Block{Type: \u0026#34;public key\u0026#34;,Bytes: x509Public} // 创建存放私钥的文件 \tprivateFile, errPri := os.Create(\u0026#34;privateKey.pem\u0026#34;) if errPri != nil { return errPri } defer privateFile.Close() pem.Encode(privateFile,\u0026amp;blockPrivate) // 创建存放公钥的文件 \tpublicFile, errPub := os.Create(\u0026#34;publicKey.pem\u0026#34;) if errPub != nil { return errPub } defer publicFile.Close() pem.Encode(publicFile,\u0026amp;blockPublic) return nil } // 加密 func RsaEncoding(src , filePath string) ([]byte,error){ srcByte := []byte(src) // 打开文件 \tfile,err := os.Open(filePath) if err != nil { return srcByte,err } // 获取文件信息 \tfileInfo, errInfo := file.Stat() if errInfo != nil { return srcByte, errInfo } // 读取文件内容 \tkeyBytes := make([]byte, fileInfo.Size()) // 读取内容到容器里面 \tfile.Read(keyBytes) // pem解码 \tblock,_ := pem.Decode(keyBytes) // x509解码 \tpublicKey , errPb := x509.ParsePKCS1PublicKey(block.Bytes) if errPb != nil { return srcByte, errPb } // 使用公钥对明文进行加密  retByte, errRet := rsa.EncryptPKCS1v15(rand.Reader,publicKey, srcByte) if errRet != nil { return srcByte, errRet } return retByte,nil } // 解密 func RsaDecoding(srcByte []byte,filePath string) ([]byte,error) { // 打开文件 \tfile,err := os.Open(filePath) if err != nil { return srcByte,err } // 获取文件信息 \tfileInfo,errInfo := file.Stat() if errInfo != nil { return srcByte,errInfo } // 读取文件内容 \tkeyBytes := make([]byte,fileInfo.Size()) // 读取内容到容器里面 \t_, _ = file.Read(keyBytes) // pem解码 \tblock,_ := pem.Decode(keyBytes) // x509解码 \tprivateKey ,errPb := x509.ParsePKCS1PrivateKey(block.Bytes) if errPb != nil { return keyBytes,errPb } // 进行解密 \tretByte, errRet := rsa.DecryptPKCS1v15(rand.Reader,privateKey,srcByte) if errRet != nil { return srcByte,errRet } return retByte,nil } func main() { //err := SaveRsaKey(2048) \t//if err != nil { \t//\tfmt.Println(\u0026#34;KeyErr\u0026#34;,err) \t//} \tmsg, err := RsaEncoding(\u0026#34;FanOne\u0026#34;,\u0026#34;publicKey.pem\u0026#34;) fmt.Println(\u0026#34;msg\u0026#34;,msg) if err != nil { fmt.Println(\u0026#34;err1\u0026#34;,err) } msg2,err := RsaDecoding(msg,\u0026#34;privateKey.pem\u0026#34;) if err != nil { fmt.Println(\u0026#34;err\u0026#34;,err) } fmt.Println(\u0026#34;msg2\u0026#34;,string(msg2)) }   ","description":"本文介绍了 Go 加密解密算法的实现","id":33,"section":"stack","tags":["golang",""],"title":"对称加密算法AES/DES/3DES和非对称加密算法RSA","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_crypt/"},{"content":"事务的介绍 1.事务 1.1事务的产生 数据库 中的数据是 共享资源 ，因此数据库系统需要支持多个用户或不同应用程序的访问，并且各个访问进程都是独立执行的，可能会出现 并发存取数据 的现象。\n这类似于Java开发中的多线程安全问题。如果不采取一定措施会出现数据异常的情况，比如: 银行卡扣款成功但白条没有还款成功。因此需要使用事务来解决这些问题\n1.2事务的概念 事务是数据库操作的最小工作单元，是一系列操作作为单个逻辑工作单元执行的。这些操作 要么都执行、要么都不执行 ，是不可再分割的操作集合\n1.3事务的特性 事务的四大特征主要是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）\n 原子性（Atomicity）：\n事务内的操作要么全部成功，要么全部失败，不会在中间的某个环节结束。如果所有的操作都成功，事务就成功；但如果有任何一个操作失败，事务会回滚到最初的状态  begin transaction; update activity_acount set money = money-100 where name = ' 小明 '； update activity_acount set money = money+100 where name = ' 小红 '； commit transaction；  一致性（Consistency）:\n事务执行是数据状态转换的过程，需要保持数据完整性和一致性。如果事务失败，会自动回滚到原始状态，提交后其他事务看到的结果保持一致，回滚后其他事务也只能看到回滚前的状态\n  隔离性（Isolation）:\n在并发环境中，不同事务同时修改相同的数据时，一个未完成的事务不会影响另一个未完成的事务\n  持久性（Durability）:\n提交事务后，数据库中的数据将永久保存，即使发生故障也不会受影响\n  1.4Mysql隔离级别 事务隔离性问题包括 脏读 、 不可重复读 和 幻读\nMysql 隔离级别分为 4 种：Read Uncommitted（读取未提交的）、Read Committed（读取提交的）、Repeatable Red（可重复读）、Serializaable（串行化）\n   隔离级别 脏读 不可重复读 幻读     Read Uncommitted（读取未提交的） yes yes yes   Read Committed（读取提交的） / yes yes   Repeatable Red（可重复读） / / yes   Serializaable（串行化） / / /     Read Uncommitted:\n脏读是指在事务隔离级别最低的情况下，一个事务读取了另一个事务更新但未提交的数据，导致当前事务读到的数据是不正确的。如果另一个事务回滚，则当前事务读到的数据就是脏数据 Read Committed:\n事务可能会遇到不可重复读（Non Repeatable Read）的问题。不可重复读是指，在一个事务内，多次读同一数据，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致 Repeatable Read:\n幻读是指在一个事务中，第一次查询某条记录时发现没有，但在试图更新这条不存在的记录时却能成功，并且再次读取同一条记录时，它就神奇地出现了 Serializable:\n最严格的隔离级别\n在 Serializable 隔离级别下，事务按照次序依次执行，避免了脏读、不可重复读、幻读。然而，由于串行执行，效率大大下降，应用程序性能急剧降低。一般情况下不会使用 Serializable 隔离级别  如果没有指定隔离级别，数据库就会使用默认的隔离级别。在 MySQL 中，如果使用 InnoDB，默认的隔离级别是 Repeatable Read\n2.本地事务 2.1本地事务定义 定义:在单体应用中，多个业务操作共用同一个连接和数据库，可以操作不同表，出现异常时可以整体回滚\n2.2本地事务的缺点 随着业务的高速发展，面对海量数据，需要考虑分库与分表方案，以减小数据库的单库单表负担，提高查询性能，缩短查询时间。分表策略包括垂直拆分和水平拆分。垂直拆分通过拆分表的字段减少行数据大小，减少网络传输字节数和 I/O 次数；水平拆分则通过拆分表的行来提高性能。水平拆分可以采用取模分表、时间维度分表等策略\n库内分表解决单表数据过大问题，但并未分散到不同物理机，无法减轻MySQL服务器压力。分库拆分将一张表数据划分到不同数据库，可通过本地事务保证强一致性。垂直拆分将业务数据放到不同数据库，导致数据一致性问题，因为每个数据库只能保证自己数据的强一致性\n随着微服务的发展，每个服务都有自己的独立数据库，导致跨服务调用可能出现数据不一致的问题，特别是在服务宕机或网络连接异常的情况下。这需要考虑分布式场景下的数据一致性问题\n当业务量级扩大之后的分库，以及微服务落地之后的业务服务化，都会产生分布式数据不一致的问题。既然 本地事务 无法满足需求，因此就需要 分布式事务\n分布式事务定义 分布式事务定义：我们可以简单地理解，它就是为了保证不同数据库的数据一致性的事务解决方案。这里，我们有必要先来了解下 CAP 原则和 BASE 理论。\nCAP 原则 是 Consistency（一致性）、Availablity（可用性）和 Partition-tolerance（分区容错性）的缩写，它是分布式系统中的平衡理论。\n 一致性：\n要求所有节点每次读操作都能保证获取到最新数据； 可用性：\n要求无论任何故障产生后都能保证服务仍然可用； 分区容错性：\n要求被分区的节点可以正常对外提供服务。  事实上，任何系统只可同时满足其中二个，无法三者兼顾。对于分布式系统而言，分区容错性是一个最基本的要求。\n如果选择一致性和分区容错性，放弃可用性，那么网络问题会导致系统不可用。\n如果选择可用性和分区容错性，放弃一致性，不同的节点之间的数据不能及时同步数据而导致数据的不一致。\n此时，BASE 理论针对一致性和可用性提出了一个方案，BASE 是 Basically Available（基本可用）、Soft-state（软状态）和 Eventually Consistent（最终一致性）的缩写，它是最终一致性的理论支撑。\n简单地理解，在分布式系统中，允许损失部分可用性，并且不同节点进行数据同步的过程存在延时，但是在经过一段时间的修复后，最终能够达到数据的最终一致性。BASE 强调的是数据的最终一致性。相比于 ACID 而言，BASE 通过允许损失部分一致性来获得可用性\n现在比较常用的分布式事务解决方案:  两阶段提交协议(强一致性) 三阶段提交协议(强一致性) 可靠事件模式、补偿模式，TCC 模式(最终一致性)  分布事务 - 强一致性解决方案 1.二阶段提交协议 在分布式系统中，每个数据库只能保证自己的数据可以满足 ACID 保证强一致性，但是它们可能部署在不同的服务器上，只能通过网络进行通信，因此无法准确的知道其他数据库中的事务执行情况。\n因此，为了解决多个节点之间的协调问题，就需要引入一个 协调者 负责控制所有节点的操作结果，要么全部成功，要么全部失败。\n其中，XA 协议 是一个分布式事务协议，它有两个角色： 事务管理者 和 资源管理者 。这里，我们可以把 事务管理者 理解为 (协调者) ，而 资源管理者 理解为 (参与者)\nXA 协议通过 二阶段提交协议保证强一致性\n二阶段提交协议，顾名思义，它具有两个阶段：\n第一阶段准备，\n第二阶段提交。\n这里，事务管理者（协调者）主要负责控制所有节点的操作结果，包括准备流程和提交流程。\n 第一阶段:\n事务管理者（协调者）向资源管理者（参与者）发起准备指令，询问资源管理者（参与者）预提交是否成功。如果资源管理者（参与者）可以完成，就会执行操作，并不提交，最后给出自己响应结果，是预提交成功还是预提交失败。 第二阶段:\n如果全部资源管理者（参与者）都回复预提交成功，资源管理者（参与者）正式提交命令。如果其中有一个资源管理者（参与者）回复预提交失败，则事务管理者（协调者）向所有的资源管理者（参与者）发起回滚命令。  PS:举个案例，现在我们有一个事务管理者（协调者），三个资源管理者（参与者），那么这个事务中我们需要保证这三个参与者在事务过程中的数据的强一致性。首先，事务管理者（协调者）发起准备指令预判它们是否已经预提交成功了，如果全部回复预提交成功，那么事务管理者（协调者）正式发起提交命令执行数据的变更。\n存在一些问题: 虽然二阶段提交协议为保证强一致性提出了一套解决方案，但是仍然存在一些问题。\n 其一：同步阻塞\n事务管理者（协调者）主要负责控制所有节点的操作结果，包括准备流程和提交流程，但是整个流程是同步的，所以事务管理者（协调者）必须等待每一个资源管理者（参与者）返回操作结果后才能进行下一步操作。这样就非常容易造成 同步阻塞问题。 其二：单点故障\n单点故障 也是需要认真考虑的问题。事务管理者（协调者）和资源管理者（参与者）都可能出现宕机，如果资源管理者（参与者）出现故障则无法响应而一直等待，事务管理者（协调者）出现故障则事务流程就失去了控制者，换句话说，就是整个流程会一直阻塞，甚至极端的情况下，一部分资源管理者（参与者）数据执行提交，一部分没有执行提交，也会出现数据不一致性。此时，读者会提出疑问：这些问题应该都是小概率情况，一般是不会产生的？是的，但是对于分布式事务场景，我们不仅仅需要考虑正常逻辑流程，还需要关注小概率的异常场景，如果我们对异常场景缺乏处理方案，可能就会出现数据的不一致性，那么后期靠人工干预处理，会是一个成本非常大的任务，此外，对于交易的核心链路也许就不是数据问题，而是更加严重的资损问题  2.三阶段提交协议 二阶段提交协议诸多问题，因此三阶段提交协议就要登上舞台了。\n三阶段提交协议是二阶段提交协议的 改良版本，它与二阶段提交协议不同之处在于，引入了 超时机制 解决同步阻塞问题，此外加入了预备阶段尽可能提早发现无法执行的资源管理者（参与者）并且终止事务，如果全部资源管理者（参与者）都可以完成，才发起第二阶段的准备和第三阶段的提交。否则，其中任何一个资源管理者（参与者）回复执行失败或者超时等待，那么就终止事务。\n总结一下，三阶段提交协议包括： 第一阶段预备 ， 第二阶段准备 ， 第二阶段提交\n3PC 主要是为了解决两阶段提交协议的单点故障问题和缩小参与者阻塞范围。 引入参与节点的超时机制之外，3PC 把 2PC 的准备阶段分成事务询问（该阶段不会阻塞）和事务预提交，则三个阶段分别为 CanCommit、PreCommit、DoCommit\n（1）第一阶段（CanCommit 阶段）\n类似于 2PC 的准备（第一）阶段。协调者向参与者发送 commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应。\n1.事务询问：\t协调者向参与者发送CanCommit请求。 询问是否可以执行事务提交操作。然后开始等待参与者的响应。 2.响应反馈\t参与者接到CanCommit请求之后，正常情况下，\t如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。\t否则反馈No （2）第二阶段（PreCommit 阶段）\n协调者根据参与者的反应情况来决定是否可以记性事务的 PreCommit 操作。根据响应情况，有以下两种可能：\n如果响应 Yes，则：\n1.发送预提交请求：\t协调者向参与者发送PreCommit请求，并进入Prepared阶段。 2.事务预提交\t参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 3.响应反馈\t如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。则有：\n1.发送中断请求：\t协调者向所有参与者发送abort请求。 2.中断事务\t参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断 （3）第三阶段（doCommit 阶段）\n该阶段进行真正的事务提交，也可以分为执行提交和中断事务两种情况。\n如果执行成功，则有如下操作：\n1.发送提交请求\t协调者接收到参与者发送的ACK响应，那么它将从预提交状态进入到提交状态。\t并向所有参与者发送doCommit请求。 2.事务提交\t参与者接收到doCommit请求之后，执行正式的事务提交。\t并在完成事务提交之后释放所有事务资源。 3.响应反馈\t事务提交完之后，向协调者发送ACK响应。 4.完成事务\t协调者接收到所有参与者的ACK响应之后，完成事务 协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务（注意这是没有收到二段段最后的 ACK，这里要理解清楚）。则有如下操作：\n1.发送中断请求\t协调者向所有参与者发送abort请求 2.事务回滚\t参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，\t并在完成回滚之后释放所有的事务资源。 3.反馈结果\t参与者完成事务回滚之后，向协调者发送ACK消息 4.中断事务\t协调者接收到参与者反馈的ACK消息之后，执行事务的中断 最关键的：在 doCommit 阶段，如果参与者无法及时接收到来自协调者的 doCommit 或者 rebort 请求时（1、协调者出现问题；2、协调者和参与者出现网络故障），会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了 PreCommit 请求，那么协调者产生 PreCommit 请求的前提条件是他在第二阶段开始之前，收到所有参与者的 CanCommit 响应都是 Yes。（一旦参与者收到了 PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到 commit 或者 abort 响应，但是它有理由相信：成功提交的几率很大）\n三阶段提交协议很好的解决了二阶段提交协议带来的问题，是一个非常有参考意义的解决方案。但是，极小概率的场景下可能会出现数据的不一致性。因为三阶段提交协议引入了超时机制，一旦参与者无法及时收到来自协调者的信息之后，他会默认执行 commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。\n分布式事务 - 最终一致性解决方案 1.TCC模式 二阶段提交协议和三阶段提交协议很好的解决了分布式事务的问题，但是在极端情况下仍然存在数据的不一致性，此外它对系统的开销会比较大，引入事务管理者（协调者）后，比较容易出现单点瓶颈，以及在业务规模不断变大的情况下，系统可伸缩性也会存在问题。注意的是，它是同步操作，因此引入事务后，直到全局事务结束才能释放资源，性能可能是一个很大的问题。因此，在高并发场景下很少使用。因此，需要另外一种解决方案：TCC 模式。注意的是，很多读者把 二阶段提交 等同于 二阶段提交协议 ，这个是一个误区，事实上，TCC 模式也是一种二阶段提交\nTCC 模式将一个任务拆分三个操作：Try、Confirm、Cancel 。假如，我们有一个 func () 方法，那么在 TCC 模式中，它就变成了 tryFunc ()、confirmFunc ()、cancelFunc () 三个方法。\n在 TCC 模式中，主业务服务负责发起流程，而从业务服务提供 TCC 模式的 Try、Confirm、Cancel 三个操作。其中，还有一个事务管理器的角色负责控制事务的一致性。例如，我们现在有三个业务服务：交易服务，库存服务，支付服务。用户选商品，下订单，紧接着选择支付方式进行付款，然后这笔请求，交易服务会先调用库存服务扣库存，然后交易服务再调用支付服务进行相关的支付操作，然后支付服务会请求第三方支付平台创建交易并扣款，这里，交易服务就是主业务服务，而库存服务和支付服务是从业务服务。\n我们再来梳理下，TCC 模式的流程。第一阶段主业务服务调用全部的从业务服务的 Try 操作，并且事务管理器记录操作日志。第二阶段，当全部从业务服务都成功时，再执行 Confirm 操作，否则会执行 Cancel 逆操作进行回滚\n注意：我们要特别注意操作的 幂等性 。\n幂等机制的核心是保证资源唯一性 ，例如: 重复提交 或 服务端的多次重试 只会产生一份结果。\n支付场景、退款场景，涉及金钱的交易不能出现多次扣款等问题。\n事实上，查询接口 用于获取资源，因为它只是查询数据而不会影响到资源的变化，因此不管调用多少次接口，资源都不会改变，所以它 是幂等的 。\n而 新增接口 是 非幂等的，因为调用接口多次，它都将会产生资源的变化。因此，我们需要在出现重复提交时进行幂等处理\n那么，如何保证幂等机制呢？\n事实上，我们有很多实现方案。其中，\n一种方案就是常见的创建唯一索引在数据库中针对我们需要约束的资源 字段创建唯一索引，可以防止插入重复的数据。但是，遇到分库分表的情况是，唯一索引也就不那么好使了，\n一种方案先查询约束字段重复性再插入操作 此时，我们可以先查询一次数据库，然后判断是否约束的资源字段存在重复，没有的重复时再进行插入操作。注意的是，为了避免并发场景 ，我们可以通过 锁机制 ，例如悲观锁与乐观锁保证数据的唯一性。这里，分布式锁是一种经常使用的方案，它通常情况下是一种悲观锁的实现。但是，很多人经常把悲观锁、乐观锁、分布式锁当作幂等机制的解决方案，这个是不正确的。\n一种方案引入状态机控制状态切换 除此之外，我们还可以引入状态机,例如：轻量级状态机 Cola-StateMachine ，通过状态机进行状态的约束以及状态跳转，确保同一个业务的流程化执行，从而实现数据幂等\n2.补偿模式 重试机制 \n事实上，它也是 一种最终一致性的解决方案 ：我们需要通过最大努力不断重试，保证数据库的操作最终一定可以保证数据一致性，如果最终多次重试失败可以根据相关 日志并主动通知开发人员进行手工介入。注意的是，被调用方需要保证其幂等性。重试机制可以是同步机制，例如主业务服务调用超时或者非异常的调用失败需要及时重新发起业务调用。\n重试机制可以大致分为\n 固定次数的重试策略  固定时间的重试策略  除此之外，我们还可以借助 消息队列 和 定时任务 机制。\n 消息队列的重试机制\n即消息消费失败则进行重新投递，这样就可以避免消息没有被消费而被丢弃，例如 JMQ 可以默认允许每条消息最多重试 多少 次，每次重试的间隔时间可以进行设置。 定时任务的重试机制\n我们可以创建一张任务执行表，并增加一个 “重试次数” 字段。这种设计方案中，我们可以在定时调用时，获取这个任务是否是执行失败的状态并且没有超过重试次数，如果是则进行失败重试。但是，当出现执行失败的状态并且超过重试次数时，就说明这个任务永久失败了，需要开发人员进行手工介入与排查问题  除了重试机制之外，也可以在每次更新的时候进行修复。例如，对于社交互动的点赞数、收藏数、评论数等计数场景，也许因为网络抖动或者相关服务不可用，导致某段时间内的数据不一致，我们就可以在每次更新的时候进行修复，保证系统经过一段较短的时间的自我恢复和修正，数据最终达到一致。需要注意的是，使用这种解决方案的情况下，如果某条数据出现不一致性，但是又没有再次更新修复，那么其永远都会是异常数据\n定时校对 也是一种非常重要的解决手段，它采取周期性的进行校验操作来保证。关于定时任务框架的选型上，业内比较常用的有单机场景下的 Quartz，以及分布式场景下 Elastic-Job、XXL-JOB、SchedulerX 等分布式定时任务中间件，咱公司有分布式调用平台（ https://schedule.jd.com/ ）。\n定时校对可以分为两种场景:\n 一种是未完成的定时重试，例如我们利用定时任务扫描还未完成的调用任务，并通过补偿机制来修复，实现数据最终达到一致。 一种是定时核对，它需要主业务服务提供相关查询接口给从业务服务核对查询，用于恢复丢失的业务数据。  现在，我们来试想一下电商场景的退款业务。在这个退款业务中会存在一个退款基础服务和自动化退款服务。此时，自动化退款服务在退款基础服务的基础上实现退款能力的增强，实现基于多规则的自动化退款，并且通过消息队列接收到退款基础服务推送的退款快照信息。但是，由于退款基础服务发送消息丢失或者消息队列在多次失败重试后的主动丢弃，都很有可能造成数据的不一致性。因此，我们通过定时从退款基础服务查询核对，恢复丢失的业务数据就显得特别重要了\n3.可靠事件模式 在分布式系统中，消息队列 在服务端的架构中的地位非常重要，主要解决 异步处理、系统解耦、流量削峰 等问题。多个系统之间如果使用同步通信，则很容易造成阻塞，同时会将这些系统耦合在一起，因此，\n引入消息队列后，一方面解决了同步通信机制造成的阻塞 ，另一方面通过消息队列实现了业务解耦\n\u0026ldquo;可靠事件模式\u0026rdquo; 通过引入可靠的消息队列，保证事件能够在消费者的业务内被消费。然而，仅仅引入消息队列并不能保证最终一致性，因为在分布式部署环境下，网络通信可能导致消息丢失\n其一，主业务服务发送消息时可能因为消息队列无法使用而发生失败。对于这种情况，我们可以让主业务服务（生产者）发送消息，再进行业务调用来确保。一般的做法是，主业务服务将要发送的消息持久化到本地数据库，设置标志状态为 “待发送” 状态，然后把消息发送给消息队列，消息队列先向主业务服务（生产者）返回消息队列的响应结果，然后主业务服务判断响应结果执行之后的业务处理。如果响应失败，则放弃之后的业务处理，设置本地的持久化消息标志状态为 “失败” 状态。否则，执行后续的业务处理，设置本地的持久化消息标志状态为 “已发送” 状态\n此外，消息队列接收消息后，也可能从业务服务（消费者）宕机而无法消费。JMQ 有 ACK 机制，如果消费失败，会重试，如果成功，会从消息队列中删除此条消息。那么，消息队列如果一直重试失败而无法投递，会在一定次数之后主动丢弃，当然我们也可以设置为一直重试，这种方式不推荐。我们需要如何解决呢？我们在上个步骤中，主业务服务已经将要发送的消息持久化到本地数据库。因此，从业务服务消费成功后，它也会向消息队列发送一个通知消息，此时它是一个消息的生产者。主业务服务（消费者）接收到消息后，最终把本地的持久化消息标志状态为 “完成” 状态。这就是使用“正反向消息机制”  确保了消息队列可靠事件投递。当然，补偿机制也是必不可少的。定时任务会从数据库扫描在一定时间内未完成的消息并重新投递。大家也可能会说，消费成功之后可以用 RPC 调用主业务服务，首先这样主业务服务要额外提供一个 RPC 的接口；另外也会对从业务服务造成业务的复杂度和耗时影响。这里要注意从业务服务要保证幂等性\n了解了 “可靠事件模式” 的方法论后，现在我们来看一个 真实的案例 来加深理解。\n首先，当用户发起退款后，自动化退款服务会收到一个退款的事件消息，此时，如果这笔退款符合自动化退款策略的话，自动化退款服务会先写入本地数据库持久化这笔退款快照，紧接着，发送一条执行退款的消息投递到给消息队列，消息队列接受到消息后返回响应成功结果，那么自动化退款服务就可以执行后续的业务逻辑。与此同时，消息队列异步地把消息投递给退款基础服务，然后退款基础服务执行自己业务相关的逻辑，执行失败与否由退款基础服务自我保证，如果执行成功则发送一条执行退款成功消息投递到给消息队列。最后，定时任务会从数据库扫描在一定时间内未完成的消息并重新投递。这里，需要注意的是，自动化退款服务持久化的退款快照可以理解为需要确保投递成功的消息，由 “正反向消息机制” 和 “定时任务” 确保其成功投递。此外，真正的退款出账逻辑在退款基础服务来保证，因此它要保证幂等性。当出现执行失败的状态并且超过重试次数时，就说明这个任务永久失败了，需要开发人员进行手工介入与排查问题\n总结一下，引入了消息队列并不能保证可靠事件投递，换句话说，由于网络等各种原因而导致消息丢失不能保证其最终的一致性，\n因此，我们需要通过 “正反向消息机制” 确保了消息队列可靠事件投递，并且使用补偿机制尽可能在一定时间内未完成的消息并重新投递\n“正反向消息机制” + 补偿机制尽\n","description":"微服务架构下的事务一致性问题以及分布式事务的解决方案","id":34,"section":"stack","tags":["golang",""],"title":"微服务保证事务的一致性","uri":"http://wangjinbao.netlify.app/en/stack/golang/paxos/"},{"content":"consul 官方网站：\nhttps://consul.io/\n安装consul  方式一：macOS系统：  1 2 3 4  brew tap hashicorp/tap brew install hashicorp/tap/consul //检查版本号 consul version   方式二：linux系统：   Debian\u0026ndash;  1 2 3  wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/knowledge/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs)main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026amp;\u0026amp; sudo apt install consul    CentOS\u0026ndash;  1 2 3  sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo sudo yum -y install consul    Fedora\u0026ndash;  1 2 3  sudo dnf install -y dnf-plugins-core sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/fedora/hashicorp.repo sudo dnf -y install consul   开启consul 启动Consul Server 命令：\n1 2  # node1 consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=n1 -bind=192.168.110.123 -ui -config-dir /etc/consul.d -rejoin -join 192.168.110.123 -client 0.0.0.0   说明\n#运行consul agent以server模式\n -server : 定义agent运行在server模式 -bootstrap-expect : 在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定server数目的时候才会引导整个集群，该标记不能和bootstrap共用 -data-dir : 提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在 -node : 节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名 -bind : 该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0 -ui : 启动web界面 -config-dir : 配置文件目录，里面所有以.json结尾的文件都会被加载 -rejoin : 使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中 -client : consul服务侦听地址，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0  1 2  # node2 consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=n2 -bind=192.168.110.156 -ui -rejoin -join 192.168.110.123   启动Consul Client 运行consul agent以clent模式，-join 加入到已有的集群中去\n1 2  # node3 consul agent -data-dir /tmp/consul -node=n3 -bind=192.168.110.124 -config-dir /etc/consul.d -rejoin -join 192.168.110.123   验证启动 1 2 3 4 5 6 7  //启动consul consul agent -dev ... 2023-11-17T16:25:34.985+0800 [INFO] agent: Starting server: address=127.0.0.1:8500 network=tcp protocol=http 2023-11-17T16:25:35.025+0800 [INFO] agent: Started gRPC listeners: port_name=grpc_tls address=127.0.0.1:8503 network=tcp 2023-11-17T16:25:35.025+0800 [INFO] agent: Started gRPC listeners: port_name=grpc address=127.0.0.1:8502 network=tcp   访问浏览器：\nhttp://127.0.0.1:8500/\n查看命令：\nconsul members \u0026ndash; 查看节点\n1 2 3  consul members Node Address Status Type Build Protocol DC Partition Segment wangdeMacBook-Pro.local 127.0.0.1:8301 alive server 1.17.0 2 dc1 default \u0026lt;all\u0026gt;   consul leave \u0026ndash; 优雅退出\n如果一个agent作为一个服务器，一个优雅的离开是很重要的。避免引起潜在的可用性故障影响达成一致性协议。\ndig @127.0.0.1 -p 8600 web.service.consul SRV \u0026ndash; 查看主机信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  $ dig @127.0.0.1 -p 8600 web.service.consul SRV ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.6 \u0026lt;\u0026lt;\u0026gt;\u0026gt; @127.0.0.1 -p 8600 web.service.consul SRV ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NXDOMAIN, id: 2157 ;; flags: qr aa rd; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1 ;; WARNING: recursion requested but not available ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;web.service.consul. IN SRV ;; AUTHORITY SECTION: consul. 0 IN SOA ns.consul. hostmaster.consul. 1700214831 3600 600 86400 0 ;; Query time: 0 msec ;; SERVER: 127.0.0.1#8600(127.0.0.1) ;; WHEN: Fri Nov 17 17:53:51 CST 2023 ;; MSG SIZE rcvd: 97   ","description":"Consul 简化了分布式环境中的服务的注册和发现流程，通过 HTTP 或者 DNS 接口发现","id":35,"section":"stack","tags":["golang"],"title":"consul安装","uri":"http://wangjinbao.netlify.app/en/stack/golang/consul/"},{"content":"常见问题解决 version of Delve is too old for Go  问题：\ngoland开启debug一直connected的问题 undefined behavior - version of Delve is too old for Go\n解决：\ngolang的调试器是delve，Goland内置有一个delve，这个问题表面上看，就是内置delve的版本过低了\n步骤一：升级到最新版本的dlvgo install github.com/go-delve/delve/cmd/dlv@latest\n步骤二：执行完上面的命令，其实是安装到了GOBIN目录下，我们执行go env 查看go的配置参数，找到gobin，并将dlv的路径添加到\u0026rsquo;help'-\u0026gt;\u0026lsquo;Edit Custom Properties\u0026rsquo;\n步骤三：在文件中添加以下配置dlv.path:/Users/zz/app/goApp/bin/dlv 重启goland即可解决问题\n ","description":"debug调试","id":36,"section":"stack","tags":["golang"],"title":"debug相关","uri":"http://wangjinbao.netlify.app/en/stack/golang/debug/"},{"content":"安装 地址：github.com/go-playground/validator/v10\n命令：\n1  go get github.com/go-playground/validator/v10   模式绑定 若要将请求主体绑定到结构体中，请使用模型绑定，目前支持JSON、XML、YAML和标准表单值(foo=bar\u0026amp;boo=baz)的绑定。\n需要在绑定的字段上设置tag，比如，绑定格式为json，需要这样设置 json:“fieldname”\ngin提供了两套绑定方法：\n1.Must bind  Methods\n支持：Bind, BindJSON, BindXML, BindQuery, BindYAML Behavior\n这些方法底层使用 MustBindWith，如果存在绑定错误，请求将被以下指令中止 c.AbortWithError(400, err).SetType(ErrorTypeBind)，响应状态代码会被设置为400，请求头Content-Type被设置为text/plain; charset=utf-8。注意，如果你试图在此之后设置响应代码，将会发出一个警告 [GIN-debug] [WARNING] Headers were already written. Wanted to override status code 400 with 422，如果你希望更好地控制行为，请使用ShouldBind相关的方法  来看看MustBindWith方法实现：\n1 2 3 4 5 6 7 8 9  //MustBindWith使用指定的绑定引擎绑定传递的结构指针。 //如果发生任何错误，它将中止HTTP 400的请求。 func (c *Context) MustBindWith(obj any, b binding.Binding) error { if err := c.ShouldBindWith(obj, b); err != nil { c.AbortWithError(http.StatusBadRequest, err).SetType(ErrorTypeBind) // nolint: errcheck \treturn err } return nil }   2.Should bind  Methods\n支持：ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML Behavior\n这些方法底层使用 ShouldBindWith，如果存在绑定错误，则返回错误，开发人员可以正确处理请求和错误。  来看看ShouldBindWith方法实现:\n1 2 3 4  //使用指定的绑定引擎绑定传递的struct指针。 func (c *Context) ShouldBindWith(obj any, b binding.Binding) error { return b.Bind(c.Request, obj) }   ShouldBindJSON方法 ShouldBindJSON是c.ShouldBindWith(obj, binding.JSON)的快捷方式。\nJSON绑定结构体：\n1 2 3 4 5  type PostParams struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Sex bool `json:\u0026#34;sex\u0026#34;` }   ShouldBindJSON代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  func main() { r := gin.Default() r.POST(\u0026#34;/testBind/\u0026#34;, func(c *gin.Context) { //声明一个PostParams结构体 \tvar p PostParams //通过ShouldBindJSON方法绑定结构体的对应属性 \terr := c.ShouldBindJSON(\u0026amp;p) fmt.Printf(\u0026#34;p: %v\\n\u0026#34;, p) if err != nil { fmt.Println(err) c.JSON(404, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;报错了\u0026#34;, \u0026#34;data\u0026#34;: gin.H{}, }) } else { c.JSON(200, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;成功了\u0026#34;, \u0026#34;data\u0026#34;: p, }) } }) r.Run(\u0026#34;:8080\u0026#34;) }   验证：\nPOST请求，访问http://localhost:8080/testBind\njson参数：\n1 2 3 4 5  { \u0026#34;name\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;age\u0026#34;: 66, \u0026#34;sex\u0026#34;: true }   ShouldBindUri方法 ShouldBindUri使用指定的绑定引擎绑定传递的struct指针。\nUri绑定结构体：\n1 2 3 4 5  type PostParams struct { Name string `uri:\u0026#34;name\u0026#34;` Age int `uri:\u0026#34;age\u0026#34;` Sex bool `uri:\u0026#34;sex\u0026#34;` }   ShouldBindUri代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  func main() { r := gin.Default() //路由路径变为uri形式获取参数 \tr.POST(\u0026#34;/testBind/:name/:age/:sex\u0026#34;, func(c *gin.Context) { //声明一个PostParams结构体 \tvar p PostParams //通过ShouldBindUri方法绑定结构体的对应属性 \terr := c.ShouldBindUri(\u0026amp;p) fmt.Printf(\u0026#34;p: %v\\n\u0026#34;, p) if err != nil { fmt.Println(err) c.JSON(404, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;报错了\u0026#34;, \u0026#34;data\u0026#34;: gin.H{}, }) } else { c.JSON(200, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;成功了\u0026#34;, \u0026#34;data\u0026#34;: p, }) } }) r.Run(\u0026#34;:8080\u0026#34;) }   验证：\nPOST请求，访问http://localhost:8080/testBind/linzy/23/true\n参数在uri上面\nShouldBindQuery方法 ShouldBindQuery是c.ShouldBindWith(obj, binding.Query)的快捷方式\nQuery绑定结构体：\n1 2 3 4 5  type PostParams struct { Name string `form:\u0026#34;name\u0026#34;` Age int `form:\u0026#34;age\u0026#34;` Sex bool `form:\u0026#34;sex\u0026#34;` }   ShouldBindQuery代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  func main() { r := gin.Default() r.GET(\u0026#34;/testBind\u0026#34;, func(c *gin.Context) { //声明一个PostParams结构体 \tvar p PostParams //通过ShouldBindQuery方法绑定结构体的对应属性 \terr := c.ShouldBindQuery(\u0026amp;p) fmt.Printf(\u0026#34;p: %v\\n\u0026#34;, p) if err != nil { fmt.Println(err) c.JSON(404, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;报错了\u0026#34;, \u0026#34;data\u0026#34;: gin.H{}, }) } else { c.JSON(200, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;成功了\u0026#34;, \u0026#34;data\u0026#34;: p, }) } }) r.Run(\u0026#34;:8080\u0026#34;) }   验证：\nGET请求，访问http://localhost:8080/testBind?name=linzy\u0026amp;age=23\u0026amp;sex=true\n参数用query\n参数验证器 我们可以给字段指定特定规则的修饰符，如果一个字段用binding:\u0026ldquo;required\u0026quot;修饰，并且在绑定时该字段的值为空，那么将返回一个错误\n结构体验证器 用gin框架数据验证，可以不用解析数据，来if-else判断，整体使代码精简了很多。\nbinding:\u0026quot;required\u0026quot; 就是gin自带的数据验证，表示数据不为空，为空则返回错误\n定义结构体：\n1 2 3 4 5 6  type PostParams struct { Name string `json:\u0026#34;name\u0026#34;` //age不为空并且大于10 \tAge int `json:\u0026#34;age\u0026#34; binding:\u0026#34;required,gt=10\u0026#34;` Sex bool `json:\u0026#34;sex\u0026#34;` }   代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func main() { r := gin.Default() r.POST(\u0026#34;/testBind\u0026#34;, func(c *gin.Context) { var p PostParams err := c.ShouldBindJSON(\u0026amp;p) fmt.Printf(\u0026#34;p: %v\\n\u0026#34;, p) if err != nil { fmt.Println(err) c.JSON(404, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;报错了\u0026#34;, \u0026#34;data\u0026#34;: gin.H{}, }) } else { c.JSON(200, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;成功了\u0026#34;, \u0026#34;data\u0026#34;: p, }) } }) r.Run(\u0026#34;:8080\u0026#34;) }   自定义数据验证 对绑定解析到结构体上的参数，自定义验证功能。比如我们想name不为空的同时，不能为admin的时候，就无法 binding 现成的方法\n结构体：\n1 2 3 4 5 6 7  type PostParams struct { //在参数binding上使用自定义的校验方法函数注册时候的名称 \t//name不为空且不能为admin \tName string `json:\u0026#34;name\u0026#34; binding:\u0026#34;required,notAdmin\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Sex bool `json:\u0026#34;sex\u0026#34;` }   自定义的校验方法：\n1 2 3 4 5 6 7 8 9  //自定义的校验方法 func notAdmin(v validator.FieldLevel) bool { //Field字段返回当前字段进行验证 \t//返回的字段需要转为接口用断言获取底层数据进行校验 \tif v.Field().Interface().(string) == \u0026#34;admin\u0026#34; { return false } return true }   代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  func main() { r := gin.Default() //将我们自定义的校验方法注册到 validator中 \tif v, ok := binding.Validator.Engine().(*validator.Validate); ok { //这里的 key 和 fn 可以不一样最终在 struct 使用的是 key \tv.RegisterValidation(\u0026#34;notAdmin\u0026#34;, notAdmin) } r.POST(\u0026#34;/testBind\u0026#34;, func(c *gin.Context) { var p PostParams err := c.ShouldBindJSON(\u0026amp;p) fmt.Printf(\u0026#34;p: %v\\n\u0026#34;, p) if err != nil { fmt.Println(err) c.JSON(404, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;name 不能为admin\u0026#34;, \u0026#34;data\u0026#34;: gin.H{}, }) } else { c.JSON(200, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;成功了\u0026#34;, \u0026#34;data\u0026#34;: p, }) } }) r.Run(\u0026#34;:8080\u0026#34;) }   ","description":"只需定义结构体使用binding或validate tag标识校验规则，就可以进行参数校验","id":37,"section":"stack","tags":["golang",""],"title":"gin框架验证器validator","uri":"http://wangjinbao.netlify.app/en/stack/golang/gin_validator/"},{"content":"kratos 优势    比对项 内容     框架名 kratos   维护公司 Bilibli   项目地址 https://github.com/go-kratos/kratos   star数 21.7k   开源时间 2019年   服务治理 服务注册/发现、负载均衡、熔断、限流、异常恢复、监控、链路跟踪、日志等   传输协议 gRPC、HTTP   服务发现拓展支持 nacos、consul、etcd、polaris、kubernetes、discovery、zookeeper   API定义 仅支持Protobuf   框架原则特点 简单、通用、高效、稳定、健壮、高性能、扩展性、容错性、工具    特性  APIS: 协议通信以 HTTP/gRPC 为基础，通过 Protobuf 进行定义 Errors: 通过 Protobuf 的 Enum 作为错误码定义，以及工具生成判定接口 Metadata: 在协议通信 HTTP/gRPC 中，通过 Middleware 规范化服务元信息传递 Config: 支持多数据源方式，进行配置合并铺平，通过 Atomic 方式支持动态配置 Logger: 标准日志接口，可方便集成三方 log 库，并可通过 fluentd 收集日志 Metrics: 统一指标接口，可以实现各种指标系统，默认集成 Prometheus Tracing: 遵循 OpenTelemetry 规范定义，以实现微服务链路追踪 Encoding: 支持 Accept 和 Content-Type 进行自动选择内容编码 Transport: 通用的 HTTP/gRPC 传输层，实现统一的 Middleware 插件支持 Registry: 实现统一注册中心接口，可插件化对接各种注册中心  kratos-layout方案 kratos官方提供了一套目录结构方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  . ├── Dockerfile ├── LICENSE ├── Makefile ├── README.md ├── api // 下面维护了微服务使用的proto文件以及根据它们所生成的go文件 │ └── helloworld │ └── v1 │ ├── error_reason.pb.go │ ├── error_reason.proto │ ├── error_reason.swagger.json │ ├── greeter.pb.go │ ├── greeter.proto │ ├── greeter.swagger.json │ ├── greeter_grpc.pb.go │ └── greeter_http.pb.go ├── cmd // 整个项目启动的入口文件 │ └── server │ ├── main.go │ ├── wire.go // 我们使用wire来维护依赖注入 │ └── wire_gen.go ├── configs // 这里通常维护一些本地调试用的样例配置文件 │ └── config.yaml ├── generate.go ├── go.mod ├── go.sum ├── internal // 该服务所有不对外暴露的代码，通常的业务逻辑都在这下面，使用internal避免错误引用 │ ├── biz // 业务逻辑的组装层，类似 DDD 的 domain 层，data 类似 DDD 的 repo，而 repo 接口在这里定义，使用依赖倒置的原则。 │ │ ├── README.md │ │ ├── biz.go │ │ └── greeter.go │ ├── conf // 内部使用的config的结构定义，使用proto格式生成 │ │ ├── conf.pb.go │ │ └── conf.proto │ ├── data // 业务数据访问，包含 cache、db 等封装，实现了 biz 的 repo 接口。我们可能会把 data 与 dao 混淆在一起，data 偏重业务的含义，它所要做的是将领域对象重新拿出来，我们去掉了 DDD 的 infra层。 │ │ ├── README.md │ │ ├── data.go │ │ └── greeter.go │ ├── server // http和grpc实例的创建和配置 │ │ ├── grpc.go │ │ ├── http.go │ │ └── server.go │ └── service // 实现了 api 定义的服务层，类似 DDD 的 application 层，处理 DTO 到 biz 领域实体的转换(DTO -\u0026gt; DO)，同时协同各类 biz 交互，但是不应处理复杂逻辑 │ ├── README.md │ ├── greeter.go │ └── service.go └── third_party // api 依赖的第三方proto ├── README.md ├── google │ └── api │ ├── annotations.proto │ ├── http.proto │ └── httpbody.proto └── validate ├── README.md └── validate.proto   安装 依赖环境：  go protoc  1 2  protoc --version libprotoc 25.0   安装protobuf的go扩展工具 protoc-gen-go  1  go install google.golang.org/protobuf/cmd/protoc-gen-go   建议开启GO111MODULE  1  go env -w GO111MODULE=on   安装kratos脚手架\nsu root  1 2  GOPROXY=https://goproxy.io,direct go install github.com/go-kratos/kratos/cmd/kratos/v2@latest \u0026amp;\u0026amp; kratos upgrade   安装kratos框架\n切换root，因数会把kratos 放到bin目录\ngo install github.com/go-kratos/kratos/cmd/kratos/v2@latest\n验证：  1 2  kratos -v kratos version v2.7.1    PS:把 $GOPATH/bin 加入系统环境变量PATH:\nlinux:\nvim /etc/profile\nexport PATH=\u0026quot;/path/to/$GOPATH/bin:$PATH\u0026quot;\nsource /etc/profile\n 创建项目 kratos new helloworld -r https://gitee.com/go-kratos/kratos-layout.git\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  kratos new helloworld -r https://gitee.com/go-kratos/kratos-layout.git 🚀 Creating service helloworld, layout repo is https://gitee.com/go-kratos/kratos-layout.git, please wait a moment. 正克隆到 \u0026#39;/Users/wangdante/.kratos/repo/gitee.com/go-kratos/kratos-layout@main\u0026#39;... CREATED helloworld/.gitignore (552 bytes) CREATED helloworld/Dockerfile (459 bytes) CREATED helloworld/LICENSE (1066 bytes) CREATED helloworld/Makefile (2525 bytes) CREATED helloworld/README.md (1062 bytes) CREATED helloworld/api/helloworld/v1/error_reason.pb.go (4991 bytes) CREATED helloworld/api/helloworld/v1/error_reason.proto (290 bytes) CREATED helloworld/api/helloworld/v1/greeter.pb.go (8074 bytes) CREATED helloworld/api/helloworld/v1/greeter.proto (678 bytes) CREATED helloworld/api/helloworld/v1/greeter_grpc.pb.go (3560 bytes) CREATED helloworld/api/helloworld/v1/greeter_http.pb.go (2139 bytes) CREATED helloworld/cmd/helloworld/main.go (1744 bytes) CREATED helloworld/cmd/helloworld/wire.go (607 bytes) CREATED helloworld/cmd/helloworld/wire_gen.go (1069 bytes) CREATED helloworld/configs/config.yaml (266 bytes) CREATED helloworld/go.mod (1053 bytes) CREATED helloworld/go.sum (18535 bytes) CREATED helloworld/internal/biz/README.md (6 bytes) CREATED helloworld/internal/biz/biz.go (128 bytes) CREATED helloworld/internal/biz/greeter.go (1236 bytes) CREATED helloworld/internal/conf/conf.pb.go (20782 bytes) CREATED helloworld/internal/conf/conf.proto (761 bytes) CREATED helloworld/internal/data/README.md (7 bytes) CREATED helloworld/internal/data/data.go (473 bytes) CREATED helloworld/internal/data/greeter.go (835 bytes) CREATED helloworld/internal/server/grpc.go (826 bytes) CREATED helloworld/internal/server/http.go (831 bytes) CREATED helloworld/internal/server/server.go (150 bytes) CREATED helloworld/internal/service/README.md (10 bytes) CREATED helloworld/internal/service/greeter.go (688 bytes) CREATED helloworld/internal/service/service.go (136 bytes) CREATED helloworld/openapi.yaml (1130 bytes) CREATED helloworld/third_party/README.md (14 bytes) CREATED helloworld/third_party/errors/errors.proto (411 bytes) CREATED helloworld/third_party/google/api/annotations.proto (1051 bytes) CREATED helloworld/third_party/google/api/client.proto (3395 bytes) CREATED helloworld/third_party/google/api/field_behavior.proto (3011 bytes) CREATED helloworld/third_party/google/api/http.proto (15140 bytes) CREATED helloworld/third_party/google/api/httpbody.proto (2671 bytes) CREATED helloworld/third_party/google/protobuf/any.proto (5909 bytes) CREATED helloworld/third_party/google/protobuf/api.proto (7734 bytes) CREATED helloworld/third_party/google/protobuf/compiler/plugin.proto (8754 bytes) CREATED helloworld/third_party/google/protobuf/descriptor.proto (38497 bytes) CREATED helloworld/third_party/google/protobuf/duration.proto (4895 bytes) CREATED helloworld/third_party/google/protobuf/empty.proto (2429 bytes) CREATED helloworld/third_party/google/protobuf/field_mask.proto (8185 bytes) CREATED helloworld/third_party/google/protobuf/source_context.proto (2341 bytes) CREATED helloworld/third_party/google/protobuf/struct.proto (3779 bytes) CREATED helloworld/third_party/google/protobuf/timestamp.proto (6459 bytes) CREATED helloworld/third_party/google/protobuf/type.proto (6126 bytes) CREATED helloworld/third_party/google/protobuf/wrappers.proto (4042 bytes) CREATED helloworld/third_party/openapi/v3/annotations.proto (2195 bytes) CREATED helloworld/third_party/openapi/v3/openapi.proto (22082 bytes) CREATED helloworld/third_party/validate/README.md (81 bytes) CREATED helloworld/third_party/validate/validate.proto (31270 bytes) 🍺 Project creation succeeded helloworld 💻 Use the following command to start the project 👇: $ cd helloworld $ go generate ./... $ go build -o ./bin/ ./... $ ./bin/helloworld -conf ./configs 🤝 Thanks for using Kratos 📚 Tutorial: https://go-kratos.dev/docs/getting-started/start   -r 指定源\n整理依赖关系 1 2  go mod tidy go mod tidy: go.mod file indicates go 1.18, but maximum supported version is 1.17   切换到go 1.18版本\n1  go mod tidy   依赖注入wire 1 2 3 4  go get github.com/google/wire/cmd/wire go generate ./.. // 写入依赖注入 wrote /Users/wangdante/D/kugou/verify-code/cmd/verify-code/wire_gen.go   添加服务 共用 go.mod ，大仓模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  kratos new helloworld cd helloworld kratos new app/user --nomod ├── app │ └── user │ ├── Dockerfile │ ├── Makefile │ ├── cmd │ │ └── user │ │ ├── main.go │ │ ├── wire.go │ │ └── wire_gen.go │ ├── configs │ │ └── config.yaml │ ├── internal │ │ ├── biz │ │ │ ├── biz.go │ │ │ └── greeter.go │ │ ├── conf │ │ │ ├── conf.pb.go │ │ │ └── conf.proto │ │ ├── data │ │ │ ├── data.go │ │ │ └── greeter.go │ │ ├── server │ │ │ ├── grpc.go │ │ │ ├── http.go │ │ │ └── server.go │ │ └── service │ │ ├── greeter.go │ │ └── service.go │ └── openapi.yaml   一、添加Proto文件  kratos-layout 项目中对 proto 文件进行了版本划分，放在了 v1 子目录下\n 1  kratos proto add api/helloworld/v1/demo.proto   二、生成Proto代码 1 2 3 4 5  # 可以直接通过 make 命令生成 make api # 或使用 kratos cli 进行生成 kratos proto client api/helloworld/v1/demo.proto   会在proto文件同目录下生成:\n1 2 3 4  api/helloworld/v1/demo.pb.go api/helloworld/v1/demo_grpc.pb.go # 注意 http 代码只会在 proto 文件中声明了 http 时才会生成 api/helloworld/v1/demo_http.pb.go   三、生成Service代码 通过 proto 文件，可以直接生成对应的 Service 实现代码：\n使用 -t 指定生成目录\n1  kratos proto server api/helloworld/v1/demo.proto -t internal/service   输出：\ninternal/service/demo.go\n规范代码 (举例verify-code项目) 使用 internal/data 目录 完成数据(数据库，缓存，文件，OSS，云服务器)的操作\n对redis的操作，就属于此类\n步骤一：在/internal/data/data.go中完成redis客户端的初始化 步骤二：使用配置文件，完成redis服务器信息的设置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  // ProviderSet is data providers. var ProviderSet = wire.NewSet(NewData, NewGreeterRepo) // Data . type Data struct { // TODO wrapped database client \tRdb *redis.Client } // NewData . func NewData(c *conf.Data, logger log.Logger) (*Data, func(), error) { data := \u0026amp;Data{} //初始化Rdb \t//连接redis,使用服务的配置，c就是解析之后的变量 \tredisURL := fmt.Sprintf(\u0026#34;redis://%s/1?dial_timeout=%d\u0026#34;, c.Redis.Addr, 1) options, err := redis.ParseURL(redisURL) if err != nil { data.Rdb = nil } // new client 不会立即连接，建立客户端，需要执行命令时才会连接 \tdata.Rdb = redis.NewClient(options) cleanup := func() { //清理了redis连接 \t_ = data.Rdb.Close() log.NewHelper(logger).Info(\u0026#34;closing the data resources\u0026#34;) } return data, cleanup, nil }   步骤三：创建data中用于完成数据操作的对象(实体)  新建 internal/data/customer.go 定义完成后，为依赖注入 wire 提供 provider 在 internal/data/data.go 中  步骤四：完成设置验证码的业务逻辑代码 更新 internal/data/customer.go 新建\nfunc (cd CustomerData) SetVerifyCode(telephone, code string, ex int64) error 方法，用于 完成设置\n步骤五：更新 CustomerService 的定义，与 CustomerData 建立关联 internal/service/customer.go\n修改如下：\n1 2 3 4 5 6 7 8 9 10  type CustomerService struct { pb.UnimplementedCustomerServer cd *data.CustomerData //修改 } func NewCustomerService(cd *data.CustomerData) *CustomerService { return \u0026amp;CustomerService{ cd: cd, //修改 \t} }   步骤六：调用 CustomerData 中定义的方法，实现设置验证码缓存的业务逻辑  添加 Req 和 Resp  customer.proto 文件中 添加 Req 和 Resp 结构，生成更新customer.pd.go 文件：\n1 2  message GetVerifyCodeReq{}message GetVerifyCodeResp{}  更新customer.pb.go文件：  1  kratos proto client api/helloworld/v1/demo.proto   GetVerifyCode方法   每次更新ProviderSet后都要重新更新依赖注入\ngo generate ./\u0026hellip;\n 查看makefile:\n1 2 3  make help sudo make init sudo make api   运行项目\n1 2 3 4 5 6 7  kratos run # 修改配置文件 config.yaml 端口 2023/11/21 19:29:48 maxprocs: Leaving GOMAXPROCS=8: CPU quota undefined DEBUG msg=config loaded: config.yaml format: yaml INFO ts=2023-11-21T19:29:48+08:00 caller=http/server.go:302 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=[HTTP] server listening on: [::]:8022 INFO ts=2023-11-21T19:29:48+08:00 caller=grpc/server.go:205 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=[gRPC] server listening on: [::]:9022   打包项目\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  $go build -o ./bin/ ./... ./helloworld 2023/12/05 11:05:26 maxprocs: Leaving GOMAXPROCS=8: CPU quota undefined panic: stat ../../configs: no such file or directory cp -r ../configs ../../ ./helloworld 2023/12/05 11:07:05 maxprocs: Leaving GOMAXPROCS=8: CPU quota undefined DEBUG msg=config loaded: config.yaml format: yaml INFO ts=2023-12-05T11:07:05+08:00 caller=http/server.go:317 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=[HTTP] server listening on: [::]:8000 INFO ts=2023-12-05T11:07:05+08:00 caller=grpc/server.go:212 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=[gRPC] server listening on: [::]:9006 INFO ts=2023-12-05T11:07:15+08:00 caller=biz/greeter.go:44 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=CreateGreeter: eric INFO ts=2023-12-05T11:07:16+08:00 caller=biz/greeter.go:44 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=CreateGreeter: eric   大集成demo 创建服务customer 1  kratos new customer -r https://gitee.com/go-kratos/kratos-layout.git   整理依赖包 1 2  cd customer go mod tidy   依赖注入wire 1 2 3 4  go get github.com/google/wire/cmd/wire // 写入依赖注入 go generate ./... wire: customer/cmd/customer: wrote /Users/wangdante/D/kugou/kratos_backend/customer/cmd/customer/wire_gen.go   验证启动  PS kratos run 的时候报错：\nmissing go.sum entry for module providing package golang.org/x/sync/errgroup (imported by github.com/go-kratos/kratos/v2); to add:\n解决方法： go get golang.org/x/sync/errgroup\n 修改 configs/config.yaml 端口：\n1 2 3 4 5 6  server:http:addr:0.0.0.0:8600timeout:1sgrpc:addr:0.0.0.0:9600  开启项目：kratos run \u0026ndash;在customer目录下\n验证访问：http://127.0.0.1:8600/helloworld/123\n添加proto文件 1  kratos proto add api/customer/customer.proto   增加路由代码 vim api/customer/customer.proto 中添加内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 导入包 import \u0026#34;google/api/annotations.proto\u0026#34;;...//获取验证码 \trpc GetVerifyCode (GetVerifyCodeReq)returns(GetVerifyCodeResp){\toption (google.api.http)={\tget: \u0026#34;/customer/get-verify-code\u0026#34;\t};\t}...message GetVerifyCodeReq {\tstring Telephone = 1;}message GetVerifyCodeResp {\tint64 Code = 1;\tstring Message = 2;\tstring Data = 3;}  增加客户端代码(client) 1  kratos proto client api/customer/customer.proto   增加服务端代码(server) 1 2 3  kratos proto server api/customer/customer.proto #或者指定目录 -t kratos proto server api/customer/customer.proto -t internal/service   http服务中加customer服务 修改 internal/server/http.go ：内容如下：\n1 2 3 4 5 6 7 8 9  import customer2 \u0026#34;customer/api/customer\u0026#34; ... func NewHTTPServer(c *conf.Server, customerService *service.CustomerService, greeter *service.GreeterService, logger log.Logger) *http.Server { ... srv := http.NewServer(opts...) // 注册customer的http的服务 customer2.RegisterCustomerHTTPServer(srv, customerService) v1.RegisterGreeterHTTPServer(srv, greeter) ...   (grpc服务中加customer服务) 修改 internal/server/grpc.go ：内容如下：\n1 2 3 4 5 6 7 8  import customer2 \u0026#34;customer/api/customer\u0026#34; ... func NewGRPCServer(c *conf.Server, customerService *service.CustomerService, greeter *service.GreeterService, logger log.Logger) *grpc.Server { ... srv := grpc.NewServer(opts...) // 注册customer的grpc的服务 customer2.RegisterCustomerServer(srv, customerService) v1.RegisterGreeterServer(srv, greeter)   修改依赖注入providerSet 修改 internal/service/service.go 内容如下：\n1  var ProviderSet = wire.NewSet(NewCustomerService, NewGreeterService)   基于wire注入依赖 集成根目录下 kratos_backend 执行\n1  go get github.com/google/wire/cmd/wire   kratos_backend/customer目录下执行：\n1 2 3  go generate ./... wire: customer/cmd/customer: wrote /Users/wangdante/D/kugou/kratos_backend/customer/cmd/customer/wire_gen.go    PS:报错\ngo: cannot find main module, but found .git/config in /Users/wangdante/D/kugou/kratos_backend to create a module there, run:go mod init\n解决方法：\ngo mod init customer\ngo mod tidy\n 启动 customer目录下执行：\n1 2 3 4 5 6  kratos run 2023/12/15 18:45:29 maxprocs: Leaving GOMAXPROCS=8: CPU quota undefined DEBUG msg=config loaded: config.yaml format: yaml INFO ts=2023-12-15T18:45:29+08:00 caller=grpc/server.go:205 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=[gRPC] server listening on: [::]:9600 INFO ts=2023-12-15T18:45:29+08:00 caller=http/server.go:302 service.id=wangdeMacBook-Pro.local service.name= service.version= trace.id= span.id= msg=[HTTP] server listening on: [::]:8600   测试http服务 浏览器输入：\nhttp://127.0.0.1:8600/customer/get-verify-code\n返回：\n1 2 3 4 5  { \u0026#34;Code\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Data\u0026#34;: \u0026#34;\u0026#34; }   测试grpc服务 使用apifox工具\n 步骤一：设置.proto文件\n/Users/wangdante/D/kugou/kratos_backend/customer/api/customer/customer.proto 步骤二：设置依赖关系目录\n把 third_party 目录中的 google复制一份到项目customer根目录下\n/Users/wangdante/D/kugou/kratos_backend/customer 步骤三：设置环境\n开发环境：127.0.0.1:9600 步骤四：请求gRPC并传参\n参数：  1 2 3  { \u0026#34;Telephone\u0026#34;:\u0026#34;13510116521\u0026#34; }   返回值：\n1 2 3 4 5  { \u0026#34;Code\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Message\u0026#34;: \u0026#34;13510116521获取验证码成功\u0026#34;, \u0026#34;Data\u0026#34;: \u0026#34;\u0026#34; }   IDE加载google/api/annotations.proto 解决代码中google报红的方法：\n编辑器设置 GoLand -\u0026gt; Settings -\u0026gt; Languages \u0026amp; Frameworks -\u0026gt; Protocol Buffers -\u0026gt; 添加项目的 third_party 目录\nfile:///Users/wangdante/D/kugou/kratos_backend/customer/third_party\n","description":"一套轻量级 Go 微服务框架，包含大量微服务相关框架及工具","id":38,"section":"stack","tags":["golang",""],"title":"kratos微服务框架","uri":"http://wangjinbao.netlify.app/en/stack/golang/kratos/"},{"content":" PS: 微服务架构  是一种设计方法;\n而 微服务 这是应该指使用这种方法而设计的一个应用。\n 微服务架构 定义：将复杂的系统使用 组件化 的方式进行拆分，并使用轻量级 通讯方式 进行整合的一种设计方法。\n微服务 定义：通过这种架构设计方法拆分出来的一个独立的 组件化 的 小应用 。\n 精髓：\u0026ldquo;分而治之，合而用之\u0026rdquo;\n 单体式开发的缺点：  复杂性逐渐变高 技术债务逐渐上升 维护成本大 持续交付周期长 可扩展性差  微服务式开发的特点：  单一职责：\n不同的服务通过 \u0026quot;管道\u0026quot; 方式灵活组合 轻量级通信：\nXML 和 JSON 它和语言无关、平台无关的；学用协议：通信协议：通常基于HTTP 独立性：\n高度解耦 进程隔离：\n每个服务单独隔离  微服务式开发的缺点：  运维要求较高\n每个模块出问题时整个个项目运行异常，不好排查问题，运维要求高 分布式的复杂性 接口调整成本高\n一旦用户微服务的接口发生大的变动，那么所有依赖它的微服务都要做相应的调整 重复劳动\n每个微服务都要一个工具类  微服务式开发的优点：  开发简单\n没有太多的累赘 快速响应需求变化\n能够快速的影响业务的需求变化 随时随地更新\n微服务的部署和更新并不会影响 全局系统 的正常运行；多实例部署的情况下，每个服务的重启和更新任何时候都可以 系统更加稳定可靠\n高可用的分布式环境之中，有配套的 监控 和 调度 管理机制，并且还可以提供自由伸缩的管理，充分保障了系统的稳定可靠性  重要组件  protobuf \n跨语言，跨平台 通讯方式 protobuf\n轻便高效的结构化数据存储格式，平台无关、语言无关、可扩展 gRPC \n通讯协议 gRPC consul \n调度管理服务发现 consul micro \n微服务的框架 micro docker \n部署 docker  数据交互的格式比较  json:\n一般的web项目中，最流行的主要还是json，因为浏览器对于json数据支持非常好，有很多内建的函数支持 xml:\n在webservice中应该最为广泛，但是相比于json，它的数据更冗余，因为需要成对的闭合标签，json使用了键值对的方式，不仅压缩了一定的数据空间，同时也具有可主读性 protobuf:\n后起之秀，是谷歌开源的一种数据格式，适合高性，对 响应速度有要求 的数据传输场景。因为profobuf是二进制数据格式，需要编码和解码。数据本身不具有可读性。因此只能反序列化之后得到真正可读的数据  相对于其它protobuf更具有优势  序列化后体积相比json和XML很小，适合网络传输 支持跨平台多语言 消息格式升级和兼容性还不错 序列化反序列化速度很快，快于json的处理速度  protobuf有如 XML ，不过它 更小、更快、也更简单 。你可以定义自己的数据结构，然后使用代码生成器生成的代码来读写一个数据结构。\n你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 Protobuf 对数据结构进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。\n它有一个非常棒的特性，即 \u0026ldquo;向后\u0026rdquo; 兼容性好，人们不必破坏已部署的、依靠\u0026quot;老\u0026quot;数据格式的程序就可以对数据结构进行升级。\nProtobuf语义更清晰，无需类似XML解析器的东西（因为Protobuf编译器会将.proto文件编译生成对应的数据访问类似对Protobuf数据进行序列化、反序列化操作）。\nProtobuf的编程模式比较友好，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人而言，protobuf比其他的技术更加有吸引力。\nProtobuf安装 mac 安装如下\u0026mdash;\u0026mdash;\u0026mdash;- 1.Protoc安装 1 2 3  brew install protobuf #验证 protoc -h    PS:报错：Error: protobuf: unknown or unsupported macOS version: :dunno\n执行重置 Homebrew : brew update-reset\n 1 2  brew install protobuf@3.17.3 protoc --version    PS: macos当前系统不支持 autoconf 需要升级\n下载地址：https://alpha.gnu.org/pub/gnu/autoconf/autoconf-2.72c.tar.gz\n 1 2 3 4 5 6  压缩 -\u0026gt; 进入目录 ./configure make # -\u0026gt;提示要升级M4 ，去下载最新版本：http://ftp.gnu.org/gnu/m4/m4-latest.tar.gz sudo make install autoconf --version autoconf (GNU Autoconf) 2.71    PS: 升级M4的操作步骤如下：\n 1 2 3 4 5  tar -zxvf m4-1.4.19 cd m4-1.4.19 ./configure make sudo make install   2.Protoc-gen-go的安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # 首先你需要将GOPATH添加到PATH中；Mac中 在终端输入 env 可以查看环境变量； # 目前Mac默认的终端是zsh，所以需要 编辑 HOME 下的 .zshrc 文件 vim .zshrc # vim 在输入法为英文的状态下，按i进入编辑模式，将下边内容添加到文件中 export GOPATH=$HOME/go export PATH=$GOPATH/bin:$PATH # 然后 按 : 输入wq ，保存退出。 重载一下 .zshrc 文件 source .zshrc # 然后在终端执行下方命令 go install github.com/golang/protobuf/protoc-gen-go@latest   主要的命令 go install github.com/golang/protobuf/protoc-gen-go@latest\n3.根据proto文件生成对应的GO代码 执行编译：\nprotoc --go_out=plugins=grpc:./ *.proto #添加grpc插件\n更新一下没有的依赖包：\n1  go get -v -u google.golang.org/grpc   1 2 3 4 5 6 7 8 9 10 11 12  # 当你写好对应的Proto文件后 # 在终端 cd 到 proto 文件的目录，然后执行 下方的命令 protoc -I . hello.proto --go_out=plugins=grpc:. # 在此间我遇到一个问题，在 proto文件中 option的问题 不能直接用 路径不能用单独用 . 至少要有个 / option go_package= \u0026#34;./;proto\u0026#34;; # 如此就成功通过proto文件生成go代码 # PS：补充个知识 option go_package = \u0026#34;ofc_app;pb_ofc_app_v1\u0026#34;; # option go_package表示生成的go文件的存放地址和包名，分号前是地址，分号后是包名。    Linux 安装如下\u0026mdash;\u0026mdash;\u0026mdash;- 一、下载 protobuf:  方式一：（本人使用下载zip）\n#地址：https://github.com/protocolbuffers/protobuf\n本人用的 protobuf-3.0.x.zip  1 2  git clone https://github.com/protocolbuffers/protobuf.git    方式二：\n#地址：https://github.com/protocolbuffers/protobuf/releases  二、安装依赖库 1  $ sudo apt-get install autoconf automake libtool curl make g++ unzip libffi-dev -y   三、安装 1 2 3 4 5 6 7 8 9 10  cd protobuf/ ./autogen.sh ./configure make sudo make install #刷新共享库，很重要的一步 sudo ldconfig #安装时候会比较卡 #成功后验证 protoc -h   四、获取proto包 #GO 语言的proto API接口\n#修改国内镜像\n PS:报错超时\ngo env -w GO111MODULE=on\ngo env -w GOPROXY=https://mirrors.aliyun.com/goproxy/,direct\n或 go env -w GOPROXY=https://goproxy.cn,direct\n有时会报错:\nwarning: go env -w GOPROXY=... does not override conflicting OS environment variable\n解决方法：\n重设一下 GOPROXY 既可\nunset GOPROXY\n go get命令 参数：\n -u : 强制使用网络去更新包和它的依赖包 -v : 显示执行的命令 -x : 显示用到的命令 -d : 只下载不安装 -f : 只有在你包含了 -u 参数的时候才有效，不让 -u 去验证 import 中的每一个都已经获取了，这对于本地 fork 的包特别有用 -fix : 在获取源码之后先运行 fix，然后再去做其他的事情 -t : 同时也下载需要为运行测试所需要的包  1  $ go get -v -u github.com/golang/protobuf/proto   五、安装protoc-gen-go插件 它是一个go 程序，编译它之后将可执行文件复制到/bin目录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #安装 go get -v -u github.com/golang/protobuf/protoc-gen-go #复制下载的内容 mkdir -p /go/src/github.com/golang/ cp -r /go/pkg/mod/github.com/golang/protobuf\\@v1.5.3/ /go/src/github.com/golang/ mv protobuf\\@v1.5.3/ protobuf/ #编译 cd $GOPATH/src/github.com/golang/protobuf/protoc-gen-go/ go build #将生成的 protoc-gen-go 可执行文件，放在/bin目录下 sudo cp protoc-gen-go /bin/ #验证直接执行命令 protoc-gen-go   Protobuf的语法 。proto 文件\n定义一个消息类型：\n1 2 3 4 5 6 7 8 9 10 11 12  syntax = \u0026#34;proto3\u0026#34; ; message PandaRequest{ string name = 1 ; //名字 int32 shengao = 2 ; // repeated int32 tizhong = 3 ; } message PandaResponse{ int32 error = 1 ; //错误号 string ermessage = 2 ; //错误信息 }   Protobuf编译器 1.新建.proto文件： 1 2 3  mkdir -p /go/src/myproto/proto1/ cd /go/src/myproto/proto1/ vim test1.proto   2.编辑.proto文件 内容如下：\n1 2 3 4 5 6 7 8 9 10 11  syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;./\u0026#34;; // 指定生成的go文件所在path message PandaRequest{ string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; } message PandaResponse{ int32 error = 1; string message = 2; }   3.编译对应语言的脚本 调用编译器：\n1 2 3  protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR path/to/file.proto # 或者 protoc --go_out=./ *.proto   说明：\n IMPORT_PATH ：\n声明了一个 .proto 文件所在的解析 import 具体目录。如果忽略则使用当前目录。 如果有多个目录则可以多次调用 --proto_path ,它们将会顺序的被访问并执行导入。-I=IMPORT_PATH 是 --proto_path 的简化形式。 cpp_out ：\n输出路径。 --cpp_out 在目标目录DST_DIR中产生C++代码。 --python_out 在目标目录DST_DIR中产生python代码。--go_out 在目标目录DST_DIR中产生GO代码。  4.验证并查看脚本 当前目录生产新的脚本：\ntest1.pb.go\n内容是go语言语法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // Code generated by protoc-gen-go. DO NOT EDIT. // versions: // protoc-gen-go v1.26.0 // protoc (unknown) // source: test1.proto  package __ import ( protoreflect \u0026#34;google.golang.org/protobuf/reflect/protoreflect\u0026#34; protoimpl \u0026#34;google.golang.org/protobuf/runtime/protoimpl\u0026#34; reflect \u0026#34;reflect\u0026#34; sync \u0026#34;sync\u0026#34; ) const ( // Verify that this generated code is sufficiently up-to-date.  _ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion) // Verify that runtime/protoimpl is sufficiently up-to-date.  _ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20) ) -- VISUAL -- 48 1,1 Top      .proto Type C++ Type Python Type Go Type     double double float float64   float float float float32   int32 int32 int int32   bool bool bool bool   string string str/unicode string   bytes string str []byte    有默认值 其他消息类型 要在 .proto 文件中指定，例如：\n1 2 3 4 5 6 7 8  message PersonInfo{ message Person{ string name = 1; int32 shengo = 2; repeated int32 tizhong = 3; } repeated Person info =1;}  其它父消息类型的外部使用这个消息类型，使用 . 链式形式，如：\n1 2 3  message PersonMessage{ PersonInfo.Person info = 1;}  定义服务(Service) 1 2 3 4  service SearchService{ //rpc 服务的函数名 (传入参数) 返回 (返回参数) rpc Search (SearchRequest) returns (SearchResponse); }   gRPC 最直观的使用 protocol buffer 的RPC系统是 gRPC\ngRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和HTTP/2设计。\n特性：双向流、流控、头部压缩、单TCP连接上的多复用请求等待，对移动设备有好，更省电、节省空间占用。\n测试 1.生成go包 测试生成的proto 的go包\n1 2 3  mkdir -p /go/src/myproto/prototext cd /go/src/myproto/prototext vim text.proto   内容如下：\n1 2 3 4 5 6 7 8 9  syntax = \u0026#34;proto3\u0026#34;;option go_package = \u0026#34;./\u0026#34;;package prototext;message Test{ string name = 1; repeated int32 tizhong = 2; int32 shengao = 3; string motto = 4;}   2.测试go包 1 2 3  mkdir -p /go/src/myproto/test cd /go/src/myproto/test vim test.go   test.go内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  package main import( \u0026#34;myproto/prototext\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/golang/protobuf/proto\u0026#34; ) func main(){ text:=\u0026amp;prototext.Test{ Name:\u0026#34;wjb\u0026#34;, Tizhong:[]int32{120,125,160,166}, Shengao:181, Motto:\u0026#34;good study!\u0026#34;, } fmt.Println(text) data,err:=proto.Marshal(text) if err!=nil{ fmt.Println(\u0026#34;failed\u0026#34;) } fmt.Println(data) newtext:=\u0026amp;prototext.Test{} proto.Unmarshal(data.newtext) if err!=nil{ fmt.Println(\u0026#34;failed\u0026#34;) } fmt.Println(newtext) fmt.Println(newtext.Name) fmt.Println(newtext.Shengao) }   RPC rpc包提供了通过网络或其他I/O连接对一个对象的导出方法的访问。\n服务端注册一个对象，使它作为一个服务被暴露，服务的名字是该对象的类型名。\n注册之后，对象的导出方法就可以被远程访问。\n服务端可以注册多个不同类型的对象（服务），但注册具有相同类型的多个对象是错误的。\n只有满足如下标准的方法才能用于远程访问，其余方法会被忽略：\n 方法是导出的 (首字母大写) 方法有两个参数，都是导出类型或内建类型 方法的第二个参数是指针 方法只有一个error接口类型的返回值  事实上，方法必须看起来像这样：\n1  func (t *T) MethodName(argType T1 , replyType *T2) error   实例(服务端+客户端) 1 2 3  rpc ├── client.go └── server.go   server.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/rpc\u0026#34; ) func pandatext(w http.ResponseWriter, r *http.Request) { io.WriteString(w, \u0026#34;hello dante hello panda\u0026#34;) } /* + 方法是导出的 (首字母大写) + 方法有两个参数，都是导出类型或内建类型 + 方法的第二个参数是指针 + 方法只有一个error接口类型的返回值 */ type Panda int //函数关键字 (对象) 函数名 (对端发送过来的内容 ，返回给对端的内容) 错误返回值 func (p *Panda) Getinfo(artType int, replyType *int) error { fmt.Println(\u0026#34;打印对端发送过来的内容：\u0026#34;, artType) //修改内容値 \t*replyType = artType + 1230 return nil } func main() { //页面的请求 \thttp.HandleFunc(\u0026#34;/panda\u0026#34;, pandatext) //-1-服务端注册一个对象 \tpd := new(Panda) rpc.Register(pd) rpc.HandleHTTP() ln, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:10086\u0026#34;) if err != nil { fmt.Println(\u0026#34;网络错误\u0026#34;) } http.Serve(ln, nil) }   运行server.go：\n1 2  go run server.go 打印对端发送过来的内容： 10086   client.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/rpc\u0026#34; ) func main() { //建立网络连接 \tcli, err := rpc.DialHTTP(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:10086\u0026#34;) if err != nil { fmt.Println(\u0026#34;网络连接失败\u0026#34;) } var pd int /* func (client *Client) Call(serviceMethod string, args any, reply any) error */ //-2-连接服务 \terr = cli.Call(\u0026#34;Panda.Getinfo\u0026#34;, 10086, \u0026amp;pd) if err != nil { fmt.Println(\u0026#34;打call失败\u0026#34;) } fmt.Println(\u0026#34;最后的值为：\u0026#34;, pd) }   运行client.go：\n1 2  go run client.go 最后的值为; 11316   gRPC定义服务 1 2  myproto └── myproto.proto   myproto.proto 的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  syntax = \u0026#34;proto3\u0026#34;;package myproto;//定义服务 service HelloServer{ //一个打招呼的函数  rpc Sayhello(HelloReq)returns(HelloRsp){} //一个说名字的函数  rpc Sayname(NameReq)returns(NameRsp){}}//客户端发送给服务端 message HelloReq{ string name = 1;}//服务端返回给客户端 message HelloRsp{ string msg = 1;}//客户端发送给服务端 message NameReq{ string name = 1;}//服务端返回给客户端 message NameRsp{ string msg = 1;}  编译并生成文件：\n1 2  protoc --go_out=./ *.proto #不加grpc插件 protoc --go_out=plugins=grpc:./ *.proto #添加grpc插件   grpc示例 1. 步骤一：在定义proto，并编译 a. 新增proto文件\n1 2 3 4 5 6 7 8  echo $GOPATH # /Users/wangdante/go01 # 新建目录newgrpc mkdir /Users/wangdante/go01/newgrpc # 新建proto文件 cd /Users/wangdante/go01/newgrpc touch newgrpc.proto   b. newgrpc.proto 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  syntax = \u0026#34;proto3\u0026#34;;option go_package = \u0026#34;./\u0026#34;;package newgrpc;//定义服务 service HisServer{ //一个打招呼的函数  rpc Sayhis(HiReqs)returns(HiRsps){} //一个说名字的函数  rpc Saynas(NaReqs)returns(NaRsps){}}//客户端发送给服务端 message HiReqs{ string name = 1;}//服务端返回给客户端 message HiRsps{ string msg = 1;}//客户端发送给服务端 message NaReqs{ string name = 1;}//服务端返回给客户端 message NaRsps{ string msg = 1;}  c. 编译生成对应语言的go文件 newgrpc.pb.go\n1 2  protoc --go_out=plugins=grpc:./ *.proto newgrpc.pb.go   d. newgrpc.pb.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466  // Code generated by protoc-gen-go. DO NOT EDIT. // versions: // protoc-gen-go v1.26.0 // protoc v4.25.0 // source: newgrpc.proto  package __ import ( context \u0026#34;context\u0026#34; grpc \u0026#34;google.golang.org/grpc\u0026#34; codes \u0026#34;google.golang.org/grpc/codes\u0026#34; status \u0026#34;google.golang.org/grpc/status\u0026#34; protoreflect \u0026#34;google.golang.org/protobuf/reflect/protoreflect\u0026#34; protoimpl \u0026#34;google.golang.org/protobuf/runtime/protoimpl\u0026#34; reflect \u0026#34;reflect\u0026#34; sync \u0026#34;sync\u0026#34; ) const ( // Verify that this generated code is sufficiently up-to-date. \t_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion) // Verify that runtime/protoimpl is sufficiently up-to-date. \t_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20) ) //客户端发送给服务端 type HiReqs struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Name string `protobuf:\u0026#34;bytes,1,opt,name=name,proto3\u0026#34; json:\u0026#34;name,omitempty\u0026#34;` } func (x *HiReqs) Reset() { *x = HiReqs{} if protoimpl.UnsafeEnabled { mi := \u0026amp;file_newgrpc_proto_msgTypes[0] ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) ms.StoreMessageInfo(mi) } } func (x *HiReqs) String() string { return protoimpl.X.MessageStringOf(x) } func (*HiReqs) ProtoMessage() {} func (x *HiReqs) ProtoReflect() protoreflect.Message { mi := \u0026amp;file_newgrpc_proto_msgTypes[0] if protoimpl.UnsafeEnabled \u0026amp;\u0026amp; x != nil { ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) if ms.LoadMessageInfo() == nil { ms.StoreMessageInfo(mi) } return ms } return mi.MessageOf(x) } // Deprecated: Use HiReqs.ProtoReflect.Descriptor instead. func (*HiReqs) Descriptor() ([]byte, []int) { return file_newgrpc_proto_rawDescGZIP(), []int{0} } func (x *HiReqs) GetName() string { if x != nil { return x.Name } return \u0026#34;\u0026#34; } //服务端返回给客户端 type HiRsps struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Msg string `protobuf:\u0026#34;bytes,1,opt,name=msg,proto3\u0026#34; json:\u0026#34;msg,omitempty\u0026#34;` } func (x *HiRsps) Reset() { *x = HiRsps{} if protoimpl.UnsafeEnabled { mi := \u0026amp;file_newgrpc_proto_msgTypes[1] ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) ms.StoreMessageInfo(mi) } } func (x *HiRsps) String() string { return protoimpl.X.MessageStringOf(x) } func (*HiRsps) ProtoMessage() {} func (x *HiRsps) ProtoReflect() protoreflect.Message { mi := \u0026amp;file_newgrpc_proto_msgTypes[1] if protoimpl.UnsafeEnabled \u0026amp;\u0026amp; x != nil { ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) if ms.LoadMessageInfo() == nil { ms.StoreMessageInfo(mi) } return ms } return mi.MessageOf(x) } // Deprecated: Use HiRsps.ProtoReflect.Descriptor instead. func (*HiRsps) Descriptor() ([]byte, []int) { return file_newgrpc_proto_rawDescGZIP(), []int{1} } func (x *HiRsps) GetMsg() string { if x != nil { return x.Msg } return \u0026#34;\u0026#34; } //客户端发送给服务端 type NaReqs struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Name string `protobuf:\u0026#34;bytes,1,opt,name=name,proto3\u0026#34; json:\u0026#34;name,omitempty\u0026#34;` } func (x *NaReqs) Reset() { *x = NaReqs{} if protoimpl.UnsafeEnabled { mi := \u0026amp;file_newgrpc_proto_msgTypes[2] ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) ms.StoreMessageInfo(mi) } } func (x *NaReqs) String() string { return protoimpl.X.MessageStringOf(x) } func (*NaReqs) ProtoMessage() {} func (x *NaReqs) ProtoReflect() protoreflect.Message { mi := \u0026amp;file_newgrpc_proto_msgTypes[2] if protoimpl.UnsafeEnabled \u0026amp;\u0026amp; x != nil { ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) if ms.LoadMessageInfo() == nil { ms.StoreMessageInfo(mi) } return ms } return mi.MessageOf(x) } // Deprecated: Use NaReqs.ProtoReflect.Descriptor instead. func (*NaReqs) Descriptor() ([]byte, []int) { return file_newgrpc_proto_rawDescGZIP(), []int{2} } func (x *NaReqs) GetName() string { if x != nil { return x.Name } return \u0026#34;\u0026#34; } //服务端返回给客户端 type NaRsps struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Msg string `protobuf:\u0026#34;bytes,1,opt,name=msg,proto3\u0026#34; json:\u0026#34;msg,omitempty\u0026#34;` } func (x *NaRsps) Reset() { *x = NaRsps{} if protoimpl.UnsafeEnabled { mi := \u0026amp;file_newgrpc_proto_msgTypes[3] ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) ms.StoreMessageInfo(mi) } } func (x *NaRsps) String() string { return protoimpl.X.MessageStringOf(x) } func (*NaRsps) ProtoMessage() {} func (x *NaRsps) ProtoReflect() protoreflect.Message { mi := \u0026amp;file_newgrpc_proto_msgTypes[3] if protoimpl.UnsafeEnabled \u0026amp;\u0026amp; x != nil { ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) if ms.LoadMessageInfo() == nil { ms.StoreMessageInfo(mi) } return ms } return mi.MessageOf(x) } // Deprecated: Use NaRsps.ProtoReflect.Descriptor instead. func (*NaRsps) Descriptor() ([]byte, []int) { return file_newgrpc_proto_rawDescGZIP(), []int{3} } func (x *NaRsps) GetMsg() string { if x != nil { return x.Msg } return \u0026#34;\u0026#34; } var File_newgrpc_proto protoreflect.FileDescriptor var file_newgrpc_proto_rawDesc = []byte{ 0x0a, 0x0d, 0x6e, 0x65, 0x77, 0x67, 0x72, 0x70, 0x63, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x07, 0x6e, 0x65, 0x77, 0x67, 0x72, 0x70, 0x63, 0x22, 0x1c, 0x0a, 0x06, 0x48, 0x69, 0x52, 0x65, 0x71, 0x73, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x22, 0x1a, 0x0a, 0x06, 0x48, 0x69, 0x52, 0x73, 0x70, 0x73, 0x12, 0x10, 0x0a, 0x03, 0x6d, 0x73, 0x67, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x03, 0x6d, 0x73, 0x67, 0x22, 0x1c, 0x0a, 0x06, 0x4e, 0x61, 0x52, 0x65, 0x71, 0x73, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x22, 0x1a, 0x0a, 0x06, 0x4e, 0x61, 0x52, 0x73, 0x70, 0x73, 0x12, 0x10, 0x0a, 0x03, 0x6d, 0x73, 0x67, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x03, 0x6d, 0x73, 0x67, 0x32, 0x67, 0x0a, 0x09, 0x48, 0x69, 0x73, 0x53, 0x65, 0x72, 0x76, 0x65, 0x72, 0x12, 0x2c, 0x0a, 0x06, 0x53, 0x61, 0x79, 0x68, 0x69, 0x73, 0x12, 0x0f, 0x2e, 0x6e, 0x65, 0x77, 0x67, 0x72, 0x70, 0x63, 0x2e, 0x48, 0x69, 0x52, 0x65, 0x71, 0x73, 0x1a, 0x0f, 0x2e, 0x6e, 0x65, 0x77, 0x67, 0x72, 0x70, 0x63, 0x2e, 0x48, 0x69, 0x52, 0x73, 0x70, 0x73, 0x22, 0x00, 0x12, 0x2c, 0x0a, 0x06, 0x53, 0x61, 0x79, 0x6e, 0x61, 0x73, 0x12, 0x0f, 0x2e, 0x6e, 0x65, 0x77, 0x67, 0x72, 0x70, 0x63, 0x2e, 0x4e, 0x61, 0x52, 0x65, 0x71, 0x73, 0x1a, 0x0f, 0x2e, 0x6e, 0x65, 0x77, 0x67, 0x72, 0x70, 0x63, 0x2e, 0x4e, 0x61, 0x52, 0x73, 0x70, 0x73, 0x22, 0x00, 0x42, 0x04, 0x5a, 0x02, 0x2e, 0x2f, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33, } var ( file_newgrpc_proto_rawDescOnce sync.Once file_newgrpc_proto_rawDescData = file_newgrpc_proto_rawDesc ) func file_newgrpc_proto_rawDescGZIP() []byte { file_newgrpc_proto_rawDescOnce.Do(func() { file_newgrpc_proto_rawDescData = protoimpl.X.CompressGZIP(file_newgrpc_proto_rawDescData) }) return file_newgrpc_proto_rawDescData } var file_newgrpc_proto_msgTypes = make([]protoimpl.MessageInfo, 4) var file_newgrpc_proto_goTypes = []interface{}{ (*HiReqs)(nil), // 0: newgrpc.HiReqs \t(*HiRsps)(nil), // 1: newgrpc.HiRsps \t(*NaReqs)(nil), // 2: newgrpc.NaReqs \t(*NaRsps)(nil), // 3: newgrpc.NaRsps } var file_newgrpc_proto_depIdxs = []int32{ 0, // 0: newgrpc.HisServer.Sayhis:input_type -\u0026gt; newgrpc.HiReqs \t2, // 1: newgrpc.HisServer.Saynas:input_type -\u0026gt; newgrpc.NaReqs \t1, // 2: newgrpc.HisServer.Sayhis:output_type -\u0026gt; newgrpc.HiRsps \t3, // 3: newgrpc.HisServer.Saynas:output_type -\u0026gt; newgrpc.NaRsps \t2, // [2:4] is the sub-list for method output_type \t0, // [0:2] is the sub-list for method input_type \t0, // [0:0] is the sub-list for extension type_name \t0, // [0:0] is the sub-list for extension extendee \t0, // [0:0] is the sub-list for field type_name } func init() { file_newgrpc_proto_init() } func file_newgrpc_proto_init() { if File_newgrpc_proto != nil { return } if !protoimpl.UnsafeEnabled { file_newgrpc_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} { switch v := v.(*HiReqs); i { case 0: return \u0026amp;v.state case 1: return \u0026amp;v.sizeCache case 2: return \u0026amp;v.unknownFields default: return nil } } file_newgrpc_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} { switch v := v.(*HiRsps); i { case 0: return \u0026amp;v.state case 1: return \u0026amp;v.sizeCache case 2: return \u0026amp;v.unknownFields default: return nil } } file_newgrpc_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} { switch v := v.(*NaReqs); i { case 0: return \u0026amp;v.state case 1: return \u0026amp;v.sizeCache case 2: return \u0026amp;v.unknownFields default: return nil } } file_newgrpc_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} { switch v := v.(*NaRsps); i { case 0: return \u0026amp;v.state case 1: return \u0026amp;v.sizeCache case 2: return \u0026amp;v.unknownFields default: return nil } } } type x struct{} out := protoimpl.TypeBuilder{ File: protoimpl.DescBuilder{ GoPackagePath: reflect.TypeOf(x{}).PkgPath(), RawDescriptor: file_newgrpc_proto_rawDesc, NumEnums: 0, NumMessages: 4, NumExtensions: 0, NumServices: 1, }, GoTypes: file_newgrpc_proto_goTypes, DependencyIndexes: file_newgrpc_proto_depIdxs, MessageInfos: file_newgrpc_proto_msgTypes, }.Build() File_newgrpc_proto = out.File file_newgrpc_proto_rawDesc = nil file_newgrpc_proto_goTypes = nil file_newgrpc_proto_depIdxs = nil } // Reference imports to suppress errors if they are not otherwise used. var _ context.Context var _ grpc.ClientConnInterface // This is a compile-time assertion to ensure that this generated file // is compatible with the grpc package it is being compiled against. const _ = grpc.SupportPackageIsVersion6 // HisServerClient is the client API for HisServer service. // // For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream. type HisServerClient interface { //一个打招呼的函数 \tSayhis(ctx context.Context, in *HiReqs, opts ...grpc.CallOption) (*HiRsps, error) //一个说名字的函数 \tSaynas(ctx context.Context, in *NaReqs, opts ...grpc.CallOption) (*NaRsps, error) } type hisServerClient struct { cc grpc.ClientConnInterface } func NewHisServerClient(cc grpc.ClientConnInterface) HisServerClient { return \u0026amp;hisServerClient{cc} } func (c *hisServerClient) Sayhis(ctx context.Context, in *HiReqs, opts ...grpc.CallOption) (*HiRsps, error) { out := new(HiRsps) err := c.cc.Invoke(ctx, \u0026#34;/newgrpc.HisServer/Sayhis\u0026#34;, in, out, opts...) if err != nil { return nil, err } return out, nil } func (c *hisServerClient) Saynas(ctx context.Context, in *NaReqs, opts ...grpc.CallOption) (*NaRsps, error) { out := new(NaRsps) err := c.cc.Invoke(ctx, \u0026#34;/newgrpc.HisServer/Saynas\u0026#34;, in, out, opts...) if err != nil { return nil, err } return out, nil } // HisServerServer is the server API for HisServer service. type HisServerServer interface { //一个打招呼的函数 \tSayhis(context.Context, *HiReqs) (*HiRsps, error) //一个说名字的函数 \tSaynas(context.Context, *NaReqs) (*NaRsps, error) } // UnimplementedHisServerServer can be embedded to have forward compatible implementations. type UnimplementedHisServerServer struct { } func (*UnimplementedHisServerServer) Sayhis(context.Context, *HiReqs) (*HiRsps, error) { return nil, status.Errorf(codes.Unimplemented, \u0026#34;method Sayhis not implemented\u0026#34;) } func (*UnimplementedHisServerServer) Saynas(context.Context, *NaReqs) (*NaRsps, error) { return nil, status.Errorf(codes.Unimplemented, \u0026#34;method Saynas not implemented\u0026#34;) } func RegisterHisServerServer(s *grpc.Server, srv HisServerServer) { s.RegisterService(\u0026amp;_HisServer_serviceDesc, srv) } func _HisServer_Sayhis_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(HiReqs) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(HisServerServer).Sayhis(ctx, in) } info := \u0026amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: \u0026#34;/newgrpc.HisServer/Sayhis\u0026#34;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(HisServerServer).Sayhis(ctx, req.(*HiReqs)) } return interceptor(ctx, in, info, handler) } func _HisServer_Saynas_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(NaReqs) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(HisServerServer).Saynas(ctx, in) } info := \u0026amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: \u0026#34;/newgrpc.HisServer/Saynas\u0026#34;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(HisServerServer).Saynas(ctx, req.(*NaReqs)) } return interceptor(ctx, in, info, handler) } var _HisServer_serviceDesc = grpc.ServiceDesc{ ServiceName: \u0026#34;newgrpc.HisServer\u0026#34;, HandlerType: (*HisServerServer)(nil), Methods: []grpc.MethodDesc{ { MethodName: \u0026#34;Sayhis\u0026#34;, Handler: _HisServer_Sayhis_Handler, }, { MethodName: \u0026#34;Saynas\u0026#34;, Handler: _HisServer_Saynas_Handler, }, }, Streams: []grpc.StreamDesc{}, Metadata: \u0026#34;newgrpc.proto\u0026#34;, }   2. 步骤二：在上级目录新建go.mod项目(方面go get XXX) 生成对应的go编译文件中部分依赖包没有需要下载：\n1  go get -v -u google.golang.org/grpc   3. 步骤三：新建test目录测试服务端+客户端 1 2 3 4  tree . ├── client.go └── server.go   服务端：server.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; pd \u0026#34;mymod/newgrpc\u0026#34; \u0026#34;net\u0026#34; ) type server struct { } func (this *server) Sayhis(ctx context.Context, in *pd.HiReqs) (out *pd.HiRsps, err error) { //return nil, status.Errorf(codes.Unimplemented, \u0026#34;method Sayhis not implemented\u0026#34;) \treturn \u0026amp;pd.HiRsps{Msg: \u0026#34;hello \u0026#34; + in.Name}, nil } func (this *server) Saynas(ctx context.Context, in *pd.NaReqs) (out *pd.NaRsps, err error) { //return nil, status.Errorf(codes.Unimplemented, \u0026#34;method Saynas not implemented\u0026#34;) \treturn \u0026amp;pd.NaRsps{Msg: \u0026#34;早上好,\u0026#34; + in.Name}, nil } func main() { ln, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:10086\u0026#34;) if err != nil { fmt.Println(\u0026#34;网络错误\u0026#34;, err) } //创建grpc的服务 \tsrv := grpc.NewServer() //注册服务 \tpd.RegisterHisServerServer(srv, \u0026amp;server{}) //等待网络连接 \terr = srv.Serve(ln) if err != nil { fmt.Println(\u0026#34;网络错误\u0026#34;, err) } }   客户端：client.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; pd \u0026#34;mymod/newgrpc\u0026#34; ) func main() { conn, err := grpc.Dial(\u0026#34;127.0.0.1:10086\u0026#34;, grpc.WithInsecure()) if err != nil { fmt.Println(\u0026#34;网络异常\u0026#34;, err) } //延时关闭网络 \tdefer conn.Close() //获得grpc句柄 \tc := pd.NewHisServerClient(conn) //通过句柄调用函数 \tres, err := c.Sayhis(context.Background(), \u0026amp;pd.HiReqs{Name: \u0026#34;大王\u0026#34;}) if err != nil { fmt.Println(\u0026#34;Sayhis服务调用失败\u0026#34;, err) } fmt.Println(\u0026#34;调用 Sayhis 的返回：\u0026#34;, res.Msg) rel, err := c.Saynas(context.Background(), \u0026amp;pd.NaReqs{Name: \u0026#34;周杰伦\u0026#34;}) if err != nil { fmt.Println(\u0026#34;Saynas 服务调用失败\u0026#34;, err) } fmt.Println(\u0026#34;调用 Saynas 的返回：\u0026#34;, rel.Msg) }   4. 步骤四：客户端调用服务端 进入test目录分别 开启 服务端、客户端\n1  go run server.go   1 2 3  go run client.go 调用 Sayhis 的返回： hello 大王 调用 Saynas 的返回： 早上好,周杰伦   ","description":"微服务的精髓：分而治之，合而用之","id":39,"section":"stack","tags":["golang",""],"title":"微服务","uri":"http://wangjinbao.netlify.app/en/stack/golang/microservices/"},{"content":"Go Modules 简介 Go Modules 是 Go 官方推出的一个 Go 包管理方案\n特性  可以使包的管理更加简单 支持版本管理 允许同一个模块多个版本共存 可以校验依赖包的哈希值，确保包的一致性，增加安全性 内置在几乎所有的 go 命令中，包括go get、go build、go install、go run、go test、go list等命令 具有 Global Caching 特性，不同项目的相同模块版本，只会在服务器上缓存一份   PS:在 Go1.14 版本以及之后的版本，Go 官方建议在生产环境中使用 Go Modules。\n Go1.5 版本前：GOPATH 在 Go1.5 版本之前，没有版本控制，所有的依赖包都放在 GOPATH 下。采用这种方式，无法实现包的多版本管理，并且包的位置只能局限在 GOPATH 目录下。如果 A 项目和 B 项目用到了同一个 Go 包的不同版本，这时候只能给每个项目设置一个 GOPATH，将对应版本的包放在各自的 GOPATH 目录下，切换项目目录时也需要切换 GOPATH，这些都增加了开发和实现的复杂度\nGo1.5 版本：Vendoring Go1.5 推出了 vendor 机制，并在 Go1.6 中默认启用。在这个机制中，每个项目的根目录都可以有一个 vendor 目录，里面存放了该项目的 Go 依赖包。\n在编译 Go 源码时，Go 优先从项目根目录的 vendor 目录查找依赖；如果没有找到，再去 GOPATH 下的 vendor 目录下找；如果还没有找到，就去 GOPATH 下找。这种方式解决了多 GOPATH 的问题，但是随着项目依赖的增多，vendor 目录会越来越大，造成整个项目仓库越来越大\n在 vendor 机制下，一个中型项目的 vendor 目录有几百 M 的大小一点也不奇怪。\nGo1.9 版本：Dep Golang 依赖管理工具混乱的局面最终由官方来终结了：Golang 官方接纳了由社区组织合作开发的 Dep，作为 official experiment。在相当长的一段时间里，Dep 作为标准，成为了事实上的官方包管理工具。\nGo1.11 版本之后：Go Modules Go1.11 版本推出了 Go Modules 机制，Go Modules 基于 vgo 演变而来，是 Golang 官方的包管理工具。在 Go1.13 版本，Go 语言将 Go Modules 设置为默认的 Go 管理工具；在 Go1.14 版本，Go 语言官方正式推荐在生产环境使用 Go Modules，并且鼓励所有用户从其他的依赖管理工具迁移过来。\n包（package）和模块（module） Go 程序被组织到 Go 包中，Go 包是同一目录中一起编译的 Go 源文件的集合。在一个源文件中定义的函数、类型、变量和常量，对于同一包中的所有其他源文件可见。模块是存储在文件树中的 Go 包的集合，并且文件树根目录有 go.mod 文件。go.mod 文件定义了模块的名称及其依赖包，通过导入路径和版本描述一个依赖。\nGo 中有 4 种类型的包：  Go 标准包：在 Go 源码目录下，随 Go 一起发布的包 第三方包：第三方提供的包，比如来自于 http://github.com 的包 匿名包：只导入而不使用的包。通常情况下，我们只是想使用导入包产生的副作用，即引用包级别的变量、常量、结构体、接口等，以及执行导入包的init()函数 内部包：项目内部的包，位于项目目录下  Go Modules 命令 Go Modules 的管理命令为 go mod，go mod 有很多子命令，你可以通过go help mod来获取所有的命令。\n下面我来具体介绍下这些命令:\n download：下载 go.mod 文件中记录的所有依赖包。 edit：编辑 go.mod 文件。 graph：查看现有的依赖结构。 init：把当前目录初始化为一个新模块。 tidy：添加丢失的模块，并移除无用的模块。默认情况下，Go 不会移除 go.mod 文件中的无用依赖。当依赖包不再使用了，可以使用go mod tidy命令来清除它 vendor：将所有依赖包存到当前目录下的 vendor 目录下。 verify：检查当前模块的依赖是否已经存储在本地下载的源代码缓存中，以及检查下载后是否有修改。 why：查看为什么需要依赖某模块。  Go Modules 开关 通过环境变量 GO111MODULE 来打开或者关闭\nGO111MODULE 有 3 个值：\n auto：在 Go1.14 版本中是默认值，在$GOPATH/src下，且没有包含 go.mod 时则关闭 Go Modules，其他情况下都开启 Go Modules。 on：启用 Go Modules，Go1.14 版本推荐打开，未来版本会设为默认值。 off：关闭 Go Modules，不推荐。  如果要打开 Go Modules，建议直接设置export GO111MODULE=on。\ngo.mod 和 go.sum 介绍 go.mod 文件是 Go Modules 的核心文件。\n下面是一个 go.mod 文件示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  module github.com/marmotedu/iam go 1.17 require ( github.com/AlekSi/pointer v1.1.0 github.com/appleboy/gin-jwt/v2 v2.6.3 github.com/asaskevich/govalidator v0.0.0-20200428143746-21a406dcc535 github.com/gin-gonic/gin v1.6.3 github.com/golangci/golangci-lint v1.30.0 // indirect  github.com/google/uuid v1.0.0 github.com/blang/semver v3.5.0+incompatible golang.org/x/text v0.3.2 ) replace ( github.com/gin-gonic/gin =\u0026gt; /home/colin/gin golang.org/x/text v0.3.2 =\u0026gt; github.com/golang/text v0.3.2 ) exclude ( github.com/google/uuid v1.1.0 )   go.mod 语句 o.mod 文件中包含了 4 个语句，分别是 module、require、replace 和 exclude。\n module：用来定义当前项目的模块路径。 go：用来设置预期的 Go 版本，目前只是起标识作用。 require：用来设置一个 特定 的模块版本，格式为\u0026lt;导入包路径\u0026gt; \u0026lt;版本\u0026gt; [// indirect]。 exclude：用来从使用中排除一个特定的模块版本，如果我们知道模块的某个版本有严重的问题，就可以使用 exclude 将该版本排除掉。 replace：用来将一个模块版本替换为另外一个模块版本。格式为 $module =\u0026gt; $newmodule ，$newmodule可以是本地磁盘的\u0026rsquo;相对路径'，例如 http://github.com/gin-gonic/gin =\u0026gt; ./gin。也可以是本地磁盘的\u0026rsquo;绝对路径'，例如 http://github.com/gin-gonic/gin =\u0026gt; /home/lk/gin。还可以是\u0026rsquo;网络路径'，例如 http://golang.org/x/text v0.3.2 =\u0026gt; http://github.com/golang/text v0.3.2。   PS:replace 之后 要 go mod tidy 重新整理依赖包\n go.mod 版本号 go.mod 文件中有很多版本号格式\n 如果模块具有符合语义化版本格式的 tag，会直接展示 tag 的值 除了 v0 和 v1 外，主版本号必须显试地出现在模块路径的尾部 对于没有 tag 的模块，Go 命令会选择 master 分支上最新的 commit  go.mod 文件修改方法 要修改 go.mod 文件，我们可以采用下面这几种方法：\n 手动编辑 go.mod 文件，编辑之后可以执行 go mod edit -fmt 格式化 go.mod 文件 执行 go mod 子命令修改,如下：  1 2 3 4 5 6 7  go mod edit -fmt # go.mod 格式化 go mod edit -require=golang.org/x/text@v0.3.3 # 添加一个依赖 go mod edit -droprequire=golang.org/x/text # require的反向操作，移除一个依赖 go mod edit -replace=github.com/gin-gonic/gin=/home/colin/gin # 替换模块版本 go mod edit -dropreplace=github.com/gin-gonic/gin # replace的反向操作 go mod edit -exclude=golang.org/x/text@v0.3.1 # 排除一个特定的模块版本 go mod edit -dropexclude=golang.org/x/text@v0.3.1 # exclude的反向操作   go.sum介绍 接下来从go.sum 文件内容、go.sum 文件生成、校验三个方面来介绍 go.sum。\ngo.sum 文件内容 go.sum 文件中，每行记录由模块名、版本、哈希算法和哈希值组成\n正常情况下，每个依赖包会包含两条记录，分别是依赖包所有文件的哈希值和该依赖包 go.mod 的哈希值，例如：\n1 2  github.com/appleboy/gin-jwt/v2 v2.6.4 h1:4YlMh3AjCFnuIRiL27b7T0RRUI= github.com/appleboy/gin-jwt/v2 v2.6.4/go.mod h1:CZpq1cRw+kqi0+yD2CwVs=   go.sum 文件生成 在 Go Modules 开启时，如果我们的项目需要引入一个新的包，通常会执行go get命令，例如：\n1  $ go get rsc.io/quote   当执行go get http://rsc.io/quote命令后，go get命令会先将依赖包下载到$GOPATH/pkg/mod/cache/download，下载的依赖包文件名格式为$version.zip，例如v1.5.2.zip。\n下载完成之后，go get会对该 zip 包做哈希运算，并将结果存在$version.ziphash文件中，例如v1.5.2.ziphash。如果在项目根目录下执行go get命令，则go get会同时更新 go.mod 和 go.sum 文件。\n校验 在我们执行构建时，go 命令会从本地缓存中查找所有的依赖包，并计算这些依赖包的哈希值，然后与 go.sum 中记录的哈希值进行对比。如果哈希值不一致，则校验失败，停止构建。\n校验失败可能是因为本地指定版本的依赖包被修改过，也可能是 go.sum 中记录的哈希值是错误的。但是 Go 命令倾向于相信依赖包被修改过，因为当我们在 go get 依赖包时，包的哈希值会经过校验和数据库（checksum database）进行校验，校验通过才会被加入到 go.sum 文件中。也就是说，go.sum 文件中记录的哈希值是可信的。\n","description":"依赖包管理是一个非常重要的内容，依赖包处理不好，就会导致编译失败","id":40,"section":"stack","tags":["golang",""],"title":"GO Modules依赖管理","uri":"http://wangjinbao.netlify.app/en/stack/golang/mod/"},{"content":"一、namespace namespace的作用就是用来隔离资源，将同一集群中的资源划分为相互隔离的组。同一名称空间内的资源名称要唯一，但不同名称空间时没有这个要求。有些k8s资源对象与名称空间没有关系，例如 StorageClass、Node、PersistentVolume 等。\n方式一：命令行管理 1.1创建 1  kubectl create ns test   1.2获取 1  kubectl get ns   1.3删除 该名称空间下所有的资源都将被一起删除\n1  kubectl delete ns test   方式二：yaml文件管理 2.1创建 创建一个yaml文件，内容如下：\nkind表示要创建的资源类型，此处为Namespace\n1 2 3 4  apiVersion:v1kind:Namespacemetadata:name:dev  使用 apply 命令创建name为dev的名称空间\n1  kubectl apply -f dev-ns.yaml   2.2获取 查看创建结果\n1  kubectl get ns   参数：-n\n1 2 3 4 5 6 7 8 9 10 11 12  kubectl get pod -n kube-system //结果： NAME READY STATUS RESTARTS AGE coredns-5d78c9869d-d6qvr 1/1 Running 4 (20m ago) 2d16h coredns-5d78c9869d-nxd7x 1/1 Running 4 (20m ago) 2d16h etcd-k8s-desktop 1/1 Running 4 (20m ago) 2d16h kube-apiserver-k8s-desktop 1/1 Running 4 (20m ago) 2d16h kube-controller-manager-k8s-desktop 1/1 Running 4 (20m ago) 2d16h kube-proxy-qpqsk 1/1 Running 4 (20m ago) 2d16h kube-scheduler-k8s-desktop 1/1 Running 4 (20m ago) 2d16h storage-provisioner 1/1 Running 8 (20m ago) 2d16h vpnkit-controller 1/1 Running 4 (20m ago) 2d16h    NAME：第一列是 pod 的名字，k8s 可以为 pod 随机分配一个五位数的后缀。 READY：第二列是 pod 中已经就绪的 docker 容器的数量，pod 封装了一个或多个 docker 容器,1/1的含义为就绪1个容器/共计1个容器。 STATUS：第三列是 pod 的当前状态，下面是一些常见的状态：     状态名 含义     Running 运行中   Error 异常，无法提供服务   Pending 准备中，暂时无法提供服务   Terminaling 结束中，即将被移除   Unknown 未知状态，多发生于节点宕机   PullImageBackOff 镜像拉取失败     RESTART：k8s 可以自动重启 pod，这一行就是标记了 pod 一共重启了多少次。 AGE：pod 一共存在了多长时间。  2.3删除 1  kubectl delete -f dev-ns.yaml   二、kubectl get列出k8s所有资源 kubectl get 可以列出 k8s 中所有资源\nkubectl get pod \u0026ndash; 查看副本控制器pod\nkubectl get svc \u0026ndash; 查看服务\nkubectl get rs \u0026ndash; 查看副本控制器\nkubectl get deploy \u0026ndash; 查看部署\n查看更多的信息，就可以指定-o wide参数\n如：kubectl get pod -n kube-system -o wide 加上这个参数之后就可以看到资源的所在ip和所在节点node了\n*** ：记得加上 -n\n-n 可以说是kubectl get命令使用最频繁的参数了，在正式使用中，我们永远不会把资源发布在默认命名空间。\n三、kubectl describe 查看详情 kubectl describe命令可以用来查看某一资源的具体信息，他同样可以查看所有资源的详情，不过最常用的还是查看 pod 的详情。\n他也同样可以使用 -n 参数指定资源所在的命名空间。\n如： kubectl describe pod coredns-5d78c9869d-d6qvr -n kube-system\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  $ kubectl describe pod coredns-5d78c9869d-d6qvr -n kube-system Name: coredns-5d78c9869d-d6qvr Namespace: kube-system Priority: 2000000000 Priority Class Name: system-cluster-critical Service Account: coredns Node: k8s-desktop/192.168.65.4 Start Time: Mon, 16 Oct 2023 17:42:55 +0800 Labels: k8s-app=kube-dns pod-template-hash=5d78c9869d Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.1.1.82 IPs: IP: 10.1.1.82 Controlled By: ReplicaSet/coredns-5d78c9869d Containers: coredns: Container ID: k8s://c3778f5414c9fae0e988ad5e8826de296d9be51712f9131e339150e8e9594de2 Image: registry.k8s.io/coredns/coredns:v1.10.1 Image ID: k8s://sha256:97e04611ad43405a2e5863ae17c6f1bc9181bdefdaa78627c432ef754a4eb108 Ports: 53/UDP, 53/TCP, 9153/TCP Host Ports: 0/UDP, 0/TCP, 0/TCP Args: -conf /etc/coredns/Corefile State: Running Started: Thu, 19 Oct 2023 09:51:06 +0800 Last State: Terminated Reason: Completed Exit Code: 0 Started: Wed, 18 Oct 2023 10:17:27 +0800 Finished: Thu, 19 Oct 2023 09:50:50 +0800 Ready: True Restart Count: 4 Limits: memory: 170Mi Requests: cpu: 100m memory: 70Mi Liveness: http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5 Readiness: http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3 Environment: \u0026lt;none\u0026gt; Mounts: /etc/coredns from config-volume (ro) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tqbb6 (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: config-volume: Type: ConfigMap (a volume populated by a ConfigMap) Name: coredns Optional: false kube-api-access-tqbb6: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: Burstable Node-Selectors: kubernetes.io/os=linux Tolerations: CriticalAddonsOnly op=Exists node-role.kubernetes.io/control-plane:NoSchedule node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SandboxChanged 53m kubelet Pod sandbox changed, it will be killed and re-created. Normal Pulled 53m kubelet Container image \u0026#34;registry.k8s.io/coredns/coredns:v1.10.1\u0026#34; already present on machine Normal Created 53m kubelet Created container coredns Normal Started 53m kubelet Started container coredns Warning Unhealthy 53m (x4 over 53m) kubelet Readiness probe failed: HTTP probe failed with statuscode: 503    实例名称：Name: coredns-5d78c9869d-d6qvr 所处命名空间：Namespace: kube-system 所在节点：Node: docker-desktop/192.168.65.4 启动时间：Start Time: Mon, 16 Oct 2023 17:42:55 +0800 标签：Labels: k8s-app=kube-dns pod-template-hash=5d78c9869d 注解：Annotations:  当前状态：Status: Running 所在节点 IP：IP: 10.1.1.82 由那种资源生成/控制：Controlled By: ReplicaSet/coredns-5d78c9869d\n其中几个比较常用的，例如 Node、labels 和 Controlled By。\na. 通过 Node 你可以快速定位到 pod 所处的机器，从而检查该机器是否出现问题或宕机等。\nb. 通过 labels 你可以检索到该 pod 的大致用途及定位。\nc. 通过 Controlled By ，你可以知道该 pod 是由那种 k8s 资源创建的，然后就可以使用kubectl get \u0026lt;资源名\u0026gt;来继续查找问题。\n例如上文 ReplicaSet/coredns-5d78c9869d，就可以通过 kubectl get ReplicaSet -n kube-system 来获取上一节资源的信息。  Events 故障原因 kubectl describe \u0026lt;资源名\u0026gt; \u0026lt;实例名\u0026gt; 可以查看一个资源的详细信息\n最常用的还是比如 kubectl describe pod \u0026lt;pod名\u0026gt; -n \u0026lt;命名空间\u0026gt; 来获取一个 pod 的基本信息。如果出现问题的话，可以在获取到的信息的末尾看到 Event 段落，其中记录着导致 pod 故障的原因。\n三、kubectl logs 查看日志 如果你想查看一个 pod 的具体日志，就可以通过 kubectl logs \u0026lt;pod名\u0026gt; 来查看。\n注意，这个只能查看 pod 的日志。通过添加 -f 参数可以 持续 查看日志。\n例如：查看 kube-system 命名空间中某个 coredns pod 的日志，注意修改 pod 名称：\nkubectl logs -f -n kube-system coredns-5d78c9869d-d6qvr\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  $ kubectl logs -f -n kube-system coredns-5d78c9869d-d6qvr [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/ready: Still waiting on: \u0026#34;kubernetes\u0026#34; [INFO] plugin/ready: Still waiting on: \u0026#34;kubernetes\u0026#34; [INFO] plugin/ready: Still waiting on: \u0026#34;kubernetes\u0026#34; [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/ready: Still waiting on: \u0026#34;kubernetes\u0026#34; [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server [WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API .:53 [INFO] plugin/reload: Running configuration SHA512 = 591cf328cccc12bc490481273e738df59329c62c0b729d94e8b61db9961c2fa5f046dd37f1cf888b953814040d180f52594972691cd6ff41be96639138a43908 CoreDNS-1.10.1 linux/arm64, go1.20, 055b2c3 [WARNING] plugin/kubernetes: Kubernetes API connection failure: Get \u0026#34;https://10.96.0.1:443/version\u0026#34;: net/http: TLS handshake timeout   ","description":"kubernetes，简称K8s，是用8代替名字中间的8个字符“ubernete”而成的缩写。目标是让部署容器化的应用简单并且高效","id":41,"section":"stack","tags":["linux",""],"title":"k8s","uri":"http://wangjinbao.netlify.app/en/stack/linux/k8s/"},{"content":"无服务器\n不够灵活,难以预料的波动\n无需CDN\n历史：\nserverless=FaaS(Function as a Service)+BaaS(Backend as a Service)\n浪费\n好处：\n1、使用的资源付费\n2、服务高可用，弹性伸缩\n3、无运维费用\n缺点：\n冷启动慢\nsocket概念 在计算机网络中，Socket是一种抽象概念，它可以看作是一种端点，用于标识网络中的一个通信连接。一个Socket由 IP地址 和 端口号 组成，它可以唯一地标识网络中的一个进程。\nSocket编程是一种在网络上进行通信的编程方式，通过使用Socket接口，开发人员可以编写程序来创建、连接、发送和接收数据，从而实现网络通信。Socket编程可以用于实现各种网络应用，如Web服务器、邮件服务器、聊天程序等。\n在Socket编程中，通常有两种类型的Socket：\n  流式Socket（Stream Socket）：也称为TCP Socket，它提供了可靠的、面向连接的通信。流式Socket使用TCP协议，在通信之前需要先建立连接，然后进行数据的传输，确保数据的可靠性和顺序。流式Socket适用于需要可靠传输的应用，如文件传输、HTTP通信等。\n  数据报式Socket（Datagram Socket）：也称为UDP Socket，它提供了无连接的通信。数据报式Socket使用UDP协议，每个数据包都是独立的，不需要事先建立连接，因此传输速度较快，但不保证数据的可靠性和顺序。数据报式Socket适用于实时性要求较高的应用，如视频流传输、实时游戏等。\n  通过Socket编程，可以实现不同计算机之间的通信和数据交换，使得网络应用能够实现数据的传输和交互。\nTCP编程 TCP/IP TCP/IP即传输控制协议/网络协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议，因为是面向连接的协议，数据像水流一样传输，会存在 黏包 的问题\n黏包 黏包（Packet Sticking）是指发送方将多个小数据包粘合在一起发送，或接收方将接收到的数据包粘合在一起，导致数据的边界不清晰，难以正确解析和处理。\n原因：  发送方的缓冲区未满：\n发送方的缓冲区未满时，可能会将多个小数据包一起发送，导致接收方接收到的数据包粘合在一起。 网络传输过程中的分段和重组：\nTCP协议在传输过程中会对数据进行分段和重组，这可能导致接收方接收到的数据包与发送方发送的数据包大小不一致。 接收方的缓冲区未及时读取：\n接收方的缓冲区未及时读取已接收的数据，导致后续的数据包与之前的数据包粘合在一起。  解决方案：  消息长度固定：发送方在每个数据包中添加固定长度的消息头，用于标识消息的长度。接收方根据消息头中的长度信息，将接收到的数据包正确地拆分成单个消息进行处理。 消息分隔符：发送方在每个数据包的末尾添加特定的分隔符（如换行符或特殊字符），接收方根据分隔符将接收到的数据包正确地拆分成单个消息进行处理。 消息头中包含消息长度信息：发送方在每个数据包的消息头中添加消息的长度信息，接收方根据消息头中的长度信息，将接收到的数据包正确地拆分成单个消息进行处理。 使用定长消息：发送方将所有的消息都固定为相同的长度，不足部分使用特定字符进行填充。接收方根据固定长度将接收到的数据包正确地拆分成单个消息进行处理。 应用层协议处理：在应用层定义自己的协议，规定消息的格式和边界，确保发送和接收的数据能够正确解析和处理。  TCP服务端 一个TCP服务端可以同时连接很多个客户端，如世界各地的用户用自己的电脑访问淘宝。因为go语言中创建多个goroutine实现并发非常方便和高效，所以我们可以每建立一次连接就创建一个goroutine去处理。\nTCP服务端程序的处理流程：\n 监听端口 接收客户端请求建立连接 创建goroutine处理连接  使用go语言中的net包实现TCP服务端代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func process(conn net.Conn) { defer conn.Close() //关闭连接 \tfor { reader := bufio.NewReader(conn) var buf [128]byte n, err := reader.Read(buf[:]) //读取数据 \tif err != nil { fmt.Println(\u0026#34;read from client failed,err:\u0026#34;, err) break } recvStr := string(buf[:n]) fmt.Println(\u0026#34;收到client端发来的数据：\u0026#34;, recvStr) conn.Write([]byte(recvStr)) //发送数据 \t} } func main() { listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:20000\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen failed,err:\u0026#34;, err) return } for { conn, err := listen.Accept() //建立连接 \tif err != nil { fmt.Println(\u0026#34;accept failed,err:\u0026#34;, err) continue } go process(conn) //启动一个goroutine处理连接 \t} }   TCP客户端 一个TCP客户端进行TCP通信的流程：\n 建立与服务端的连接 进行数据收发 关闭连接  使用go语言的net包实现TCP客户端代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) func main() { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:20000\u0026#34;) if err != nil { fmt.Println(\u0026#34;err:\u0026#34;, err) return } defer conn.Close() //关闭连接 \tinputReader := bufio.NewReader(os.Stdin) for { input, _ := inputReader.ReadString(\u0026#39;\\n\u0026#39;) //读取用户输入 \tinputInfo := strings.Trim(input, \u0026#34;\\r\\n\u0026#34;) if strings.ToUpper(inputInfo) == \u0026#34;Q\u0026#34; { return } _, err = conn.Write([]byte(inputInfo)) //发送数据 \tif err != nil { return } buf := [512]byte{} n, err := conn.Read(buf[:]) if err != nil { if err == io.EOF { break } fmt.Println(\u0026#34;recv failed, err:\u0026#34;, err) return } fmt.Println(\u0026#34;接收到服务器发来的数据：\u0026#34; + string(buf[:n])) } }   UDP编程 UDP协议 UDP协议（用户数据报协议），是OSI模型中的一种无连接的传输层协议，不需要建立连接就能直接进行数据发送和接收，属于不可靠的、没有时序的通信，但是UDP协议的实时性比较好，通常用于视频直播相关领域。\nUDP服务端 使用go语言的net包实现的UDP服务端代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.ListenUDP(\u0026#34;udp\u0026#34;, \u0026amp;net.UDPAddr{ IP: net.IPv4(0, 0, 0, 0), Port: 30000, }) if err != nil { fmt.Println(\u0026#34;listen failed,err:\u0026#34;, err) return } defer listen.Close() for { var data [1024]byte n, addr, err := listen.ReadFromUDP(data[:]) //接收数据 \tif err != nil { fmt.Println(\u0026#34;read udp failed,err:\u0026#34;, err) continue } fmt.Printf(\u0026#34;data:%v addr:%v count:%v\\n\u0026#34;, string(data[:n]), addr, n) _, err = listen.WriteToUDP(data[:n], addr) if err != nil { fmt.Println(\u0026#34;write to udp failed,err:\u0026#34;, err) continue } } }   UDPp客户端 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { socket, err := net.DialUDP(\u0026#34;udp\u0026#34;, nil, \u0026amp;net.UDPAddr{ IP: net.IPv4(0, 0, 0, 0), Port: 30000, }) if err != nil { fmt.Println(\u0026#34;连接服务端失败，err:\u0026#34;, err) return } defer socket.Close() sendData := []byte(\u0026#34;Hello Server\u0026#34;) _, err = socket.Write(sendData) //发送数据 \tif err != nil { fmt.Println(\u0026#34;发送数据失败，err:\u0026#34;, err) } data := make([]byte, 4096) n, remoteAddr, err := socket.ReadFromUDP(data) //接收数据 \tif err != nil { fmt.Println(\u0026#34;接收数据失败，err:\u0026#34;, err) return } fmt.Printf(\u0026#34;recv:%v addr:%v count:%v\\n\u0026#34;, string(data[:n]), remoteAddr, n) }   Http编程 http服务端 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { //单独写回调函数 \thttp.HandleFunc(\u0026#34;/go\u0026#34;, myHandler) //addr:监听地址 \t//handler：回调函数 \thttp.ListenAndServe(\u0026#34;127.0.0.1:8000\u0026#34;, nil) } func myHandler(w http.ResponseWriter, r *http.Request) { fmt.Println(r.RemoteAddr, \u0026#34;连接成功\u0026#34;) fmt.Println(\u0026#34;method:\u0026#34;, r.Method) fmt.Println(\u0026#34;url:\u0026#34;, r.URL.Path) fmt.Println(\u0026#34;header:\u0026#34;, r.Header) fmt.Println(\u0026#34;body:\u0026#34;, r.Body) w.Write([]byte(\u0026#34;你好: jarvenwang\u0026#34;)) }   http客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { resp, _ := http.Get(\u0026#34;http://127.0.0.1:8000/go\u0026#34;) defer resp.Body.Close() fmt.Println(resp.Status) fmt.Println(resp.Header) buf := make([]byte, 1024) for { //接收服务端信息 \tn, err := resp.Body.Read(buf) if err != nil \u0026amp;\u0026amp; err != io.EOF { fmt.Println(err) return } else { fmt.Println(\u0026#34;读取完毕\u0026#34;) res := string(buf[:n]) fmt.Println(res) break } } }   WebSocket编程 WebSocket概念：  WebSocket是一种在单个TCP连接上进行全双工通信的协议 WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据 在WebSocket API中，浏览器和服务器只要完成一次握手，两者之间就是可以创建持久性的连接，并进行双向数据传输 安装第三方包：go get -u -v github.com/gorilla/websocket  ","description":"serverless狭义上是指Serverless computing 架构 = FaaS 架构 = Trigger(事件驱动)+FaaS(函数即服务)+BaaS(后端即服务，持久化或第三方服务)=FaaS + BaaS，广义上是指服务端免运维，也就是具有 Serverless 特性的云服务","id":42,"section":"stack","tags":["linux",""],"title":"Serverless","uri":"http://wangjinbao.netlify.app/en/stack/linux/serverless/"},{"content":"进程 进程(Process)就是程序在操作系统中的 一次执行过程， 是系统进行资源分配和调度的基本单位，进程是一个动态概念，是程序在执行过程中分配和管理资源的基本单位，每一个进程都有一个自己的地址空间。\n一个进程至少有 5 种基本状态，它们是：初始态，执行态，等待状态，就绪状态，终止状态。\n通俗的讲 进程 就是 一个正在执行的程序。\n线程 线程 是进程的一个执行实例，是程序执行的最小单元，它是比进程更小的能独立运行的基本单位。\n一个进程可以创建多个线程，同一个进程中的多个线程可以并发执行，一个程序要运行至少有一个进程。\n关于并行和并发 并发： 并发：多个线程同时竞争一个位置，竞争到的才可以执行，每一个时间段 只有一个线程 在执行。\n并行： 并行：多个线程可以同时执行，每一个时间段，可以有 多个线程同时执行 。\n通俗的讲 ： 多线程程序在 单核CPU上面运行 就是 并发， 多线程程序在 多核CPU 上运行就是 并行，\n如果线程数大于CPU术数，则多线程程序在多个CPU上面运行既有并行又有并发。\n协程 golang中的主线程：在一个golang程序的主线程上可以起多个协程。golang中多协程可以实现并行或并发。\n协程：可以理解为 用户级线程，完全由用户自己的程序进行调度的。Golang的一大特色就是\n从语言层面原生支持协程，在函数或者方法前面加go关键字就可以创建一个协程。可以说Golang中的协程就是goroutine。\nJAVA/C 中开一个线程大概消耗 2MB 左右，一个goroutine占用内存非常小，只有 2KB 左右。\n协程执行完毕 sync.WaitGroup 1 2 3 4 5 6 7 8 9 10 11 12 13  var wg sync.WaitGroup func test(){ ... wg.Done() //协程计数器加 -1 } func main(){ wg.add(1) //协程计数器加 1  go test() ... wg.Wait() //等待协程执行完毕...计数器为0  }    获取当前计算机上面的CUP个数  1  cpuNum:=runtime.NumCPU()    可以自己设置使用多个CPU  1  runtime.GOMAXPROCS(cpuNum - 1)   ","description":"Goroutine可以理解为一种Go语言的协程（轻量级线程)，是Go支持高并发的基础，属于用户态的线程，由Goruntime管理而不是操作系统。","id":43,"section":"stack","tags":["golang",""],"title":"goroutine概念","uri":"http://wangjinbao.netlify.app/en/stack/golang/process/"},{"content":"socket概念 在计算机网络中，Socket是一种抽象概念，它可以看作是一种端点，用于标识网络中的一个通信连接。一个Socket由 IP地址 和 端口号 组成，它可以唯一地标识网络中的一个进程。\nSocket编程是一种在网络上进行通信的编程方式，通过使用Socket接口，开发人员可以编写程序来创建、连接、发送和接收数据，从而实现网络通信。Socket编程可以用于实现各种网络应用，如Web服务器、邮件服务器、聊天程序等。\n在Socket编程中，通常有两种类型的Socket：\n  流式Socket（Stream Socket）：也称为TCP Socket，它提供了可靠的、面向连接的通信。流式Socket使用TCP协议，在通信之前需要先建立连接，然后进行数据的传输，确保数据的可靠性和顺序。流式Socket适用于需要可靠传输的应用，如文件传输、HTTP通信等。\n  数据报式Socket（Datagram Socket）：也称为UDP Socket，它提供了无连接的通信。数据报式Socket使用UDP协议，每个数据包都是独立的，不需要事先建立连接，因此传输速度较快，但不保证数据的可靠性和顺序。数据报式Socket适用于实时性要求较高的应用，如视频流传输、实时游戏等。\n  通过Socket编程，可以实现不同计算机之间的通信和数据交换，使得网络应用能够实现数据的传输和交互。\nTCP编程 TCP/IP TCP/IP即传输控制协议/网络协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议，因为是面向连接的协议，数据像水流一样传输，会存在 黏包 的问题\n黏包 黏包（Packet Sticking）是指发送方将多个小数据包粘合在一起发送，或接收方将接收到的数据包粘合在一起，导致数据的边界不清晰，难以正确解析和处理。\n原因：  发送方的缓冲区未满：\n发送方的缓冲区未满时，可能会将多个小数据包一起发送，导致接收方接收到的数据包粘合在一起。 网络传输过程中的分段和重组：\nTCP协议在传输过程中会对数据进行分段和重组，这可能导致接收方接收到的数据包与发送方发送的数据包大小不一致。 接收方的缓冲区未及时读取：\n接收方的缓冲区未及时读取已接收的数据，导致后续的数据包与之前的数据包粘合在一起。  解决方案：  消息长度固定：发送方在每个数据包中添加固定长度的消息头，用于标识消息的长度。接收方根据消息头中的长度信息，将接收到的数据包正确地拆分成单个消息进行处理。 消息分隔符：发送方在每个数据包的末尾添加特定的分隔符（如换行符或特殊字符），接收方根据分隔符将接收到的数据包正确地拆分成单个消息进行处理。 消息头中包含消息长度信息：发送方在每个数据包的消息头中添加消息的长度信息，接收方根据消息头中的长度信息，将接收到的数据包正确地拆分成单个消息进行处理。 使用定长消息：发送方将所有的消息都固定为相同的长度，不足部分使用特定字符进行填充。接收方根据固定长度将接收到的数据包正确地拆分成单个消息进行处理。 应用层协议处理：在应用层定义自己的协议，规定消息的格式和边界，确保发送和接收的数据能够正确解析和处理。  TCP服务端 一个TCP服务端可以同时连接很多个客户端，如世界各地的用户用自己的电脑访问淘宝。因为go语言中创建多个goroutine实现并发非常方便和高效，所以我们可以每建立一次连接就创建一个goroutine去处理。\nTCP服务端程序的处理流程：\n 监听端口 接收客户端请求建立连接 创建goroutine处理连接  使用go语言中的net包实现TCP服务端代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func process(conn net.Conn) { defer conn.Close() //关闭连接 \tfor { reader := bufio.NewReader(conn) var buf [128]byte n, err := reader.Read(buf[:]) //读取数据 \tif err != nil { fmt.Println(\u0026#34;read from client failed,err:\u0026#34;, err) break } recvStr := string(buf[:n]) fmt.Println(\u0026#34;收到client端发来的数据：\u0026#34;, recvStr) conn.Write([]byte(recvStr)) //发送数据 \t} } func main() { listen, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:20000\u0026#34;) if err != nil { fmt.Println(\u0026#34;listen failed,err:\u0026#34;, err) return } for { conn, err := listen.Accept() //建立连接 \tif err != nil { fmt.Println(\u0026#34;accept failed,err:\u0026#34;, err) continue } go process(conn) //启动一个goroutine处理连接 \t} }   TCP客户端 一个TCP客户端进行TCP通信的流程：\n 建立与服务端的连接 进行数据收发 关闭连接  使用go语言的net包实现TCP客户端代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) func main() { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:20000\u0026#34;) if err != nil { fmt.Println(\u0026#34;err:\u0026#34;, err) return } defer conn.Close() //关闭连接 \tinputReader := bufio.NewReader(os.Stdin) for { input, _ := inputReader.ReadString(\u0026#39;\\n\u0026#39;) //读取用户输入 \tinputInfo := strings.Trim(input, \u0026#34;\\r\\n\u0026#34;) if strings.ToUpper(inputInfo) == \u0026#34;Q\u0026#34; { return } _, err = conn.Write([]byte(inputInfo)) //发送数据 \tif err != nil { return } buf := [512]byte{} n, err := conn.Read(buf[:]) if err != nil { if err == io.EOF { break } fmt.Println(\u0026#34;recv failed, err:\u0026#34;, err) return } fmt.Println(\u0026#34;接收到服务器发来的数据：\u0026#34; + string(buf[:n])) } }   UDP编程 UDP协议 UDP协议（用户数据报协议），是OSI模型中的一种无连接的传输层协议，不需要建立连接就能直接进行数据发送和接收，属于不可靠的、没有时序的通信，但是UDP协议的实时性比较好，通常用于视频直播相关领域。\nUDP服务端 使用go语言的net包实现的UDP服务端代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { listen, err := net.ListenUDP(\u0026#34;udp\u0026#34;, \u0026amp;net.UDPAddr{ IP: net.IPv4(0, 0, 0, 0), Port: 30000, }) if err != nil { fmt.Println(\u0026#34;listen failed,err:\u0026#34;, err) return } defer listen.Close() for { var data [1024]byte n, addr, err := listen.ReadFromUDP(data[:]) //接收数据 \tif err != nil { fmt.Println(\u0026#34;read udp failed,err:\u0026#34;, err) continue } fmt.Printf(\u0026#34;data:%v addr:%v count:%v\\n\u0026#34;, string(data[:n]), addr, n) _, err = listen.WriteToUDP(data[:n], addr) if err != nil { fmt.Println(\u0026#34;write to udp failed,err:\u0026#34;, err) continue } } }   UDPp客户端 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; ) func main() { socket, err := net.DialUDP(\u0026#34;udp\u0026#34;, nil, \u0026amp;net.UDPAddr{ IP: net.IPv4(0, 0, 0, 0), Port: 30000, }) if err != nil { fmt.Println(\u0026#34;连接服务端失败，err:\u0026#34;, err) return } defer socket.Close() sendData := []byte(\u0026#34;Hello Server\u0026#34;) _, err = socket.Write(sendData) //发送数据 \tif err != nil { fmt.Println(\u0026#34;发送数据失败，err:\u0026#34;, err) } data := make([]byte, 4096) n, remoteAddr, err := socket.ReadFromUDP(data) //接收数据 \tif err != nil { fmt.Println(\u0026#34;接收数据失败，err:\u0026#34;, err) return } fmt.Printf(\u0026#34;recv:%v addr:%v count:%v\\n\u0026#34;, string(data[:n]), remoteAddr, n) }   Http编程 http服务端 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { //单独写回调函数 \thttp.HandleFunc(\u0026#34;/go\u0026#34;, myHandler) //addr:监听地址 \t//handler：回调函数 \thttp.ListenAndServe(\u0026#34;127.0.0.1:8000\u0026#34;, nil) } func myHandler(w http.ResponseWriter, r *http.Request) { fmt.Println(r.RemoteAddr, \u0026#34;连接成功\u0026#34;) fmt.Println(\u0026#34;method:\u0026#34;, r.Method) fmt.Println(\u0026#34;url:\u0026#34;, r.URL.Path) fmt.Println(\u0026#34;header:\u0026#34;, r.Header) fmt.Println(\u0026#34;body:\u0026#34;, r.Body) w.Write([]byte(\u0026#34;你好: jarvenwang\u0026#34;)) }   http客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { resp, _ := http.Get(\u0026#34;http://127.0.0.1:8000/go\u0026#34;) defer resp.Body.Close() fmt.Println(resp.Status) fmt.Println(resp.Header) buf := make([]byte, 1024) for { //接收服务端信息 \tn, err := resp.Body.Read(buf) if err != nil \u0026amp;\u0026amp; err != io.EOF { fmt.Println(err) return } else { fmt.Println(\u0026#34;读取完毕\u0026#34;) res := string(buf[:n]) fmt.Println(res) break } } }   WebSocket编程 WebSocket概念：  WebSocket是一种在单个TCP连接上进行全双工通信的协议 WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据 在WebSocket API中，浏览器和服务器只要完成一次握手，两者之间就是可以创建持久性的连接，并进行双向数据传输 安装第三方包：go get -u -v github.com/gorilla/websocket  ","description":"Socket（套接字）是一种用于网络通信的编程接口，它提供了一种机制，使得不同计算机上的进程能够通过网络进行通信和交换数据","id":44,"section":"stack","tags":["linux",""],"title":"Socket编程","uri":"http://wangjinbao.netlify.app/en/stack/linux/socket/"},{"content":"协程池 协程池是一种用于管理和复用协程的机制，它可以在并发编程中提供更好的性能和资源利用率。\n在Go语言中，协程池可以通过使用 goroutine 和 channel 来实现。\n原理  创建一个固定大小的协程池，池中包含多个协程（goroutine）。 当需要执行一个任务时，从协程池中获取一个空闲的协程。 将任务发送到该协程的输入通道（channel）中。 协程从输入通道中接收任务，并执行任务。 执行完任务后，将协程标记为空闲状态，并将自己重新放回协程池中。  通过使用协程池，可以减少协程的创建和销毁开销，提高系统的并发能力和资源利用率。\n协程池实现 以下为协程池的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) //------有关Task角色的功能------ //定义一个任务类型Task type Task struct { f func() error //一个Task里面一个具体的任务 } //创建一个Task任务 func NewTask(arg_f func() error) *Task { t := Task{ f: arg_f, } return \u0026amp;t } //Task也需要一个执行业务的方法 func (t *Task) Execute() { t.f() //调用任务中已经绑定的业务方法 } //------有关Pool角色的功能------ //定义一个Pool协程池的类型 type Pool struct { //对外的Task入口 EntryChannel \tEntryChannel chan *Task //对内部的Task队列 JobsChannel \tJobsChannel chan *Task //协程池中最大的worker的数量 \tworker_num int } //创建Pool的函数 func NewPool(cap int) *Pool { //创建一个Pool \tp := Pool{ EntryChannel: make(chan *Task), JobsChannel: make(chan *Task), worker_num: cap, } //返回这个Pool \treturn \u0026amp;p } //协程池创建一个worker，并且让这个worker去工作 func (p *Pool) worker(work_id int) { //一个worker具体的工作  //1永久的从JobsChannel去取任务 \tfor task := range p.JobsChannel { //task 就是当前worker从JobsChannel中拿到的任务 \t//2 一旦取到任务，执行这个任务 \ttask.Execute() fmt.Println(\u0026#34;worker ID\u0026#34;, work_id, \u0026#34; 执行完了一个任务\u0026#34;) } } //让协程池，开始真正的工作，协程池一个启动方法 func (p *Pool) run() { //1 根据worker_num 来创建worker去工作 \tfor i := 0; i \u0026lt; p.worker_num; i++ { //每个worker都应该是一个goroutine \tgo p.worker(i) } //2 从EntryChannel 中去取任务，将取到的任务，发送给JobsChannel \tfor task := range p.EntryChannel { //一旦有task 读到 \tp.JobsChannel \u0026lt;- task } } //主函数，执行协程池的工作 func main() { //1创建一些任务 \tt := NewTask(func() error { fmt.Println(time.Now()) return nil }) //2创建一个Pool协程池 \tp := NewPool(4) task_num := 0 //3将这些任务交给协程池 \tgo func() { for { p.EntryChannel \u0026lt;- t task_num++ fmt.Println(\u0026#34;一共执行数：--\u0026#34;, task_num) } }() //4启动pool，让pool开始工作 \tp.run() }   以下是一个简单的示例代码，演示了如何使用协程池来执行任务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type Task struct { ID int Data string } func worker(id int, tasks \u0026lt;-chan Task, wg *sync.WaitGroup) { defer wg.Done() for task := range tasks { fmt.Printf(\u0026#34;Worker %d processing task %d with data: %s\\n\u0026#34;, id, task.ID, task.Data) // 执行任务的逻辑代码 \t} } func main() { poolSize := 5 taskCount := 10 // 创建任务通道和等待组 \ttasks := make(chan Task, taskCount) var wg sync.WaitGroup // 创建协程池 \tfor i := 1; i \u0026lt;= poolSize; i++ { wg.Add(1) go worker(i, tasks, \u0026amp;wg) } // 添加任务到通道中 \tfor i := 1; i \u0026lt;= taskCount; i++ { tasks \u0026lt;- Task{ID: i, Data: fmt.Sprintf(\u0026#34;data-%d\u0026#34;, i)} } close(tasks) // 等待所有任务完成 \twg.Wait() }   ","description":"协程池是一种用于管理和复用协程的机制，它可以在并发编程中提供更好的性能和资源利用率","id":45,"section":"stack","tags":["golang",""],"title":"协程池的设计和原理","uri":"http://wangjinbao.netlify.app/en/stack/golang/gorountine/"},{"content":"常见的网络I/O模型有哪些 1.阻塞式I/O（Blocking I/O） 应用程序通过调用系统提供的I/O函数进行数据读写时，会阻塞等待直到数据传输完成。这种模型适用于简单的应用场景，但在处理多个并发连接时效率较低。\n2.非阻塞式I/O（Non-blocking I/O） 应用程序使用非阻塞的方式调用I/O函数，可以立即返回，不会等待数据的传输完成。通过不断轮询判断是否有数据可读或可写，实现了并发处理。但是，轮询会消耗大量的CPU资源。\n3.I/O多路复用（I/O Multiplexing） 使用操作系统提供的select、poll或epoll等函数，将多个文件描述符注册到一个集合中，通过调用这些函数等待数据的就绪状态。当有数据到达时，返回就绪的文件描述符，应用程序可以进行相应的处理。相较于非阻塞式I/O，I/O多路复用减少了无效轮询的消耗。\n说明:文件描述符（fd） fd就是(file discriptor)为文件描述符。socket起源于unix，unix中把所有的资源都看作是文件，如网卡、打印机等。\n简单点说也就是int fd = socket(AF_INFT,SOCK_STREAM,0);函数socket()返回的是这个描述符。\nepoll的实现 在Linux系统中，epoll是一种高性能的I/O事件通知机制，用于处理大量的并发连接。epoll提供了一组系统调用接口，用于注册、管理和等待I/O事件。\nepoll的接口主要包括以下几个函数：\n  epoll_create：创建一个epoll实例，返回一个文件描述符，用于后续的操作。\n  epoll_ctl：向epoll实例中注册或删除文件描述符，以及设置关注的事件类型。\n EPOLL_CTL_ADD：将文件描述符添加到epoll实例中。 EPOLL_CTL_MOD：修改已注册的文件描述符的关注事件类型。 EPOLL_CTL_DEL：从epoll实例中删除已注册的文件描述符。    epoll_wait：等待事件的发生，返回就绪的文件描述符和事件信息。\n events参数：用于接收就绪的事件信息的数组。 maxevents参数：指定events数组的大小，表示最多等待多少个事件。 timeout参数：指定等待的超时时间，可以设为-1表示无限等待。    1 2 3 4 5 6 7 8 9  events常用参数： EPOLLIN：表示文件描述符可读，即有数据可以从文件描述符中读取。 EPOLLOUT：可写，即可以向文件描述符中写入数据。 EPOLLERR：发生错误，需要进行错误处理。 EPOLLPRI：有紧急数据可读，需要进行处理。 EPOLLHUP：挂起，即文件描述符被挂起或关闭，需要进行处理。 EPOLLET：设置为边缘触发模式，即只有状态改变时才会触发事件。 EPOLLONESHOT：表示只监听一次事件，当事件触发后，需要重新设置监听。 这些宏可以在使用epoll进行事件监听时，通过设置epoll_event结构体的events字段来指定所关注的事件类型。   以下演示如何使用epoll的接口来实现事件驱动的网络服务器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) func main() { // 创建epoll实例 \tepollFd, err := syscall.EpollCreate1(0) if err != nil { log.Fatal(err) } // 创建监听套接字 \tlistener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) if err != nil { log.Fatal(err) } defer listener.Close() // 将监听套接字添加到epoll实例中 \tevent := syscall.EpollEvent{ Events: syscall.EPOLLIN, Fd: int32(listener.(*net.TCPListener).Fd()), } err = syscall.EpollCtl(epollFd, syscall.EPOLL_CTL_ADD, int(listener.(*net.TCPListener).Fd()), \u0026amp;event) if err != nil { log.Fatal(err) } events := make([]syscall.EpollEvent, 10) for { // 等待事件的发生 \tn, err := syscall.EpollWait(epollFd, events, -1) if err != nil { log.Fatal(err) } // 处理就绪的事件 \tfor i := 0; i \u0026lt; n; i++ { if int(events[i].Fd) == int(listener.(*net.TCPListener).Fd()) { // 接受新的连接 \tconn, err := listener.Accept() if err != nil { log.Println(err) continue } // 处理连接 \tgo handleConnection(conn) } } } } func handleConnection(conn net.Conn) { defer conn.Close() // 处理连接的业务逻辑 \tfmt.Fprintf(conn, \u0026#34;Hello, client!\\n\u0026#34;) }   这只是一个简化的示例，实际使用epoll时还需要处理错误、设置非阻塞模式、处理其他事件类型等。详细的epoll接口使用可以参考相关的文档和资料。\nET LT：   水平触发（LT）是指当socket接收缓冲区中有数据可读时，读事件会持续触发；当socket发送缓冲区未满时，可以继续写入数据，写事件也会持续触发。\n  边缘触发（ET）是指当socket接收缓冲区发生变化时，即空的接收缓冲区刚接收到数据时，会触发读事件；当socket发送缓冲区状态发生变化时，即满的缓冲区刚空出空间时，会触发写事件。\n  LT的处理过程： LT的处理过程：\naccept一个连接，添加到epoll中监听EPOLLIN事件。\n当EPOLLIN事件到达时，read fd中的数据并处理，\n当需要写出数据时，把数据write到fd中；如果数据较大，无法一次性写出，那么在epoll中监听EPOLLOUT事件。\n当EPOLLOUT事件到达时，继续把数据write到fd中 ；如果数据写出完毕，那么在epoll中关闭EPOLLOUT事件。\nET的处理过程如下：\n接受一个连接，并将其添加到epoll中，监听EPOLLIN|EPOLLOUT事件。\n当EPOLLIN事件到达时，从文件描述符（fd）中读取数据并进行处理。需要一直读取，直到返回EAGAIN为止。\n当需要写出数据时，将数据写入fd中，直到数据全部写完或者write返回EAGAIN。\n当EPOLLOUT事件到达时，继续将数据写入fd中，直到数据全部写完或者write返回。\nET模式accept存在的问题：\n多个连接同时到达时，服务器TCP会瞬间积累多个就绪连接。由于是边缘触发模式，epoll只会通知一次，而accept只处理一个连接，这导致TCP就绪队列中剩下的连接都得不到处理。为了解决这个问题，可以在while循环中使用accept调用，处理完就绪队列中的所有连接后再退出循环。要判断是否处理完所有连接，可以通过accept返回-1并且将error设置为errno的值EAGAIN来判断。\nLT==\u0026gt;只要event为EPOLLIN时，就会不断调用回调函数。\nET==\u0026gt;只有当从EPOLLOUT变化为EPOLLIN时，才会触发。\n4.信号驱动式I/O（Signal-driven I/O） 应用程序将文件描述符设置为非阻塞模式，并使用异步I/O函数（如aio_read、aio_write）进行数据的读写操作。当数据就绪时，操作系统会发送一个信号给应用程序，应用程序通过信号处理函数来处理数据。这种模型较少使用。\n5.异步I/O（Asynchronous I/O） 应用程序发起I/O操作后，通过回调函数或事件通知的方式来处理数据读写。操作系统会在数据就绪时通知应用程序，应用程序继续处理其他任务，当操作系统完成数据传输后，再执行回调函数来处理数据。这种模型相较于其他模型有更好的性能表现，但编程复杂度较高。\n","description":"epoll是Linux操作系统中的一种事件通知机制，通过该机制可以同时监控多个文件描述符上的事件","id":46,"section":"stack","tags":["linux",""],"title":"epoll模型的原理和工作过程","uri":"http://wangjinbao.netlify.app/en/stack/linux/epoll/"},{"content":"常见并发模型 进程\u0026amp;线程(apache) C10K:C10K problem是指如何让服务器能够支持10k并发，当然你可以买昂贵的服务器，但是还有更便宜的办法。\n异步非阻塞(nginx/libevent/nodejs) 复杂度高\n协程(golang/erlang/lua)  程序并发执行（goroutine）\ngoroutines（程序并发执行）  1 2 3  foo()//函数 go foo() //执行函数foo bar() //不用等待foo返回    多个goroutine间的数据同步和通信（channels）\nchannels（多个goroutine间的数据通信与同步）  1 2 3 4 5 6  c:=make(chan string) //创建一个channel go func(){ time.Sleep(1*time.Second) c\u0026lt;-\u0026#34;message from closure\u0026#34; //发送数据到channel中 }() msg:=\u0026lt;-c //阻塞直到接收到数据    多个channel选择数据读取或写入（select）\nselect(从多个channel中读取或写入数据)  1 2 3 4 5 6 7 8  select{ case v := \u0026lt;-c1: fmt.Println(\u0026#34;channel 1 sends\u0026#34;,v) case v := \u0026lt;-c2: fmt.Println(\u0026#34;channel 2 sends\u0026#34;,v) default://可选  fmt.Println(\u0026#34;neither channel was ready\u0026#34;) }   golang中的面向对象 1. 封装 实现：\n1 2 3 4 5 6 7 8 9 10  type Foo struct{ baz string } func (f *Foo) echo (){ fmt.Println(f.baz) } func main(){ f :=Foo{baz:\u0026#34;hello , struct\u0026#34;} f.echo() }   2. 继承 1 2 3 4 5 6 7 8 9 10 11 12 13  type Foo struct{ baz string } type Bar struct{ Foo } func (f *Foo) echo (){ fmt.Println(f.baz) } func main(){ b := Bar{Foo{baz:\u0026#34;hello, struct\u0026#34;}} b.echo() }   3. 多态 1 2 3 4 5 6 7 8 9 10 11 12 13  type Foo interface{ qux() } type Bar struct{} type Baz struct{} func (b Bar) qux(){} func (b Baz) qux(){} func main(){ var f Foo f = Bar{} f = Baz{} fmt.Println(f) }   协和例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) type LogProcess struct { rc chan string wc chan string path string //读取文件的路径 \tinfluxDBDsn string //data source } func (l *LogProcess) ReadFromFile() { //读取模块 \tline := \u0026#34;message\u0026#34; l.rc \u0026lt;- line } func (l *LogProcess) Process() { //解析模块 \tdata := \u0026lt;-l.rc l.wc \u0026lt;- strings.ToUpper(data) } func (l *LogProcess) WriteToInfluxDB() { //写入模块 \tfmt.Println(\u0026lt;-l.wc) } func main() { lp := \u0026amp;LogProcess{ rc: make(chan string), wc: make(chan string), path: \u0026#34;/tmp/access.log\u0026#34;, influxDBDsn: \u0026#34;user\u0026amp;pwd\u0026#34;, } go lp.ReadFromFile() go lp.Process() go lp.WriteToInfluxDB() time.Sleep(1 * time.Second) }   读取、写入部分模块用接口独立出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) type Reader interface { Read(rc chan string) } type Writer interface { Write(wc chan string) } type ReadFromFile struct { path string //读取文件的路径 } func (r *ReadFromFile) Read(rc chan string) { //读取模块 \tline := \u0026#34;message\u0026#34; rc \u0026lt;- line } type WriteToInfluxDB struct { influxDBDsn string //data source } func (w *WriteToInfluxDB) Write(wc chan string) { //写入模块 \tfmt.Println(\u0026lt;-wc) } type LogProcess struct { rc chan string wc chan string read Reader write Writer } func (l *LogProcess) Process() { //解析模块 \tdata := \u0026lt;-l.rc l.wc \u0026lt;- strings.ToUpper(data) } func main() { r := \u0026amp;ReadFromFile{ path: \u0026#34;/tmp/access.log\u0026#34;, } w := \u0026amp;WriteToInfluxDB{ influxDBDsn: \u0026#34;user\u0026amp;pwd\u0026#34;, } lp := \u0026amp;LogProcess{ rc: make(chan string), wc: make(chan string), read: r, write: w, } go lp.read.Read(lp.rc) go lp.Process() go lp.write.Write(lp.wc) time.Sleep(1 * time.Second) }   实现简单日志读取：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) type Reader interface { Read(rc chan []byte) } type Writer interface { Write(wc chan string) } type ReadFromFile struct { path string //读取文件的路径 } func (r *ReadFromFile) Read(rc chan []byte) { //读取模块 \t//打开文件 \tf, err := os.Open(r.path) if err != nil { panic(err) } //从文件末尾读取文件内容 \tf.Seek(0, 2) rd := bufio.NewReader(f) for { line, err := rd.ReadBytes(\u0026#39;\\n\u0026#39;) if err == io.EOF { time.Sleep(500 * time.Millisecond) continue } else if err != nil { panic(err) } //line := \u0026#34;message\u0026#34; \trc \u0026lt;- line[:len(line)-1] } } type WriteToInfluxDB struct { influxDBDsn string //data source } func (w *WriteToInfluxDB) Write(wc chan string) { //写入模块 \tfor v := range wc { fmt.Println(v) } } type LogProcess struct { rc chan []byte wc chan string read Reader write Writer } func (l *LogProcess) Process() { //解析模块 \tfor v := range l.rc { l.wc \u0026lt;- strings.ToUpper(string(v)) } } func main() { r := \u0026amp;ReadFromFile{ path: \u0026#34;./access.log\u0026#34;, } w := \u0026amp;WriteToInfluxDB{ influxDBDsn: \u0026#34;user\u0026amp;pwd\u0026#34;, } lp := \u0026amp;LogProcess{ rc: make(chan []byte), wc: make(chan string), read: r, write: w, } go lp.read.Read(lp.rc) go lp.Process() go lp.write.Write(lp.wc) time.Sleep(30 * time.Second) }   运行：\n1 2 3  go run log_process.go # 之后输入日志内容 echo 123123123\u0026gt;\u0026gt;access.log   ","description":"epoll是Linux操作系统中的一种事件通知机制，通过该机制可以同时监控多个文件描述符上的事件","id":47,"section":"stack","tags":["golang",""],"title":"goroutine并发实现","uri":"http://wangjinbao.netlify.app/en/stack/golang/gorountines/"},{"content":"缺点  当一个网内容特别多(如：淘宝)的情况下，要一套代码响应多端这个工作比较繁琐，最关键的问题是移动端网站速度太慢了 SEO的问题   PS:问题：什么样的网站适合\u0026quot;完全\u0026quot;响应式？[一个url响应多端]\n答：展示类的网站 ==\u0026gt; 文档类、网站官网\n*** 其它的不建议完全的响应式，但可以写一点点@media\n PC端跳转移动端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;script\u0026gt; function isMobile(){ var userAgentInfo = navigator.userAgent; var Agents = [\u0026#34;Android\u0026#34;,\u0026#34;iPhone\u0026#34;,\u0026#34;SymbianOS\u0026#34;,\u0026#34;Windows Phone\u0026#34;,\u0026#34;iPad\u0026#34;,\u0026#34;iPod\u0026#34;]; var flag = false; for (var v=0;v\u0026lt;Agents.length;v++){ if(userAgentInfo.indexOf(Agents[v])\u0026gt;0){ flag=true; break; } } return flag; } var flag = isMobile(); if(flag){ window.location.href=\u0026#34;xxx.html\u0026#34; } \u0026lt;/script\u0026gt;   响应式网页设计 对移动设备开启响应式 在html头部中添加 meta 元素：\n1  \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1.0\u0026#34;/\u0026gt;   宽度设计(纵向)  方式一：百分比  1 2 3  .container{ width:100%; }   方式二：max-width  1 2 3 4  .container{ max-width:80%; margin:0 auto; }   方式三：固定宽度  1 2 3 4 5 6 7 8 9 10 11  @media(max-width:900px){ .container{ width:600px; } } @media(max-width:700px){ .container{ width:500px; } }   宽度设计(横向) flex横向多列布局： 1 2 3 4 5 6 7 8 9 10 11 12 13 14  /* flex */ .container{ display:flex; } //解决方案如下： /* 当屏幕过窄， 会影响阅读，设置换行 */ .container{ display:flex; flex-wrap:wrap; } /* 每个 flex item 最小宽度 */ .container p{ flex:250px; }   grid横向多列布局： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  /* Grid */ .container{ display:grid; } //解决方案一如下： //在一行中容纳最多数量的列 .container{ display:grid; grid-template-columns:repeat(auto-fill,minmax(250px,1fr)) } //解决方案二如下： //使用media query 手动控制列数 .container{ display:grid; grid-template-columns:1fr 1fr 1fr; } @media(max-width:900px){ .container{ grid-template-columns:1fr 1fr; } } @media(max-width:700px){ .container{ grid-template-columns:1fr; } }   图片设计 1 2 3  img { max-width:100%; }   不同宽度加载不同图片  方式一：srcset + sizes  1 2 3 4 5 6 7 8 9  \u0026lt;img src=\u0026#34;../image-300.png\u0026#34; srcset=\u0026#34; ../image-1240.png 1240w, ../image-600.png 600w, ../image-300.png 300w, \u0026#34; sizes=\u0026#34;(max-width:400px) 300px,(max-width:900px) 600px,1240px\u0026#34; /\u0026gt;   2.方式二：picture\n1 2 3 4 5  \u0026lt;picturn\u0026gt; \u0026lt;sorce media=\u0026#34;(max-width:400px)\u0026#34; srcset=\u0026#34;../image-300.png\u0026#34; /\u0026gt; \u0026lt;sorce media=\u0026#34;(max-width:900px)\u0026#34; srcset=\u0026#34;../image-600.png\u0026#34; /\u0026gt; \u0026lt;img src=\u0026#34;../image-1240.png\u0026#34; /\u0026gt; \u0026lt;/picturn\u0026gt;   字体设计  方式一：百分比  1 2 3 4 5 6 7 8 9 10 11  h1 { font-size:6vw; } 或 h1 { font-size:6rem; } //升级：最小2rem h1 { font-size: calc(2rem+2vw); }   方式二：media quary  1 2 3 4 5 6 7 8 9 10  @media(max-width:900px){ h1{ font-size:3rem; } } @media(max-width:700px){ h1{ font-size:2rem; } }   ","description":"一个网站能够兼容多个终端——而不是为每个终端做一个特定的版本。这个概念是为解决移动互联网浏览而诞生的","id":48,"section":"stack","tags":["javascript",""],"title":"响应式布局","uri":"http://wangjinbao.netlify.app/en/stack/javascript/layout/"},{"content":"支持Node版本 支持的node 版本： ^4.8.0 || ^5.7.0 || ^6.2.2 || \u0026gt;=8.0.0\nyarn的优点   速度快：\nyarn使用并行安装和缓存机制，可以大大提高安装依赖包的速度。\n  稳定性好：\nyarn使用lockfile来锁定依赖包的版本，保证了项目的稳定性。\n  安全性高：\nyarn使用yarn.lock文件来锁定依赖包的版本，避免了由于依赖包版本不一致导致的安全问题。\n  易于维护：\nyarn提供了一些方便的命令，如yarn upgrade，yarn outdated等，可以方便地更新和查看依赖包。\n  支持离线安装：\nyarn可以将依赖包缓存到本地，支持离线安装，避免了网络不好的情况下安装依赖包失败的问题。\n  yarn 安装和使用 安装： 可以用yarn代替npm，yarn更快、对开发者更友好。但是在用yarn之前需要先通过npm安装它。\n npm i yarn -g 或 npm install --global yarn\n命令使用：   初始化项目：yarn init 该命令会在当前目录下创建一个新的package.json文件，用于管理项目的依赖和配置。\n  安装依赖：yarn install 该命令会根据package.json文件中的依赖列表，下载并安装项目所需的依赖包。\n  添加依赖：yarn add [package] 该命令会将指定的依赖包添加到项目中，并更新package.json文件的依赖列表。\n  更新依赖：yarn upgrade [package] 该命令会将指定的依赖包更新到最新版本，并更新package.json文件的依赖列表。\n  移除依赖：yarn remove [package] 该命令会将指定的依赖包从项目中移除，并更新package.json文件的依赖列表。\n  运行脚本：yarn run [script] 该命令会运行项目中定义的脚本命令，例如启动开发服务器、打包代码等。\n  清理缓存：yarn cache clean 该命令会清理yarn的缓存，可以解决一些依赖包版本冲突或缓存问题。\n  yarn改国内镜像 1.查看镜像源：\nyarn config get registry\n如果显示：\n https://registry.yarnpkg.com\n则表示不是国内镜像源。可以通过以下步骤设置\n2.设置为淘宝镜像源：\n yarn config set registry https://registry.npm.taobao.org/\n","description":"yarn是一个包管理工具，它的作用是帮助开发者管理项目中的依赖包。使用yarn可以方便地安装、更新、卸载、查看依赖包。","id":49,"section":"stack","tags":["javascript",""],"title":"yarn包管理工具","uri":"http://wangjinbao.netlify.app/en/stack/javascript/yarn/"},{"content":"初步初始化项目 生成依赖文件package.json npm init -y\n1  npm init -y   脚手架的安装 cnpm i -D @vue/cli\n1 2  cnpm i -D @vue/cli 指定安装（cnpm i -D @vue/cli@4.5.15）   查看vue-cli版本号：\n1  npx vue -V   项目创建 局部创建： npx vue create project-one 或 npx vue init webpack project-one\n1 2 3 4 5 6 7  npx vue create project-one vue2 yarn $ cd project-one $ yarn serve //运行项目yarn run serve    全局创建： npx vue ui\n界面：\n1 2 3  npx vue ui 🚀 Starting GUI... 🌠 Ready on http://localhost:8000   全局安装vue-cli 2.9.6 和项目创建：  安装webpack： npm i webpack -g 安装脚手架： npm i vue-cli -g 创建项目： vue init webpack demo  全局安装vue-cli 4.5.15 和项目创建：  用npm安装脚手架 ： npm install -g @vue/cli 用yarn安装脚手架： yarn global add @vue/cli 创建项目： vue create my-project 或 vue ui  ** ps: 修改端口\n文件package.json 里修改：--port 5173\n1 2 3 4 5  \u0026#34;scripts\u0026#34;: { \u0026#34;serve\u0026#34;: \u0026#34;vue-cli-service serve --port 5173 --open\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;vue-cli-service build\u0026#34;, \u0026#34;lint\u0026#34;: \u0026#34;vue-cli-service lint\u0026#34; },   添加配置文件 新建vue.config.js\n1 2 3 4 5  module.exports = { devServer: { open: true } }   elementUI 安装： npm i element-ui -S 全局使用：-S\n使用： 在main.js中引入：\n1 2 3 4  import ElementUI from \u0026#39;element-ui\u0026#39; import \u0026#39;element-ui/lib/theme-chalk/index.css\u0026#39; Vue.use(ElementUI)   安装sass 官网：https://sass.hk/\n指定版本： cnpm i sass-loader@10 node-sass@6 -S\n或 cnpm i sass-loader node-sass -S\n以下是部分版本号对应，具体可百度\n   sass-loader node-sass     4.1.1 4.3.0   7.0.3 4.7.2   7.3.1 4.7.2   7.3.1 4.14.1   10.0.1 6.0.1    1 2 3 4 5  cnpm i sass-loader node-sass -S ... dependencies: + sass-loader ^13.3.2 + node-sass ^9.0.0   使用：\n样式嵌套\n1 2 3  \u0026lt;style lang=\u0026#34;scss\u0026#34;\u0026gt; 样式嵌套 \u0026lt;/style\u0026gt;    *** 报错：Syntax Error: TypeError: this.getOptions is not a function\n解决方法：\n这个报错是类型错误，this.getOptions 不是一个函数 。这个错误一般就是less-loader库里的错误。\n主要是less-loader版本太高，不兼容this.getOptions方法。\n 删除目录 node_modules 去年package.json中sass和sass-loader\n找到package.json文件中的“less”和“less-loader”然后删除这两行\n或 找到package.json文件中的“sass”和“sass-loader”然后删除这两行    *** node-sass安装失败报错：\n1 2  ✖ Install fail! Error: run postinstall error, please remove node_modules before retry! Command failed with exit code 1: node scripts/build.js   解决方法：\nnode版本太高，对应的node-sass的版本过低，对应如下表：\n    NodeJS Supported node-sass version Node Module     Node17 7.0+ 102   Node16 6.0+ 93   Node15 5.0+,\u0026lt;7.0 88   Node14 4.14+ 83   Node13 4.13+,\u0026lt;5.0 79   Node12 4.12+ 72   Node11 4.10,\u0026lt;5.0 67   Node10 4.9+,\u0026lt;6.0 64   Node8 4.5.3,\u0026lt;5.0 57   Node\u0026lt;8 \u0026lt;5.0 \u0026lt;57    安装less cnpm i less less-loader -S\n安装图标font-awesome 官网地址：https://fontawesome.com.cn/\ncnpm i -D font-awesome\n 使用：\nmain.js内容：  1 2 3  import \u0026#39;font-awesome/css/font-awesome.min.css\u0026#39; \u0026lt;i class=\u0026#34;fa fa-bluetooth-b fa-2x fa-border\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;   常用正则插件 vscode里搜索 any-rule\n安装axios cnpm i axios -S\n使用：\n在main.js中：\n1 2 3  import axios from \u0026#39;axios\u0026#39; Vue.prototype.axios = axios //挂载到原型，可以在全局使用   安装router cnpm i vue-router@3.5.3 -S\n使用：\n 步骤一：新建router/index.js  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import Vue from \u0026#34;vue\u0026#34;; import Router from \u0026#39;vue-router\u0026#39; import Home from \u0026#39;../components/Home.vue\u0026#39; Vue.use(Router) export default new Router({ routes: [ { path: \u0026#39;/home\u0026#39;, //component: () =\u0026gt; import(\u0026#39;@/components/Home\u0026#39;) //路由懒加载  //component: resolve =\u0026gt; require([\u0026#39;@/components/Home\u0026#39;],resolve) //异步加载  component: Home } ], mode: \u0026#39;history\u0026#39; })   步骤二：main.js中加载\nmain.js中的内容：  1 2 3 4 5 6  import router from \u0026#39;./router\u0026#39; new Vue({ router, render: h =\u0026gt; h(App), }).$mount(\u0026#39;#app\u0026#39;)   步骤三：router-view引用  1 2  \u0026lt;router-view\u0026gt;\u0026lt;/router-view\u0026gt;   mock模拟数据 使用Apifox 的 \u0026ldquo;高级Mock\u0026rdquo; 功能 定义接口及反回值\naxios二次封装 步骤一：新建service.js src/service.js内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  import axios from \u0026#34;axios\u0026#34;; import { getToken } from \u0026#34;./utils/setToken\u0026#34;; import { Message } from \u0026#34;element-ui\u0026#34;; const service = axios.create({ baseURL: \u0026#39;/api\u0026#39;, //baseURL会自动加在请求地址上 timeout: 3000 }) //添加请求拦截器 service.interceptors.request.use((config) =\u0026gt; { //在请求之前做些什么（获取并设置token） config.headers[\u0026#39;token\u0026#39;] = getToken(\u0026#39;token\u0026#39;) return config }, (error) =\u0026gt; { //捕捉异常 return Promise.reject(error) }) //添加响应拦截器 service.interceptors.response.use((response) =\u0026gt; { //对响应数据做些什么 （状态码提示） let { status, message } = response.data if (status !== 200) { Message({ message: message || \u0026#39;error\u0026#39;, type: \u0026#39;warning\u0026#39; }) } return response //注意return回去 }, (error) =\u0026gt; { //捕捉异常 return Promise.reject(error) }) export default service   步骤二：vue.config.js配置代理 src/vue.config.js配置代理内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  module.exports = { devServer: { open: true, proxy: { \u0026#39;/api\u0026#39;: { target: \u0026#39;http://i.system_admin.com/api\u0026#39;, changeOrigin: true, //允许跨域  pathRewrite: { \u0026#39;^/api\u0026#39;: \u0026#39;\u0026#39; } } } }, configureWebpack: { devtool: \u0026#39;source-map\u0026#39; } }   步骤三：main.js中全局挂载service src/main.js修改内容如下：\n1 2 3  import service from \u0026#39;./service\u0026#39; ... Vue.prototype.service = service //挂载到原型，可以在全局使用   步骤四：this.service.post直接使用 1 2 3 4 5 6 7 8 9 10 11 12 13  this.service.post(\u0026#34;/login\u0026#34;, this.form) .then((res) =\u0026gt; { console.log(res.data); if (res.data.status == 200) { removeToken(\u0026#34;username\u0026#34;); setToken(\u0026#34;username\u0026#34;, res.data.data); setToken(\u0026#34;token\u0026#34;, res.data.data.token); this.$message({ message: res.data.message, type: \u0026#34;success\u0026#34; }); this.$router.push(\u0026#34;/home\u0026#34;); } else { this.$message.error(\u0026#34;登录失败\u0026#34;); } })    PS:报错：Proxy error: Could not proxy request /m1/3477035-0-default/api/login from 127.0.0.1:5173 to http://dev.kg_wbgl.com:4523.\n解决方法:\n原因：容器网络与本地postman接口mock请求不通过，解决：开一个后台接口容器即可\n  PS:报错：[Vue warn]: Error in v-on handler: \u0026ldquo;TypeError: Cannot read properties of undefined (reading \u0026lsquo;post\u0026rsquo;)\u0026rdquo;\n解决方法:\n在把service.js中的变量 暴露出去 export default service\n body样式调整 在App.vue中添加：\n1 2 3 4  body { margin: 0; padding: 0; }   配置路由  步骤一：router/indexjs添加 步骤二：数据挂载  1 2 3  created() { this.menus = [...this.$router.options.routes]; },   步骤三：开启路由  1 2  \u0026lt;el-menu router ...\u0026gt; //菜单开启    步骤四：添加router-view\nHome.vue中添加：  1  \u0026lt;router-view\u0026gt;\u0026lt;/router-view\u0026gt;   面包屑  步骤一：制作面包屑组件\n新建 BreadCrumb.vue:  1 2 3 4 5 6 7 8  \u0026lt;el-card\u0026gt; \u0026lt;el-breadcrumb separator-class=\u0026#34;el-icon-arrow-right\u0026#34;\u0026gt; \u0026lt;el-breadcrumb-item :to=\u0026#34;{ path: \u0026#39;/\u0026#39; }\u0026#34;\u0026gt;首页\u0026lt;/el-breadcrumb-item\u0026gt; \u0026lt;el-breadcrumb-item\u0026gt;活动管理\u0026lt;/el-breadcrumb-item\u0026gt; \u0026lt;el-breadcrumb-item\u0026gt;活动列表\u0026lt;/el-breadcrumb-item\u0026gt; \u0026lt;el-breadcrumb-item\u0026gt;活动详情\u0026lt;/el-breadcrumb-item\u0026gt; \u0026lt;/el-breadcrumb\u0026gt; \u0026lt;/el-card\u0026gt;   步骤二：主页引入面包屑  1 2  import BreadCrumb from \u0026#34;./common/BreadCrumb.vue\u0026#34;; \u0026lt;BreadCrumb /\u0026gt;   步骤三：$route.matched循环  1 2  \u0026lt;el-breadcrumb-item v-for=\u0026#34;(item, index) in $route.matched\u0026#34; :key=\u0026#34;index\u0026#34;\u0026gt;{{ item.name }} \u0026lt;/el-breadcrumb-item\u0026gt;   数据列表  步骤一:引入el-table  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  \u0026lt;template\u0026gt; \u0026lt;el-table :data=\u0026#34;tableData\u0026#34; stripe style=\u0026#34;width: 100%\u0026#34;\u0026gt; \u0026lt;el-table-column prop=\u0026#34;date\u0026#34; label=\u0026#34;日期\u0026#34; width=\u0026#34;180\u0026#34;\u0026gt; \u0026lt;/el-table-column\u0026gt; \u0026lt;el-table-column prop=\u0026#34;name\u0026#34; label=\u0026#34;姓名\u0026#34; width=\u0026#34;180\u0026#34;\u0026gt; \u0026lt;/el-table-column\u0026gt; \u0026lt;el-table-column prop=\u0026#34;address\u0026#34; label=\u0026#34;地址\u0026#34;\u0026gt; \u0026lt;/el-table-column\u0026gt; \u0026lt;/el-table\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default { data() { return { tableData: [{ date: \u0026#39;2016-05-02\u0026#39;, name: \u0026#39;王小虎\u0026#39;, address: \u0026#39;上海市普陀区金沙江路 1518 弄\u0026#39; }, { date: \u0026#39;2016-05-04\u0026#39;, name: \u0026#39;王小虎\u0026#39;, address: \u0026#39;上海市普陀区金沙江路 1517 弄\u0026#39; }, { date: \u0026#39;2016-05-01\u0026#39;, name: \u0026#39;王小虎\u0026#39;, address: \u0026#39;上海市普陀区金沙江路 1519 弄\u0026#39; }, { date: \u0026#39;2016-05-03\u0026#39;, name: \u0026#39;王小虎\u0026#39;, address: \u0026#39;上海市普陀区金沙江路 1516 弄\u0026#39; }] } } } \u0026lt;/script\u0026gt;   步骤二：封装接口  1 2 3 4 5 6 7  export function student(params) { return service({ method: \u0026#39;get\u0026#39;, url: \u0026#39;/student\u0026#39;, params }) }   步骤三：请求处理数据  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  \u0026lt;script\u0026gt; import { student } from \u0026#34;@/api/api\u0026#34;; export default { data() { return { tableData: [], }; }, created() { this.getData(); }, methods: { getData(params) { student(params).then((res) =\u0026gt; { console.log(res); if (res.data.status === 200) { this.tableData = res.data.data; this.tableData.forEach((item) =\u0026gt; { //尽量不要修改原数据  item.sex === 1 ? (item.sex_text = \u0026#34;男\u0026#34;) : (item.sex_text = \u0026#34;女\u0026#34;); item.state === \u0026#34;1\u0026#34; ? (item.state_text = \u0026#34;已入学\u0026#34;) : item.state === \u0026#34;2\u0026#34; ? (item.state_text = \u0026#34;未入学\u0026#34;) : (item.state_text = \u0026#34;休学中\u0026#34;); }); } }); }, }, }; \u0026lt;/script\u0026gt;   **PS报错： error The template root requires exactly one element\nVue只允许模板里存在一个根节点。在 \u0026lt;template\u0026gt; 中添加一个 \u0026lt;div\u0026gt;标签，之后所有的组件全部加在 \u0026lt;div\u0026gt; 里即可解决。\n分页  步骤一：复制分页样式  1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;div class=\u0026#34;block\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;demonstration\u0026#34;\u0026gt;完整功能\u0026lt;/span\u0026gt; \u0026lt;el-pagination @size-change=\u0026#34;handleSizeChange\u0026#34; @current-change=\u0026#34;handleCurrentChange\u0026#34; :current-page=\u0026#34;currentPage4\u0026#34; :page-sizes=\u0026#34;[100, 200, 300, 400]\u0026#34; :page-size=\u0026#34;100\u0026#34; layout=\u0026#34;total, sizes, prev, pager, next, jumper\u0026#34; :total=\u0026#34;400\u0026#34;\u0026gt; \u0026lt;/el-pagination\u0026gt; \u0026lt;/div\u0026gt;   步骤二：修改currentPage、pageSize、total等变量和方法  1 2 3  :current-page=\u0026#34;currentPage\u0026#34; :page-size=\u0026#34;pageSize\u0026#34; :total=\u0026#34;total\u0026#34;   步骤三：计算computed每页数据  1 2 3 4 5 6 7 8  computed: { compData() { return this.tableData.slice( (this.currentPage - 1) * this.pageSize, this.currentPage * this.pageSize ); }, },   步骤四：handleSizeChange和handleCurrentChange修改变量  1 2 3 4 5 6 7 8 9  handleSizeChange(val) { this.pageSize = val; this.currentPage = 1; console.log(`每页 ${val}条`); }, handleCurrentChange(val) { this.currentPage = val; console.log(`当前页: ${val}`); },   新增/编辑form提交  步骤一：验证form\n提交方法 sure(\u0026lsquo;form\u0026rsquo;) 传参数  1  \u0026lt;el-button type=\u0026#34;primary\u0026#34; @click=\u0026#34;sure(\u0026#39;form\u0026#39;)\u0026#34;\u0026gt;确 定\u0026lt;/el-button\u0026gt;   步骤二：请求添加/编辑组合接口  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  sure(form) { this.$refs[form].validate((valid) =\u0026gt; { if (valid) { //增加  if (this.status) { info(this.form).then((res) =\u0026gt; { console.log(\u0026#34;新增\u0026#34;); if (res.data.status === 200) { this.getData(); this.$message({ type: \u0026#34;success\u0026#34;, message: res.data.message }); this.dialogFormVisible = false; this.$refs[\u0026#34;form\u0026#34;].resetFields(); } }); } else { updateInfo(this.form).then((res) =\u0026gt; { console.log(\u0026#34;更新\u0026#34;); if (res.data.status === 200) { this.getData(); this.$message({ type: \u0026#34;success\u0026#34;, message: res.data.message }); this.dialogFormVisible = false; this.$refs[\u0026#34;form\u0026#34;].resetFields(); } }); } } }); },   清空之前的form表单避免验证  方法一：@close=\u0026ldquo;close\u0026rdquo; 和 destroy-on-close\nclose Dialog关闭的回调\u0026ndash;清空表单\ndestroy-on-close\t关闭时销毁 Dialog 中的元素\tboolean\t—\tfalse  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;template\u0026gt; \u0026lt;el-dialog :destroy-on-close=\u0026#34;true\u0026#34; @close=\u0026#34;close\u0026#34;\u0026gt; \u0026lt;/el-dialog\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; close() { this.form = { name: \u0026#34;\u0026#34;, sex: \u0026#34;1\u0026#34;, age: \u0026#34;\u0026#34;, father: \u0026#34;\u0026#34;, mather: \u0026#34;\u0026#34;, address: \u0026#34;\u0026#34;, time: \u0026#34;\u0026#34;, phone: \u0026#34;\u0026#34;, }; }, \u0026lt;/script\u0026gt;    PS:报错：[Vue warn]: Invalid prop: type check failed for prop “xxx“.Expected Boolean, got String with value\n解决方案：\nElement UI官方文档中，只需要在 destroy-on-close 前面加冒号 : 就能解决标红。\n 方法二：   在el-form标签中添加 :validate-on-rule-change=\u0026ldquo;false\u0026rdquo; 属性\n使用 this.$refs[formName].clearValidate();\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;el-form :model=\u0026#34;form\u0026#34; :rules=\u0026#34;rules\u0026#34; ref=\u0026#34;form\u0026#34; :validate-on-rule-change=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;/el-form\u0026gt; \u0026lt;script\u0026gt; addStudent() { this.form = { name: \u0026#34;\u0026#34;, sex: \u0026#34;1\u0026#34;, age: \u0026#34;\u0026#34;, father: \u0026#34;\u0026#34;, mather: \u0026#34;\u0026#34;, address: \u0026#34;\u0026#34;, time: \u0026#34;\u0026#34;, phone: \u0026#34;\u0026#34;, }; if (this.$refs[\u0026#34;form\u0026#34;]) { this.$nextTick(() =\u0026gt; { this.$refs[\u0026#34;form\u0026#34;].clearValidate(); }); } } \u0026lt;/script\u0026gt;   避免编辑双向绑定 { ...row }\n1 2 3 4 5 6  edit(row) { this.dialogFormVisible = true; console.log(row); this.form = { ...row }; this.status = false; },   删除确定弹窗 this.$confirm().then().catch()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;script\u0026gt; del(row) { // console.log(row);  this.$confirm(\u0026#34;确定要删除？\u0026#34;, \u0026#34;提示\u0026#34;, { confirmButtonText: \u0026#34;确定\u0026#34;, cancelButtonText: \u0026#34;取消\u0026#34;, type: \u0026#34;warning\u0026#34;, // showCancelButton: false, //是否显示取消按钮  // showClose: false, //是否显示右上角的x  closeOnClickModal: true, //是否可以点击空白处关闭弹窗  }) .then(() =\u0026gt; { delInfo(row.id).then((res) =\u0026gt; { if (res.data.status === 200) { this.getData(); this.$message({ message: res.data.message, type: \u0026#34;success\u0026#34; }); } }); }) .catch(() =\u0026gt; { this.$message({ message: \u0026#34;已取消删除\u0026#34;, type: \u0026#34;info\u0026#34; }); }); }, \u0026lt;/script\u0026gt;   表格数据获取封装 在utils/table.js中内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;script\u0026gt; //作业列表获取表格数据 export function getTableData(root, url, params, arr) { root.service.get(url, { params: params || {} }).then((res) =\u0026gt; { if (res.data.status === 200) { root.tableData = res.data.data root.total = res.data.total root.tableData.map(item =\u0026gt; { arr.map(aItem =\u0026gt; { item[aItem] ? item[aItem + \u0026#39;_text\u0026#39;] = \u0026#39;是\u0026#39; : item[aItem + \u0026#39;_text\u0026#39;] = \u0026#39;否\u0026#39; }) }) } }).catch((err) =\u0026gt; { throw err }) } \u0026lt;/script\u0026gt;   分页组件的封装和使用  步骤一：封装\n新增 /components/common/Pageing.vue:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;el-pagination @size-change=\u0026#34;handleSizeChange\u0026#34; @current-change=\u0026#34;handleCurrentChange\u0026#34; :current-page=\u0026#34;page\u0026#34; :page-sizes=\u0026#34;[5, 10, 15, 20]\u0026#34; :page-size=\u0026#34;size\u0026#34; layout=\u0026#34;total, sizes, prev, pager, next, jumper\u0026#34; :total=\u0026#34;total\u0026#34; :url=\u0026#34;url\u0026#34; \u0026gt; \u0026lt;/el-pagination\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; import { getTableData } from \u0026#34;@/utils/table\u0026#34;; export default { props: { total: Number, url: String, }, data() { return { page: 1, size: 5, }; }, created() { getTableData(this.$parent, \u0026#34;/works\u0026#34;, { page: this.page, size: this.size }, [ \u0026#34;completed\u0026#34;, ]); }, methods: { handleSizeChange(val) { this.size = val; this.page = 1; getTableData(this.$parent, \u0026#34;/works\u0026#34;, { page: this.page, size: val }, [ \u0026#34;completed\u0026#34;, ]); // console.log(`每页 ${val} 条`);  }, handleCurrentChange(val) { this.page = val; getTableData(this.$parent, \u0026#34;/works\u0026#34;, { page: this.page, size: val }, [ \u0026#34;completed\u0026#34;, ]); // console.log(`当前页: ${val}`);  }, }, }; \u0026lt;/script\u0026gt;   步骤二：定义传参  1 2 3 4 5 6 7 8 9 10  \u0026lt;template\u0026gt; :total=\u0026#34;total\u0026#34; :url=\u0026#34;url\u0026#34; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; props: { total: Number, url: String, } \u0026lt;/script\u0026gt;   步骤三：使用  1 2 3 4 5 6 7 8  1.引入组件： import Page from \u0026#34;@/components/common/Pageing.vue\u0026#34;; 2.注册组件： components: { Page, }, 3.使用组件： \u0026lt;Page :total=\u0026#34;total\u0026#34; :ur=\u0026#34;url\u0026#34; /\u0026gt;   echarts 使用 安装 cnpm i -D echarts@4\n挂载使用 在main.js中：\n1 2  import echarts from \u0026#39;echarts\u0026#39; Vue.prototype.$echarts = echarts   之后全局中就可以使用 this.$echarts 了\n图形渲染 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;data-view\u0026#34;\u0026gt; \u0026lt;el-card\u0026gt; \u0026lt;div id=\u0026#34;main1\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/el-card\u0026gt; \u0026lt;el-card\u0026gt; \u0026lt;div id=\u0026#34;main2\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/el-card\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; import { dataview } from \u0026#34;@/api/api\u0026#34;; export default { data() { return {}; }, created() { dataview() .then((res) =\u0026gt; { console.log(res); if (res.data.status === 200) { let { legend, xAxis, series } = res.data.data; this.draw(legend, xAxis, series); } }) .catch((err) =\u0026gt; { throw err; }); }, mounted() { let myChart = this.$echarts.init(document.getElementById(\u0026#34;main1\u0026#34;)); myChart.setOption({ title: { text: \u0026#34;大佬进阶班\u0026#34;, }, tooltip: {}, xAxis: { data: [\u0026#34;一班\u0026#34;, \u0026#34;二班\u0026#34;, \u0026#34;三班\u0026#34;, \u0026#34;四班\u0026#34;, \u0026#34;五班\u0026#34;, \u0026#34;六班\u0026#34;], }, yAxis: {}, series: [ { name: \u0026#34;人数\u0026#34;, type: \u0026#34;line\u0026#34;, data: [32, 22, 11, 66, 65, 89], }, ], }); }, methods: { draw(legend, xAxis, series) { let myChart1 = this.$echarts.init(document.getElementById(\u0026#34;main2\u0026#34;)); let option = { title: { text: \u0026#34;会话量\u0026#34;, }, tooltip: { trigger: \u0026#34;axis\u0026#34;, }, legend: { data: legend, }, xAxis: { type: \u0026#34;category\u0026#34;, data: xAxis, }, yAxis: { type: \u0026#34;value\u0026#34;, }, series: series, }; myChart1.setOption(option); }, }, }; \u0026lt;/script\u0026gt;   树形控件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;userList\u0026#34;\u0026gt; \u0026lt;el-tree :data=\u0026#34;menus\u0026#34; show-checkbox node-key=\u0026#34;id\u0026#34; :props=\u0026#34;defaultProps\u0026#34;\u0026gt; \u0026lt;/el-tree\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; export default { data() { return { menus: [], defaultProps: { children: \u0026#34;children\u0026#34;, label: \u0026#34;name\u0026#34;, }, }; }, created() { this.menus = [...this.$router.options.routes]; console.log(this.$router.options.routes); }, }; \u0026lt;/script\u0026gt;   权限管理和动态路由  思路：\n1.根据不同的用户登录上来，返回对应的路由权限菜单\n2.通过树形控件达到权限的精准控制，根据不同角色，勾选不同的菜单权限，将菜单数据提交给后端进行保存\n3.后端保存之后，在用户进行登录的时候就会查询该用户或该角色所拥有的菜单数据，最终进行动态的渲染展示\n4.动态添加路由使用 router.addRoutes (vue-router3.x版本方法，已废弃)方法，后续使用 router.addRoute 进行动态路由添加\n 权限节点获取 element组件tree的方法：getCheckedNodes\n说明：若节点可被选择（即 show-checkbox 为 true），则返回目前被选中的节点所组成的数组\n(leafOnly, includeHalfChecked) 接收两个 boolean 类型的参数，1. 是否只是叶子节点，默认值为 false 2. 是否包含半选节点，默认值为 false\n实现：\n 步骤一：el-tree组件中添加ref=\u0026ldquo;tree\u0026rdquo;  1 2 3  \u0026lt;el-tree :data=\u0026#34;menus\u0026#34; show-checkbox node-key=\u0026#34;id\u0026#34; :props=\u0026#34;defaultProps\u0026#34; ref=\u0026#34;tree\u0026#34;\u0026gt; \u0026lt;/el-tree\u0026gt;   步骤二：绑定获取节点方法  1  \u0026lt;el-button @click=\u0026#34;getCheckedNodesFunc\u0026#34;\u0026gt;通过node获取\u0026lt;/el-button\u0026gt;   步骤三：this.$refs.tree.getCheckedNodes()  1 2 3 4 5 6 7 8  \u0026lt;script\u0026gt; methods: { getCheckedNodesFunc() { let arr = this.$refs.tree.getCheckedNodes(); console.log(arr); }, }, \u0026lt;/script\u0026gt;   路由导航守卫 在main.js中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import { getToken } from \u0026#34;@/utils/setToken.js\u0026#34;; //路由导航守卫 router.beforeEach((to, from, next) =\u0026gt; { if (!getToken(\u0026#34;username\u0026#34;)) { if (to.path !== \u0026#39;/login\u0026#39;) { console.log(\u0026#34;from.path == \u0026#34;, from.path) console.log(\u0026#34;to.path !== /login\u0026#34;) next(\u0026#39;/login\u0026#39;) } else next() } next() }) new Vue({ router, render: h =\u0026gt; h(App), }).$mount(\u0026#39;#app\u0026#39;)    ps:如果报错 Error: Navigation cancelled from “/\u0026hellip;“ to “/\u0026hellip;“ with a new navigation\n在src/router/index.js内添加：\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import Vue from \u0026#34;vue\u0026#34;; import Router from \u0026#39;vue-router\u0026#39; Vue.use(Router) //解决编程式路由往同一地址跳转时会报错的情况 const originalPush = Router.prototype.push; const originalReplace = Router.prototype.replace; //push Router.prototype.push = function push(location, onResolve, onReject) { if (onResolve || onReject) return originalPush.call(this, location, onResolve, onReject); return originalPush.call(this, location).catch(err =\u0026gt; err); }; //replace Router.prototype.replace = function push(location, onResolve, onReject) { if (onResolve || onReject) return originalReplace.call(this, location, onResolve, onReject); return originalReplace.call(this, location).catch(err =\u0026gt; err); }; export default new Router({...})   ","description":"通用后台管理系统","id":50,"section":"stack","tags":["javascript",""],"title":"通用后台管理系统","uri":"http://wangjinbao.netlify.app/en/stack/javascript/system/"},{"content":"1 minikube搭建kubernetes集群环境 1.1 安装minikube minikube的安装：\n1 2 3 4 5 6 7 8 9  # macOS brew install minikube # Windows choco install minikube # Linux curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube   也可以到官网直接下载安装包来安装：https://minikube.sigs.k8s.io/docs/start/\n1.2 启动minikube 1 2  # 启动minikube minikube start   2. Multipass和k3s搭建kubernetes集群环境 minikube只能用来在本地搭建一个单节点的kubernetes集群环境，\n下面介绍如何使用Multipass和k3s来搭建一个多节点的kubernetes集群环境，\n2.1 Multipass介绍 Multipass是一个轻量级的虚拟机管理工具，\n可以用来在本地快速创建和管理虚拟机，\n相比于VirtualBox或者VMware这样的虚拟机管理工具，\nMultipass更加轻量快速，\n而且它还提供了一些命令行工具来方便我们管理虚拟机。\n官方网址: https://Multipass.run/\n2.2 安装Multipass 1 2 3 4 5 6 7 8  # macOS brew install multipass # Windows choco install multipass # Linux sudo snap install multipass   2.3 Multipass常用命令 关于Multipass的一些常用命令我们可以通过multipass help来查看，\n这里大家只需要记住几个常用的命令就可以了，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  # 查看帮助 multipass help multipass help \u0026lt;command\u0026gt; # 创建一个名字叫做k3s的虚拟机 multipass launch --name k3s # 在虚拟机中执行命令 multipass exec k3s -- ls -l # 进入虚拟机并执行shell multipass shell k3s # 查看虚拟机的信息 multipass info k3s # 停止虚拟机 multipass stop k3s # 启动虚拟机 multipass start k3s # 删除虚拟机 multipass delete k3s # 清理虚拟机 multipass purge # 查看虚拟机列表 multipass list # 挂载目录（将本地的~/kubernetes/master目录挂载到虚拟机中的~/master目录） multipass mount ~/kubernetes/master master:~/master   Multipass有个问题，\n每次M1芯片的Mac升级之后Multipass的虚拟机都会被删除，\n不知道大家有没有遇到类似的问题。\n1 2 3 4  # 镜像位置 /var/root/Library/Application Support/multipassd/qemu/vault/instances # 配置文件 /var/root/Library/Application Support/multipassd/qemu/multipassd-vm-instances.json   2.4 k3s介绍 k3s 是一个轻量级的Kubernetes发行版，它是 Rancher Labs 推出的一个开源项目，\n旨在简化Kubernetes的安装和维护，同时它还是CNCF认证的Kubernetes发行版。\n2.5 创建和配置master节点 首先我们需要使用multipass创建一个名字叫做k3s的虚拟机，\n1  multipass launch --name k3s --cpus 2 --memory 8G --disk 10G   虚拟机创建完成之后，\n可以配置SSH密钥登录，\n不过这一步并不是必须的，\n即使不配置也可以通过multipass exec或者multipass shell命令来进入虚拟机，\n然后我们需要在master节点上安装k3s，\n使用k3s搭建kubernetes集群非常简单，\n只需要执行一条命令就可以在当前节点上安装k3s，\n打开刚刚创建的k3s虚拟机，\n执行下面的命令就可以安装一个k3s的master节点，\n1 2  # 安装k3s的master节点 curl -sfL https://get.k3s.io | sh -   国内用户可以换成下面的命令，使用ranher的镜像源来安装：\n1  curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -   安装完成之后，可以通过kubectl命令来查看集群的状态，\n1  sudo kubectl get nodes   2.6 创建和配置worker节点 接下来需要在这个master节点上获取一个token，\n用来作为创建worker节点时的一个认证凭证，\n它保存在/var/lib/rancher/k3s/server/node-token这个文件里面，\n我们可以使用sudo cat命令来查看一下这个文件中的内容，\n1  sudo cat /var/lib/rancher/k3s/server/node-token   将TOKEN保存到一个环境变量中\n1  TOKEN=$(multipass exec k3s sudo cat /var/lib/rancher/k3s/server/node-token)   保存master节点的IP地址\n1  MASTER_IP=$(multipass info k3s | grep IPv4 | awk \u0026#39;{print $2}\u0026#39;)   确认：\n1  echo $MASTER_IP   使用刚刚的TOKEN和MASTER_IP来创建两个worker节点\n并把它们加入到集群中\n1 2 3 4 5 6 7 8  # 创建两个worker节点的虚拟机 multipass launch --name worker1 --cpus 2 --memory 8G --disk 10G multipass launch --name worker2 --cpus 2 --memory 8G --disk 10G # 在worker节点虚拟机上安装k3s for f in 1 2; do multipass exec worker$f -- bash -c \u0026#34;curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=\\\u0026#34;https://$MASTER_IP:6443\\\u0026#34; K3S_TOKEN=\\\u0026#34;$TOKEN\\\u0026#34; sh -\u0026#34; done   这样就完成了一个多节点的kubernetes集群的搭建。\n3. 在线实验环境 Killercoda\nPlay-With-K8s\n4. kubectl常用命令 4.1 基础使用 1 2 3 4 5 6 7 8  # 查看帮助 kubectl --help # 查看API版本 kubectl api-versions # 查看集群信息 kubectl cluster-info   4.2 资源的创建和运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 创建并运行一个指定的镜像 kubectl run NAME --image=image [params...] # e.g. 创建并运行一个名字为nginx的Pod kubectl run nginx --image=nginx # 根据YAML配置文件或者标准输入创建资源 kubectl create RESOURCE # e.g. # 根据nginx.yaml配置文件创建资源 kubectl create -f nginx.yaml # 根据URL创建资源 kubectl create -f https://k8s.io/examples/application/deployment.yaml # 根据目录下的所有配置文件创建资源 kubectl create -f ./dir # 通过文件名或标准输入配置资源 kubectl apply -f (-k DIRECTORY | -f FILENAME | stdin) # e.g. # 根据nginx.yaml配置文件创建资源 kubectl apply -f nginx.yaml   4.3 查看资源信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # 查看集群中某一类型的资源 kubectl get RESOURCE # 其中，RESOURCE可以是以下类型： kubectl get pods / po # 查看Pod kubectl get svc # 查看Service kubectl get deploy # 查看Deployment kubectl get rs # 查看ReplicaSet kubectl get cm # 查看ConfigMap kubectl get secret # 查看Secret kubectl get ing # 查看Ingress kubectl get pv # 查看PersistentVolume kubectl get pvc # 查看PersistentVolumeClaim kubectl get ns # 查看Namespace kubectl get node # 查看Node kubectl get all # 查看所有资源 # 后面还可以加上 -o wide 参数来查看更多信息 kubectl get pods -o wide # 查看某一类型资源的详细信息 kubectl describe RESOURCE NAME # e.g. 查看名字为nginx的Pod的详细信息 kubectl describe pod nginx   4.4 资源的修改、删除和清理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # 更新某个资源的标签 kubectl label RESOURCE NAME KEY_1=VALUE_1 ... KEY_N=VALUE_N # e.g. 更新名字为nginx的Pod的标签 kubectl label pod nginx app=nginx # 删除某个资源 kubectl delete RESOURCE NAME # e.g. 删除名字为nginx的Pod kubectl delete pod nginx # 删除某个资源的所有实例 kubectl delete RESOURCE --all # e.g. 删除所有Pod kubectl delete pod --all # 根据YAML配置文件删除资源 kubectl delete -f FILENAME # e.g. 根据nginx.yaml配置文件删除资源 kubectl delete -f nginx.yaml # 设置某个资源的副本数 kubectl scale --replicas=COUNT RESOURCE NAME # e.g. 设置名字为nginx的Deployment的副本数为3 kubectl scale --replicas=3 deployment/nginx # 根据配置文件或者标准输入替换某个资源 kubectl replace -f FILENAME # e.g. 根据nginx.yaml配置文件替换名字为nginx的Deployment kubectl replace -f nginx.yaml   4.5 调试和交互 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # 进入某个Pod的容器中 kubectl exec [-it] POD [-c CONTAINER] -- COMMAND [args...] # e.g. 进入名字为nginx的Pod的容器中，并执行/bin/bash命令 kubectl exec -it nginx -- /bin/bash #如果pod中有多个容器，需要指定名称 kubectl exec nginx-pod -c XXX(容器名称) -it -- /bin/bash # 查看某个Pod的日志 kubectl logs [-f] [-p] [-c CONTAINER] POD [-n NAMESPACE] # e.g. 查看名字为nginx的Pod的日志 kubectl logs nginx # 将某个Pod的端口转发到本地 kubectl port-forward POD [LOCAL_PORT:]REMOTE_PORT [...[LOCAL_PORT_N:]REMOTE_PORT_N] # e.g. 将名字为nginx的Pod的80端口转发到本地的8080端口 kubectl port-forward nginx 8080:80 # 连接到现有的某个Pod（将某个Pod的标准输入输出转发到本地） kubectl attach POD -c CONTAINER # e.g. 将名字为nginx的Pod的标准输入输出转发到本地 kubectl attach nginx # 运行某个Pod的命令 kubectl run NAME --image=image -- COMMAND [args...] # e.g. 运行名字为nginx的Pod kubectl run nginx --image=nginx -- /bin/bash   5. Portainer的安装和使用 Portainer 是一个轻量级的容器管理工具，\n可以用来管理Docker和Kubernetes，\n它提供了一个Web界面来方便我们管理容器，\n官方网址: https://www.portainer.io/\n5.1 安装Portainer 1 2  # 创建一个名字叫做portainer的虚拟机 multipass launch --name portainer --cpus 2 --memory 8G --disk 10G   当然也可以直接安装在我们刚刚创建的master节点上，\n1 2  # 在master节点上安装portainer，并将其暴露在NodePort 30777上 kubectl apply -n portainer -f https://downloads.portainer.io/ce2-19/portainer.yaml   或者使用Helm安装\n1 2  # 使用Helm安装Portainer helm upgrade --install --create-namespace -n portainer portainer portainer/portainer --set tls.force=true   然后直接访问 https://localhost:30779/ 或者 http://localhost:30777/ 就可以了，\n6. Helm的安装和使用 Helm 是一个Kubernetes的包管理工具，\n可以用来管理Kubernetes的应用，\n它提供了一个命令行工具来方便我们管理Kubernetes的应用，\n官方网址: https://helm.sh/\n6.1 安装Helm 使用包管理器安装：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # macOS brew install helm # Windows choco install kubernetes-helm # 或者 scoop install helm # Linux（Debian/Ubuntu） curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg \u0026gt; /dev/null sudo apt-get install apt-transport-https --yes echo \u0026#34;deb [arch=$(dpkg --print-architecture)signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main\u0026#34; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list sudo apt-get update sudo apt-get install helm # Linux（CentOS/Fedora） sudo dnf install helm # Linux（Snap） sudo snap install helm --classic # Linux（FreeBSD） pkg install helm   使用脚本安装\n1 2 3  $ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 $ chmod 700 get_helm.sh $ ./get_helm.sh   或者\n1  curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash   ","description":"本地部署k8s集群及包管理工具使用。","id":51,"section":"stack","tags":["docker"],"title":"本地部署k8s集群及包管理工具使用","uri":"http://wangjinbao.netlify.app/en/stack/k8s/k8s1/"},{"content":"组件介绍  ElasticSearch：日志存储 + 索引 + 搜索 Fluentd：日志采集、装饰、转换和传输 Kibana：日志查询展示 生产环境 + Kafka  minikube环境搭建EFK  Fluentd DaemonSet 也可以采用minikube efk addon ,更简单  配置信息如下： 新建目录： /Users/wangdante/D/myk8s/efk\n1 2 3 4 5 6 7  tree efk efk ├── elastic.yml ├── fluentd-daemonset.yml ├── fluentd-rbac.yml ├── kibana.yml └── ns.yml   ns.yml: 1 2 3 4  apiVersion:v1kind:Namespacemetadata:name:logging  elastic.yml: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  apiVersion:apps/v1kind:Deploymentmetadata:name:elasticsearchnamespace:loggingspec:selector:matchLabels:component:elasticsearchtemplate:metadata:labels:component:elasticsearchspec:containers:- name:elasticsearchimage:docker.elastic.co/elasticsearch/elasticsearch:6.5.4env:- name:discovery.typevalue:single-nodeports:- containerPort:9200name:httpprotocol:TCPresources:limits:cpu:500mmemory:2Girequests:cpu:500mmemory:2Gi---apiVersion:v1kind:Servicemetadata:name:elasticsearchnamespace:logginglabels:service:elasticsearchspec:type:NodePortselector:component:elasticsearchports:- port:9200targetPort:9200nodePort:31200  kibana.yml: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  apiVersion:apps/v1kind:Deploymentmetadata:name:kibananamespace:loggingspec:selector:matchLabels:run:kibanatemplate:metadata:labels:run:kibanaspec:containers:- name:kibanaimage:docker.elastic.co/kibana/kibana:6.5.4env:- name:ELASTICSEARCH_URLvalue:http://elasticsearch:9200- name:XPACK_SECURITY_ENABLEDvalue:\u0026#34;true\u0026#34;ports:- containerPort:5601name:httpprotocol:TCP---apiVersion:v1kind:Servicemetadata:name:kibananamespace:logginglabels:service:kibanaspec:type:NodePortselector:run:kibanaports:- port:5601targetPort:5601nodePort:31601  fluentd-rbac.yml: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  apiVersion:apps/v1kind:ServiceAccountmetadata:name:fluentdnamespace:kube-system---apiVersion:rbac.authorization.k8s.io/v1beta1kind:ClusterRolemetadata:name:fluentdnamespace:kube-systemrules:- apiGroups:- \u0026#34;\u0026#34;resources:- pods- namespacesverbs:- get- list- watch---kind:ClusterRoleBindingapiVersion:rbac.authorization.k8s.io/v1beta1metadata:name:fluentdroleRef:kind:ClusterRolename:fluentdapiGroup:rbac.authorization.k8s.iosubjects:- kind:ServiceAccountname:fluentdnamespace:kube-system  fluentd-daemonset.yml: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  apiVersion:apps/v1kind:DaemonSetmetadata:name:fluentdnamespace:kube-systemlabels:k8s-app:fluentd-loggingversion:v1kubernetes.io/cluster-service:\u0026#34;true\u0026#34;spec:selector:matchLabels:k8s-app:fluentd-loggingversion:v1template:metadata:labels:k8s-app:fluentd-loggingversion:v1kubernetes.io/cluster-service:\u0026#34;true\u0026#34;spec:serviceAccount:fluentdserviceAccountName:fluentdtolerations:- key:node-role.kubernetes.io/mastereffect:NoSchedulecontainers:- name:fluentdimages:fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearchenv:- name:FLUENT_ELASTICSEARCH_HOSTvalue:\u0026#34;elasticsearch.logging\u0026#34;- name:FLUENT_ELASTICSEARCH_PORTvalue:\u0026#34;9200\u0026#34;- name:FLUENT_ELASTICSEARCH_SCHEMEvalue:\u0026#34;http\u0026#34;- name:FLUENT_UIDvalue:\u0026#34;0\u0026#34;- name:FLUENTD_SYSTEMD_CONFvalue:disableresource:limit:memory:200Mirequests:cpu:100mmemgory:200MivolumeMounts:- name:varlogmountPath:/var/log- name:varlibdockercontainersmountPath:/var/lib/docker/containersreadOnly:trueterminationGracePeriodSeconds:30volumes:- name:varloghostPath:path:/var/log- name:varlibdockercontainershostPath:path:/var/lib/docker/containers---apiVersion:rbac.authorization.k8s.io/v1beta1kind:ClusterRolemetadata:name:fluentdnamespace:kube-systemrules:- apiGroups:- \u0026#34;\u0026#34;resources:- pods- namespacesverbs:- get- list- watch---kind:ClusterRoleBindingapiVersion:rbac.authorization.k8s.io/v1beta1metadata:name:fluentdroleRef:kind:ClusterRolename:fluentdapiGroup:rbac.authorization.k8s.iosubjects:- kind:ServiceAccountname:fluentdnamespace:kube-system  发布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  $ kubectl apply -f ns.yml $ kubectl get ns NAME STATUS AGE default Active 111m kube-node-lease Active 111m kube-public Active 111m kube-system Active 111m kubernetes-dashboard Active 102m logging Active 20s $ kubectl apply -f elastic.yml deployment.apps/elasticsearch created service/elasticsearch created $ kubectl get all -n logging NAME READY STATUS RESTARTS AGE pod/elasticsearch-659897658c-smhb7 1/1 Running 0 44s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/elasticsearch NodePort 10.102.0.244 \u0026lt;none\u0026gt; 9200:31200/TCP 45s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/elasticsearch 1/1 1 1 45s NAME DESIRED CURRENT READY AGE replicaset.apps/elasticsearch-659897658c 1 1 1 45s   1 2 3 4 5 6 7 8 9 10  $ minikube service list |----------------------|---------------------------|--------------|-----| | NAMESPACE | NAME | TARGET PORT | URL | |----------------------|---------------------------|--------------|-----| | default | kubernetes | No node port | | | kube-system | kube-dns | No node port | | | kubernetes-dashboard | dashboard-metrics-scraper | No node port | | | kubernetes-dashboard | kubernetes-dashboard | No node port | | | logging | elasticsearch | 9200 | | |----------------------|---------------------------|--------------|-----|   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  $ kubectl apply -f kibana.yml deployment.apps/kibana created service/kibana created $ kubectl get all -n logging NAME READY STATUS RESTARTS AGE pod/elasticsearch-659897658c-smhb7 1/1 Running 0 5m36s pod/kibana-78fdff978c-kkpgv 0/1 ContainerCreating 0 9s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/elasticsearch NodePort 10.102.0.244 \u0026lt;none\u0026gt; 9200:31200/TCP 5m37s service/kibana NodePort 10.105.62.205 \u0026lt;none\u0026gt; 5601:31601/TCP 9s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/elasticsearch 1/1 1 1 5m37s deployment.apps/kibana 0/1 1 0 9s NAME DESIRED CURRENT READY AGE replicaset.apps/elasticsearch-659897658c 1 1 1 5m37s replicaset.apps/kibana-78fdff978c 1 1 0 9s    PS:端口转发：\nkubectl port-forward --address 0.0.0.0 -n logging kibana-78fdff978c-kkpgv 31602:5601\n ","description":"ElasticSearch、Fluentd、Kibana组成的日志监控平台","id":52,"section":"stack","tags":["docker"],"title":"EFK日志监控平台部署架构","uri":"http://wangjinbao.netlify.app/en/stack/k8s/efk/"},{"content":"1、利用肢体语言表达关心 善用肢体语言 让对方感受到你的专注，有时候多说无意，只要给予对方一个微笑，或适时的点头，就能表达出内心的支持，\n对此不妨尝试 SOLER 倾听法，\n S:面向对方（Squarely）\n停下手头的事情，避免单向沟通 O：采取开放的姿态（Open）\n把自己想像成一个杯子，接纳对方所说的话，双手不要抱在胸前，可自然放在膝盖上， L：上半身微微向对方前倾（Lean）\n能让对方想多了解他 E：眼神接触（Eye Contact）\n注视对方，让其感受到尊重 R：放松（Relax）\n身体轻松自然  2、用简短的响应引导对方多说话 对于朋友向你倾诉的烦恼，你该扮演的角色应该是，鼓励对方多说话的听众，让对方从梳理自己的思绪当中，自己解决问题，反而能让对方有自我成长的机会，但给予对方说话空间的同时，也要注意你的倾听过程和响应，能让对方感受到你的关心和支持，\n3、发挥同理心去倾听对方的声音 一段倾听是否能让人感到温暖，关键就在于，听者能否走出自己的世界，去贴近对方，现在经历的各种情绪（站点对方的角度）\n4、谨慎地给予忠告 当说话者对于，想要解决的问题，感到不知所措时，他可能需要的并不是情绪上的支持或安慰，而是希望能寻求协助，此时我们还是可以提供具体的建议给对方，\n但是在说话前应该要注意2件事（1，心态，真的想帮助。2，需求，开口前\u0026quot;你觉得我可以怎么样帮你呢？\u0026quot; \u0026ldquo;我能帮上什么忙吗？\u0026ldquo;听听我的想法？\u0026quot;），可确认对方是不是要自己的忠告\n总结  利用肢体语言表达关心 用简短的响应引导对方多说话 发挥同理心去倾听对方的声音 谨慎地给予忠告  ","description":"4个倾听技术，让你和谁都聊得来","id":54,"section":"stack","tags":["career"],"title":"4个倾听技术，让你和谁都聊得来","uri":"http://wangjinbao.netlify.app/en/stack/career/qtjq/"},{"content":"背景 小A：\u0026ldquo;我有一个提议想听听您的意见，我们的对手挖走了本公司的过半销售员，我认为我们需要改变公司吸引及激励人才的机制\u0026rdquo;\n经理：\u0026ldquo;考虑到销售部门工作低效且不规范，如此严重的人员流失见怪不怪了，\u0026rdquo;\n小A：\u0026ldquo;所以我们需要重组销售部门，引进本行业内招聘及管理人才的最佳体制\u0026rdquo;\n经理：\u0026ldquo;你的建议会不会让人才流失的更快呢？有没有具体方案和处理措施呢？\u0026rdquo;\n小A：\u0026ldquo;呃。。。\u0026rdquo;\n建议能给公司带来多少效益，是说服上司的有效方法，如果你不充值说明你的建议如何实现公司的战略目标，比如如何解决人才流失的问题，那这个方案就显得无足轻重了，\n在自上而下的等级制下，有的中层管理者担心自己的建议一旦效果不理想，反而引火烧身，有的出于太多苦衷，他们不得不屈从于上级，并对其想法和关注的问题只字不提，\n有的却是因为自己建议的理论依据不充分，准备工作不足而被上司拒绝，但作为公司的中层管理者，如果无法建立并推广革新理念，组织就不能蓬勃发展，因为中层员工能够直接接触到顾客、供应商及同事。\n因此汇总了各路宝贵意见，他们所处位置利于其判断某种产品的市场成熟与否，或者提早觉察出某合作项目可能不会成功，那么，作为中层管理者，该如何成功的推销自己的建议呢？\n解决方案 策略如下：  定制推销方案\n定制推销方案对能否成功说服决策者起决定作用，中层管理者首先应熟悉并综合考虑上司的价值观，学识以及所要达成的目标，然后定制特色推销方案，根据收集的意见反馈，起草一份建议书，阐述建议，并适当美化表述方式，\n方案不仅针对领导所关心的问题，还涵盖了对实现公司预期收入目标的建议，一份书面方案和一次报告既让你省去了召开各种会议之苦，又让你站在更高的平台上，讲出自己的主张，并赢得该有的支持 控制自我和听众情绪\n由于建议推销涉及人际往来，而且建议争议性往往很大，所以中层管理者推广建议时，难免会情绪波动，如果他们的激情表现得恰如其分，比如很激励人心，而不是马景涛式咆哮，就很有可能引起关注，并带动更多人行动，激情与愤怒只有一线之隔，\n尽管中层管理者的强烈情绪可以激发上司有所行动，但是不加控制地释放情绪反而会导致事倍功半，中层管理者 不仅要控制自己的情绪，还要留意并控制决策者的情绪，二者都决定了你能否推销成功，\n推销者想说服决策者，就要 激发他们的正面情绪，比如强调建议将带来的效益或可行性 看准时机\n看准时机后再提出建议也很关键，时机可能出现在 公司工作重心转移的时候， 可能出现在 公司员工变动的时候 ， 也可能出现在 上司关注点转变的时候\n中层管理者能观察到自己的建议，能联系上哪些大众日渐关注的话题或潮流，顺水推舟，让建议向受关注的热点靠拢，除了要警惕大趋势和大事件外，还应考虑到建议的紧迫性 结盟\n如果能联合更多人发起倡议，效果比单打独斗要好得多，如果有很多人不遗余力参与进来，那方案支持者中，有人可能掌握重要数据，有人可能和你要劝说的高管有私交，可以利用自己的人脉，也可以联合没有交集的人，这会帮你吸收到更多可能支持你或给你专业帮助的人 衡量场合\n中层管理者须清楚领导一般根据什么数据做决策。他们喜欢以何种方式接收信息，以及他们是否倾向于支持和自己观点一致的提议。弄清楚这些规则后，可通过闲谈表达个人意见（私下事前通所），并避免让上司在公共场合感到难堪，但正式手段更有威慑力，能给决策者施压，\n在明确公司目标后，应权衡使用哪种手段更为恰当 给出解决方案\n人们通常认为，他们要是提出问题，最好也要给出解决方案，给出解决方案，能证明自己认真思考了建议，并尊重领导的时间。\n有些问题的最佳解决方法要通过集合多人智慧、经验及专长，讨论出对策，对于这种情况，若认为很有必要提出某个建议，却没想到解决方案，可以 先给出解决此问题的基本思路 ，这样做既遵循了规则 ，给出了解决思路，\n同时也让更多人及时并积极参与到问题的讨论中  总结 综合以上，三点：\n 战略性：\n指必须清楚组织目标，如何实现这些目标以及决策者所起作用， 关联性\n指中层管理者必须明白谁会关心其建议，谁会受到影响，谁会反对等 了解组织规则\n指的会选择最佳方法，地点和时机，说出自己的想法和关注的问题，他们会利用修辞技工，政治敏感话题以及人脉，使公司决策者授受自己的方案  ","description":"六个小策略教你成功推销建议","id":55,"section":"stack","tags":["career"],"title":"六个小策略教你成功推销建议","uri":"http://wangjinbao.netlify.app/en/stack/career/txjy/"},{"content":"沟通技巧 如何有效提建议\n场景 小A是某商场市场部的职员，一直希望能够在职场上大显身手，一天你拿着建议书来到了经理办公室，\n小A:\u0026ldquo;经理，我想在圣诞节开展宣传活动，提高商场知名度\u0026rdquo;\n经理：\u0026ldquo;很好，你有什么建议吗？\u0026rdquo;\n小A:\u0026ldquo;我觉得可以组织关于圣诞的故事秀或时尚秀\u0026rdquo;\n经理：\u0026ldquo;这样应该需要不少的费用吧？你还有没有其他的方案？\u0026rdquo;\n小A:\u0026ldquo;额，也可以降价促销\u0026rdquo;\n经理：\u0026ldquo;这跟其他商场比起来我们没有什么优势呀\u0026rdquo;\n小A:\u0026ldquo;额，现场抽奖也很吸引人\u0026rdquo;\n经理：\u0026ldquo;那这种方案的成本大概是多少呢？\u0026rdquo;\n小A:\u0026ldquo;我还不确定\u0026rdquo;\n经理：\u0026ldquo;那我先考虑一下，再给答复\u0026rdquo;\n一周后，建议石沉大海\n解决方案  做好事前准备\n预则立，凡事做好充分的准备，才能让自己的观点站得住脚，小A因为没有做好事前的准备，不能对方案提供详细说明，当然不能说服领导\n如果提前做好知识积累，掌握一手资料，预告设想领导会提出什么问题，自己要怎样回答，那么在提建议时才会逻辑清晰，观点明确，让沟通更有效， 用数据说明\n数据是最真实最直观的，如果只凭文字讲解，是没有太大说服力的，举个例子：2020年，xxx，2021年，xxx。\n一个好的建议，除了收集数据，还要分析对比，从中找到规律并发现问题，然后提炼自己的观点，找出解决方案，只有这样才能让你的观点变得有理有据 争取领导的支持\n研究发现，一次谈话中，约30%的访谈会被当场忘掉，谈话结束后，信息留存率只有5%，而且随着时间的推移，变得更少，所以领导听了你的建议后很可能会事后遗忘。\n因此，在得到领导确认后，还要确保领导能当场给予承诺和保证  ","description":"如何有效提建议","id":56,"section":"stack","tags":["career"],"title":"如何有效提建议","uri":"http://wangjinbao.netlify.app/en/stack/career/tjy/"},{"content":"沟通技巧 忠言如何不逆耳\n场景 经理 ：\u0026ldquo;你们赶紧开发A产品的吐槽功能，这样可以吸引更多的年轻客户\u0026rdquo;\n小A：\u0026ldquo;我认为现在最重要的是保证现有产品的稳定，而且我觉得吐槽功能并没有什么用，如果这个决定是错误的，将来会给公司带来更大的损失，可这些话我实在不知道该怎么和经理说\u0026rdquo;\n解决方法： 小B:其实你可以提出一些建设性地反对意见，但这需要一定的技工和策略，让你忠言瞬间逆袭成为美言\n步骤如下：  调整心态\n首先，要在心态上明确上级是你的伙伴，而不是对立面，有时候上级听到反对意见后可能会在无意中产生抵触情绪，这时你需要冷静应对，要让上级认识到你的出发点是为了公司利益 达成共识\n在提出你的建议时要表明你的目标与上级是一致的，将你的想法与上级的目标联系起来，以达成基本共识，譬如你可以这样说：\u0026ldquo;我们的目录是为了抓住更多的用户，但我分析的结论是。。。\u0026rdquo;\n这样表明你们的立场和目标是一致的，只是你有不同的看法 提出建议\n提出反对意见之后，还要为上级提供可行性建议，并向他说明每个选项背后的思路，否则，单纯的反对往往是无效的，描述你给出建议是基于怎样的原则以及你的思考过程\n如：如果我们想要吸纳更多忠诚的客户，我们可以在现有的功能上做更深一步的优化，具体可以这么做（方案A方案B）。。。备选方案可以让上级在否定原有方案后，有一个可能更适合的方法去达到原来的目标 汇总决定\n接下来与上级尽可能找出所有可行选项，再做决定，讨论透彻每个选项可能产生的结果，评估与之相关的优缺点，保证双方积极互动，然后进行讨论规划出行动路线，\n汇总时应多暂停听听上级对目前交谈的反应及接受度，如\u0026quot;你觉得这样可以吗？\u0026quot;  综上所述，工作中不可能永远和上级保持一致，当分歧产生时最好的办法不是回避、妥协甚至盲目地大声直言，而是应该充分沟通，冷静理智地提出更有建设性地意见，\n","description":"忠言如何不逆耳","id":57,"section":"stack","tags":["career"],"title":"忠言如何不逆耳","uri":"http://wangjinbao.netlify.app/en/stack/career/zybne/"},{"content":"资源调整 原docker desktop中的配置：\n 关闭k8x：勾掉 Enable Kubernetes\n也可调配置：降低 2h4G  安装minikube 安装kubectl 地址：\nhttps://kubernetes.io/docs/tasks/tools/\n本是mac：\nhttps://kubernetes.io/docs/tasks/tools/install-kubectl-macos/\n1 2 3  brew install kubectl kubectl version --client   安装minikube 地址：\nhttps://minikube.sigs.k8s.io/docs/start/\n本是mac：\n1 2 3 4  brew install minikube #如果哪一个minikube在通过brew安装后失败，您可能需要删除旧的minikube链接并链接新安装的二进制文件： brew unlink minikube brew link minikube   启动minikube(开VPN) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  minikube start --image-mirror-country=\u0026#39;cn\u0026#39; # 指定资源配置 $ minikube start --cpus=4 --memory=6000mb --image-mirror-country=\u0026#39;cn\u0026#39; 😄 Darwin 14.0 (arm64) 上的 minikube v1.33.0 ✨ 根据现有的配置文件使用 docker 驱动程序 👍 Starting \u0026#34;minikube\u0026#34; primary control-plane node in \u0026#34;minikube\u0026#34; cluster 🚜 Pulling base image v0.0.43 ... 🏃 正在更新运行中的 docker \u0026#34;minikube\u0026#34; container ... \u0026gt; kubectl.sha256: 64 B / 64 B [-------------------------] 100.00% ? p/s 0s \u0026gt; kubeadm.sha256: 64 B / 64 B [-------------------------] 100.00% ? p/s 0s \u0026gt; kubelet.sha256: 64 B / 64 B [-------------------------] 100.00% ? p/s 0s \u0026gt; kubectl: 47.63 MiB / 47.63 MiB [-------------] 100.00% 5.03 MiB p/s 9.7s \u0026gt; kubeadm: 46.69 MiB / 46.69 MiB [------------] 100.00% 950.05 KiB p/s 51s \u0026gt; kubelet: 91.98 MiB / 91.98 MiB [----------] 100.00% 968.87 KiB p/s 1m37s ▪ 正在生成证书和密钥... ▪ 正在启动控制平面... ▪ 配置 RBAC 规则 ... 🔗 配置 bridge CNI (Container Networking Interface) ... 🔎 正在验证 Kubernetes 组件... ▪ 正在使用镜像 registry.cn-hangzhou.aliyuncs.com/google_containers/storage-provisioner:v5 🌟 启用插件： storage-provisioner, default-storageclass 🏄 完成！kubectl 现在已配置，默认使用\u0026#34;minikube\u0026#34;集群和\u0026#34;default\u0026#34;命名空间   minikube 提供了非常多的配置参数，\n常用配置参数如下\n \u0026ndash;driver=*** 从1.5.0版本开始，Minikube缺省使用系统优选的驱动来创建Kubernetes本地环境，比如您已经安装过Docker环境，minikube 将使用 docker 驱动 \u0026ndash;cpus=2: 为minikube虚拟机分配CPU核数 \u0026ndash;memory=2048mb: 为minikube虚拟机分配内存数 \u0026ndash;registry-mirror=*** 为了提升拉取Docker Hub镜像的稳定性，可以为 Docker daemon 配置镜像加速，参考阿里云镜像服务 \u0026ndash;kubernetes-version=***: minikube 虚拟机将使用的 kubernetes 版本  验证minikube 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  $ minikube status minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured $ kubectl version --client Client Version: v1.29.1 Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3 # kubectl 的配置已经指向 minikube $ kubectl config current-context minikube # 删除minikube集群 kubectl config get-contexts kubectl config use-context docker-desktop 切换其它群集 # kubectl 集群信息 kubectl cluster-info Kubernetes control plane is running at https://127.0.0.1:61296 CoreDNS is running at https://127.0.0.1:61296/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use \u0026#39;kubectl cluster-info dump\u0026#39;. $ kubectl get no NAME STATUS ROLES AGE VERSION minikube Ready control-plane 7m51s v1.30.0   界面dashboard 1  $ minikube dashboard   查看扩展列表 1 2 3 4 5 6 7 8 9 10 11  # 查看扩展列表 $ minikube addons list |-----------------------------|----------|--------------|--------------------------------| | ADDON NAME | PROFILE | STATUS | MAINTAINER | |-----------------------------|----------|--------------|--------------------------------| | ambassador | minikube | disabled | 3rd party (Ambassador) | | auto-pause | minikube | disabled | minikube | | cloud-spanner | minikube | disabled | Google | | csi-hostpath-driver | minikube | disabled | Kubernetes | | dashboard | minikube | enabled ✅ | Kubernetes | | default-storageclass | minikube | enabled ✅ | Kubernetes |   ","description":"用于在本地计算机上运行单节点Kubernetes集群的工具","id":58,"section":"stack","tags":["docker"],"title":"minikube安装(单机集群)","uri":"http://wangjinbao.netlify.app/en/stack/k8s/minukube/"},{"content":"starting失败原因 Kubernetes is starting\n解决方案 拉取仓库k8s-docker-desktop-for-mac 我们先将该仓库拉取到本地：\n1  git clone git@github.com:maguowei/k8s-docker-desktop-for-mac.git   查看版本 然后确认一下 Docker Desktop 自带的 Kubernetes 的版本。点击 Docker 图标，选择 About Docker Desktop，看到如下界面：\n可以看到 Kubernetes 的版本是 Kubernetes: v1.29.1。\n之后我们打开 k8s-docker-desktop-for-mac 项目下的 images 文件：\n1 2 3 4 5 6 7 8  $cat images k8s.gcr.io/kube-proxy:v1.25.2=gotok8s/kube-proxy:v1.25.2 k8s.gcr.io/kube-controller-manager:v1.25.2=gotok8s/kube-controller-manager:v1.25.2 k8s.gcr.io/kube-scheduler:v1.25.2=gotok8s/kube-scheduler:v1.25.2 k8s.gcr.io/kube-apiserver:v1.25.2=gotok8s/kube-apiserver:v1.25.2 k8s.gcr.io/coredns:v1.9.3=gotok8s/coredns:v1.9.3 k8s.gcr.io/pause:3.8=gotok8s/pause:3.8 k8s.gcr.io/etcd:3.5.4-0=gotok8s/etcd:3.5.4-0%   获取k8s版本镜像 确保文件中的 Kubernetes 版本号与 Docker Desktop 自带的 Kubernetes 版本号一致后，执行命令：\n1  ./load_images.sh   该命令会帮助我们拉取启动 Kubernetes 所需的所有镜像。\n命令执行完毕后，点击 Docker 图标，在 Preferences.. \u0026gt; Reset 界面中点击 Reset Kubernetes cluster，重启 Kubernetes。大功告成！\n验证成功 1 2 3 4 5  $kubectl cluster-info Kubernetes control plane is running at https://kubernetes.docker.internal:6443 CoreDNS is running at https://kubernetes.docker.internal:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use \u0026#39;kubectl cluster-info dump\u0026#39;.   ","description":"启动 Kubernetes 所需的镜像往往会下载失败，于是点击 Apply 后，该配置页面的右下角始终显示 Kubernetes is starting，无法正常启动。","id":59,"section":"stack","tags":["k8s"],"title":"启动Kubernetes下载镜像失败一直starting","uri":"http://wangjinbao.netlify.app/en/stack/k8s/kubernetes/"},{"content":"1、文本匹配模型分类 文本匹配模型在问答系统、信息检索、文本分类、自然语言处理等任务中都有广泛的应用。根据具体的任务和需求，可以选择合适的模型来进行文本匹配。\n1.1基于规则的匹配模型 使用预定义的规则或启发式方法来判断文本之间的匹配程度。这些规则可以基于关键字、语法、词性等来判断文本的相似性。\n1.2统计匹配模型 使用统计方法和特征工程来预测文本之间的匹配程度。常见的统计特征包括词频、TF-IDF、词向量等。\n1.3传统机器学习模型 使用传统的机器学习算法，如支持向量机（SVM）、随机森林（Random Forest）或逻辑回归（Logistic Regression）来预测文本之间的匹配程度。\n1.4神经网络模型 使用神经网络来建模文本之间的匹配关系。常见的神经网络模型包括卷积神经网络（CNN）、循环神经网络（RNN）以及变种模型如长短期记忆网络（LSTM）和门控循环单元（GRU）。\n1.5预训练语言模型 像GPT-3一样的预训练语言模型也可以用于文本匹配任务。这些模型通常通过将两个文本进行拼接，然后输入模型，利用模型学习它们之间的关系。\n2、基础概念 2.1 自然语言处理(NLP) NLP（自然语言处理）语言模型是一种机器学习模型，用于处理和生成自然语言文本。这些模型被训练使用大量的文本数据来学习语言的规律性和结构。最近，深度学习模型，如循环神经网络（RNN）和变压器（Transformer），成为了NLP语言模型的主流。\n2.2 Word2vec Word2vec 是“word to vector”的简称，顾名思义，它是一个生成对“词”的向量表达的模型。想要训练 Word2vec 模型，我们需要准备由一组句子组成的语料库。假设其中一个长度为 T 的句子包含的词有 w1,w2……wt，并且我们假定每个词都跟其相邻词的关系最密切。\n根据模型假设的不同，Word2vec 模型分为两种形式:\nCBOW 模型（图 3 左）和 Skip-gram 模型（图 3 右）\n CBOW 模型\nCBOW 模型假设句子中每个词的选取都由相邻的词决定，因此我们就看到 CBOW 模型的输入是 wt周边的词， 预测的输出是 wt。 Skip-gram 模型\nSkip-gram 模型则正好相反，它假设句子中的每个词都决定了相邻词的选取，所以你可以看到 Skip-gram 模型的输入是 wt，预测的输出是 wt周边的词。  2.3 评测结果  shibing624/text2vec-base-chinese模型，是用CoSENT方法训练，基于hfl/chinese-macbert-base在中文STS-B数据训练得到，并在中文STS-B测试集评估达到较好效果，模型文件已经上传HF model hub，中文通用语义匹配任务推荐使用 shibing624/text2vec-base-chinese-sentence模型，是用CoSENT方法训练，基于nghuyong/ernie-3.0-base-zh用人工挑选后的中文STS数据集训练得到，并在中文各NLI测试集评估达到较好效果，模型文件已经上传HF model hub，中文s2s语义匹配任务推荐使用 shibing624/text2vec-base-chinese-paraphrase模型，是用CoSENT方法训练，基于nghuyong/ernie-3.0-base-zh用人工挑选后的中文STS数据集，并加入了s2p数据，强化了其长文本的表征能力，并在中文各NLI测试集评估达到SOTA，模型文件已经上传HF model hub，中文s2p语义匹配任务推荐使用  2.4 中文文本向量化模型 shibing624/text2vec-base-chinese 是一个预训练的中文文本向量化模型。它是基于 Transformers 架构和 BERT (Bidirectional Encoder Representations from Transformers) 模型进行训练的。这个模型使用了大规模的中文文本数据进行预训练，所以可以用于多种自然语言处理任务，例如文本分类、命名实体识别、语义相似度等。\n关于 shibing624/text2vec-base-chinese 的更多信息可以在以下链接找到：\n GitHub 仓库：https://github.com/shibing624/text2vec-base-chinese 模型下载地址：https://huggingface.co/shibing624/text2vec-base-chinese  用该模型进行文本向量化，请参考以下代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import torch from transformers import BertTokenizer, BertModel # 加载 tokenizer tokenizer = BertTokenizer.from_pretrained(\u0026#39;shibing624/text2vec-base-chinese\u0026#39;) # 加载模型 model = BertModel.from_pretrained(\u0026#39;shibing624/text2vec-base-chinese\u0026#39;) # 输入文本 text = \u0026#34;今天天气真好\u0026#34; # 对文本进行 tokenization input_ids = tokenizer.encode(text, add_special_tokens=True) # 将 token 转换为 tensor input_ids = torch.tensor(input_ids).unsqueeze(0) # 添加 batch 维度 # 使用模型进行 forward pass outputs = model(input_ids) # 得到文本的向量表示 text_vector = outputs[0].squeeze(0) print(\u0026#34;文本向量表示：\u0026#34;, text_vector)   上述代码加载了模型并使用它对输入文本进行编码，最后输出了文本的向量表示。\n请注意，使用该模型需要安装 Transformers 库，您可以通过运行以下命令进行安装：\n1  pip install transformers   ","description":"文本匹配模型是一种用于确定文本之间相似度或相关性的模型。它将两个文本作为输入，并输出一个表示它们之间相似程度的分数。","id":60,"section":"stack","tags":["python",""],"title":"文本匹配模型","uri":"http://wangjinbao.netlify.app/en/stack/python/answer/"},{"content":"1、相关连接 Python官方网站：\nhttps://www.python.org/ 这是Python语言的官方网站，你可以在这里找到Python的最新版本、文档、教程等。\nPython入门教程：\nhttps://docs.python.org/3/tutorial/index.html 这是Python官方提供的入门教程，适合初学者了解Python的基础知识和语法。\nPython标准库：\nhttps://docs.python.org/3/library/index.html Python标准库是Python内置的一组模块和函数，提供了丰富的功能和工具，你可以在这里找到它们的详细文档。\nPython第三方库：\nhttps://pypi.org/ PyPI（Python Package Index）是Python第三方库的官方仓库，你可以在这里搜索、下载和安装各种有用的库。\nPython常用库：\n NumPy：用于科学计算和数组操作。官方网站：https://numpy.org/ Pandas：用于数据分析和处理。官方网站：https://pandas.pydata.org/ Matplotlib：用于绘图和数据可视化。官方网站：https://matplotlib.org/ Requests：用于发送HTTP请求和处理API。官方网站：https://requests.readthedocs.io/ Flask：用于构建Web应用程序。官方网站：https://flask.palletsprojects.com/  ","description":"Python是一种高级编程语言，它具有简单易学、可读性强和功能强大的特点。","id":61,"section":"stack","tags":["python",""],"title":"python常用资料","uri":"http://wangjinbao.netlify.app/en/stack/python/links/"},{"content":"全链路压测 概念 全链路压测（End-to-End（E2E） Performance Testing）\n是指对软件系统或服务进行综合性能测试的一种方法。它模拟了真实的用户场景和环境，从用户端到服务器端的整个链路进行测试，包括用户界面、网络传输、服务器处理、数据库访问等环节。\n目标 是评估系统在高负载和复杂场景下的性能表现，找出性能瓶颈和潜在的问题，以便优化系统的性能和稳定性。通过模拟大量的并发用户访问、持续高负载、复杂数据操作等情况，可以检测系统在真实应用场景下的性能指标，例如响应时间、并发处理能力、吞吐量、资源利用率等指标。\n全链路压测的演进史 QQ音乐和酷狗全链路压测的演进史\nQQ音乐 酷狗音乐 微服务下的挑战 线上服务性能挑战 全链路压测 全链路压测系统核心功能 QQ音乐全链路压测系统架构 酷狗线上流量压测系统架构 全链路压测平台的介绍 一个基本的压测流程 用例准备阶段 用例准备阶段-场景编排 数据准备阶段-生产环境流星获取 数据准备阶段-自定义流星获取 压测执行阶段-链路发现 压测执行阶段-标记透传 压测执行阶段-存储隔离 压测执行阶段-实时监控 服务器资源占用监控 QQ音乐运维平台 酷狗KMC监控系统 应用性能监控 QQ音乐模调系统 酷狗APM监控系统 压测执行阶段-安全性保障 压测报告查看 QQ音乐 酷狗 实践案例分享 社交属性业务特性与挑战 业务特性： 突增流量、高并发读写、实时性\n实例分享-时代少年团空降评论区 迭代优化方案   热key问题\n  缓存命中率\n  缓存防穿透\n  业务降级策略\n  中间件\n  业务机器扩容\n  总结 ","description":"全链路压测（End-to-End（E2E） Performance Testing）是指对软件系统或服务进行综合性能测试的一种方法。","id":62,"section":"stack","tags":["knowledge"],"title":"全链路压测实践","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/e2e/"},{"content":"引言 在分布式系统中，事务管理是一项非常重要的任务。分布式事务涉及到多个事务参与者之间的协调和一致性保证，同时还要解决网络延迟、故障恢复等问题。\nGolang作为一门强大的编程语言，提供了一些工具和框架来帮助开发人员实现分布式事务。\n分布式事务的概念 分布式事务 是指跨越多个事务参与者的事务，这些参与者可能分布在不同的计算机节点上。在分布式系统中，事务参与者之间需要相互协调和通信，以保证数据的一致性和正确性。\n分布式事务通常需要满足 ACID（原子性、一致性、隔离性和持久性）的特性。\n 原子性 要求事务要么全部执行成功，要么全部回滚； 一致性 要求事务执行后系统的状态满足预期的约束； 隔离性 要求各个事务之间互相隔离，互相不干扰； 持久性 要求事务一旦提交，其结果应该永久保存；  分布式事务的原理 在分布式系统中，分布式事务的实现通常使用 两阶段提交（Two-Phase Commit，2PC）协议\n该协议包括两个阶段：准备阶段（Prepare Phase）和 提交阶段（Commit Phase）。\n 准备阶段，事务协调者向参与者发送准备请求，参与者执行事务操作，并将操作结果和准备通知返回给事务协调者。事务协调者收集到所有参与者的准备通知后，如果所有参与者都准备就绪，则进入提交阶段；否则，进入中止阶段。 提交阶段，事务协调者向参与者发送提交请求，参与者执行事务操作，并将提交通知返回给事务协调者。事务协调者收集到所有参与者的提交通知后，如果所有参与者都提交成功，则提交事务；否则，回滚事务。  2PC协议保证了分布式系统的数据一致性，但也存在一些 问题，例如 协调者单点故障 、 网络延迟导致的长时间等待 等，为了解决这些问题，可以使用一些分布式事务解决方案\n分布式事务解决方案 方法1:分布式事务解决方案 TCC是一种 补偿型事务处理模式，是常用的分布式事务解决方案。\nTCC事务通过用户自定义的 尝试（Try）、确认（Confirm）和 取消（Cancel） 操作来实现事务的执行、确认和回滚。\n在TCC事务中，每个事务参与者都需要实现三个方法：Try方法用于执行事务操作，Confirm方法用于确认事务，Cancel方法用于回滚事务。事务协调者通过调用每个参与者的Try方法来执行事务操作，根据返回的结果来决定是否确认或回滚事务。\n由于TCC事务是用户自定义的，所以可以根据具体的业务需求来实现事务操作的逻辑，并且具有较好的灵活性和可扩展性。\n方法2:消息队列 消息队列是一种异步通信机制，可以用于实现分布式事务。在分布式系统中，可以 将事务操作 和 确认操作 作为消息发布和消费的过程，通过消息队列来实现事务的执行和确认。\n在消息队列的实现中，通过将事务操作封装成消息并发布到消息队列中，然后由消费者接收并执行事务操作。一旦所有的事务操作都执行成功，消费者可以发送确认消息，表示事务的确认。如果事务操作中出现错误，消费者可以发送回滚消息，表示事务的回滚。\n消息队列可以提供较好的可靠性和可扩展性，同时还可以实现事务的异步执行，提高系统的吞吐量。\n方法3:分布式事务框架 除了上述解决方案外，还有一些 成熟的分布式事务框架 可供选择，例如 Seata、 XA 和 SAGA等。\nSeata是一个开源的分布式事务框架，支持多种分布式事务模式，包括AT（自动化事务）和TCC（补偿性事务）。Seata提供了全局事务管理和分布式事务协调的能力，可以简化分布式事务的开发和管理。\nXA是一种经典的分布式事务协议，它定义了分布式事务的协议和接口规范。Golang中有一些支持XA协议的数据库驱动，可以用于实现分布式事务。\nSAGA是一种基于事件驱动的分布式事务模式，通过将事务分解成一系列的子事务和补偿操作，来实现分布式事务的执行和回滚。Golang中有一些支持SAGA模式的框架和工具，可以用于实现分布式事务。\n案例 1. 订单支付案例 假设我们有一个电商平台，用户下单后需要进行支付操作。在分布式系统中，订单和支付可能分布在不同的服务中。为了保证订单和支付的一致性，我们可以使用分布式事务来实现。\n在这个案例中，当用户下单后，订单服务会创建订单并记录订单信息。同时，支付服务会接收到订单信息，并执行支付操作。如果支付成功，则订单服务将订单状态设置为已支付；如果支付失败，则订单服务将订单状态设置为支付失败。\n2. 转账交易案例 假设我们有两个银行账户A和B，用户需要将一定金额从账户A转移到账户B。在分布式系统中，账户A和账户B可能分布在不同的服务中。为了保证转账交易的一致性，我们可以使用分布式事务来实现。\n在这个案例中，当用户发起转账请求后，转账服务会扣除账户A的金额，并记录转账信息。同时，转账服务会向账户B发起请求，将金额添加到账户B中。如果转账操作成功，则确认事务；如果转账操作失败，则取消事务\n3. 分布式库存扣减案例 假设我们有一个电商平台，用户购买商品后，需要从库存中扣减相应数量的商品。在分布式系统中，库存和订单可能分布在不同的服务中。为了保证库存和订单的一致性，我们可以使用分布式事务来实现。\n在这个案例中，当用户下单后，订单服务会创建订单并记录订单信息。同时，订单服务会向库存服务发起请求，扣减相应数量的商品库存。如果库存扣减成功，则确认事务；如果库存扣减失败，则取消事务。\ngo代码 1. TCC事务示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  // 定义事务参与者接口 type TransactionParticipant interface { Try() error Confirm() error Cancel() error } // 定义事务协调者 type TransactionCoordinator struct { participants []TransactionParticipant } // 执行事务 func (c *TransactionCoordinator) Execute() error { // 尝试执行所有参与者的事务操作  for _, p := range c.participants { if err := p.Try(); err != nil { c.cancel() return err } } // 确认所有参与者的事务操作  for _, p := range c.participants { if err := p.Confirm(); err != nil { c.cancel() return err } } return nil } // 取消事务 func (c *TransactionCoordinator) cancel() { for _, p := range c.participants { p.Cancel() } } // 使用TCC事务执行订单支付操作 func PerformOrderPayment(orderId string, amount float64) error { // 创建订单支付参与者  orderParticipant := NewOrderPaymentParticipant(orderId) // 创建支付参与者  paymentParticipant := NewPaymentParticipant(orderId, amount) // 创建事务协调者  coordinator := \u0026amp;TransactionCoordinator{ participants: []TransactionParticipant{orderParticipant, paymentParticipant}, } // 执行事务  if err := coordinator.Execute(); err != nil { return err } return nil }   2. 消息队列示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  // 定义消息队列生产者 type MessageProducer struct { mq *MessageQueue } // 发送消息 func (p *MessageProducer) Send(message Message) error { // 发布消息到消息队列  if err := p.mq.Publish(message); err != nil { return err } return nil } // 定义消息队列消费者 type MessageConsumer struct { mq *MessageQueue } // 接收消息 func (c *MessageConsumer) Receive() (Message, error) { // 从消息队列订阅消息  message, err := c.mq.Subscribe() if err != nil { return nil, err } return message, nil } // 使用消息队列执行订单支付操作 func PerformOrderPayment(orderId string, amount float64) error { // 创建消息队列实例  mq := NewMessageQueue() // 创建消息生产者  producer := \u0026amp;MessageProducer{ mq: mq, } // 创建消息消费者  consumer := \u0026amp;MessageConsumer{ mq: mq, } // 创建订单支付消息  paymentMessage := NewPaymentMessage(orderId, amount) // 发送订单支付消息  if err := producer.Send(paymentMessage); err != nil { return err } // 接收订单支付确认消息  confirmMessage, err := consumer.Receive() if err != nil { return err } // 处理订单支付确认消息  if err := processPaymentConfirmation(confirmMessage); err != nil { return err } return nil }   3. Seata框架示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  // 使用Seata框架执行订单支付操作 func PerformOrderPayment(orderId string, amount float64) error { // 创建全局事务实例  tx := seata.BeginGlobalTransaction() // 创建订单服务实例  orderService := NewOrderService(tx) // 创建支付服务实例  paymentService := NewPaymentService(tx) // 执行订单创建操作  if err := orderService.CreateOrder(orderId); err != nil { tx.Rollback() return err } // 执行支付操作  if err := paymentService.PayOrder(orderId, amount); err != nil { tx.Rollback() return err } // 提交事务  if err := tx.Commit(); err != nil { return err } return nil }   以上是三个案例的示例代码，分别演示了使用TCC事务、消息队列和Seata框架来实现分布式事务。在实际应用中，可以根据具体的业务需求和系统架构选择合适的分布式事务解决方案，并合理地设计和实现分布式事务的逻辑。\ngo中分布式事务的常用解决方案(概括) 方法1 使用两阶段提交 （Two-Phase Commit，2PC）：\n2PC是一种经典的 分布式事务协议 ，它包含一个协调者（Coordinator）和 多个参与者（Participants）。在执行分布式事务时，协调者会向所有参与者发送事务的 准备请求 ，参与者执行事务操作并将结果返回给协调者，协调者根据参与者的结果来决定是否提交或者回滚事务\n方法2 使用TCC模式 （Try-Confirm-Cancel）\nTCC是一种 补偿型事务处理模式 ，它将一个分布式事务分解为\n三个阶段：尝试（Try）、确认（Confirm）和 取消（Cancel）\n在尝试阶段，参与者会尝试执行事务操作，如果所有参与者都成功执行，则进入 确认阶段，否则进入 取消阶段。在确认阶段，参与者将确认执行事务操作，而在取消阶段，参与者会回滚之前的操作。\n方法3 使用消息队列 可以使用消息队列来实现分布式事务。\n在这种模式下，应用程序 将事务请求发送到消息队列中，并等待其他应用程序处理该请求。其他应用程序会执行相关的事务操作，并将结果发送回消息队列，原始应用程序根据结果来决定是否提交或者回滚事务。\n方法4 使用分布式事务中间件 目前有一些 开源的分布式事务中间件，如 Seata、TCC-Transaction和Hmily 等，它们提供了一些解决方案来简化分布式事务的管理和处理。这些中间件通常提供了一套完整的分布式事务解决方案，包括事务管理、事务补偿和事务日志等功能\n","description":"分布式事务的几种方案","id":63,"section":"stack","tags":["knowledge"],"title":"分布式事务的常用解决方案","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/transaction/"},{"content":"错误的解决方案 1 先更新数据库，再删除缓存 若数据库更新成功，删除缓存操作失败，则此后读到的都是缓存中过期的数据，造成不一致问题。\n2 先更新数据库，再更新缓存 同删除缓存策略一样，若数据库更新成功缓存更新失败则会造成数据不一致问题。\n3 先删除缓存，再更新数据库    时间 线程A 线程B 数据库 缓存     1 删除缓存  v1 null   2  缓存失效 v1 null   3  从数据库读取v1 v1 null   4 更新数据库v2  v2 null   5  将v1写入缓存 v2 v1    4 先更新缓存，再更新数据库 若缓存更新成功数据库更新失败， 则此后读到的都是未持久化的数据。因为缓存中的数据是易失的，这种状态非常危险。\n   时间 线程A 线程B 数据库 缓存     1   v0 v0   2 更新缓存为v1  v0 v1   3  更新缓存为v2 v0 v2   4  更新数据库为v2 v2 v2   5 更新数据库为v1  v1 v2    正确的解决方案 1 使用 CAS CAS (Check-And-Set 或 Compare-And-Swap)是一种常见的保证并发安全的手段。CAS 当且仅当客户端最后一次取值后该 key 没有被其他客户端修改的情况下，才允许当前客户端将新值写入。\n1 2 3 4 5  func CAS(oldVal, newVal) { if cache.get() == oldVal { cache.set(newVal) } }      时间 线程A 线程B 数据库 缓存     1   v0 v0   2 更新数据库为v1  v1 v0   3  更新数据库为v2 v0 v2   4  执行CAS操作：当且仅当缓存中为v0时将v2写入缓存 v2 v2   5 执行CAS操作：当且仅当缓存中为v0时将v1写入缓存。当前缓存为v2故放弃写缓存  v2 v2     目前一些兼容 Redis 协议的中间件已经提供了 CAS 命令的支持，比如阿里的 Tair 以及腾讯的 Tendis。 Redis 官方本身是不支持CAS的操作,但是我们可以通过WATCH 和MULTI 命令实现类似的效果 WATCH 命令用于监视一个或多个键的变化，并在某个键被修改后取消事务，从而确保事务的原子性 MULTI 命令用于开始一个事务，将多个命令打包成一个事务，然后一次性执行。如果在执行事务期间有其他客户端对事务中的键进行修改，那么事务会被取消  2 使用分布式锁 CAS 假设发生并发问题的概率不大, 所以 CAS 也被称为乐观锁。那么悲观锁能否解决我们的问题呢？\n还是以「先更新数据库，再更新缓存」方案中两个写线程竞争为例， 我们要求任何线程在写入或读取数据库 前都需要获取排它锁 。\n   时间 线程A 线程B 数据库 缓存     0   v0 v0   1 获取排它锁  v0 v0   2 更新数据库为v1  v1 v0   3 更新缓存为v1  v1 v1   4  等待排它锁 v1 v1   5 释放排它锁  v1 v1   6  获取排它锁 v1 v1   7  更新数据库为v2 v2 v1   8  更新缓存为v2 v2 v2   9  释放排它锁 v2 v2    分布式锁同样可以解决并发问题，只是成本可能略高。\n3 使用消息队列异步更新 使用消息队列实现异步更新时，可以 将缓存更新的请求发送到消息队列中，由消息队列异步地处理缓存更新操作。\n下面是一个简单的案例：\n假设有一个电商网站，需要对商品信息进行缓存。当用户访问商品详情页面时，先从缓存中读取商品信息，如果缓存中没有，则从数据库中读取。\n当商品信息发生变化时，需要更新缓存中的数据。这时可以通过消息队列异步更新缓存，具体步骤如下：\n 当商品信息发生变化时，先更新数据库中的数据 将商品信息更新请求发送到消息队列中 消息队列异步地处理缓存更新操作，读取最新的商品信息，并将其更新到缓存中  这样就可以保证缓存中的数据是最新的，避免了因为缓存中的数据过期而导致的数据不一致问题。同时，使用消息队列可以提高更新的可靠性和性能，避免因为缓存更新失败而导致的数据库和缓存数据不一致问题。\n 问题一：为什么异步更新可以解决?\n异步更新缓存：\n当商品信息发生变化时，先更新数据库中的数据，然后将缓存更新请求发送到消息队列中，由消息队列异步地处理缓存更新操作。这样，即使缓存更新失败，也不会影响数据库中的数据，仅仅是缓存中的数据不是最新的而已。\n消息队列的可靠性：\n消息队列通常具有高可靠性和高可用性，可以保证消息的可靠传输和处理。即使在消息队列出现故障的情况下，也可以通过消息队列的备份、重试等机制来保证消息的可靠性。因此，即使缓存更新失败，也可以通过重试等机制来保证缓存最终被更新。\n  问题二：如果通过异步更新,更新缓存还是失败了怎么办?\n重试更新缓存：\n当缓存更新失败时，可以尝试重新更新缓存。可以设置重试次数和重试间隔时间，避免因为频繁重试而影响性能。\n回滚数据库更新：\n当缓存更新失败时，可以回滚数据库中的更新操作，保证数据库和缓存中的数据一致。但是，回滚操作可能会影响数据库中的其他操作，需要考虑到这个问题。\n延迟更新缓存：\n当缓存更新失败时，可以将缓存更新请求放入一个延迟队列中，一段时间后再次尝试更新缓存。这样可以避免频繁重试而影响性能，同时保证缓存最终被更新。\n使用读写分离：\n将读请求和写请求分别处理，读请求从缓存中读取数据，写请求先更新数据库，再更新缓存。这样可以避免因为缓存更新失败而导致的数据不一致问题。\n 3 数据库和缓存更新放在同一事务 可以保证在事务执行成功时，数据库和缓存中的数据都被更新；在事务执行失败时，数据库和缓存中的数据都不会被更新，保证了数据的一致性。\n 要将 MySQL和Redis放入同一个事务中，需要使用 分布式事务处理框架，如 XA 或 TCC。这些框架可以确保在整个事务过程中，MySQL和Redis的操作都能够得到正确的协调和同步 XA：XA是一种分布式事务处理标准，它可以确保在多个数据库之间进行事务处理时，所有的操作都能够得到正确的协调和同步。在MySQL和Redis中都有XA实现，可以通过XA接口实现分布式事务。 TCC：TCC是一种补偿性事务处理框架，它通过 尝试（Try）、确认（Confirm）和取消（Cancel）三个步骤来实现分布式事务。在MySQL和Redis中都有TCC实现，可以通过TCC接口实现分布式事务 需要注意的是，使用分布式事务框架会增加系统的复杂性和开销，需要仔细考虑是否真正需要在MySQL和Redis之间实现分布式事务如果可以接受稍微降低一些数据一致性的风险，可以使用其他技术来实现MySQL和Redis之间的数据同步，如 消息队列、定时任务 等。  ","description":"保证缓存和数据库的数据一致性","id":64,"section":"stack","tags":["knowledge"],"title":"保证缓存和数据库的数据一致性","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/data_same/"},{"content":"监控流程 数据上报 数据处理 接入使用 公有云建设（独立部署，功能闭环）  功能优化：   HTTP接口，支持客户端外网上报 DC Agent，兼容基础指标上报 告警通道：  企业微信（拉群助手） 微信（企业号） 邮件（覆盖全员）     建设成果：   首次10min内全流程跑通，后续3min内 酷我17数据流、13看板、60亿+/天 懒人12数据流、1看板、3亿+/天 QQ音乐业务线20数据流、11看板\n  数据感知-查询 多维能力  多个维度筛选查询 支持拆线图、比例图  对比分析  多维度对比、比较差异 定位优化方向  地图分布  客户端质量全局掌控 支持下钻查询\n  自定义看板  自主配置Dashboard 支持多种图表：拆线、柱状、饼、表格、漏斗等\n  数据感知-告警 常规模调告警 模块间调用，点对点关系\n缺乏扩展关联性\n微服务Trace扩展 OpenTelemetry规范\n统一Jaeger Agent采集\n链路精准可靠\n告警关联变更\n上下游变更周知\n告警链路 大规模告警\n 短时间发生大量模调告警 分析告警关联性 实际告警链路 智能分析   聚集分析 关联存储 关联变更 关联告警 陡增陡降 返回码信息 压测 腾讯云公告  数据应用-业务视图 以业务特性为维度进行管理  关联相关各种资源 全局视角把控服务质量 快速变更、容量管理  活动监控  分钟级实时监控   负载、流量、成功率、告警   异常数据，动态排序 可接入多种第三方监控   Grafana 腾讯云监控 自定义看板  ","description":"监控体系演进及可视化。","id":65,"section":"stack","tags":["knowledge"],"title":"监控体系演进及可视化","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/monitor/"},{"content":"一、分布式理论基础 CAP  Consitency(一致性) Availability(可用性) Partition tolerance(分区容错性)  CAP无法同时满足\nBASE理论  Basically Available(基本可用) Soft state(软状态) Eventually consistent(最终一致性)  BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性，但应该可以采用适合的方式达到最终一致性（Eventually consistent）\n分布式事务  Q：什么是分布式事务？\n顾名思义就是要在分布式系统中实现事务，它其实是由多个事务组合而成。\n要么都成功，要么都失败，解决分布式系统中业务之间的一致性问题\n 2PC 2pc(Two-Phase-Commit)\n事务管理器 分 \u0026ldquo;两个阶段\u0026rdquo; 来协调资源管理\n 准备 提交/回滚  TCC TCC（Try-Confirm-Cancel）服务化的两阶段，三个操作都需要编码实现\n一阶段：Try\n二阶段：Commit/Cancel\n Try:检查预留的资源 Confirm:真正的业务提交 Cancel:释放预留的资源  Saga Saga 是一种补偿协议\n 业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者 一阶段正向服务和二阶段补偿服务都由业务开发者实现  优点  一阶段提交本事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐  缺点  一阶段已经提交本地数据库事务，且没有进行\u0026quot;预留\u0026quot;动作，所以不能保证隔离性  二、送礼链路简介 营收的业务特性\n 数据一致性 \u0026gt; 可用性 不多发少发   面试题：保证不多发少发？\n 三、多发少发的原因 产生的原因： 就是 各种异常场景，也基本上是由 幂等、事务一致性 导致\n四、幂等 分布式事务的基础 用户反馈：点击送礼了一次，结果扣了两次星币，可能的原因？\n Q:幂等id由后端服务端生成，怎么理解？\n前端通过操作id与后端的幂等id做映射，有检验，更安全\n  Q:为什么要用全局id?能降级么？\n全局id保证了全链路幂等，通过 雪花算法，降级要基于业务场景考虑，但可能会导致冲突。\n 全局id如何生成 后端：Global ID生成（雪花算法）\n雪花算法Snowflake ID有64bits长，由以下三部分组成：\n客户端 操作id生成方案： SessionId统一算法:\n SessionId算法：\nsessionId = Md5(imei + pageName + 随机盐 + 时间戳 )  1 2 3 4 5 6  //以下为Android端Demo String rawStr = MediaApplicationController.getMID() + //imei  this.getClass().getSimpleName() + //pageName  MD5Utils.getCommonSalt() + //随机盐  SystemClock.elapsedRealtime(); //时间戳 String sessionId = MD5Utils.getMd5(rawStr);   随机盐算法：  1 2 3 4 5 6 7 8 9 10 11 12  public static String getCommonSalt() { Random r = new Random(); StringBuilder sb = new StringBuilder(16); sb.append(r.nextInt(99999999)).append(r.nextInt(99999999)); int len = sb.length(); if (len \u0026lt; 16) { for (int i = 0; i \u0026lt; 16 - len; i++) { sb.append(\u0026#34;0\u0026#34;); } } return sb.toString(); }   web 操作id生成方案： Ack重试机制幂等ID技术方案:\n技术方案\n 增加Fx.ajax拦截器，对支持幂等重试的接口增加幂等ID 幂等ID作为URL参数携带，参数Key：idempotent 幂等ID计算公式：UUID  1 2 3 4 5 6 7 8 9 10 11  function uuid() { let d = new Date().getTime(); if (typeof performance !== \u0026#39;undefined\u0026#39; \u0026amp;\u0026amp; typeof performance.now === \u0026#39;function\u0026#39;){ d += performance.now(); } return \u0026#39;xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\u0026#39;.replace(/[xy]/g, function (c) { let r = (d + Math.random() * 16) % 16 | 0; d = Math.floor(d / 16); return (c === \u0026#39;x\u0026#39; ? r : (r \u0026amp; 0x3 | 0x8)).toString(16); }); }   增加幂等ID前接口请求:\n1  curl https://fx.service.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;jsonpcallback=jsonphttpsxxx   增加幂等ID后接口请求（单数据中心）\n1 2 3 4 5 6  # 首次走CDN curl https://fx.service.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=cf1a9a7c-c204-48bc-a173-73d7ca86a9ef\u0026amp;jsonpcallback=jsonphttpsfxservicekugouxx # 走北京接入重试 curl https://fxservice1.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=cf1a9a7c-c204-48bc-a173-73d7ca86a9ef\u0026amp;jsonpcallback=jsonphttpsfxservice1kugouxx # 走广州接入专线回北京 curl https://fxservice2.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=cf1a9a7c-c204-48bc-a173-73d7ca86a9ef\u0026amp;jsonpcallback=jsonphttpsfxservice2kugouxx   增加幂等ID后接口请求（双数据中心）\n1 2 3 4 5 6 7 8 9 10  # 已北方用户为例，南方用户首次走 fx2 # 首次走CDN回北京 curl https://fx1.service.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=cf1a9a7c-c204-48bc-a173-73d7ca86a9ef\u0026amp;jsonpcallback=jsonphttpsfxservicekugouxx # 重试走北京接入 curl https://fxservice3.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=cf1a9a7c-c204-48bc-a173-73d7ca86a9ef\u0026amp;jsonpcallback=jsonphttpsfxservice3kugouxx # 重试走CDN回广州 curl https://fx2.service.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=1531987904734x99303996x683693\u0026amp;jsonpcallback=jsonphttpsfx2servicekugouxx # 重试直连广州 curl https://fxservice4.kugou.com/TreasureHuntServices/TreasureHuntService/TreasureHuntV2/treasureHunt?args=[3,1031429,1300549442,3]\u0026amp;idempotent=cf1a9a7c-c204-48bc-a173-73d7ca86a9ef\u0026amp;jsonpcallback=jsonphttpsfxservice4kugouxx   Ack提供获取幂等ID函数\n增加幂等ID\n1 2 3 4 5 6 7  // 获取幂等ID function getIdempotent() { return { key: IDEMPOTENT_KEY, val: uuid() } }   经典幂等问题 五、分布式事务一致性方案 基于回查 目前营收90%以上的业务使用了该方案，解决营收top10的业务丢单问题 基于本地事务消息表 基于Pulsar的可靠消息最终一致性(at least once)，目前在主推\n最大努力通知型 六、mysql集群一致性 直播mysql集群部署简介 南北双活（MHA + Consul + Otter） 同城主备-依赖 MHA + Consul 实现 高可用  Q:直接mysql目前采用复制方式是哪种？\n异步\n  单机房写，强一致性，但当master故障、机房网络故障或脑裂时，mysql数据未复制到新master，MHA强制切换可能会造成数据不一致 故障切换时一致性和不可用时长需要取舍 核心是：止损  mysql集群一致性问题：都可归为 多副本数据不一致 的问题\n遇到的经典问题：\n线上问题更多的是 读方案 的问题，而不是MHA切换 的问题\n复盘守的问题 总结：\n 业务需评估是否为高实时业务 修改表结构需评估主从延时 业务要判断主从延时的影响  七、缓存与DB的一致性 常用的缓存模式 方法：\n JOB定时将数据从DB同步到Cache中 应用直接访问cache，不回查数据库  方法：\n 失效：应用程序先从Cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中 命中：应用程序从Cache中取数据，取到后返回 更新：先把数据存到数据库中，成功后，再让缓存失效   Q1:什么情况下会使用缓存？\n挡量、提高访问速度、使用简单\n  Q2:缓存与DB的一致性怎么保障？\n 涉及到两个系统，那么必然会存在数据一致性的问题 基于Q1的回答及CAP的理论，要么通过2PC或是Paxos协议保证数据的强一致性，要么就是接受数据的最终一致性   案例 DB同步是采用otter、采用nsq通知来清除redis的数据 两种同步/通知机制\n 异地查询脏数据 DB与缓存（有效期间内）\n最终一致性无法保证   怎么办？\n收到消息线程sleep?\n延时队列？\n 解决方案：\n采用同一种机制\u0026ndash;基于otter\n缺点：\notter意向回环，非主机房nsq流量翻倍\n基于otter做数据变更模型：\n在otter\u0026ndash;node执行SETL的L阶段（load阶段）进行数据推送\n八、分布式锁 分布式锁主要的三种实现方式 基于DB 乐观锁\n 版本号字段 基于CAS 不具有互斥性 不会产生锁等待  悲观锁\n select \u0026hellip; where \u0026hellip; for update 索引、锁表  基于redis 分布式锁\nredis分布式锁\n 性能高 锁失效 多机房情况  基于ZK 分布式锁\n应用场景 消费服务更新余额：\n redis 是无法真正锁住的（挡量） 数据库进行兜底  ","description":"分布式系统的一致性。","id":66,"section":"stack","tags":["knowledge"],"title":"直播分布式系统的一致性","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/trace/"},{"content":"背景 kafka 是一个比较流行的 分布式 、 可拓展 、 高性能 、 可靠性 的流处理平台。\n在处理kafka的数据时，这里有 确保处理效率和可靠性的 多种最佳实践。\n下面介绍这几种实践方式，并通过sarama实现他们。\n需要注意的点(最佳实践方案) 1.选择合适的提交策略 Kafka提供两种提交策略，自动 和 手动。\n 虽然自动操作很容易使用， 但它可能会导致 数据丢失或重复 。 手动提交提供了更高级别的控制，确保消息至少处理一次或恰好一次，具体取决于用例。  a、自动提交 Sarama 的 ConsumerGroup 默认情况下会自动提交偏移量。这意味着它会定期提交已成功消费的消息的偏移量，这允许消费者在重新启动或消费失败时从中断的地方继续。\n下面是一个自动提交的消费者组消费消息的例子：\n1 2 3 4  // 自动提交偏移量  config := consumerGroup.Config() config.Consumer.Offsets.AutoCommit.Enable = true config.Consumer.Offsets.AutoCommit.Interval = 1 * time.Second   根据 config.Consumer.Offsets.AutoCommit.Interval 可以看到，消费者会每秒自动提交offset。\nb、手动提交 手动提交使我们更好地控制何时提交消息偏移量。下面是一个手动提交的消费者组消费消息的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func (h msgConsumerGroup) ConsumeClaim(sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error { for msg := range claim.Messages() { fmt.Printf(\u0026#34;%s Message topic:%q partition:%d offset:%d value:%s \u0026#34;, h.name, msg.Topic, msg.Partition, msg.Offset, string(msg.Value)) // 插入mysql....  // 手动提交模式下，也需要先进行标记  sess.MarkMessage(msg, \u0026#34;\u0026#34;) consumerCount++ if consumerCount%3 == 0 { // 手动提交，不能频繁调用  t1 := time.Now().Nanosecond() sess.Commit() t2 := time.Now().Nanosecond() fmt.Println(\u0026#34;commit cost:\u0026#34;, (t2-t1)/(1000*1000), \u0026#34;ms\u0026#34;) } } return nil }   2.尽量减少Kafka的传输次数 大批量读取消息 可以显著 提高吞吐量。\n这可以通过调整 fetch.min.bytes 和 fetch.max.wait.ms 等参数来实现。\n减少kafka的传输次数可以通过 优化从kafka中 读取和写入 数据的方式来实现：\na、增加批次的大小 使用kafka批量发送消息的效果优于逐个发送消息，批次越大，kafka发送数据效率就越高。但是需要权衡延迟和吞吐量之间的关系。较大的批次虽然代表着更大的吞吐量，但也会增加延迟。\n因为批次越大，填充批次的时间也越久\n在Go中，我们可以在使用sarama包生成消息时设置批次大小：\n可以通过kafka.Config结构体的 Producer.Return.Successes 配置项来设置批次大小.个配置项决定了当一个消息成功被Kafka接收时，是否会被客户端返回。如果设置为true，那么成功投递的消息会被批量返回。\n1 2 3 4  config := sarama.NewConfig() config.Producer.Return.Successes = true config.Producer.BatchSize = 16384 // 设置批次大小为16KB  config.Producer.Flush.Messages = 100 // 当批次消息数达到100时刷新到磁盘   b、使用长轮询 长轮询是指消费者轮询时如果Kafka中没有数据，则消费者将等待数据到达。这减少了往返次数，因为消费者不需要在没有数据时不断请求数据。\n1 2  // 设置最大轮询间隔时间为10秒  config.Consumer.MaxProcessingTime = 10 * time.Second   3.尽量使用消费者组 Kafka允许 多个消费者 组成一个 消费者组并行消费数据 。这使得 Kafka 能够将数据分发给一个组中的所有消费者，从而实现高效的数据消费。\n消费者组是一组协同工作消费来自kafka主题的消息的消费者。消费者组允许我们在多个消费者之间分配消息，从而提供横向拓展能力。使用消费者组时，kafka负责将分区分配给组中的消费者，并确保 每个分区同时仅被一个消费者消费。\n接下来是sarama中消费者组的使用：\na.使用消费者组需要实现一个ConsumerGroupHandler接口： 该接口具有三个方法：Setup、Cleanup、 和ConsumeClaim\n1 2 3 4 5 6 7 8 9 10  func (consumerGroupHandler) Setup(_ sarama.ConsumerGroupSession) error { return nil } func (consumerGroupHandler) Cleanup(_ sarama.ConsumerGroupSession) error { return nil } func (h consumerGroupHandler) ConsumeClaim(sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error { for msg := range claim.Messages() { fmt.Printf(\u0026#34;%s Message topic:%q partition:%d offset:%d value:%s\\n\u0026#34;,h.name, msg.Topic, msg.Partition, msg.Offset, string(msg.Value)) // 手动确认消息 \tsess.MarkMessage(msg, \u0026#34;\u0026#34;) } return nil }   4.调整消费者缓冲区大小 通过调整 消费者的缓冲区大小 ，如 receive.buffer.bytes 和 max.partition.fetch.bytes ，可以根据消息的 预期大小 和 消费者的内存容量 进行调整。这可以提高消费者的表现。\n在sarama中，我们可以调整消费者缓冲区的大小，以调整消费者在处理消息之前可以在内存中保存的消息数量。\n默认情况下，缓冲区大小设置为256，这代表Sarama在开始处理消息之前将在内存中保存最多256条消息。如果消费者速度很慢，增加缓冲区大小可能有助于提高吞吐量。但是，更大的缓冲区也会消耗更多的内存。\n5.处理rebalance 当 新的消费者加入消费者组，或者现有的消费者离开 时，Kafka会 触发rebalance以重新分配负载 。在此过程中， 消费者停止消费数据 。因此，快速有效地处理重新平衡可以提高整体吞吐量。\n当新消费者添加到消费者组或现有消费者离开消费者组时，kafka会重新平衡该组中的消费者。rebalance是kafka确保消费者组中的所有消费者不会消费同一分区的保证。\n在sarama中，处理rebalance是通过 Setup 和CleanUp 函数来完成的。\n通过正确处理重新平衡事件，您可以确保应用程序正常处理消费者组的更改，例如消费者离开或加入，并且在这些事件期间不会丢失或处理两次消息。\n6.监控消费者 使用 Kafka 的消费者指标来 监控消费者的性能 。 定期监控 可以帮助我们识别性能瓶颈并调整消费者的配置。\n监控Kafka消费者对于确保系统的健康和性能至关重要，我们需要时刻关注延迟、处理时间和错误率的指标。\n PS:Golang没有内置对 Kafka 监控的支持，但有几个库和工具可以帮助我们。让我们看一下其中的一些：\n1 . Sarama的Metrics：Sarama 提供了一个指标注册表，它报告了有助于监控的各种指标，例如请求、响应的数量、请求和响应的大小等。这些指标可以使用 Prometheus 等监控系统来收集和监控。\n2 . JMX Exporter：如果您在 JVM 上运行 Kafka， 则可以使用 JMX Exporter 将kafka的 MBeans 发送给Prometheus\n3 . Kafka Exporter：Kafka Exporter是一个第三方工具，可以提供有关Kafka的更详细的指标。它可以提供消费者组延迟，这是消费kafka消息时要监控的关键指标。\n4 . Jaeger 或 OpenTelemetry：这些工具可用于分布式追踪，这有助于追踪消息如何流经系统以及可能出现瓶颈的位置。\n5 . 日志：时刻关注应用程序日志，记录消费者中的任何错误或异常行为。这些日志可以帮助我们诊断问题。\n6 . 消费者组命令， 可以使用kafka-consumer-groups 命令来描述消费者组的状态。\n 请记住，不仅要追踪这些指标，还要针对任何需要关注的场景设置警报。通过这些方法，我们可以在问题还在初始阶段时快速做出响应。\n实践例子 安装驱动包： 迁移了 go get github.com/IBM/sarama\n1 2  go get github.com/Shopify/sarama ## 迁移了 go get github.com/IBM/sarama   生产者（Producer） 创建一个函数，用于连接并返回一个Kafka生产者：\n1 2 3 4 5 6  func createProducer(brokers []string) (sarama.AsyncProducer, error) { config := sarama.NewConfig() config.Producer.Return.Successes = true config.Producer.Timeout = 5 * time.Second return sarama.NewAsyncProducer(brokers, config) }   创建一个函数，用于发送消息到指定的Kafka主题：\n1 2 3 4 5 6 7 8  func produceMessage(producer sarama.AsyncProducer, topic, value string) { message := \u0026amp;sarama.ProducerMessage{ Topic: topic, Value: sarama.StringEncoder(value), } producer.Input() \u0026lt;- message }   消费者（Consumer） 创建一个函数，用于连接并返回一个Kafka消费者：\n1 2 3 4 5  func createConsumer(brokers []string, groupID string) (sarama.ConsumerGroup, error) { config := sarama.NewConfig() config.Consumer.Offsets.Initial = sarama.OffsetOldest return sarama.NewConsumerGroup(brokers, groupID, config) }   定义一个消费者组对象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  type KafkaConsumerGroupHandler struct { ready chan bool } func (handler *KafkaConsumerGroupHandler) Setup(_ sarama.ConsumerGroupSession) error { close(handler.ready) return nil } func (handler *KafkaConsumerGroupHandler) Cleanup(_ sarama.ConsumerGroupSession) error { return nil } func (handler *KafkaConsumerGroupHandler) ConsumeClaim(sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error { for message := range claim.Messages() { fmt.Printf(\u0026#34;消息: 主题=%s 分区=%d 偏移量=%d\\n\u0026#34;, message.Topic, message.Partition, message.Offset) fmt.Printf(\u0026#34;消息内容: %s\\n\u0026#34;, string(message.Value)) sess.MarkMessage(message, \u0026#34;\u0026#34;) } return nil }   创建一个函数，用于消费指定的Kafka主题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  func consumeMessages(consumer sarama.ConsumerGroup, topics []string) { handler := \u0026amp;KafkaConsumerGroupHandler{ ready: make(chan bool), } for { err := consumer.Consume(context.Background(), topics, handler) if err != nil { log.Printf(\u0026#34;消费者错误: %v\u0026#34;, err) } select { case \u0026lt;-handler.ready: default: return } } }   main方法 在 main 函数中调用以上方法展示生产和消费操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  func main() { brokers := strings.Split(\u0026#34;localhost:9092\u0026#34;, \u0026#34;,\u0026#34;) topic := \u0026#34;my_topic\u0026#34; groupID := \u0026#34;my_group\u0026#34; // 创建生产者 \tproducer, err := createProducer(brokers) if err != nil { log.Fatal(\u0026#34;无法创建生产者:\u0026#34;, err) } defer func() { if err := producer.Close(); err != nil { log.Fatal(\u0026#34;无法关闭生产者:\u0026#34;, err) } }() // 发送消息 \tproduceMessage(producer, topic, \u0026#34;hello world\u0026#34;) // 创建消费者 \tconsumer, err := createConsumer(brokers, groupID) if err != nil { log.Fatal(\u0026#34;无法创建消费者:\u0026#34;, err) } defer func() { if err := consumer.Close(); err != nil { log.Fatal(\u0026#34;无法关闭消费者:\u0026#34;, err) } }() topics := []string{topic} wg := \u0026amp;sync.WaitGroup{} wg.Add(1) go func() { defer wg.Done() consumeMessages(consumer, topics) }() // 监听退出信号 \tsigterm := make(chan os.Signal, 1) signal.Notify(sigterm, os.Interrupt) \u0026lt;-sigterm // 优雅关闭消费者 \twg.Wait() }   ","description":"golang中使用kafka的综合指南","id":67,"section":"stack","tags":["knowledge"],"title":"golang中使用kafka的综合指南","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/kafkatips/"},{"content":"介绍 在Kafka中，生产者（Producer） 和 消费者（Consumer） 是通过 发布订阅模式 进行协作的，生产者将消息发送到Kafka集群，而消费者从Kafka集群中拉取消息进行消费，\n无论是生产者发送消息到Kafka集群还是消费者从Kafka集群中拉取消息进行消费，都是容易出现问题的，比较典型的就是\n消费端的重复消费问题 、 生产端和消费端产生的消息丢失 问题 。\n下面将对这两个问题出现的场景以及常见的解决方案进行讲解。\n重复消费 1 重复消费出现的场景 重复消费出现的常见场景主要分为两种：\n Consumer在消费过程中，应用进程被强制kill掉或者发生异常退出（挂掉…） Consumer消费的时间过长  1.1 消费者消费过程中，进程挂掉/异常退出 在Kafka消费端的使用中，位移（Offset）的提交有两种方式，自动提交 和 手动提交：\n自动提交情况下 ，当消费者拉取一批消息进行消费后，需要进行Offset的提交，在消费端提交Offset之前，Consumer挂掉了，当Consumer重启后再次拉取Offset，这时候拉取的依然是挂掉之前消费的Offset，因此造成 重复消费 的问题。\n手动提交模式下 ，在提交代码调用之前，Consumer挂掉也会造成重复消费。\n1.2 消费者消费时间过长 Kafka消费端的参数 max.poll.interval.ms 定义了两次poll的最大间隔，它的默认值是 5 分钟，表示 Consumer 如果在 5 分钟之内无法消费完 poll方法返回的消息，那么Consumer 会主动发起“离开组”的请求\n在 离开消费组后 ，开始Rebalance，因此 提交Offset失败 。之后 重新Rebalances，消费者再次分配Partition后，再次poll拉取消息依然从之前消费过的消息处开始消费，这样就造成重复消费。而且若不解决消费单次消费时间过长的问题，这部分消息可能会一直重复消费。\n整体上来说，如果我们在消费中将消息数据处理入库，但是在 执行Offset提交时，Kafka宕机或者网络原因等 无法提交Offset ，当我们重启服务或者Rebalance过程触发，Consumer将再次消费此消息数据。\n PS :1.一开始以为poll()方法里传的是Kafka返回的记录条数，\n但其实是传的时间（ms）\n2.Kafka轮询一次就相当于拉取（poll）一定时间段broker中可消费的数据，\n在这个指定时间段里拉取，时间到了就立刻返回数据。\n3.例如poll（5000）：\n即在5s中内拉去的数据返回到消费者端。\n 2 重复消费解决方案 2.1 针对于消费端挂掉等原因造成的重复消费问题 这部分主要集中在消费端的 编码层面 ，需要我们在设计代码时 以幂等性的角度进行开发设计 ，保证同一数据无论进行多少次消费，所造成的结果都一样。\n处理方式可以在消息体中 添加唯一标识(比如将消息生成md5保存到Mysql或者是Redis中，在处理消息前先检查下Mysql/Redis是否已经处理过该消息了)，消费端进行确认此唯一标识是否已经消费过，如果消费过，则不进行之后处理。从而尽可能的避免了重复消费。\n幂等性角度大概两种实现：\n 解决方法一：将唯一标识存入第三方介质（如Redis）\n要操作数据的时候先判断第三方介质(数据库或者缓存)有没有这个唯一标识。 解决方法二：将版本号(offset)存入到数据里面\n然后再要操作数据的时候用这个版本号做 乐观锁 ，当 版本号大于 原先的才能操作。   PS:乐观锁的实现：\n数据库表设计时加入的\u0026quot;版本号\u0026quot;字段\nCREATE TABLE items (\nid INT PRIMARY KEY AUTO_INCREMENT,\nvalue VARCHAR(255),\nversion INT DEFAULT 0\n);\n更新操作： UPDATE items SET value = 'new value', version = version + 1 WHERE id = 1 AND version = 0;\n 2.2 针对于Consumer消费时间过长带来的重复消费问题  解决方法一：提高单条消息的处理速度。\n例如对消息处理中比较耗时的操作可通过 异步的方式 进行处理、多线程处理 等。 解决方法二：将 max.poll.interval.ms 值设置大一点\n避免不必要的rebalance，此外可适当减小 max.poll.records 的值，默认值是500，可根据实际消息速率适当调小。  消息丢失 在Kafka中，消息丢失在Kafka的 生产端 和 消费端 都会出现。在此之前我们先来了解一下生产者和消费者的原理。\n1 生产端问题 生产者原理： Kafka生产者生产消息后，会将消息发送到Kafka集群的Leader中，然后Kafka集群的Leader收到消息后会返回ACK确认消息给生产者Producer。\n主要拆解为以下几个步骤：\n Producer先从Kafka集群找到该Partition的Leader Producer将消息发送给Leader，Leader将该消息写入本地 Follwer从Leader pull消息，写入本地Log后Leader发送ACK Leader 收到所有 ISR（In-Sync Replicas，同步副本集） 中的 Replica 的 ACK 后，增加High Watermark，并向 Producer 发送 ACK  因此，Kafka集群（其实是分区的Leader）最终会返回一个ACK来确认Producer推送消息的结果，这里\nKafka提供了 发送消息三种模式：\n NoResponse RequiredAcks = 0：\n这个代表的就是不进行消息推送是否成功的确认。 WaitForLocal RequiredAcks = 1：\n当local(Leader)确认接收成功后，就可以返回了。 WaitForAll RequiredAcks = -1：\n当所有的Leader和Follower都接收成功时，才会返回。  因此这个配置的影响也分为下面三种情况：\n 设置为 0\nProducer不进行消息发送的确认，Kafka集群（Broker）可能由于一些原因并没有收到对应消息，从而引起消息丢失。 设置为 1\nProducer在确认到 Topic Leader 已经接收到消息后，完成发送，此时有可能 Follower 并没有接收到对应消息。此时如果 Leader 突然宕机，在经过选举之后，没有接到消息的 Follower 晋升为 Leader，从而引起消息丢失。 设置为 -1\n可以很好的确认Kafka集群是否已经完成消息的接收和本地化存储，并且可以在Producer发送失败时进行重试。  生产端解决消息丢失方案：  解决方法一： 通过设置 RequiredAcks模式 来解决，选用WaitForAll（对应值为-1）可以保证数据推送成功，不过会影响延时。 解决方法二： 引入 重试机制 ，设置重试次数和重试间隔。 解决方法三： 使用Kafka的 多副本机制 保证Kafka集群本身的可靠性，确保当Leader挂掉之后能进行Follower选举晋升为新的Leader。  2 消费端问题 消费端的消息丢失问题：\n消费端的消息丢失主要是因为在 消费过程中出现了异常 ，但是对应消息的 Offset 已经提交，那么消费异常的消息将会丢失。\n前面介绍过，Offset的提交包括 手动提交 和 自动提交 ，可通过kafka.consumer.enable-auto-commit进行配置。\n 手动提交\n可以灵活的确认是否将本次消费数据的Offset进行提交，可以很好的避免消息丢失的情况。 自动提交\n是引起消息丢失的主要诱因。因为消息的消费并不会影响到Offset的提交。   解决方法： 尽量使用手动提交的方式，或者用sarama自动提交方式（先进行标记，标记前处理数据，再进行提交，因此没有标记，offset没有提交）\n 大部分的解决方案为了 尽可能的保证数据的完整性，都是尽量去选用 手动提交 的方式，当数据处理完之后再进行提交。\n当然，在golang中我们主要使用sarama包的Kafka，sarama自动提交的原理是先进行标记，再进行提交，如下代码所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  type exampleConsumerGroupHandler struct{} func (exampleConsumerGroupHandler) Setup(_ ConsumerGroupSession) error { return nil } func (exampleConsumerGroupHandler) Cleanup(_ ConsumerGroupSession) error { return nil } func (h exampleConsumerGroupHandler) ConsumeClaim(sess ConsumerGroupSession, claim ConsumerGroupClaim) error { for msg := range claim.Messages() { fmt.Printf(\u0026#34;Message topic:%q partition:%d offset:%d \u0026#34;, msg.Topic, msg.Partition, msg.Offset) // 标记消息已处理，sarama会自动提交  // 处理数据（如真正持久化mysql...）  sess.MarkMessage(msg, \u0026#34;\u0026#34;) } return nil }   因此，我们完全可以在标记之前进行数据的处理，例如插入Mysql等，当出现插入成功后程序崩溃，下一次最多重复消费一次（因为还没标记，Offset没有提交），而不会因为Offset超前，导致应用层消息丢失了。\n手动提交模式下当然是很灵活的控制的，但确实已经没必要了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  consumerConfig := sarama.NewConfig() consumerConfig.Version = sarama.V2_8_0_0 consumerConfig.Consumer.Return.Errors = false consumerConfig.Consumer.Offsets.AutoCommit.Enable = false // 禁用自动提交，改为手动 consumerConfig.Consumer.Offsets.Initial = sarama.OffsetNewest func (h msgConsumerGroup) ConsumeClaim(sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error { for msg := range claim.Messages() { fmt.Printf(\u0026#34;%s Message topic:%q partition:%d offset:%d value:%s \u0026#34;, h.name, msg.Topic, msg.Partition, msg.Offset, string(msg.Value)) // 插入mysql....  // 手动提交模式下，也需要先进行标记  sess.MarkMessage(msg, \u0026#34;\u0026#34;) consumerCount++ if consumerCount%3 == 0 { // 手动提交，不能频繁调用  t1 := time.Now().Nanosecond() sess.Commit() t2 := time.Now().Nanosecond() fmt.Println(\u0026#34;commit cost:\u0026#34;, (t2-t1)/(1000*1000), \u0026#34;ms\u0026#34;) } } return nil }   ","description":"Kafka的重复消费和消息丢失问题","id":68,"section":"stack","tags":["knowledge"],"title":"Kafka的重复消费和消息丢失问题","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/kafkaquestion/"},{"content":"应用的稳定性，以及出现问题的时候，怎样的快速定位到真正的原因，对于很多企业来说是都是一直在不断的设计和完善的能力。主要体现在怎样监控系统，怎样从日志上快速的找到错误，怎样快速的知道调用链是不是出现了问题，以及应用的运行时有没有出问题，应用依赖的数据库，中间件等是不是出现问题了。\n图上介绍了Metrics 、 Tracing 、 Logging 的定义和关系，三者都有各自发挥的空间，每种数据都没办法完全被其他数据代替。\n观测性方案 常用方案总结：\n日志方案： filebeats-\u0026gt;elasticsearch-\u0026gt;kibana；\nfilebeats-\u0026gt;kafka-\u0026gt;logstash-\u0026gt;elasticsearch-\u0026gt;kibana; \nfluentd-\u0026gt;elasticsearch-\u0026gt;kibana；\nfluentd-\u0026gt;kafka-\u0026gt;fluentd-\u0026gt;elasticsearch-\u0026gt;kibana；\n监控方案： 比较统一的都在使用 prometheus ，prometheus-operator ，thanos，grafana\n链路方案: 主要方案有开源的 skywalking，jaeger，zipkin，还有商业的方案，如 dynatrace 等。\n","description":"观测性的大三要素，监控，日志，链路。","id":69,"section":"stack","tags":["knowledge"],"title":"云原生观测性","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/observation/"},{"content":"前言 小伙伴们有没有遇到过生产环境经常出现过重复的数据？在排查问题的时候，数据又是正常的。这个是何解呢？怎么会出现这种情况，而且还很难排查问题。今天我给大家分享一下这里的原因，以及解决方案。\n产生重 复数据或数据不一致 （假定程序业务代码没问题），绝大部分就是发生了重复的请求，\n重复请求 是指同一个请求因为某些原因被多次提交。\n导致这个情况会有几种场景：\n 微服务场景:\n在我们传统应用架构中调用接口，要么成功，要么失败。但是在微服务架构下，会有 第三个情况【未知】 ，也就是超时。如果超时 了，微服务框架会进行 重试。 用户交互的时候多次点击:\n如：快速点击按钮多次 MQ消息中间件:\n消息重复消费 第三方平台的接口:\n（如：支付成功回调接口），因为异常也会导致多次异步回调 其他中间件/应用服务根据自身的特性，也有可能进行重试  我们知道了发生的原因，本质就是多次请求了，那如何解决呢？\n幂等性 定义：多次调用对系统的产生的影响是一样的 ，即对资源的作用是一样的，但是返回值允许不同\n幂等场景 我们来看一下SQL相关业务是否幂等？\n一、查询 select * from user where xxx，不会对数据产生任何变化，具备幂等性。\n二、新增 insert into user(userid,name) values(1,'a')\n如 userid为唯一主键，即重复操作上面的业务，只会插入一条用户数据，具备幂等性 。\n如 userid不是主键，可以重复，那上面业务多次操作，数据都会新增多条，不具备幂等性 。\n三、修改 区分直接赋值和计算赋值\n 直接赋值，update user set point = 20 where userid=1，不管执行多少次，point都一样，具备幂等性 计算赋值，update user set point = point + 20 where userid=1，每次操作point数据都不一样，不具备幂等性  四、删除 delete from user where userid=1，多次操作，结果一样，具备幂等性 。\n常用的方案：token机制、乐观锁机制、唯一主键机制、去重表机制\ntoken机制 token方式的流程，上一张图，比较清晰：\n上图就是 token + redis的幂等方案 ，适用绝大部分场景。\n主要思想：\n 服务端提供token的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取token，服务器会把token保存到redis中。（微服务肯定是分布式了，如果单机就适用jvm缓存）。 然后调用业务接口请求时，携带token过去 ，一般放在请求头部。 服务器判断token是否存在redis中 ，存在表示第一次请求 ，可以继续执行业务，执行业务完成后，最后需要把 redis中的token删除。 如果判断token 不存在redis中 ，就表示是重复操作 ，直接 返回重复标记给client ，这样就保证了业务代码，不被重复执行。  这种方案是比较常用的方案，也是网上经常介绍的，但是有一点不同的地方：\n 网上方案：检验token存在（表示第一次请求）后，就立刻删除token，再进行业务处理 上面方案：检验token存在（表示第一次请求）后，先进行业务处理，再删除token  关键点就是 先删除token，还是后删除token 。\n网上方案缺点: 先删除token，这是出现系统问题导致业务处理出现异常，业务处理没有成功，接口调用方也没有获取到明确的结果，然后进行重试，但token已经删除掉了，服务端判断token不存在，认为是重复请求 ，就直接返回了，无法进行业务处理了\n上面方案缺点: 后删除token 也是会存在问题的，如果进行业务处理成功后，删除redis中的token失败，这样就导致了有 可能会发生重复请求，因为token没有被删除\n其实上面的问题就是数据库和缓存redis数据不一致的问题\n总结，我认为 网上方案先删除token，先保证不会因为重复请求，业务数据出现问题。顶多再让用户处理一次\n出现 业务异常，可以让调用方配合处理一下，重新获取新的token，再次由业务调用方发起重试请求就ok了\ntoken机制缺点 业务请求每次请求，都会有额外的请求（一次获取token请求、判断token是否存在的业务）。其实真实的生产环境中，1万请求也许只会存在10个左右的请求会发生重试，为了这10个请求，我们让9990个请求都发生了额外的请求。（当然redis性能很好，耗时不会太明显）\n乐观锁机制 乐观锁这里解决了 计算赋值型 的修改场景，\n我们对之前的sql语句进行修改\nupdate user set point = point + 20, version = version + 1 where userid=1 and version=1\n加上了版本号 后，就让此计算赋值型业务，具备幂等性 。\n乐观锁机制缺点 就是在操作业务前，需要先查询出当前的version版本\n唯一主键机制 这个机制是利用了数据库的 主键唯一约束 的特性，解决了在insert场景时幂等问题。\n但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键，必须要处理 分布式唯一主键ID 的生成，\n如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。\n唯一主键机制缺点 因为对主键有一定的要求，这个方案就跟业务有点耦合了，无法用自增主键了。\n去重表机制 这个方案业务中要有 唯一主键，这个 去重表中只要一个字段 就行，设置唯一主键约束，当然根据业务自行添加其他字段。\n主要流程上图\n上面的主要流程就是 把唯一主键插入去重表，再进行业务操作，且他们在同一个事务中。\n这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等问题\n注意：\n这里要注意的是，去重表和业务表应该在 同一库中 ，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。\n这个方案也是比较常用的，去重表是跟业务无关的，很多业务可以共用同一个去重表，只要规划好唯一主键就行了\n总结 上面介绍了一些幂等方案，小伙伴们根据自身的业务进行选择，尽量不要让系统变的复杂，所以推荐 唯一主键 和 乐观锁方式 ，因为实现比较简单\n","description":"微服务架构之幂等性问题","id":70,"section":"stack","tags":["knowledge"],"title":"微服务架构之幂等性问题","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/manyquest/"},{"content":"概述 Filebeat是一个轻量级的日志数据收集工具，属于Elastic公司的Elastic Stack（ELK Stack）生态系统的一部分。\n目的 从各种来源收集日志数据，将数据发送到 Elasticsearch 、 Logstash 或 其他目标，以便进行 搜索、分析和可视化\n特点 轻量级： Filebeat是一个 轻量级的代理，对系统资源的消耗非常低。它设计用于高性能和低延迟，可以在各种环境中运行，包括 服务器、容器和虚拟机。\n多源收集： Filebeat支持从各种来源收集数据，包括 日志文件、系统日志、Docker容器日志、Windows事件日志 等。它具有多个输入模块，可以轻松配置用于不同数据源的数据收集。\n模块化： Filebeat 采用模块化的方式组织配置，每个输入类型都可以作为一个模块，易于扩展和配置。这使得添加新的数据源和日志格式变得更加简单。\n自动发现： Filebeat支持 自动发现服务，可以在容器化环境中自动识别新的容器和服务，并开始收集其日志数据。\n安全性： Filebeat支持 安全传输，可以使用 TLS/SSL加密协议 将数据安全地传输到目标。它还支持基于令牌的身份验证。\n数据处理： Filebeat可以对数据进行简单的处理，如 字段分割、字段重命名和数据过滤 ，以确保数据适合进一步处理和分析。\n目标输出： Filebeat可以 将数据发送到多个目标 ，最常见的是将数据发送到 Elasticsearch，以便进行全文搜索和分析。此外，还可以将数据发送到 Logstash、Kafka等目标。\n实时性： Filebeat可以以 实时方式收集和传输数据，确保日志数据及时可用于分析和可视化。\n监控和管理： Filebeat具有 自身的监控功能，可以监视自身的状态和性能，并与 Elasticsearch、Kibana 等工具集成，用于管理和监控数据收集\n采集原理的主要步骤 一、数据源检测： Filebeat首先配置要监视的数据源，这可以是日志文件、系统日志、Docker容器日志、Windows事件日志等。Filebeat可以通过输入模块配置来定义数据源。\n二、数据收集： 一旦数据源被定义，Filebeat会定期轮询这些数据源，检查是否有新的数据产生。\n如果有新数据，Filebeat将读取数据并将其发送到后续处理阶段。\n三、数据处理： Filebeat可以对采集到的数据进行一些简单的处理，例如字段分割、字段重命名、数据解析等。这有助于确保数据格式适合进一步的处理和分析。\n四、数据传输： 采集到的数据将被传输到一个或多个目标位置，通常是Elasticsearch、Logstash或Kafka等。\nFilebeat可以配置多个输出目标，以便将数据复制到多个地方以增加冗余或分发数据。\n五、安全性和可靠性： Filebeat支持安全传输，可以使用TLS/SSL协议对数据进行加密。\n它还具有数据重试机制，以确保数据能够成功传输到目标位置。\n六、数据目的地： 数据被传输到目标位置后，可以被进一步处理、索引和分析。目标位置通常是Elasticsearch，用于全文搜索和分析，或者是Logstash用于进一步的数据处理和转换，也可以是Kafka等其他消息队列。\n七、实时性和监控： Filebeat可以以实时方式监视数据源，确保新数据能够快速传输和处理。\nFilebeat还可以与监控工具集成，以监控其自身的性能和状态，并将这些数据发送到监控系统中。\n总结，\nFilebeat采集原理是通过轮询监视数据源，将新数据采集并发送到目标位置，同时确保数据的安全传输和可靠性。它提供了一种高效且灵活的方式来处理各种类型的日志和事件数据，以便进行后续的分析和可视化。\n组件组成 Filebeat由两个主要组件组成：inputs 和 harvesters\nharvester 一个harvester负责读取一个单个文件的内容。harvester逐行读取每个文件（一行一行地读取每个文件），并把这些内容发送到输出。\n每个文件启动一个harvester。\nharvester负责打开和关闭这个文件，这就意味着在harvester运行时文件描述符保持打开状态。\n在harvester正在读取文件内容的时候，文件被删除或者重命名了，那么Filebeat会续读这个文件。这就有一个问题了，就是只要负责这个文件的harvester没用关闭，那么磁盘空间就不会释放。默认情况下，Filebeat保存文件打开直到close_inactive到达。\ninput 一个input负责管理harvesters，并找到所有要读取的源。\n如果input类型是log，则input查找驱动器上与已定义的glob路径匹配的所有文件，并为每个文件启动一个harvester。\n每个input都在自己的Go例程中运行。\n下面的例子配置Filebeat从所有匹配指定的glob模式的文件中读取行：\n1 2 3 4 5 6 7  filebeat.inputs:- type:logpaths:- /var/log/*.log- /var/path2/*.log  Filebeat安装 步骤一：下载 下载：wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-linux-x86_64.tar.gz\n步骤二：解压 解压：tar -zvxf filebeat-7.5.1-linux-x86_64.tar.gz\n步骤三：编辑 在解压出来的目录中，编辑filebeat.yml（缩进比较严格）\n 复制一份用于备份 清空内容并输入，如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  filebeat.inputs:- type:logignore_older:3600paths:- /data/www/tmewbgl-api/runtime/logs/error/error.logfields:sys_name:wbglerrorlogtopic:topic-logstash-flowprocessors:- drop_fields:fields:[\u0026#34;beat.hostname\u0026#34;,\u0026#34;beat.name\u0026#34;,\u0026#34;beat.version\u0026#34;,\u0026#34;input_type\u0026#34;,\u0026#34;beat\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;source\u0026#34;]- type:logignore_older:3600paths:- /data/www/tmewbgl-api/runtime/schedule/info/info.logfields:sys_name:wbglinfologtopic:topic-logstash-flowprocessors:- drop_fields:fields:[\u0026#34;beat.hostname\u0026#34;,\u0026#34;beat.name\u0026#34;,\u0026#34;beat.version\u0026#34;,\u0026#34;input_type\u0026#34;,\u0026#34;beat\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;source\u0026#34;]output.kafka:hosts:[\u0026#34;10.130.64.159:9092\u0026#34;]topic:\u0026#39;%{[fields.logtopic]}\u0026#39;max_message_bytes:1000000required_acks:1compression:none  步骤四：启动 启动\n检验是否成功：\n1  ./filebeat -e -c filebeat.yml -d \u0026#34;publish\u0026#34;   参数解释：\n./filebeat -e -c filebeat.yml\n -c：配置文件位置 -path.logs：日志位置 -path.data：数据位置 -path.home：家位置 -e：关闭日志输出 -d 选择器：启用对指定选择器的调试。 对于选择器，可以指定逗号分隔的组件列表，也可以使用-d“*”为所有组件启用调试.例如，-d“publish”显示所有“publish”相关的消息。  步骤五：后台启动 后台启动\n1  nohup ./filebeat -e -c filebeat.yml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;   将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出\n1  nohup ./filebeat -e -c filebeat.yml \u0026gt; filebeat.log \u0026amp;   步骤六：停止 1  ps -ef|grep filebeat,kill -9 pid   配置多个日志地址： 1 2 3 4 5 6 7  filebeat.inputs:- type:log #日志目录一paths:- /var/log/system.log- type:log #日志目录二paths:- \u0026#34;/var/log/apache2/*\u0026#34;  ","description":"一个轻量级的日志数据收集工具。","id":71,"section":"stack","tags":["knowledge"],"title":"Filebeat日志采集组件","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/filebeat/"},{"content":"新建Dockerfile 新建文件夹zookeeper、kafka、kafka-manager，并添加相应的Dockerfile\nzookeeper目录下的Dockerfile内容如下：\n1  FROMwurstmeister/zookeeper  kafka目录下的Dockerfile内容如下：\n1 2  FROMwurstmeister/kafkaRUN apt-get update \u0026amp;\u0026amp; apt-get install -y vim  kafka-manager目录下的Dockerfile内容如下：\n1 2  FROMsheepkiller/kafka-managerRUN apt-get update \u0026amp;\u0026amp; apt-get install -y vim  配置docker-compose.yml文件 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  version: \u0026#34;3\u0026#34;services: ... ... ... zookeeper: build: ./zookeeper container_name: zookeeper ports: - \u0026#34;2181:2181\u0026#34; volumes: - /Users/wangdante/D/kugou/:/var/www/html/ restart: always networks: jarven: ipv4_address: 172.19.0.18 kafka: build: ./kafka container_name: kafka ports: - \u0026#34;9092:9092\u0026#34; environment: KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1 KAFKA_MESSAGE_MAX_BYTES: 2000000 KAFKA_CREATE_TOPICS: \u0026#34;Topic1:1:3,Topic2:1:1:compact\u0026#34; KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 volumes: - /Users/wangdante/D/kugou/:/var/www/html/ restart: always networks: jarven: ipv4_address: 172.19.0.16 kafka-manager: build: ./kafka-manager container_name: kafka-manager ports: - \u0026#34;9020:9000\u0026#34; environment: ZK_HOSTS: zookeeper:2181 volumes: - /Users/wangdante/D/kugou/:/var/www/html/ restart: always networks: jarven: ipv4_address: 172.19.0.17...  进入kafka容器修改配置 进入容器：\ndocker-compose exec kafka /bin/bash\n修改配置：\n1 2 3 4 5 6  cd /opt/kafka/config/ # ls connect-console-sink.properties connect-file-source.properties consumer.properties server.properties connect-console-source.properties connect-log4j.properties kraft tools-log4j.properties connect-distributed.properties connect-mirror-maker.properties log4j.properties trogdor.conf connect-file-sink.properties connect-standalone.properties producer.properties zookeeper.properties   修改zookeeper的配置文件：zookeeper.properties\n1 2 3 4 5 6 7 8 9 10  #新建目录 kafkaLogs 和 zooLogs mkdir /opt/kafka/kafkaLogs mkdir /opt/kafka/zooLogs cd /opt/kafka/config/ vim zookeeper.properties #配置如下： dataDir=/opt/kafka/zooLogs clientPort=2181 maxClientCnxns=0 admin.enableServer=false   修改kafka的配置文件：server.porperties\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  ############################# Server Basics ############################# broker.id=0 ############################# Socket Server Settings ############################# //9092:因为9093和下面冲突 listeners=PLAINTEXT://127.0.0.1:9093 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 ############################# Log Basics ############################# log.dirs=/opt/kafka/kafkaLogs num.partitions=1 num.recovery.threads.per.data.dir=1 ############################# Internal Topic Settings ############################# offsets.topic.replication.factor=1 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 ############################# Log Retention Policy ############################# log.retention.hours=168 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 ############################# Zookeeper ############################# #zookeeper.connect=zookeeper:2181 #jarvenwang update zookeeper.connect=127.0.0.1:2181 zookeeper.connection.timeout.ms=18000 ############################# Group Coordinator Settings ############################# group.initial.rebalance.delay.ms=0 #port=9092 #jarvenwang update port=9093 advertised.host.name=127.0.0.1 message.max.bytes=2000000 #jarvenwang add advertised.port=9093   启动zookeeper 和 启动kafka 启动zookeeper:\n1 2  cd /opt/kafka/config zookeeper-server-start.sh zookeeper.properties \u0026amp;   启动kafka:\n1 2  cd /opt/kafka/config kafka-server-start.sh server.properties \u0026amp;   生产消息 和 消费消息 创建一个主题： PS：如果已经创建了主题可以，直接查看:\nkafka-topics.sh --list --zookeeper 127.0.0.1:2181\n前提必须要开启zookeeper的服务==》kafka-topics.sh \u0026ndash;create \u0026ndash;zookeeper 127.0.0.1:2181 \u0026ndash;replication-factor 1 \u0026ndash;partitions 1 \u0026ndash;topic test\n1 2  kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1 --topic test #kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1 --topic test2   查看创建的主题： 1 2 3  $ kafka-topics.sh --list --zookeeper 127.0.0.1:2181 jarvenwang test   生产者： 1 2 3 4  $ kafka-console-producer.sh --broker-list 127.0.0.1:9093 --topic test \u0026gt;第一个消息 \u0026gt;第二个消息 \u0026gt;   消费者： 1 2 3  $ kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9093 --topic test --from-beginning 第一个消息 第二个消息   查看版本： 1  ps -ef|grep \u0026#39;/libs/kafka.\\{2,40\\}.jar\u0026#39;   进入kafka-manager容器修改配置 进入容器（可能要尝试多次）\n 提示：qemu: uncaught target signal 11 (Segmentation fault) - core dumped （镜像的问题）\ndocker-compose exec kafka-manager /bin/bash\n 1 2 3 4  [root@65567f1ceed6 kafka-manager-1.3.1.8]# ls README.md bin lib RUNNING_PID conf share application.home_IS_UNDEFINED hs_err_pid1.log start-kafka-manager.sh   修改配置信息zkhosts 修改配置\nvi conf/application.conf\n1 2 3 4  # 修改 kafka-manager.zkhosts=\u0026#34;172.19.0.18:2181\u0026#34; # 如果是集群，参考如下 # kafka-manager.zkhosts=\u0026#34;10.0.0.50:2181,10.0.0.60:2181,10.0.0.70:2181\u0026#34;   启动kafka-manager 确保自己本地的ZK已经启动了之后，我们来启动Kafka-manager, kafka-manager 默认的端口是9000\n 如果想修改端口：\n-Dhttp.port=8081，指定端口; 如：bin/kafka-manager -Dhttp.port=8081\n-Dconfig.file=conf/application.conf 指定配置文件；如：nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8081 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\n 前台启动 1 2 3 4  $ bin/kafka-manager 05:18:59,993 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy] 05:18:59,995 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml] ...   如果要结束进程：\nrm -rf /kafka-manager-1.3.1.8/RUNNING_PID\n后台启动 1 2  $ nohup bin/kafka-manager -Dconfig.file=conf/application.conf \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; [1] 3722   访问 测试端口是否成功：\nnc -zv 一下\nnc -zv 127.0.0.1 9020\n由于9000端口映射的端口为9020\n输入地址：127.0.0.1:9020 即可访问\n启动完毕后可以查看端口是否启动，由于启动过程需要一段时间，端口起来的时间可能会延后\n","description":"zookeeper、kafka、kafka-manager安装","id":72,"section":"stack","tags":["knowledge"],"title":"zookeeper、kafka、kafka-manager安装","uri":"http://wangjinbao.netlify.app/en/stack/knowledge/kafka/"},{"content":"垃圾回收算法 垃圾回收（Garbage Collection，简称 GC）是一种内存管理策略，由垃圾收集器以类似 守护协程 的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间.\nGC优势   屏蔽内存回收的细节\n拥有 GC 能力的语言能够为用户屏蔽复杂的内存管理工作，使用户更好地聚焦于核心的业务逻辑.\n  以全局视野执行任务\n现代软件工程项目体量与日剧增，一个项目通常由团体协作完成，研发人员负责各自模块的同时，不可避免会涉及到临界资源的使用. 此时由于缺乏全局的视野，手动对内存进行管理无疑会增加开发者的心智负担. 因此，将这部分工作委托给拥有全局视野的垃圾回收模块来完成，方为上上之策.\n  GC劣势   提高了下限但降低了上限\n将释放内存的工作委托给垃圾回收模块，研发人员得到了减负，但同时也失去了控制主权. 除了运用有限的GC调优参数外，更多的自由度都被阉割，需要向系统看齐，服从设定.\n  增加了额外的成本\n全局的垃圾回收模块化零为整，会需要额外的状态信息用以存储全局的内存使用情况. 且部分时间需要中断整个程序用以支持垃圾回收工作的执行，这些都是GC额外产生的成本.\n  GC的总体评价 除开少量追求极致速度的特殊小规模项目之外，在绝大多数高并发项目中，GC模块都为我们带来了极大的裨益，已经成为一项不可或缺的能力.\n经典垃圾回收算法 一、标记清扫 标记清扫（Mark-Sweep）算法，分为两步走：\n 标记：标记出当前还存活的对象 清扫：清扫掉未被标记到的垃圾对象  这是一种类似于排除法的间接处理思路，不直接查找垃圾对象，而是标记存活对象，从而取补集推断出垃圾对象.\n至于标记清扫算法的不足之处，通过上图也得以窥见一二，那就是会 产生内存碎片 . 经过几轮标记清扫之后，空闲的内存块可能零星碎片化分布，此时倘若有大对象需要分配内存，可能会因为内存空间无法化零为整从而导致分配失败.\n二、标记压缩 标记压缩（Mark-Compact）算法，是在标记清扫算法的基础上做了升级，在第二步”清扫“的同时还会对存活 对象进行压缩整合 ，使得整体空间更为紧凑，从而解决内存碎片问题.\n标记压缩算法在功能性上呈现得很出色，而其存在的缺陷也很简单，就是实现时会有 很高的复杂度.\n三、半空间复制-java 半空间复制（Semispace Copy）算法\n 分配两片相等大小的空间，称为 fromspace 和 tospace 每轮只使用 fromspace 空间，以GC作为分水岭划分轮次 GC时，将fromspace存活对象转移到tospace中，并以此为契机对空间进行压缩整合 GC后，交换fromspace和tospace，开启新的轮次  半空间复制算法应用了以空间换取时间的优化策略，解决了内存碎片的问题，也在一定程度上降低了压缩空间的复杂度. 但其缺点也同样很明显—— 比较浪费空间 .\n四、引用计数(不可循环引用) 引用计数（Reference Counting）算法是很简单高效的：\n 对象每被引用一次，计数器加1 对象每被删除引用一次，计数器减1 GC时，把计数器等于 0 的对象删除  这个朴素的算法存在一个致命的缺陷：无法解决循环引用或者自引用 问题\nGolang 中的垃圾回收 Golang 在 1.8版本之后 ，GC策略框架已经奠定，就是 并发三色标记法 + 混合写屏障 机制\n三色标记法 Golang GC 中用到的 三色标记法 属于 标记清扫-算法 下的一种实现\n要点：\n 对象分为三种颜色标记：黑、灰、白 黑对象代表，对象自身存活，且其指向对象都已标记完成 灰对象代表，对象自身存活，但其指向对象还未标记完成 白对象代表，对象尙未被标记到，可能是垃圾对象 标记开始前，将根对象（全局对象、栈上局部变量等）置黑，将其所指向的对象置灰 标记规则是，从灰对象出发，将其所指向的对象都置灰. 所有指向对象都置灰后，当前灰对象置黑 标记结束后，白色对象就是不可达的垃圾对象，需要进行清扫.  并发垃圾回收 Golang 1.5 版本 是个分水岭，在此之前，GC时需要 停止全局的用户协程，专注完成GC工作 后 ，再恢复用户协程，这样做在实现上简单直观，但是会对用户造成不好的体验\n1.5版本以来 ，Golang引入了并发垃圾回收机制，允许用户协程和后台的GC协程并发运行，大大地提高了用户体验. 但“并发”是一个值得大家警惕的字眼. 用户协程运行时可能对对象间的引用关系进行调整，这会严重打乱GC三色标记时的标记秩序\n几个问题 一、Golang 并发垃圾回收可能存在 漏标问题 漏标问题 指的是在 用户协程 与 GC协程 并发执行的场景下，部分存活对象未被标记从而被误删的情况 .\n这一问题产生的过程如下：\n 条件：初始时刻，对象B持有对象C的引用 moment1：GC协程下，对象A被扫描完成，置黑；此时对象B是灰色，还未完成扫描 momen2：用户协程下，对象A建立指向对象C的引用 moment3：用户协程下，对象B删除指向对象C的引用 moment4：GC协程下，开始执行对对象B的扫描  上述场景中，由于GC协程在B删除C的引用后才开始扫描B，因此无法到达C. 又因为A已经被置黑，不会再重复扫描，因此从扫描结果上看，C是不可达的.\n然而事实上，C应该是存活的（被A引用），而GC结束后会因为C仍为白色，因此被GC误删.\n漏标问题是无法接受，其引起的误删现象可能会导致程序出现致命的错误. 针对漏标问题，Golang 给出的解决方案是 屏障机制 的使用\n二、Golang 并发垃圾回收可能存在 多标问题 多标问题 指的是在用户协程与GC协程并发执行的场景下，部分垃圾对象被误标记从而导致GC未按时将其回收的问题.\n这一问题产生的过程如下：\n 条件：初始时刻，对象A持有对象B的引用 moment1：GC协程下，对象A被扫描完成，置黑；对象B被对象A引用，因此被置灰 momen2：用户协程下，对象A删除指向对象B的引用  上述场景引发的问题是，在事实上，B在被A删除引用后，已成为垃圾对象，但由于其事先已被置灰，因此最终会更新为黑色，不会被GC删除\n多标问题对比于漏标问题而言，是相对可以接受的. 其导致本该被删但仍侥幸存活的对象被称为“浮动垃圾”，至多到下一轮GC，这部分对象就会被GC回收，因此错误可以得到弥补\n三、Golang 垃圾回收如何解决 内存碎片问题 标记清扫算法会存在产生“内存碎片”的缺陷\nGolang采用 TCMalloc 机制，依据 对象的大小将其归属为到事先划分好的spanClass 当中，这样能够消解外部碎片的问题，将问题限制在相对可控的内部碎片当中\n基于此，Golang选择采用实现上更为简单的 标记清扫算法 ，避免使用复杂度更高的标记压缩算法，因为在 TCMalloc 框架下，后者带来的优势已经不再明显\n四、Golang为什么不选择分代垃圾回收机制 分代算法指的是，将对象分为年轻代和老年代两部分（或者更多），采用不同的GC策略进行分类管理. 分代GC算法有效的前提是，绝大多数年轻代对象都是朝生夕死，拥有更高的GC回收率，因此适合采用特别的策略进行处理\n然而Golang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收.\n内存逃逸机制减弱了分代算法对Golang GC所带来的优势，考虑分代算法需要产生额外的成本（如不同年代的规则映射、状态管理以及额外的写屏障），Golang 选择不采用分代GC算法.\n屏障机制 强弱三色不变式 漏标问题 的本质：一个已经 扫描完成的黑对象 指向了一个 被灰\\白对象删除引用 的 白色对象\n场景的要素拆分如下:\n 黑色对象指向了白色对象 灰、白对象删除了白色对象 1,2 步中谈及的白色对象是同一个对象 1 发生在 2 之前  一套用于解决漏标问题的方法论称之为 强弱三色不变式 ：\n 强三色不变式 ：白色对象不能被黑色对象直接引用（直接破坏1） 弱三色不变式 ：白色对象可以被黑色对象引用，但要从某个灰对象出发仍然可达该白对象（间接破坏了1、2的联动）  插入写屏障 屏障\u0026ndash;\u0026gt;先触发的回调\n步骤：\n 步骤一：黑对象尝试指向白对象 步骤二：触发屏障，白对象被置灰 步骤三：黑对象指向灰对象  屏障机制类似于一个回调保护机制，指的是在完成某个特定动作前，会先完成屏障成设置的内容.\n插入写屏障（Dijkstra）的目标是 实现强三色不变式，保证当一个黑色对象指向一个白色对象前，会先触发屏障将白色对象置为灰色，再建立引用.漏标问题得以解决\n删除写屏障 步骤：\n 步骤一：对象A尝试删除对B引用 步骤二：屏障触发，B被置灰 步骤三：引用删除成功  删除写屏障（Yuasa barrier）的目标是实现弱三色不变式，保证当一个白色对象即将被上游删除引用前，会触发屏障将其置灰，之后再删除上游指向其的引用，漏标问题得以解决\n混合写屏障 插入写屏障、删除写屏障二者择其一，即可解决并发GC的漏标问题，至于错标问题，则采用容忍态度，放到下一轮GC中进行延后处理即可.\n真实场景中，需要补充一个新的设定—— 屏障机制 无法作用于栈对象 .\n这是因为栈对象可能涉及频繁的轻量操作，倘若这些高频度操作都需要一一触发屏障机制，那么所带来的成本将是无法接受的.\n在这一背景下，单独看插入写屏障或删除写屏障，都无法真正解决漏标问题，除非我们引入额外的Stop the world（STW）阶段，对栈对象的处理进行兜底。\n为了消除这个额外的 STW 成本，Golang 1.8 引入了混合写屏障机制，可以视为糅合了\n插入写屏障 + 删除写屏障 的加强版本\n要点如下：\n GC 开始前，以栈为单位分批扫描，将栈中所有对象置黑 GC 期间，栈上新创建对象直接置黑 堆对象正常启用插入写屏障 堆对象正常启用删除写屏障  ","description":"Golang 垃圾回收原理分析","id":73,"section":"stack","tags":["golang",""],"title":"Golang垃圾回收原理分析","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_memery_analysis/"},{"content":"背景 为什么需要锁？\n锁是 sync 包中的核心，它主要有两个方法，分别是 加锁（Lock）和 解锁（Unlock）。\n在并发的情况下，多个线程或协程同时其修改一个变量，使用锁能保证在某一时间内，只有一个协程或线程修改这一变量。\n不使用锁时，在并发的情况下可能无法得到想要的结果,如下所示:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var a = 0 for i := 0; i \u0026lt; 1000; i++ { go func(idx int) { a += 1 fmt.Println(a) }(i) } time.Sleep(time.Second) }   从理论上来说，上面的程序会将 a 的值依次递增输出，然而实际结果却是下面这样子的。\n输出：\n1 2 3 4 5 6 7  ... 479 997 484 947 391 487   通过运行结果可以看出 a 的值并不是按顺序递增输出的，这是为什么呢？\n协程的执行顺序大致如下所示：\n 从寄存器读取 a 的值； 然后做加法运算； 最后写到寄存器。  按照上面的顺序，假如有一个协程取得 a 的值为 3，然后执行加法运算，此时又有一个协程对 a 进行取值，得到的值同样是 3，最终两个协程的返回结果是相同的。\n而锁的概念就是，当一个协程正在处理 a 时将 a 锁定，其它协程需要等待该协程处理完成并将 a 解锁后才能再进行操作，也就是说同时处理 a 的协程只能有一个，从而避免上面示例中的情况出现。\n互斥锁 Mutex 上面的示例中出现的问题怎么解决呢？加一个互斥锁 Mutex 就可以了。那什么是互斥锁呢 ？互斥锁中其有两个方法可以调用，如下所示：\n1 2  func (m *Mutex) Lock() func (m *Mutex) Unlock()   将上面的代码略作修改，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var a = 0 var lock sync.Mutex for i := 0; i \u0026lt; 1000; i++ { go func(idx int) { lock.Lock() defer lock.Unlock() a += 1 fmt.Printf(\u0026#34;goroutine %d, a=%d\\n\u0026#34;, idx, a) }(i) } // 等待 1s 结束主程序  // 确保所有协程执行完  time.Sleep(time.Second) }   运行结果如下：\n1 2 3 4 5 6  ... goroutine 515, a=996 goroutine 356, a=997 goroutine 327, a=998 goroutine 78, a=999 goroutine 978, a=1000   需要注意的是一个互斥锁只能同时被一个 goroutine 锁定，其它 goroutine 将阻塞直到互斥锁被解锁（重新争抢对互斥锁的锁定），示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan struct{}, 2) var l sync.Mutex go func() { l.Lock() defer l.Unlock() fmt.Println(\u0026#34;goroutine1: 我会锁定大概 2s\u0026#34;) time.Sleep(time.Second * 2) fmt.Println(\u0026#34;goroutine1: 我解锁了，你们去抢吧\u0026#34;) ch \u0026lt;- struct{}{} }() go func() { fmt.Println(\u0026#34;goroutine2: 等待解锁\u0026#34;) l.Lock() defer l.Unlock() fmt.Println(\u0026#34;goroutine2: 欧耶，我也解锁了\u0026#34;) ch \u0026lt;- struct{}{} }() // 等待 goroutine 执行结束  for i := 0; i \u0026lt; 2; i++ { \u0026lt;-ch } }   上面的代码运行结果如下：\n1 2 3 4  goroutine2: 等待解锁 goroutine1: 我会锁定大概 2s goroutine1: 我解锁了，你们去抢吧 goroutine2: 欧耶，我也解锁了   读写锁 读写锁有如下四个方法：\n 写操作的锁定和解锁分别是*func (RWMutex) Lock 和 func (*RWMutex) Unlock； 读操作的锁定和解锁分别是*func (RWMutex) Rlock 和 *func (RWMutex) RUnlock  读写锁的区别在于：  \u0026quot;写锁定，不读不写直到解锁\u0026quot;\n当有一个 goroutine 获得写锁定，其它无论是读锁定还是写锁定都将阻塞直到写解锁； \u0026quot;读锁定，仍然可读\u0026quot;\n当有一个 goroutine 获得读锁定，其它读锁定仍然可以继续； \u0026quot;读锁定，不写直到解锁\u0026quot;\n当有一个或任意多个读锁定，写锁定将等待所有读锁定解锁之后才能够进行写锁定  所以说这里的读锁定（RLock）目的其实是告诉写锁定，有很多协程或者进程正在读取数据，写操作需要等它们读（读解锁）完才能进行写（写锁定）\n总结为如下三条：\n 同时只能有一个 goroutine 获得 写锁定； 同时可以有多个 gorouinte 获得 读锁定； 同时只能存在写锁定或读锁定（读和写互斥）\n示例代码如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sync\u0026#34; ) var count int var rw sync.RWMutex func main() { ch := make(chan struct{}, 10) for i := 0; i \u0026lt; 5; i++ { go read(i, ch) } for i := 0; i \u0026lt; 5; i++ { go write(i, ch) } for i := 0; i \u0026lt; 10; i++ { \u0026lt;-ch } } func read(n int, ch chan struct{}) { rw.RLock() fmt.Printf(\u0026#34;goroutine %d 进入读操作...\\n\u0026#34;, n) v := count fmt.Printf(\u0026#34;goroutine %d 读取结束，值为：%d\\n\u0026#34;, n, v) rw.RUnlock() ch \u0026lt;- struct{}{} } func write(n int, ch chan struct{}) { rw.Lock() fmt.Printf(\u0026#34;goroutine %d 进入写操作...\\n\u0026#34;, n) v := rand.Intn(1000) count = v fmt.Printf(\u0026#34;goroutine %d 写入结束，新值为：%d\\n\u0026#34;, n, v) rw.Unlock() ch \u0026lt;- struct{}{} }   执行结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  goroutine 2 进入读操作... goroutine 2 读取结束，值为：0 goroutine 4 进入写操作... goroutine 4 写入结束，新值为：931 goroutine 3 进入读操作... goroutine 3 读取结束，值为：931 goroutine 4 进入读操作... goroutine 4 读取结束，值为：931 goroutine 0 进入读操作... goroutine 0 读取结束，值为：931 goroutine 1 进入读操作... goroutine 1 读取结束，值为：931 goroutine 0 进入写操作... goroutine 0 写入结束，新值为：308 goroutine 1 进入写操作... goroutine 1 写入结束，新值为：152 goroutine 2 进入写操作... goroutine 2 写入结束，新值为：21 goroutine 3 进入写操作... goroutine 3 写入结束，新值为：33   【示例 1】多个读操作同时读取一个变量时，虽然加了锁，但是读操作是不受影响的。（读和写是互斥的，读和读不互斥）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package main import ( \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var m *sync.RWMutex func main() { m = new(sync.RWMutex) // 多个同时读  go read(1) go read(2) time.Sleep(2*time.Second) } func read(i int) { println(i,\u0026#34;read start\u0026#34;) m.RLock() println(i,\u0026#34;reading\u0026#34;) time.Sleep(1*time.Second) m.RUnlock() println(i,\u0026#34;read over\u0026#34;) }   结果如下：\n1 2 3 4 5 6  1 read start 1 reading 2 read start 2 reading 2 read over 1 read over   【示例 2】由于读写互斥，所以写操作开始的时候，读操作必须要等写操作进行完才能继续，不然读操作只能继续等待\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package main import ( \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var m *sync.RWMutex func main() { m = new(sync.RWMutex) // 写的时候啥也不能干  go write(1) go read(2) go write(3) time.Sleep(2*time.Second) } func read(i int) { println(i,\u0026#34;read start\u0026#34;) m.RLock() println(i,\u0026#34;reading\u0026#34;) time.Sleep(1*time.Second) m.RUnlock() println(i,\u0026#34;read over\u0026#34;) } func write(i int) { println(i,\u0026#34;write start\u0026#34;) m.Lock() println(i,\u0026#34;writing\u0026#34;) time.Sleep(1*time.Second) m.Unlock() println(i,\u0026#34;write over\u0026#34;) }   结果如下：\n1 2 3 4 5 6  1 write start 3 write start 1 writing 2 read start 1 write over 2 reading   ","description":"sync包里提供了互斥锁 Mutex 和读写锁 RWMutex 用于处理并发过程中可能出现同时两个或多个协程读或写同一个变量的情况","id":74,"section":"stack","tags":["golang",""],"title":"Golang的sync包与锁","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_package_sync/"},{"content":"思想 1.以空间换时间，一次缓存，多次复用 go中的堆 mheap 正是\u0026quot;缓存\u0026quot;的思想。\n堆mheap的特点：\n 对于操作系统，是用户进程中缓存的内存 对于go进行内部，堆是所有对象的内存起源  2.多级缓存，实现无/细锁化 堆 是Go运行时中最大的临界共享资源，这意味着每次存取都要加锁，在性能层面是一件很可怕的事情。\n相关概念：\n mheap : 全局的内存起源，访问要加全局锁 mcentral : 每种对象大小规格（全局共划分为68种）对应的缓存，锁的粒度也仅限于同一种规格以内 mcache ：每个P（正是GMP中的P）持有一份的内存缓存，访问时无锁  3.多级规格，提高利用率 \u0026ndash;\u0026gt; span大小趋势递增\n\u0026ndash;\u0026gt; 分配object大小趋势递增\n相关概念：\n page ： 最小的存储单元\ngo借鉴操作系统分页管理的思想，每个最小的存储单元也称之为页 page ，但大小为 8KB mspan : 最小的管理单元\nmspan大小为page的整数倍，且从8B到80KB被划分为 68 种不同的规格，分配对象时，会根据大小映射到不同规格的mspan，从中获取空间  内存单元mspan mspan中包括：next、prev指针、startAddr、allocCache（0表示被对象占用，1是空闲的 ）、pages\nmspan类的源码位于 runtime/mheap.go文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  type mspan struct { //标识前后节点的指针 \tnext *mspan // next span in list, or nil if none \tprev *mspan // previous span in list, or nil if none \t//起始地址 \tstartAddr uintptr // address of first byte of span aka s.base() \t//包含几页，页是连续的 \tnpages uintptr // number of pages in span \t//标识此前的位置都已被占用 \tfreeindex uintptr //最多可以存放多少个object \tnelems uintptr // number of object in the span. \t//bitmap每个bit对应一个object块，标识该块是否已被占用 \tallocCache uint64 //标识mspan等级，包含class和noscan两部分信息 \tspanclass spanClass // size class and noscan (uint8) }   mspan等级的源码 runtime/sizeclasses.go中：\n1 2 3 4 5 6 7  // class bytes/obj bytes/span objects tail waste max waste min align // 1 8 8192 1024 0 87.50% 8 // 2 16 8192 512 0 43.75% 16 // 3 24 8192 341 8 29.24% 8 // 4 32 8192 256 0 21.88% 32 // 5 48 8192 170 32 31.52% 16 // 6 64 8192 128 0 23.44% 64   最大浪费率：\n（（24-77）*341 + 8）8192 = 29.24% \n代码位于 runtime/mheap.go\n线程缓存mcache 特点：\n mcache是每个P独有的缓存，因此交互无锁 mcache将每种spanClass等级的mspan各缓存一个，总数为2（noscan维度）*68（大小维度）=136 mcache中还有一个为对象分配器tiny allocator，用于处理小于16B对象的内存分配  mcache代码位于runtime/mcache.go:\n1 2 3 4 5 6 7 8 9  type mcache struct { //微对象分配器相关  tiny uintptr tinyoffset uintptr tinyAllocs uintptr //mcache中缓存的mspan，每种spanClass各一个 \talloc [numSpanClasses]*mspan }   中心缓存mcentral 特点：\n 每个mcentral对应一种spanClass 每个mcentral下聚合了该spanClass下的mspan mcentral下的mspan分为两个链表，分别为有空间mspan链表partial和满空间mspan链表full 每个mcentral一把锁  代码位于runtime/mcentral.go:\n1 2 3 4 5 6 7 8  type mcentral struct { //对应的spanClass \tspanclass spanClass //有空位的mspan集合，数组长度为2是用于抗一轮GC \tpartial [2]spanSet // list of spans with a free object \t//无空位的mspan集合 \tfull [2]spanSet // list of spans with no free objects }   全局堆缓存mheap 要点：\n 对于go上层应该而言，堆是操作系统虚拟内存的抽象 以页（8KB）为单位，作为最小内存存储单元 负责将连续页组装成mspan 全局内存基于bitMap标识其使用情况，每个bit对应一页，为0则自由，为1则已被mspan组装 通过heapArena聚合页，记录了页到msapn的映射信息 建立空闲页基数树索引radix tree index，辅助快速寻找空闲页 是mcentral的持有者，持有所有spanClass下的mcentral，作为自身的缓存 内存不够时，向操作系统申请，申请单位为heapArena  代码在 runtime/mheap.go中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  type mheap struct { //堆的全局锁  lock mutex //空闲页分配器，底层是多棵基数树组成的索引，每棵树对应16GB内存空间 \tpages pageAlloc //记录了所有的mspan，需要知道，所有mspan都是经由mheap，使用连续空闲页组装 \tallspans []*mspan // all spans out there \t//heapAreana数组，64位系统下，二维数据容量为 [1][2^22] \t//每个heapArena大小64M，因此理论上，Golang堆上限为2^22*64M=256T \tarenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena // 多个mcentral，总个数为spanClass的个数 \tcentral [numSpanClasses]struct { mcentral mcentral //用于内存地址对齐 \tpad [(cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize) % cpu.CacheLinePadSize]byte } }   空闲页索引pageAlloc 基数树数据结构的含义：\n mheap会基于 bitMap 标识内存中各页的使用情况，bit位为 0 ，代表该页是空闲的，为 1 代表该页已被mspan占用。 每棵基数树聚合了 16GB 内存空间中各页使用情况的索引信息，用于帮助mheap快速找到指定长度的连续空闲页的所在位置 mheap持有 2^14 棵基数树，因此索引全面覆盖到 2^14 * 16GB = 256 T 的内存空间。  heapArena 特点：\n 每个heapArena 包含 8192 个页，大小为 8192 * 8KB = 64 MB heapArena记录了页到mspan的映射，因为GC时，通过地址偏移找到页很方便，但找到其所属的mspan不容易，因些需要通过这个映射信息进行辅助 heapArena是mheap向操作系统申请内存的单位（64MB）  代码位于runtime/mheap.go\n1 2 3 4 5 6  const pagesPerArena = 8192 type heapArena struct{ //实现page到mspan的映射  spans [pagesPerArena]*mspan }   对象分配流程 分配对象的流程，不论是以下哪种方式，最终都会殊途同归步入 mallocgc 方法中\n mew(T) \u0026amp;T{} make(xxxx)  分配流程总览  tiny微对象 (0,16B) small小对象 (16B,32KB) large大对象 (32KB,*)-\u0026gt;0等级  不同类型的对象，会有着不同的分配策略，这些内容在 mallocgc 方法中都有体现.\n核心流程类似于读多级缓存的过程，由上而下，每一步只要成功则直接返回. 若失败，则由下层方法兜底.\n对于微对象的分配流程：\n（1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）\n（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）\n（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）\n（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）\n（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.\n对于小对象的分配流程是跳过（1）步，执行上述流程的（2）-（5）步；\n对于大对象的分配流程是跳过（1）-（3）步，执行上述流程的（4）-（5）步.\n主干方法 mallocgc malloc 方法主干全流程展示\n代码位于 runtime/malloc.go 文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { // ...  // 获取 m  mp := acquirem() // 获取当前 p 对应的 mcache  c := getMCache(mp) var span *mspan var x unsafe.Pointer // 根据当前对象是否包含指针，标识 gc 时是否需要展开扫描  noscan := typ == nil || typ.ptrdata == 0 // 是否是小于 32KB 的微、小对象  if size \u0026lt;= maxSmallSize { // 小于 16 B 且无指针，则视为微对象  if noscan \u0026amp;\u0026amp; size \u0026lt; maxTinySize { // tiny 内存块中，从 offset 往后有空闲位置  off := c.tinyoffset // 如果大小为 5 ~ 8 B，size 会被调整为 8 B，此时 8 \u0026amp; 7 == 0，会走进此分支  if size\u0026amp;7 == 0 { // 将 offset 补齐到 8 B 倍数的位置  off = alignUp(off, 8) // 如果大小为 3 ~ 4 B，size 会被调整为 4 B，此时 4 \u0026amp; 3 == 0，会走进此分支  } else if size\u0026amp;3 == 0 { // 将 offset 补齐到 4 B 倍数的位置  off = alignUp(off, 4) // 如果大小为 1 ~ 2 B，size 会被调整为 2 B，此时 2 \u0026amp; 1 == 0，会走进此分支  } else if size\u0026amp;1 == 0 { // 将 offset 补齐到 2 B 倍数的位置  off = alignUp(off, 2) } // 如果当前 tiny 内存块空间还够用，则直接分配并返回  if off+size \u0026lt;= maxTinySize \u0026amp;\u0026amp; c.tiny != 0 { // 分配空间  x = unsafe.Pointer(c.tiny + off) c.tinyoffset = off + size c.tinyAllocs++ mp.mallocing = 0 releasem(mp) return x } // 分配一个新的 tiny 内存块  span = c.alloc[tinySpanClass] // 从 mCache 中获取  v := nextFreeFast(span) if v == 0 { // 从 mCache 中获取失败，则从 mCentral 或者 mHeap 中获取进行兜底  v, span, shouldhelpgc = c.nextFree(tinySpanClass) } // 分配空间  x = unsafe.Pointer(v) (*[2]uint64)(x)[0] = 0 (*[2]uint64)(x)[1] = 0 size = maxTinySize } else { // 根据对象大小，映射到其所属的 span 的等级(0~66）  var sizeclass uint8 if size \u0026lt;= smallSizeMax-8 { sizeclass = size_to_class8[divRoundUp(size, smallSizeDiv)] } else { sizeclass = size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)] } // 对应 span 等级下，分配给每个对象的空间大小(0~32KB)  size = uintptr(class_to_size[sizeclass]) // 创建 spanClass 标识，其中前 7 位对应为 span 的等级(0~66)，最后标识表示了这个对象 gc 时是否需要扫描  spc := makeSpanClass(sizeclass, noscan) // 获取 mcache 中的 span  span = c.alloc[spc] // 从 mcache 的 span 中尝试获取空间  v := nextFreeFast(span) if v == 0 { // mcache 分配空间失败，则通过 mcentral、mheap 兜底  v, span, shouldhelpgc = c.nextFree(spc) } // 分配空间  x = unsafe.Pointer(v) // ...  } // 大于 32KB 的大对象  } else { // 从 mheap 中获取 0 号 span  span = c.allocLarge(size, noscan) span.freeindex = 1 span.allocCount = 1 size = span.elemsize // 分配空间  x = unsafe.Pointer(span.base()) } // ...  return x }   分配步骤 步骤1：tiny分配 每个 P 独有的 mache 会有个微对象分配器，基于 offset 线性移动的方式对微对象进行分配，每 16B 成块，对象依据其大小，会向上取整为 2 的整数次幂进行空间补齐，然后进入分配流程.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  noscan := typ == nil || typ.ptrdata == 0 // ...  if noscan \u0026amp;\u0026amp; size \u0026lt; maxTinySize { // tiny 内存块中，从 offset 往后有空闲位置  off := c.tinyoffset // ...  // 如果当前 tiny 内存块空间还够用，则直接分配并返回  if off+size \u0026lt;= maxTinySize \u0026amp;\u0026amp; c.tiny != 0 { // 分配空间  x = unsafe.Pointer(c.tiny + off) c.tinyoffset = off + size c.tinyAllocs++ mp.mallocing = 0 releasem(mp) return x } // ...  }   步骤2：mcache 分配 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 根据对象大小，映射到其所属的 span 的等级(0~66）  var sizeclass uint8 // get size class ....  // 对应 span 等级下，分配给每个对象的空间大小(0~32KB)  // get span class  spc := makeSpanClass(sizeclass, noscan) // 获取 mcache 中的 span  span = c.alloc[spc] // 从 mcache 的 span 中尝试获取空间  v := nextFreeFast(span) if v == 0 { // mcache 分配空间失败，则通过 mcentral、mheap 兜底  v, span, shouldhelpgc = c.nextFree(spc) } // 分配空间  x = unsafe.Pointer(v)    在 mspan 中，基于 Ctz64 算法，根据 mspan.allocCache 的 bitMap 信息快速检索到空闲的 object 块，进行返回.\n 代码位于 runtime/malloc.go 文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func nextFreeFast(s *mspan) gclinkptr { // 通过 ctz64 算法，在 bit map 上寻找到首个 object 空位  theBit := sys.Ctz64(s.allocCache) if theBit \u0026lt; 64 { result := s.freeindex + uintptr(theBit) if result \u0026lt; s.nelems { freeidx := result + 1 if freeidx%64 == 0 \u0026amp;\u0026amp; freeidx != s.nelems { return 0 } s.allocCache \u0026gt;\u0026gt;= uint(theBit + 1) // 偏移 freeindex  s.freeindex = freeidx s.allocCount++ // 返回获取 object 空位的内存地址  return gclinkptr(result*s.elemsize + s.base()) } } return 0 }   步骤3：mcentral 分配  当 mspan 无可用的 object 内存块时，会步入 mcache.nextFree 方法进行兜底.\n 代码位于 runtime/mcache.go 文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func (c *mcache) nextFree(spc spanClass) (v gclinkptr, s *mspan, shouldhelpgc bool) { s = c.alloc[spc] // ...  // 从 mcache 的 span 中获取 object 空位的偏移量  freeIndex := s.nextFreeIndex() if freeIndex == s.nelems { // ...  // 倘若 mcache 中 span 已经没有空位，则调用 refill 方法从 mcentral 或者 mheap 中获取新的 span  c.refill(spc) // ...  // 再次从替换后的 span 中获取 object 空位的偏移量  s = c.alloc[spc] freeIndex = s.nextFreeIndex() } // ...  v = gclinkptr(freeIndex*s.elemsize + s.base()) s.allocCount++ // ...  return }    倘若 mcache 中，对应的 mspan 空间不足，则会在 mcache.refill 方法中，向更上层的 mcentral 乃至 mheap 获取 mspan，填充到 mache 中:\n 代码位于 runtime/mcache.go 文件中：\n1 2 3 4 5 6 7 8 9  func (c *mcache) refill(spc spanClass) { s := c.alloc[spc] // ...  // 从 mcentral 当中获取对应等级的 span  s = mheap_.central[spc].mcentral.cacheSpan() // ...  // 将新的 span 添加到 mcahe 当中  c.alloc[spc] = s }    mcentral.cacheSpan 方法中，会加锁（spanClass 级别的 sweepLocker），分别从 partial 和 full 中尝试获取有空间的 mspan:\n 代码位于 runtime/mcentral.go 文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  func (c *mcentral) cacheSpan() *mspan { // ...  var sl sweepLocker // ...  sl = sweep.active.begin() if sl.valid { for ; spanBudget \u0026gt;= 0; spanBudget-- { s = c.partialUnswept(sg).pop() // ...  if s, ok := sl.tryAcquire(s); ok { // ...  sweep.active.end(sl) goto havespan } // 通过 sweepLock，加锁尝试从 mcentral 的非空链表 full 中获取 mspan  for ; spanBudget \u0026gt;= 0; spanBudget-- { s = c.fullUnswept(sg).pop() // ...  if s, ok := sl.tryAcquire(s); ok { // ...  sweep.active.end(sl) goto havespan } // ...  } } // ...  } // ...  // 执行到此处时，s 已经指向一个存在 object 空位的 mspan 了 havespan: // ...  return }   步骤4：mheap 分配  在 mcentral.cacheSpan 方法中，倘若从 partial 和 full 中都找不到合适的 mspan 了，则会调用 mcentral 的 grow 方法，将事态继续升级：\n 1 2 3 4 5 6 7 8 9 10 11 12  func (c *mcentral) cacheSpan() *mspan { // ...  // mcentral 中也没有可用的 mspan 了，则需要从 mheap 中获取，最终会调用 mheap_.alloc 方法  s = c.grow() // ...  // 执行到此处时，s 已经指向一个存在 object 空位的 mspan 了 havespan: // ...  return }    经由 mcentral.grow 方法和 mheap.alloc 方法的周转，最终会步入 mheap.allocSpan 方法中：\n 1 2 3 4 5 6 7 8 9 10 11 12  func (c *mcentral) grow() *mspan { npages := uintptr(class_to_allocnpages[c.spanclass.sizeclass()]) size := uintptr(class_to_size[c.spanclass.sizeclass()]) s := mheap_.alloc(npages, c.spanclass) // ...  // ...  return s }   代码位于 runtime/mheap.go\n1 2 3 4 5 6 7 8  func (h *mheap) alloc(npages uintptr, spanclass spanClass) *mspan { var s *mspan systemstack(func() { // ...  s = h.allocSpan(npages, spanAllocHeap, spanclass) }) return s }   代码位于 runtime/mheap.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  func (h *mheap) allocSpan(npages uintptr, typ spanAllocType, spanclass spanClass) (s *mspan) { gp := getg() base, scav := uintptr(0), uintptr(0) // ...此处实际上还有一阶缓存，是从每个 P 的页缓存 pageCache 中获取空闲页组装 mspan，此处先略去了...  // 加上堆全局锁  lock(\u0026amp;h.lock) if base == 0 { // 通过基数树索引快速寻找满足条件的连续空闲页  base, scav = h.pages.alloc(npages) // ...  } // ...  unlock(\u0026amp;h.lock) HaveSpan: // 把空闲页组装成 mspan  s.init(base, npages) // 将这批页添加到 heapArena 中，建立由页指向 mspan 的映射  h.setSpans(s.base(), npages, s) // ...  return s }   步骤5：向操作系统申请  倘若 mheap 中没有足够多的空闲页了，会发起 mmap 系统调用，向操作系统申请额外的内存空间.\n 代码位于 runtime/mheap.go 文件的 mheap.grow 方法中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func (h *mheap) grow(npage uintptr) (uintptr, bool) { av, asize := h.sysAlloc(ask) } func (h *mheap) sysAlloc(n uintptr) (v unsafe.Pointer, size uintptr) { v = sysReserve(unsafe.Pointer(p), n) } func sysReserve(v unsafe.Pointer, n uintptr) unsafe.Pointer { return sysReserveOS(v, n) } func sysReserveOS(v unsafe.Pointer, n uintptr) unsafe.Pointer { p, err := mmap(v, n, _PROT_NONE, _MAP_ANON|_MAP_PRIVATE, -1, 0) if err != 0 { return nil } return p }   PS:拓展：基数树寻页\n核心源码位于 runtime/pagealloc.go 的 pageAlloc 方法中，要点都以在代码中给出注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  func (p *pageAlloc) find(npages uintptr) (uintptr, offAddr) { // 必须持有堆锁  assertLockHeld(p.mheapLock) // current level.  i := 0 // ...  lastSum := packPallocSum(0, 0, 0) lastSumIdx := -1 nextLevel: // 1 ~ 5 层依次遍历  for l := 0; l \u0026lt; len(p.summary); l++ { // ...  // 根据上一层的 index，映射到下一层的 index.  // 映射关系示例：上层 0 -\u0026gt; 下层 [0~7]  // 上层 1 -\u0026gt; 下层 [8~15]  // 以此类推  i \u0026lt;\u0026lt;= levelBits[l] entries := p.summary[l][i : i+entriesPerBlock] // ...  // var levelBits = [summaryLevels]uint{  // 14,3,3,3,3  // }  // 除第一层有 2^14 个节点外，接下来每层都只要关心 8 个 节点.  // 由于第一层有 2^14 个节点，所以 heap 内存上限为 2^14 * 16G = 256T  var base, size uint for j := j0; j \u0026lt; len(entries); j++ { sum := entries[j] // ...  // 倘若当前节点对应内存空间首部即满足，直接返回结果  s := sum.start() if size+s \u0026gt;= uint(npages) { if size == 0 { base = uint(j) \u0026lt;\u0026lt; logMaxPages } size += s break } // 倘若当前节点对应内存空间首部不满足，但是内部最长连续页满足，则到下一层节点展开搜索  if sum.max() \u0026gt;= uint(npages) { i += j lastSumIdx = i lastSum = sum continue nextLevel } // 即便内部最长连续页不满足，还可以尝试将尾部与下个节点的首部叠加，看是否满足  if size == 0 || s \u0026lt; 1\u0026lt;\u0026lt;logMaxPages { size = sum.end() base = uint(j+1)\u0026lt;\u0026lt;logMaxPages - size continue } // The entry is completely free, so continue the run.  size += 1 \u0026lt;\u0026lt; logMaxPages } // 根据 i 和 j 可以推导得到对应的内存地址，进行返回  ci := chunkIdx(i) addr := chunkBase(ci) + uintptr(j)*pageSize // ...  return addr, p.findMappedAddr(firstFree.base) }   ","description":"Golang 的内存管理","id":75,"section":"stack","tags":["golang",""],"title":"Golang的内存管理","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_memery_cms/"},{"content":"go list (列出包和模块信息) go list在项目的根目录，go.mod目录，输出module名称\nusage: go list [-f format] [-json] [-m] [list flags] [build flags] [packages]\n用法: go list [-f format] [-json] [-m] [list flags] [build flags] [包]\n可选参数:\n -m 相当于module -f {{.字段名}} 查看指定的字段信息 -json 以json格式打印信息  1 2 3 4 5 6 7 8  type Package struct { Dir string // 输出给定包的本地下载路径  ImportPath string // 引用包使用的包名  ImportComment string // path in import comment on package statement  Name string // 包名  Root string // 项目的绝对路径  。。。 }   示例：\n1.打印所有模块 go list -m all\n1 2 3 4 5  $ go list -m all kg_info_dashboard_api cloud.google.com/go v0.100.2 cloud.google.com/go/bigquery v1.8.0 cloud.google.com/go/compute v1.6.1   2. 以json格式打印 time 包信息 go list -json time\n1 2 3 4 5 6 7 8 9 10 11  $ go list -json time { \u0026#34;Dir\u0026#34;: \u0026#34;/usr/local/go/src/time\u0026#34;, \u0026#34;ImportPath\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;Doc\u0026#34;: \u0026#34;Package time provides functionality for measuring and displaying time.\u0026#34;, \u0026#34;Root\u0026#34;: \u0026#34;/usr/local/go\u0026#34;, \u0026#34;Match\u0026#34;: [ \u0026#34;time\u0026#34; ], ...   3. 打印模块信息 go list -m testmod\ngo list -m golang.org/x/time\n1 2  $ go list -m golang.org/x/time golang.org/x/time v0.0.0-20191024005414-555d28b269f0   4.查看包的详细信息 go list -compiled -json github.com/gin-gonic/gin\n5.列出可升级版本信息 go list -m -u all\n详情查看：\ngo list -m -u -json all\n6.用shell获取依赖树 go list -f '{{.Deps}}' 是 Go 语言中的一个命令，用于列出指定包的依赖关系。这个命令会返回一个依赖包的列表。\n这个命令的一般形式是 go list -f 'format'，其中 format 是一个模板字符串，用来定义输出的格式。在这个字符串中，{{.Deps}} 是一个动作，它会输出当前包的所有依赖。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  #!/bin/bash  pacakge=$1 deps=\u0026#34;\u0026#34; get_deps() { local package=$1 local output=$(go list -f \u0026#39;{{.ImportPath}}: {{range .Deps}}{{.}}{{end}}\u0026#39; $package) echo \u0026#34;$output\\n\u0026#34; for dep in $(echo $output | grep -o \u0026#39;[^:]*$\u0026#39;); do deps=\u0026#34;$deps\\n$dep\u0026#34; get_deps $dep done } get_deps $pacakge | sed \u0026#39;s/^/ /\u0026#39; echo -e $deps | grep -v \u0026#39;^\u0026#39; | sort | uniq   1 2 3 4  #输出如下： sudo sh dep.sh kg_info_dashboard_api: bytescontainer/listcontextcryptocrypto/aescrypto/...   8.列出工作空间中的软件包 到工作空间文件夹:\ngo list ./...\n说明：./ 告诉从当前文件夹开始，…告诉递归向下\n9.列出所有已安装的库 ls $GOPATH/src\ngo get(下载并安装包和依赖) get 命令 下载并安装包和依赖(下载包和依赖,并对它们进行编译安装)\nusage: go get [-d] [-f] [-t] [-u] [-v] [-fix] [-insecure] [build flags] [packages]\n用法: go get [-d] [-f] [-t] [-u] [-v] [-fix] [-insecure] [build flags] [包]\n可选参数:\n -d 只下载不安装(只执行下载动作, 不执行安装动作) -f 只有在包含了-u参数的时候才有效.该参数会让命令程序忽略掉对已下载代码包的导入路径的检查.如果下载并安装的代码包所属的项目是你从别人那里Fork过来的,那么这样做就尤为重要了 -fix 会下载代码包后先执行修正动作,而后再进行编译和安装 -insecure 请谨慎使用, 允许使用不安全(http或者自定义域)的存储库中下载解析. -t 同时也下载需要为运行测试所需要的包 -u 强制从网络更新包和它的依赖包.默认情况下,该命令只会从网络上下载本地不存在的代码包,而不会更新已有的代码包 -v 显示执行的命令  示例：\ngo get -u github.com/xxx\ngo build 编译包和依赖项 build 编译包和依赖项\nusage: go build [-o output] [-i] [build flags] [packages]\n用法: go build [-o output] [-i] [build 参数] [包]\n可选参数:\n  -o 编译单个包才能使用(不能同时对多个代码包进行编译),例如我们经常重新命名可执行文件名字\n  -i 标志安装的包是目标的依赖项\n  -a 强制重新构建已经更新的包\n  -n 打印编译时执行的命令,但不真正执行\n  -p 开启并发编译,默认情况下该值为CPU逻辑核数\n  -race 开启竞态检测,只支持linux/amd64、freebsd/amd64、darwin/amd64和windows/amd64.\n  -msan 内存扫描\n  -v 编译包时打印包的名称\n  -work 编译时打印临时工作目录的名称,退出时不删除它\n  -x 打印编译时执行的命令(打印编译时会用到的所有命令)\n  -asmflags \u0026lsquo;[pattern=]arg list\u0026rsquo;,传递给每个go工具asm调用的参数\n  -buildmode mode 使用编译模式, 更多信息请参见“go help buildmode”\n  -compiler name 设置编译时使用编译器名,编译器名称只有2个选项(gccgo或gc)\n  -gccgoflags \u0026lsquo;[pattern=]arg list\u0026rsquo; 传递每个gccgo编译器/链接器调用的参数列表\n  -gcflags \u0026lsquo;[pattern=]arg list\u0026rsquo; 用于指定需要传递给go tool compile命令的参数的列表,更多信息参见(go tool compile)\n  -installsuffix suffix 为了使当前的输出目录与默认的编译输出目录分离,可以使用这个标记.此标记的值会作为结果文件的父目录名称的后缀.其实,如果使用了-race标记,这个标记会被自动追加且其值会为race.如果我们同时使用了-race标记和-installsuffix,那么在-installsuffix标记的值的后面会再被追加_race,并以此来作为实际使用的后缀\n  -ldflags \u0026lsquo;[pattern=]arg list\u0026rsquo; 用于指定需要传递给go tool link命令的参数的列表\n  -linkshared\n  -mod mode 模块下载方式,只有2个选项(readonly或vendor),更多信息请参见(go help modules)\n  -pkgdir dir 设置包目录.编译器会只从该目录中加载代码包的归档文件,并会把编译可能会生成的代码包归档文件放置在该目录下\n  -tags \u0026lsquo;tag list\u0026rsquo;\n  -toolexec \u0026lsquo;cmd args\u0026rsquo; 用于在编译期间使用一些Go语言自带工具(如vet、asm等)的方式\n  示例：\ngin 框架打包（指定系统、处理器架构、模式）\nGOOS=linux GOARCH=amd64 GIN_MODE=release go build main.go\ngo build [1个或多个go源文件, 或者包名, 或者包所在目录]\ngo build a.go b.go main.go 多源文件\ngo build main.go 1个源文件\ngo build hello 名句或目录\n把 main.go 编译成可执行文件 hello.exe：\ngo build -o hello.exe main.go\n打印编译时执行的命令,但不真正执行\ngo build -n\n答应工作目录\ngo build -work\ngo clean(删除对象文件和缓存的文件) clean 删除执行其他命令时产生的文件、目录和缓存文件.\n具体地说 .clean 会删除从导入路径对应的源码目录中,删除以下这些文件和目录\n _obj/ old object directory, left from Makefiles _test/ old test directory, left from Makefiles _testmain.go old gotest file, left from Makefiles test.out old test log, left from Makefiles build.out old test log, left from Makefiles *.[568ao] object files, left from Makefiles DIR(.exe) from go build DIR.test(.exe) from go test -c MAINFILE(.exe) from go build MAINFILE.go *.so from SWIG  usage: go clean [clean flags] [build flags] [packages]\n用法: go clean [clean 参数] [build参数] 包\n可选参数:\n  -i 会删除安装当前代码包所有产生的所有文件, 如果当前包是一个普通包(不是main包),则结果文件指的就是在工作区的pkg目录的相应目录下的归档文件.如果当前代码包中只包含一个命令源码文件, 则删除当前目录和在工作区的bin目录下的可执行文件和测试文件.\n  -n 打印clean执行的命令,但不真正执行\n  -r 删除当前代码包和所有的依赖包产生的文件、目录和缓存文件\n  -x 打印clean执行的删除命令\n  -cache 删除所有 go build 的缓存\n  -testcache 删除当前包所有的测试结果\n  go doc (显示包文档) doc与godoc 显示包或符号的文档, 更多用法请参考(godoc -h)\nusage: go doc [-u] [-c] [package|[package.]symbol[.methodOrField]]\n用法: go doc [-u] [-c] [package|[package.]symbol[.methodOrField]]\n可选参数:\n  -c 区分参数包名的大小写.默认情况下,包名是大小写不敏感的\n  -cmd 打印 main 包文档, 默认情况下不会打印 main 包文档\n  -u 打印出所有的文档(同事包含可导出和不可导出实体)\n  示例:\ngo doc -c crontab\n1 2 3 4 5 6 7 8 9 10 11  $ go doc -c crontab package crontab // import \u0026#34;kg_info_dashboard_api/crontab\u0026#34; * @Author: jarvenwang jarvaniv0611@gmail.com * @Date: 2022-07-25 09:53:30 * @LastEditors: dante jarvaniv0611@gmail.com * @LastEditTime: 2022-11-24 19:24:02 * @FilePath: /kg_info_dashboard_api/crontab/cron.go * @Description: * * Copyright (c) 2022 by jarvenwang jarvaniv0611@gmail.com, All Rights Reserved. func CronExec() func FindKPIChildDataPermission(adminUserName string) string ...   go env 打印环境信息 env 打印Go语言的环境信息\nusage: go env [-json] [var \u0026hellip;]\n用法: go env [-json] [变量 \u0026hellip;]\n可选参数:\n -json 以json格式打印环境信息  示例：\ngo env\n以json格式打印所有环境信息\ngo env -json\n以json格式只打印 GOOS 程序构建环境的目标操作系统\ngo env -json GOOS\n只打印 GOOS 程序构建环境的目标操作系统\ngo env GOOS\ngo fix 与 go tool fix 版本修复 fix 会把指定包中的所有Go语言源码文件中旧版本代码修正为新版本的代码，升级版本时非常有用\nusage: go fix [packages]\n示例:\ngo fix testmod\ngo fix time\ngo tool fix -h\nusage: go tool fix [-diff] [-r fixname,\u0026hellip;] [-force fixname,\u0026hellip;] [path \u0026hellip;]\n  -diff 不将修正后的内容写入文件, 而只打印修正前后的内容的对比信息到标准输出\n  -force string 使用此参数后, 即使源码文件中的代码已经与Go语言的最新版本相匹配, 也会强行执行指定的修正操作.该参数值就是需要强行执行的修正操作的名称,多个名称之间用英文半角逗号分隔\n  -r string 只对目标源码文件做有限的修正操作.该参数的值即为允许的修正操作的名称.多个名称之间用英文半角逗号分隔\n  fmt与gofmt 格式化go源文件 fmt与gofmt 命令 格式化go源文件,fmt命令实际\u0026quot;gofmt -l -w\u0026quot;命令之上做了一层包装,我们一般使用\nfmt usage: go fmt [-n] [-x] [packages]\n用法: go fmt [-n] [-x] 包\n可选参数:\n  -x 打印执行的命令\n  -n 打印执行的命令,但不真正执行\n  示例:\n格式化 testmod 包, 并显示执行命令\ngo fmt -x testmod\ngofmt usage: gofmt [flags] [path \u0026hellip;]\n用法: gofmt [参数] [路径 \u0026hellip;]\n可选参数:\n  -cpuprofile string 将cpu配置文件写入此文件\n  -d 显示格式化前后差异,但不写入文件\n  -e 打印所有错误, 默认只会打印不同行的前10个错误\n  -l 列出需要格式化的文件\n  -r string 重新规则,方便我们做批量替换,例如我们需要把hellomod.Hello替换成hellomod.HelloNew(\u0026ldquo;hellomod.Hello -\u0026gt; hellomod.HelloNew\u0026rdquo;)\n  -s 简化代码\n  -w 将结果直接写入到文件中\n  示例:\n格式当前目录代码\ngofmt -w ./\n把当前目录中的“hellomod.Hello” 替换成 \u0026ldquo;hellomod.HelloNew\u0026rdquo;\ngofmt -r \u0026quot;hellomod.Hello -\u0026gt; hellomod.HelloNew\u0026quot; -w ./\ngo install 编译并安装指定包及它们的依赖包 install 编译并安装指定包及它们的依赖包,先生成中间文件(可执行文件或者.a包),然后把编译好的结果移到$GOPATH/pkg或者$GOPATH/bin\nusage: go install [-i] [build flags] [packages]\n用法: go install [-i] [编译 flags] [包]\n可选参数:\n -i  示例:\n安装包 go install github.com/gin-gonic/gin\ngo mod 管理模块 Usage: go mod  [arguments]\n用法: go mod \u0026lt;命令\u0026gt; [参数]\n可选命令: go help mod \ngo mod download 下载模块到本地缓存\nusage: go mod download [-json] [modules]\n用法:\n可选参数:\n -json  示例:\n下载模块,以json格式打印模块信息\ngo mod download -json github.com/qq1060656096/hellomod \njson格式打印 github.com/qq1060656096/hellomod 模块信息\n1 2 3  { \u0026#34;Path\u0026#34;: \u0026#34;github.com/qq1060656096/hellomod\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;v1.0.0\u0026#34;,   go mod edit 提供命令来编辑go.mod文件, 主要用于工具或脚本\nusage: go mod edit [editing flags] [go.mod]\n用法: go mod edit [editing flags] [go.mod]\n可选参数:\n  -fmt 只会格式化go.mod文件\n  -module 更改模块路径\n  -require=path@version 添加模块依赖\n示例:\n添加hellomod模块v1.0.0版本\ngo mod edit -require=github.com/qq1060656096/hellomod@v1.0.0\n  -droprequire=path 删除模块依赖\n示例:\n删除hellomod模块\ngo mod edit -droprequire=github.com/qq1060656096/hellomod\n  -exclude=path@version 排查模块\n排除hellomod模块v1.0.0版本\ngo mod edit -exclude=github.com/qq1060656096/hellomod@v1.0.0\n  -dropexclude=path@version 删除排除的模块(恢复排除的模块)\n恢复排除hellomod模块v1.0.0版本\ngo mod edit -dropexclude=github.com/qq1060656096/hellomod@v1.0.0\n  -replace=old[@v]=new[@v] 替换模块\n示例:\nhellomod模块v1.0.0版本替换成v2.0.0版本\ngo mod edit -replace=github.com/qq1060656096/hellomod@v1.0.0=github.com/qq1060656096/hellomod@v2.0.0\n  -dropreplace=old[@v]\n  -print 打印结果,不会操作go.mod文件\n  -json 以json格式打印结果,不会操作go.mod文件\n  go mod graph 打印模块需求图 usage: go mod graph\n用法: go mod graph\ngo mod init 在当前⽂件夹下初始化⼀个新的模块(创建go.mod⽂件) usage: go mod init [module]\n用法: go mod init [模块名]\n示例:\n创建“github.com/qq1060656096/hellomod”模块\ngo mod init github.com/qq1060656096/hellomod\ngo mod tidy 整理模块(增加缺少的模块,删除未⽤的模块) usage: go mod tidy [-v]\n用法: go mod tidy [-v]\n可选参数:\n -v 打印已经删除的模块信息  示例:\n整理模块,并打印已经删除的模块\ngo mod tidy -v\ngo mod vendor 将依赖复制到vendor下 usage: go mod vendor [-v]\n用法: go mod vendor [-v]\n可选参数:\n -v 打印复制到vendor的所有包和模块  示例:\n打印复制到vendor的所有包和模块\ngo mod vendor -v\ngo mod verify 校验依赖的HASH码,验证检查当前模块的依赖 如果依赖本有更改就使用之前的, 如果所有模块都没有更改,就打印\u0026quot;all modules verified\u0026quot;, 否则就报告(打印)已更改的模块\nusage: go mod verify\n用法: go mod verify\n示例:\ngo mod verify\ngo mod why 解释为什么需要依赖 usage: go mod why [-m] [-vendor] packages\u0026hellip;\n用法: go mod why [-m] [-vendor] packages\u0026hellip;\n可选参数\n -vendor -m  go run 编译并运行Go程序 run 命令 编译并运行Go程序\nusage: go run [build flags] [-exec xprog] package [arguments\u0026hellip;]\n用法: go run [编译 flags] [-exec xprog] 包 [arguments\u0026hellip;]\n可选参数: 其他参数请参考(go help build)\n -exec  示例:\n运行main.go\ngo run main.go\n运行main.go并开启竞态检测(开发时建议开启这个选项)\ngo run -race main.go\ngo test 测试包 go test 用于测试包\nusage: go test [build/test flags] [packages] [build/test flags \u0026amp; test binary flags]\n -c 把包编译二进制测试包, 注意不会运行, 需要你手动执行二进制测试  示例:\ngo test -c package_import_path\ngo test -c 包的导入路径\n go test -c 在当前目录生成二进制测试  1 2  $go test -c ? kg_info_dashboard_api [no test files]   go test -c go test -c go-tutorials/8/examples/demo1   -exec 运行二进制测试  示例:\ngo test -c -exec demo1.test\n -json 运行测试,并将结果输出为json格式  示例:\ngo test -json path\n go test -json 测试当前包  1 2 3 4  go test -json {\u0026#34;Time\u0026#34;:\u0026#34;2024-03-19T16:39:08.408073+08:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;start\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;kg_info_dashboard_api\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2024-03-19T16:39:08.408253+08:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;output\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;kg_info_dashboard_api\u0026#34;,\u0026#34;Output\u0026#34;:\u0026#34;? \\tkg_info_dashboard_api\\t[no test files]\\n\u0026#34;} {\u0026#34;Time\u0026#34;:\u0026#34;2024-03-19T16:39:08.408262+08:00\u0026#34;,\u0026#34;Action\u0026#34;:\u0026#34;skip\u0026#34;,\u0026#34;Package\u0026#34;:\u0026#34;kg_info_dashboard_api\u0026#34;,\u0026#34;Elapsed\u0026#34;:0}   go test -json ./   -o 把测试编译成自己命名二进制包, 默认仍然会运行测试(除非指定-c或者-i)  示例:\ngo test -o file_name\ngo test -o 文件名\n go test -o demo1.custom_name.test   -bench 运行基准测试, 默认情况下不运行  示例:\ngo test -bench regexp\ngo test -bench 正则表达式\n go test -bench 运行所有基准测试 go test -bench=. 运行所有基准测试 go test -bench=hah 运行指定的基准测试   -benchtime 基准测试,持续时间(默认1秒) -count 运行测试次数\n示例:\ngo test -count n\ngo test -count 次数   go test -count 10 运行所有的测试10次    -cover 覆盖率统计, 注意覆盖率统计是通过代码注释来工作的\n  -list regexp 列出匹配的测试\n示例:\ngo test -list regexp\ngo test -list 正则表达式\n   go test -list Login 列出demo1中的测试   -v 详细输出运行时记录所有的测试\n示例:\ngo test -v  go tool 运行指定的go工具 tool 命令 运行指定的go工具\nusage: go tool [-n] command [args\u0026hellip;]\n用法: go tool [-n] 命令 [args\u0026hellip;]\n可选参数:\n -n 打印要执行的命令, 但是不真正的执行  示例:\n打印vet工具执行的命令\ngo tool -n vet\ngo tool 工具列表 # go tool: 列表工具列表 # go tool 工具 -h: 查看工具帮助文档 # 查看vet工具帮助文档: go tool vet -h addr2line api asm buildid cgo compile cover dist doc fix link nm objdump pack pprof 可以帮助开发者快速分析及定位各种性能问题,如 CPU 消耗、内存分配及阻塞分析 test2json trace vet 报告包中可能出现的错误,开发时建议使用这个工具(fmt printf函数参数不对或者声明结构体 tag声明不对等) go version 查看当前go语言版本 version 查看go当前的版本\nusage: go version\n示例:\n查看go当前的版本\ngo version\ngo vet 报告包中可能出现的错误 vet 静态检查工具,报告包中可能出现的错误, 开发时建议使用这个工具(fmt printf函数参数不对或者声明结构体 tag声明不对等)\nusage: go vet [-n] [-x] [build flags] [vet flags] [packages]\n用法: go vet [-n] [-x] [编译参数] [vet flags] [包]\n可选参数:\n-n 打印要执行的命令, 但是不真正的执行 -x 打印执行的命令  更多参数请参考(go help build)\n示例:\n检测 testmod 包中可能存在的问题 go vet time\ngo vet -n time\ngo vet -x time\n","description":"Golang 的常用命令","id":76,"section":"stack","tags":["golang",""],"title":"Golang的常用命令","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_commond/"},{"content":"CentOS Linux 将于 Jun 30th, 2024 EOF(结束生命周期). 届时, 我们的 OS 还有哪些选择?\n 不要选择 CentOS Stream !  不要选择 CentOS Stream !  不要选择 CentOS Stream !   Linux生态 红帽企业级 Linux 生态系统形成了 Fedora、RHEL 和 CentOS Linux 协同发展的局面\n 上游：通过 Fedora 向广大开发工程师提供桌面操作系统的持续创新和技术架构整合，大约是每 6 个月发布一个版本 中游：是红帽企业级 Linux，主要面向广大企业和应用开发商，特点是稳定、安全和性能优化 下游：是社区领导的 CentOS Linux，面向成本敏感用户和生态开发者，特点是无成本、易获取，大约在红帽企业 Linux 发布的几个月后发布  CentOS Stream CentOS Stream 本身介于 Fedora 和 RHEL 之间，离 RHEL 更近，相当于 RHEL 上开发的所有功能都已经在 CentOS Stream 具备，该版本同样对所有人免费开放，可保证开发者提前获得 RHEL 新特性，在此基础上来做诸如开发第三方组件等工作，拓展他们对于 RHEL 生态的影响。相当于 CentOS Stream 是 RHEL 的试验田。2019 年 9 月，Red Hat 宣布了 CentOS Stream，它是 CentOS 的滚动发行版本，介于 Fedora Linux 的上游开发和 RHEL 的下游开发之间而存在，当官方明确表示未来不会再发布由 RHEL 代码编译而成的 CentOS 后，意味着 CentOS Stream 先行，稳定之后再发布 RHEL，所以不难理解众多开发者对这个决策的不满。\nPS:\n而且现在 CentOS 只提供大版本, 如 CentOS Stream 8 和 9, 没有之前的 7.X 这样的小版本.\n虽然 RedHat 官方保证 CentOS Stream 足够稳定, 但是根据笔者和其他相关人士的沟通, 均不再选择其作为生产环境 OS.\nCentOS 替代品 1.RHEL Linux RHEL 大家都熟悉, 就不做简介了. 不考虑钱的因素, RHEL Linux 是最完美的替代品\n特点：\n 不差钱 对稳定性要求极高 需要购买专业Linux维护服务 金融行业\n  2.Rocky Linux Rocky Linux 直接从 RHEL® 重建源代码，无论用例如何，您都将拥有超级稳定的体验。\n使用 Rocky Linux 替代 CentOS, 代价也是最小的. 但是 Rocky Linux 的稳定性还需要经过更长时间的检验.\n特点：\n 开源 期望寻找 CentOS 的平替 熟悉 Fedora RHEL CentOS 生态\n  3.公有云Linux 如果您的全部或大部分资源都在公有云上托管, 那么还有一个可行的方案是选择: 公有云提供的 Linux. 如:\n Amazon Linux Alibaba Cloud Linux  特点：\n 公有云用户\n  4.Debian系Linux 以上提到的几种选择, 都是基于 Fedora 这一系的 Linux 衍生而来. 切换代价也相对较小.\n但是如果用户相比稳定性, 更追求创新, 追求更新的内核, 更新的功能, 那么也可以选择切换到 Debian 系 Linux, 推荐的选择有: Debian 和 Ubuntu\n当然, 要切换到 Dbian 系 Linux, 代价还是相对较大的:\n 包管理软件会从 yum/dnf 切换到 apt/dpkg 大多数人的观点是 Debian 系统不像 RHEL/CentOS 那样稳定或无故障 Debian 的内核/软件相对更新  特点：\n 相比稳定性, 更追求创新 熟悉 Debian 生态 已经较多使用容器/K8s (因为 Debian 在容器生态中更常见) 需要使用较新内核或较新的功能, 如 eBPF 和 Cilium\n  5.信创系Linux(美脱钩) 如果您主要面向的是国内的政企/金融客户, 有信创的刚需, 那么推荐您切换到信创系 Linux, 主流的包括: 华为主导的 openeuler 和 阿里主导的 anolis(龙蜥) os.\n这两款也是基于 Fedora 的生态系统, 其官网也往往会有用于一键迁移 OS 的实用工具. 但是软件生态还需要更多时间来培养成熟.\n特点：\n 信创需求 面向政企/金融客户\n  总结  不要选择 CentOS Stream; RHEL Linux, 适合金融客户; Rocky Linux, 适合需要开源免费且平替 CentOS Linux的客户; 公有云 Linux, 适合资源都在公有云上的客户; 信创 Linux, 适合面向国内政企/金融, 有信创需求的客户.  ","description":"CentOS 停止技术支持后，我们应该如何选择适合的操作系统?","id":77,"section":"stack","tags":["linux",""],"title":"CentOS24年停更后平替系统","uri":"http://wangjinbao.netlify.app/en/stack/linux/centos_stop/"},{"content":"istio概念 讲多了记不住，那就：服务网格 + 微服务治理 。\n","description":"Istio 是一个开源服务网格，它透明地分层到现有的分布式应用程序上","id":78,"section":"stack","tags":["linux"],"title":"Istio","uri":"http://wangjinbao.netlify.app/en/stack/linux/istio/"},{"content":"安装 Powerlevel9k 步骤一：安装 Powerline 字体库 1 2 3 4  $git clone https://github.com/powerline/fonts.git $./install.sh Copying fonts... Powerline fonts installed to /Users/wangdante/Library/Fonts （字段安装的目录）   brew tap 更新第三方库，才能用 homebrew 安裝字型。执行过可以跳过\nbrew tap caskroom/fonts (旧版本，新版本用：brew tap homebrew/cask)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # 获取homebrew-cask-completion brew install brew-cask-completion # 获取homebrew-cask-fonts brew tap homebrew/cask-fonts # 获取homebrew-cask-drivers brew tap homebrew/cask-drivers # 查看满足nerd格式的字段有哪些，选择下载 brew search nerd ==\u0026gt; Formulae container-diff nerdctl ==\u0026gt; Casks font-go-mono-nerd-font font-sauce-code-pro-nerd-font ✔ ... # 下载/安裝指令 brew install homebrew/cask-fonts/font-sauce-code-pro-nerd-font   步骤二：安装 Powerlevel9k 主题 1 2 3 4 5 6 7 8 9 10 11 12  # 安装P9k $git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k # 配置 oh-my-zsh ：编辑 ~/.zshrc 修改zsh的主题 ZSH_THEME=\u0026#34;powerlevel9k/powerlevel9k\u0026#34; # 显示在左边的提示元素（分段位于括号中并以空格隔开） POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(context # 显示在右边的提示元素（分段） POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(status) # 左侧提示符是否显示两行（光标显示在下一行） POWERLEVEL9K_PROMPT_ON_NEWLINE=true   步骤三：修改终端字体： 修改终端所使用的字体为 你安装的某 nerd font 字体。 装完后，依次Preferences \u0026gt; Profiles \u0026gt; Text \u0026gt; Change Font，将字体改成SauceCodePro Nerd Font或你自己下载的字体：\n步骤四：source ~/.zshrc 使配置生效 步骤五：修改配色方案 1 2 3  git clone https://github.com/mbadolato/iTerm2-Color-Schemes.git 之后import \u0026#39;Tomorrow Night Eighties\u0026#39; monokai remastered (个人比较喜欢)   配置好后，如下图：\n","description":"Powerlevel9k主题可以用于 vanilla ZSH 或 ZSH 框架，如 oh-my-ZSH、 Prezto、 Antigen 等等。","id":79,"section":"stack","tags":["linux",""],"title":"zsh下安装主题Powerlevel9k","uri":"http://wangjinbao.netlify.app/en/stack/linux/zsh/"},{"content":"linux的架构 组成：\n 内核 系统库 shell 应用程序\n  内核 组件包括：\n 设备驱动程序 进程管理 内存管理 文件系统 网络协议系统  系统库 接口和函数包括：\n C标准库（libc） 数学库（libm） 动态链接库（libdl） 线程库（libpthread） 第三方库（\u0026hellip;）  shell: 是内核kernel的外壳，接受用户输入的命令，传递给操作系统来执行\n应用程序 软件程序：如 nginx/mysql等\n发行版 由 内核、应用软件、系统工具、库文件、图形界面、shell、包管理器 组成的操作系统\n常风的发行版本：\n RedHat CentOS KALI(深透) ubuntu(个人桌面) fedora debian alpine(容器化)  虚拟机工具 常见的虚拟机工具：\nwindows上：\n vmware virtualBox hyper-v Multipass（推荐，只支持ubuntu） parallelsDesktop UTM QEMU   ps: ubuntu 官网： https://ubuntu.com/\n multipass multipass常见的命令：\n安装虚拟机镜像实例： multipass launch\n如： multipass launch -n [实例名] -c [CPU核数] -m [内存大小] -d [磁盘大小]\n查看已经安装的虚拟机实例： multipass list/ls\n进入虚拟机实例 multipass shell vm-name\n如： multipass shell master\n启动虚拟机实例 multipass start vm-name\n停止虚拟机实例 multipass stop vm-name\nvi/vim 三种模式：\n 命令模式： 插入模式： 尾行模式：\n  i ：插入\nI ：行首\na : 后面插入\nA : 行尾\nO : 上一行插入\no : 下一行插入\n移动：\nH : 左\nJ : 下\nK : 上\nL : 右\n复制粘贴：\nyy : 复制一行内容，2yy 复制2次\np : 粘贴复制或删除的一行内容，3p复制3次\ndd : 删除一行内容\nctrl+f: 前一页\nctrl+b：后一页\nctrl+u：上一半页\nctrl+d：下一半页\nG：文章最后一行\ngg：文章第一行\n100G：文章第一行 或 :100\n查看：\n:/内容：严格大小写，\\c不会区分大小写 或:set ic\n替换：\n:n1,n2s/old/new/g：:40,50s/替换/被替换/g ： /s 替换，/g 全局\nu : 撤销\nvi .vimrc文件：保存设置\n:set nu ：行数\n:syntx on ： 忽略大小写\n常用命令 ls\ncat hello.txt\nls -l : 详情\nls -i : inode ，i节点\nls -a 隐藏文件\nls -h -t -r -l ：大小 、时间、排序\nln : (link)创建链接文件\nln -s : 软链接\n如： ln -s hello.txt link.txt\n文件权限： lrwxrwxrwx:\n前组：文件所有者的权限(user)\n中组：同组用户的权限(group)\n后组：其他用户的权限(other)\nr （4）: 可读\nw （2）：可写\nx （1）：可执行\nchmod chmod 修改权限\n添加权限 + 号\nchmod +x 1.txt\nchmod +rw 1.txt\n删除权限 - 号\nchmod -x 1.txt\n只有文件的所有者添加权限 + 号\nchmod u+x 1.txt\n只有文件的所有者或组成员添加权限 + 号\nchmod ug+x 1.txt\ntouch pwd cd - ./\n..\ncp cp 1.txt 2.txt\ncp -r a b 目录\nmv mv 1.txt 2.txt\nrm rm file.txt\nrm -r 删除目录递归的删除\nmkdir mkdir a\nmkdir -p a/b/c 层级目录\ndu 查看文件的大小\n也可以查看目录多文件\n目录 /bin 基本命令 + 二进行可执行 文件\n/etc 软件\n配置文件 ：nginx 、 mysql 的配置文件\n/home 家目录，进入系统的默认目录\n/dev 设备文件\n/lib 系统库文件\n/opt 可选的第三方软件包\n/tmp 临时文件\n/usr 用户程序\n/var 可变文件，如日志\n/boot 启动加载器文件\n/proc 进程信息\n/sys 系统文件\n","description":"linux的架构","id":80,"section":"stack","tags":["linux",""],"title":"linux的架构","uri":"http://wangjinbao.netlify.app/en/stack/linux/linux_model/"},{"content":"一、4层代理和7层代理什么意思？ 这里的层是OSI 7层网络模型，OSI 模型是从上往下的，越底层越接近硬件，越往上越接近软件，这七层模型分别是：\n物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。\n  4层 是指传输层的 tcp / udp 。\n  7层 是指应用层，通常是http 。\n  二、OSI模型 OSI（开放系统互联）网络模型是一个用于理解和描述计算机网络功能和协议的参考模型。它定义了将网络通信划分为七个不同的层级，每个层级都描述了特定的功能和任务，从物理传输到应用层。\n为了方便记忆，可以使用以下助记词或短语来代表每个层级的名称：\n  物：物理层（Physical Layer）- 提供传输介质和机械、电气、功能和过程特性，用于直接传输数据比特流。\n  链：数据链路层（Data Link Layer）- 负责在直连的网络节点之间可靠地传输数据帧，并管理物理地址。\n  网：网络层（Network Layer）- 处理分组在网络中的路由和转发，使数据能够跨越多个网络进行传输。\n  传：传输层（Transport Layer）- 提供端到端的可靠数据传输，处理数据分段、重组、流量控制和错误恢复。\n  会话：会话层（Session Layer）- 管理建立、维护和终止应用程序之间的会话。\n  表示：表示层（Presentation Layer）- 处理数据的表示形式，包括数据格式、数据加密和数据压缩。\n  应用：应用层（Application Layer）- 提供网络应用程序与网络服务之间的接口，这是最高级的层级。\n  三、代理原理 4层 用的是NAT技术。NAT英文全称是“Network Address Translation”，中文意思是“网络地址转换”，请求进来的时候，nginx修改数据包里面的目标和源IP和端口，然后把数据包发向目标服务器，服务器处理完成后，nginx再做一次修改，返回给请求的客户端。\n7层代理：需要读取并解析http请求内容，然后根据具体内容(url,参数，cookie,请求头)然后转发到相应的服务器，转发的过程是：建立和目标机器的连接，然后转发请求，收到响应数据在转发给请求客户端。\n在Nginx负载均衡中，4层代理和7层代理是两种不同的代理模式，它们的区别主要体现在所操作的网络层级和负载均衡的粒度上。\n4层代理（也被称为传输层代理）是在传输层（即网络层）上进行负载均衡的一种代理方式。它通过检查传输层的头部信息（如源IP地址、目标IP地址和端口号）来决定将请求转发到后端服务器的哪个节点。4层代理是基于网络层的信息进行路由和负载均衡，能够处理更高的并发请求，但在实现复杂的应用层路由策略方面有限。\n7层代理（也被称为应用层代理）是在应用层进行负载均衡的一种代理方式。它能够解析和处理应用层协议（如HTTP、HTTPS等），并根据应用层的内容来决定请求的转发。7层代理不仅可以基于传输层的信息进行负载均衡，还能够根据请求的路径、域名、Cookie等更具体的应用层信息来进行路由和负载均衡。因此，7层代理更加灵活，能够实现复杂的路由和负载均衡策略，适合处理有状态的应用。\n总结来说，4层代理基于网络层的信息进行负载均衡，适用于处理高并发请求，而7层代理则基于应用层的信息进行负载均衡，具备更灵活的路由和负载均衡策略，适用于处理有状态的应用。选择使用哪种代理方式取决于具体的应用场景和负载均衡需求。\n四、优缺点对比： 1、性能： 理论上4层要比7层快，因为7层代理需要解析数据包的具体内容，需要消耗额外的cpu。但nginx具体强大的网络并发处理能力， 对于一些慢连接，nginx可以先将网络请求数据缓冲完了一次性转发给上游server,这样对于上游网络并发处理能力弱的服务器(比如tomcat)，这样对tomcat来说就是慢连接变成快连接(nginx到tomcat基本上都是可靠内网),从而节省网络数据缓冲时间，提供并发性能。\n2、灵活性： 由于4层代理用的是NAT，所以nginx不知道请求的具体内容，所以nginx啥也干不了。 用7层代理，可以根据请求内容(url,参数，cookie,请求头)做很多事情，比如：\n  a:动态代理：不同的url转发到不同服务器。\n  b.风控：屏蔽外网IP请求某些敏感url；根据参数屏蔽某些刷单用户。\n  c.审计：在nginx层记录请求日志。\n  ","description":"Nginx负载均衡中4层代理和7层代理的区别","id":81,"section":"stack","tags":["linux",""],"title":"Nginx负载均衡中4层代理和7层代理的区别","uri":"http://wangjinbao.netlify.app/en/stack/linux/proxy47/"},{"content":"Machinery Golang的分布式任务队列还不算多，目前比较成熟的应该就只有 Machinery 了。\n如果熟悉Python中的异步任务框架的话，想必一定听过Celery。\n异步任务框架是什么呢？异步任务的主要作用是将需要长时间执行 的代码放到一个单独的程序中，例如调用第三方邮件接口，但是这个接口可能非常慢才响应，而你又想确保自己的API及时响应。这个 时候就可以采用异步任务来进行解耦。\n异步任务的组成和流程 一般来说，异步任务都由这么几部分组成：\n1 2 3 4  - broker：用来传递信息的，想象成“信使”，作用是暂时保存产生的任务以便于消费 - 生产者：它负责产生任务 - 消费者：它负责消费任务 - result backend：这个不是必需，但是如果有保存结果的需要，那么就需要它。   一般来流程：\n1 2 3  生产者发布任务 -\u0026gt; broker -\u0026gt; 消费者竞争任务，然后消费 -\u0026gt; (可选：消费后向broker确认已经消费，然后broker删除此任务，否则将超时重发任务) -\u0026gt; result backend保存结果   集成Machinery到goframe框架 步骤一 首先我们来把 Machinery 代码拉下来：\n1  $ go get github.com/RichardKnop/machinery/v2   在internal/cmd/cmd.go文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  var ( Main = gcmd.Command{ Func: func(ctx context.Context, parser *gcmd.Parser) (err error) { //获取命令参数并解析 \t//** goland中设置debug加参数(-server worker) \t//** 1、添加go build 执行脚本 \t//** 2、设置 Working directory:/Users/wangdante/D/kugou/go/src/tme_doc_api \t//** 3、Program arguments:-server worker) \t//-server worker \topt := gconv.Map(parser.GetOptAll()) server := opt[\u0026#34;server\u0026#34;] if server == \u0026#34;worker\u0026#34; { service.Machinery().Worker(ctx) return nil } else { s := g.Server() //------不需要鉴权------ \ts.Group(\u0026#34;/api\u0026#34;, func(group *ghttp.RouterGroup) { group.Middleware( ghttp.MiddlewareCORS, service.Middleware().MiddlewareLog, service.Middleware().MiddlewareErrorHandler, service.Middleware().MiddlewareResponseEcf, ) //绑定路由 \tgroup.Bind( controller.Hello, controller.Public, //controller.User, \t) }) //------需要鉴权------ \ts.Group(\u0026#34;/api\u0026#34;, func(group *ghttp.RouterGroup) { group.Middleware( ghttp.MiddlewareCORS, service.Middleware().MiddlewareLog, service.Middleware().MiddlewareErrorHandler, service.Middleware().MiddlewareResponseEcf, service.Middleware().MiddlewareToken, ) //gfToken.Middleware(ctx, group) \t//绑定路由 \tgroup.Bind( controller.User, ) }) s.Run() return nil } }, } )   步骤二 新建文件logic/machinery/machinery.go\n同时添加 jaeger.go 、 server.go 、 worker.go (来至拉下来的代码)\n在machinery文件中添加三个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166  func (s *sMachinery) Worker(ctx context.Context) error { consumerTag := \u0026#34;machinery_worker_ecf\u0026#34; cleanup, err := SetupTracer(consumerTag) if err != nil { log.FATAL.Fatalln(\u0026#34;Unable to instantiate a tracer:\u0026#34;, err) } defer cleanup() server, err := service.Machinery().StartServer() if err != nil { return err } // The second argument is a consumer tag \t// Ideally, each worker should have a unique tag (worker1, worker2 etc) \tworker := server.NewWorker(consumerTag, 0) // Here we inject some custom code for error handling, \t// start and end of task hooks, useful for metrics for example. \terrorHandler := func(err error) { log.ERROR.Println(\u0026#34;I am an error handler:\u0026#34;, err) } preTaskHandler := func(signature *tasks.Signature) { log.INFO.Println(\u0026#34;I am a start of task handler for:\u0026#34;, signature.Name) } postTaskHandler := func(signature *tasks.Signature) { log.INFO.Println(\u0026#34;I am an end of task handler for:\u0026#34;, signature.Name) } worker.SetPostTaskHandler(postTaskHandler) worker.SetErrorHandler(errorHandler) worker.SetPreTaskHandler(preTaskHandler) return worker.Launch() } func (s *sMachinery) Send(ctx context.Context) error { cleanup, err := SetupTracer(\u0026#34;sender\u0026#34;) if err != nil { log.FATAL.Fatalln(\u0026#34;Unable to instantiate a tracer:\u0026#34;, err) } defer cleanup() server, err := service.Machinery().StartServer() if err != nil { return err } var ( addTask0 tasks.Signature //addTask1, addTask2 tasks.Signature \t//multiplyTask0, multiplyTask1 tasks.Signature \t//sumIntsTask, sumFloatsTask, concatTask, splitTask tasks.Signature \t//panicTask tasks.Signature \t//longRunningTask tasks.Signature \t) var initTasks = func() { addTask0 = tasks.Signature{ Name: \u0026#34;add\u0026#34;, Args: []tasks.Arg{ { Type: \u0026#34;int64\u0026#34;, Value: 1, }, { Type: \u0026#34;int64\u0026#34;, Value: 1, }, }, } } /* * Lets start a span representing this run of the `send` command and * set a batch id as baggage so it can travel all the way into * the worker functions. */ span, ctx := opentracing.StartSpanFromContext(context.Background(), \u0026#34;send\u0026#34;) defer span.Finish() batchID := uuid.New().String() span.SetBaggageItem(\u0026#34;batch.id\u0026#34;, batchID) span.LogFields(opentracinglog.String(\u0026#34;batch.id\u0026#34;, batchID)) log.INFO.Println(\u0026#34;Starting batch:\u0026#34;, batchID) /* * First, let\u0026#39;s try sending a single task */ initTasks() log.INFO.Println(\u0026#34;Single task:\u0026#34;) asyncResult, err := server.SendTaskWithContext(ctx, \u0026amp;addTask0) if err != nil { return fmt.Errorf(\u0026#34;Could not send task: %s\u0026#34;, err.Error()) } results, err := asyncResult.Get(time.Millisecond * 5) if err != nil { return fmt.Errorf(\u0026#34;Getting task result failed with error: %s\u0026#34;, err.Error()) } log.INFO.Printf(\u0026#34;1 + 1 = %v\\n\u0026#34;, tasks.HumanReadableResults(results)) return nil } func (s *sMachinery) StartServer() (*machinery.Server, error) { //=====创建并配置broker=====  //读取redis配置参数 \tvar ctx = gctx.New() redisData, _ := g.Cfg().Get(ctx, \u0026#34;redis\u0026#34;) deMap := redisData.MapDeep()[\u0026#34;default\u0026#34;] var redisAddress, redisPass, redisQueue string var redisDB, redisExpire int if cnf, ok := deMap.(map[string]interface{}); ok { redisAddress = common.Strval(cnf[\u0026#34;address\u0026#34;]) redisPass = common.Strval(cnf[\u0026#34;pass\u0026#34;]) redisDB, _ = strconv.Atoi(common.Strval(cnf[\u0026#34;work\u0026#34;])) redisQueue = common.Strval(cnf[\u0026#34;default_queue\u0026#34;]) redisExpire, _ = strconv.Atoi(common.Strval(cnf[\u0026#34;expire_in\u0026#34;])) } cnf := \u0026amp;config.Config{ DefaultQueue: redisQueue, ResultsExpireIn: redisExpire, Redis: \u0026amp;config.RedisConfig{ MaxIdle: 3, IdleTimeout: 240, ReadTimeout: 15, WriteTimeout: 15, ConnectTimeout: 15, NormalTasksPollPeriod: 1000, DelayedTasksPollPeriod: 500, }, } // Create server instance \tbroker := redisbroker.New(cnf, redisAddress, redisPass, \u0026#34;\u0026#34;, redisDB) backend := redisbackend.New(cnf, redisAddress, redisPass, \u0026#34;\u0026#34;, redisDB) lock := eagerlock.New() server := machinery.NewServer(cnf, broker, backend, lock) //=====创建任务tasks=====  // Register tasks \ttasksMap := map[string]interface{}{ \u0026#34;add\u0026#34;: exampletasks.Add, // \u0026#34;multiply\u0026#34;: exampletasks.Multiply, \t//\u0026#34;sum_ints\u0026#34;: exampletasks.SumInts, \t// \u0026#34;sum_floats\u0026#34;: exampletasks.SumFloats, \t// \u0026#34;concat\u0026#34;: exampletasks.Concat, \t// \u0026#34;split\u0026#34;: exampletasks.Split, \t// \u0026#34;panic_task\u0026#34;: exampletasks.PanicTask, \t// \u0026#34;long_running_task\u0026#34;: exampletasks.LongRunningTask, \t} //=====注册任务tasks=====  return server, server.RegisterTasks(tasksMap) }   Machinery定时任务 步骤一：创建并配置broker 体能在方法StartServer中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  //=====创建并配置broker=====  //读取redis配置参数 var ctx = gctx.New() redisData, _ := g.Cfg().Get(ctx, \u0026#34;redis\u0026#34;) deMap := redisData.MapDeep()[\u0026#34;default\u0026#34;] var redisAddress, redisPass, redisQueue string var redisDB, redisExpire int if cnf, ok := deMap.(map[string]interface{}); ok { redisAddress = common.Strval(cnf[\u0026#34;address\u0026#34;]) redisPass = common.Strval(cnf[\u0026#34;pass\u0026#34;]) redisDB, _ = strconv.Atoi(common.Strval(cnf[\u0026#34;work\u0026#34;])) redisQueue = common.Strval(cnf[\u0026#34;default_queue\u0026#34;]) redisExpire, _ = strconv.Atoi(common.Strval(cnf[\u0026#34;expire_in\u0026#34;])) } cnf := \u0026amp;config.Config{ DefaultQueue: redisQueue, ResultsExpireIn: redisExpire, Redis: \u0026amp;config.RedisConfig{ MaxIdle: 3, IdleTimeout: 240, ReadTimeout: 15, WriteTimeout: 15, ConnectTimeout: 15, NormalTasksPollPeriod: 1000, DelayedTasksPollPeriod: 500, }, }   步骤二：创建server实例 1 2 3 4 5  // Create server instance broker := redisbroker.New(cnf, redisAddress, redisPass, \u0026#34;\u0026#34;, redisDB) backend := redisbackend.New(cnf, redisAddress, redisPass, \u0026#34;\u0026#34;, redisDB) lock := eagerlock.New() server := machinery.NewServer(cnf, broker, backend, lock)   步骤三：注册普通任务tasks 1 2 3 4 5 6 7 8 9 10 11 12 13 14  //=====创建任务tasks=====  // Register tasks tasksMap := map[string]interface{}{ \u0026#34;add\u0026#34;: exampletasks.Add, \u0026#34;transferDepartment\u0026#34;: s.TransferDepartment, \u0026#34;transferBU\u0026#34;: s.TransferBU, \u0026#34;transferStaff\u0026#34;: s.TransferStaff, \u0026#34;ecfDepartment\u0026#34;: s.EcfDepartment, \u0026#34;ecfBU\u0026#34;: s.EcfBU, \u0026#34;ecfStaff\u0026#34;: s.EcfStaff, } return server, server.RegisterTasks(tasksMap)   步骤四：注册定时任务tasks 在注册完普通任务return注册定时任务即可\n公式：Cron * * * * ?: minute, hour, day of month, month and day of week\n1 2 3 4  signatureBU := \u0026amp;tasks.Signature{ Name: \u0026#34;transferBU\u0026#34;, } server.RegisterPeriodicTask(\u0026#34;57 9 * * ?\u0026#34;, \u0026#34;periodic-task-bu\u0026#34;, signatureBU)   步骤五：写好注册定时任务执行方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // TransferDepartment /** * @Name: TransferDepartment * @Description: 集团数据中转-行政组织 * @receiver s * @param args * @return int64 * @return error */ func (s *sMachinery) TransferDepartment(args ...int64) (int64, error) { ctx := context.TODO() service.Tme().GetCenterData(ctx, \u0026#34;department\u0026#34;) return 1, nil } // TransferBU /** * @Name: TransferBU * @Description: 集团数据中转-业务单元 * @receiver s * @param args * @return int64 * @return error */ func (s *sMachinery) TransferBU(args ...int64) (int64, error) { ctx := context.TODO() service.Tme().GetCenterData(ctx, \u0026#34;business_unit\u0026#34;) return 1, nil }   ","description":"goframe框架集成分布式异步任务队列machinery","id":82,"section":"stack","tags":["golang",""],"title":"goframe框架集成任务队列machinery和定时任务","uri":"http://wangjinbao.netlify.app/en/stack/golang/goframe_machinery/"},{"content":"目录 ├── Dockerfile\n├── authorized_keys\n└── run.sh\nauthorized_keys文件生成 authorized_keys文件生成：\n1 2 3 4  ssh-keygen -t rsa cat ~/.ssh/id_rsa.pub cat ~/.ssh/id_rsa.pub \u0026gt; ~/.ssh/authorized_keys cp /root/.ssh/authorized_keys .   run.sh run.sh脚本用于运行容器时，启动容器李的sshd服务 1 2  #!/bin/bash /usr/sbin/sshd -D   Dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  FROM golang:1.18.9 RUN go env -w GO111MODULE=on RUN go env -w CGO_ENABLED=0 RUN go env -w GOOS=linux RUN go env -w GOARCH=amd64 RUN go env -w GOPROXY=https://goproxy.cn,direct RUN echo \u0026#34;deb http://mirrors.aliyun.com/debian/ bullseye main non-free contrib \\n \\ deb-src http://mirrors.aliyun.com/debian/ bullseye main non-free contrib \\n \\ deb http://mirrors.aliyun.com/debian-security/ bullseye-security main \\n \\ deb-src http://mirrors.aliyun.com/debian-security/ bullseye-security main \\n \\ deb http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib \\n \\ deb-src http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib \\n \\ deb http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib \\n \\ deb-src http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib\u0026#34; \u0026gt; /etc/apt/sources.list RUN apt-get update \u0026amp;\u0026amp; apt-get install -y vim git openssh-server # RUN echo \u0026#34;export PATH=$GOPATH/bin:$PATH \u0026#34; \u0026gt;\u0026gt; /etc/profile # RUN source /etc/profile # RUN chmod -R 777 /usr/local/go/ /go RUN go install github.com/go-delve/delve/cmd/dlv@latest RUN cp /go/bin/linux_amd64/dlv /go/bin/dlv # RUN cd /usr/local/go/src/ # RUN git clone https://github.com/go-delve/delve.git \u0026amp;\u0026amp; \\ # cd delve/cmd/dlv/ \u0026amp;\u0026amp; \\ # go build \u0026amp;\u0026amp; \\ # go install WORKDIR /var/www/html # 创建运行服务所需要的目录 RUN mkdir -p /var/run/shhd /run/sshd /root/.ssh RUN chmod 755 /run/sshd RUN sed -ri \u0026#39;s/session required pam_loginuid.so/#session required pam_loginuid.so/g\u0026#39; /etc/pam.d/sshd # 将宿主机产生的authorized.keys文件复制镜像的/root/.ssh/目录下 COPY authorized_keys /root/.ssh/authorized_keys # 将run.sh脚本文件复制到根目录下,并配置执行权限 COPY run.sh /run.sh RUN chmod 755 /run.sh EXPOSE 22 # 设置启动sshd服务命令 ENTRYPOINT [\u0026#34;/usr/sbin/sshd\u0026#34;, \u0026#34;-D\u0026#34;] # CMD [\u0026#34;/run.sh\u0026#34;]   ","description":"Docker中设置authorized_keys进行无密码登录","id":83,"section":"stack","tags":["docker",""],"title":"ssh无密码登录容器","uri":"http://wangjinbao.netlify.app/en/stack/k8s/sshlogin/"},{"content":"目标  用Docker搭建一套三层架构的Web系统（nodejs+PHP+MySQL） 掌握日常使用Docker进行程序开发、配置和发布的方法与原理  准备  安装docker desktop 克隆git项目:  1  git clone http://git.tmeoa.com/TMEIT/container-step-by-step   切换目录:  1  cd ${PWD}/container-step-by-step/k8s   实验一 容器基本操作 目标  用公共镜像启动一个Nginx服务，并能通过浏览器访问  目的  掌握容器的启动、停止和删除操作  实验步骤 运行nginx  前台运行 1  k8s run nginx    后台运行 1  k8s run -ti -d nginx     查看容器运行状况 1 2 3  k8s ps # 不加参数，查看正在运行的容器 # -a 查看全部容器，包括已停止的   停止和启动容器 1 2 3 4 5 6  # 停止容器 k8s stop \u0026lt;name or id\u0026gt; # 强制停止 # k8s kill \u0026lt;name or id\u0026gt; # 启动容器 k8s start \u0026lt;name or id\u0026gt;   暴露容器端口  启动新的nginx容器 1  k8s run -ti -d -p 8080:80 nginx    打开浏览器，访问：http://127.0.0.1:8080\n@startuml\nagent 浏览器 as br\nnode Docker服务器{\nport 8080\nnode Nginx容器{\nport 80\nrectangle nginx\n}\n8080 \u0026ndash;\u0026gt; 80\n' 80 \u0026hellip; nginx\n}\nbr \u0026ndash;\u0026gt; 8080\n@enduml  删除容器 1 2  # 容器停止状态下执行 k8s rm \u0026lt;name or id\u0026gt;   实验二 在容器内使用指定文件 目标  通过容器内Nginx，用浏览器访问指定的静态文件  目的  了解如何拷贝本地文件到容器 了解如何拷贝容器文件到本地 掌握如何挂载本地文件到容器  实验步骤 文件拷贝方式  启动nginx 1  k8s run -d -ti -p 8081:80 nginx    拷贝静态文件到容器指定目录 1  k8s cp dist/ \u0026lt;id or name\u0026gt;:/usr/knowledge/nginx/html/    浏览器访问http://127.0.0.1:8081  挂载文件方式  启动nginx并挂载文件夹(或文件) 1 2 3 4  cp -R exp2/* data/ k8s run -d -ti -p 8082:80 -v ${PWD}/data/dist:/usr/knowledge/nginx/html nginx # 或 # k8s run -d -ti -p 8082:80 -v ${PWD}/data/dist/index.html:/usr/knowledge/nginx/html/index.html nginx    浏览器访问http://127.0.0.1:8082 修改dist/index.html 刷新浏览器  实验三 容器间通信 目标  启动后端服务，通过Nginx转发HTTP请求 通过客户端访问后端服务  目的  理解Docker的容器网络环境 了解容器间通信方式  实验步骤  创建自定义网络 1 2 3  k8s network create my_network # 查看现有网络列表 k8s network ls    启动php-fpm容器，并挂载代码到指定目录 1 2  cp -R exp3/* data/ k8s run -d -ti --name php-fpm-svr -v ${PWD}/data/php:/app/php --network my_network php:fpm    启动nginx容器，并挂载配置文件和静态文件 1  k8s run -d -ti --name nginx-front -v ${PWD}/data/nginx_configs/default.conf:/etc/nginx/conf.d/default.conf -v ${PWD}/data/dist:/app/dist --network my_network -p 8080:80 nginx    浏览器访问：http://localhost:8080/api/getCurTime http://localhost:8080/  @startuml\nagent 浏览器 as br\nnode Docker服务器{\ncloud 主机网络 as hn\nport \u0026ldquo;port_8080\u0026rdquo; as hnp\nrectangle bridge网桥 as bridge {\nportout port1\nportout port2\n}\nnode contanier1{\nportin cp1\nport1 \u0026ndash; cp1\n}\nnode contanier2{\nportin cp2\nport2 \u0026ndash; cp2\n}\nrectangle my_network网桥 as my_network { portout port3 portout port4 } node Nginx容器 as nginx{ portin cp3 port3 -- cp3 } node php-fpm容器 as fpm{ portin cp4 port4 -- cp4 } hnp -- hn hn -- bridge hn -- my_network  }\nbr -[#red,dotted]- hnp\nhnp -[#red,dotted]- hn\nhn -[#red,dotted]- my_network\nmy_network -[#red,dotted]- cp3\n' nginx -[#blue,dotted]- port4\n@enduml\n实验四 使用临时容器执行任务 目标  启动MySQL数据库 通过MySQL容器初始化数据库 数据持久化  目的  了解如何查找和获取公共镜像版本 理解容器环境隔离性和临时性 理解容器存储原理  实验步骤 临时容器  浏览器访问 hub.docker.com，搜索mysql，进入mysql镜像页面 下载指定版本镜像 1 2 3  k8s pull mysql:5.7 # 查看镜像列表 k8s images    启动mysql 1 2 3 4  k8s run -d -ti -e MYSQL_ROOT_PASSWORD=rootpass mysql:5.7 #查看容器IP k8s inspect \u0026lt;id or name\u0026gt; # 或者 k8s inspect -f \u0026#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; \u0026lt;id or name\u0026gt;    启动临时容器，导入数据 1 2 3 4 5 6 7 8  cp -R exp4/* data/ k8s run --rm -ti -v ${PWD}/data/exp4.sql:/root/exp4.sql mysql:5.7 bash mysql -h\u0026lt;ip\u0026gt; -uroot -p # mysql shell source /root/exp4.sql quit # bash exit   或者 1 2 3 4  k8s run --rm -ti -v ${PWD}/data/exp4.sql:/root/exp4.sql mysql:5.7 mysql -h\u0026lt;ip\u0026gt; -uroot -p # mysql shell source /root/exp4.sql quit    查看容器 1  k8s ps -a     数据持久化 启动新的mysql容器，指定数据存储目录，并导入数据\n1 2 3 4 5 6 7 8  k8s run -d -ti --name mysql_svr -e MYSQL_ROOT_PASSWORD=rootpass -v ${PWD}/data/mysql_data:/var/lib/mysql mysql:5.7 # 将mysql容器加入到my_network网络中，以便使用容器名进行访问 k8s network connect my_network mysql_svr # 导入数据 k8s run --rm -ti -v ${PWD}/data/exp4.sql:/root/exp4.sql --network my_network mysql:5.7 mysql -hmysql_svr -uroot -p # mysql shell source /root/exp4.sql quit   @startuml\nnode Docker服务器{\nnode mysql容器 {\nrectangle rootfs #aliceblue;line:blue;line.dotted;text:blue {\nfolder \u0026ldquo;/\u0026rdquo; as root\nfolder \u0026ldquo;/\u0026rdquo; as root\nfolder \u0026ldquo;/var\u0026rdquo; as var\nfolder \u0026ldquo;/usr\u0026rdquo; as usr\nfolder \u0026ldquo;\u0026hellip;\u0026rdquo; as other\nfolder \u0026ldquo;/var/lib/mysql\u0026rdquo; as var_lib_mysql #aliceblue;line:grey;line.dotted;text:grey\nfolder \u0026ldquo;/var/lib/\u0026hellip;\u0026rdquo; as var_lib_other\n root -- var root -- usr root -- other var -- var_lib_other var -- var_lib_mysql } }  folder mysql_data\nmysql_data \u0026lt;\u0026ndash;\u0026gt; var_lib_mysql\n}\n@enduml\n配置后端访问  为PHP安装mysql驱动 1 2 3 4 5 6 7 8  # 进入容器shell k8s exec -ti php-fpm-svr bash # 容器内 bash k8s-php-ext-install pdo pdo_mysql exit # 重启php-fpm-svr容器 k8s stop php-fpm-svr k8s start php-fpm-svr    浏览器访问：http://localhost:8080/api/getDbData  实验五 创建容器镜像 目标  固化程序版本，不再依赖本地文件和容器 可同时访问新旧版本API  目的  掌握Dockerfile基本使用方法  实验步骤  修改 data/php/api.php 文件 第23行 1  $response = [\u0026#39;time\u0026#39; =\u0026gt; $currentTime, \u0026#39;version\u0026#39; =\u0026gt; \u0026#39;1.0\u0026#39;];    浏览器访问：http://127.0.0.1:8080/api/getCurTime 确认修改已生效 拷贝Dockerfile 1  cp exp5/Dockerfile data/php/    构建镜像 1 2  cd data/php k8s build -t php-fpm-svr:v1.0 .    运行1.0版本镜像 1  k8s run -d -ti --name php-fpm-svr-v1 --network my_network php-fpm-svr:v1.0    修改nginx_configs/default.conf文件，添加如下配置： 1 2 3 4 5 6 7 8 9  location /api/v1/{ if ($uri ~ \u0026#34;^/api/v1/(.*)$\u0026#34;) { set $newuri /api/$1; } fastcgi_pass php-fpm-svr-v1:9000; # 新的PHP后端服务地址  fastcgi_param SCRIPT_FILENAME /app/php/api.php; include fastcgi_params; fastcgi_param REQUEST_URI $newuri; }    reload nginx使配置生效 1  k8s exec -ti nginx-front nginx -s reload    修改 data/php/api.php 文件 第23行 1  $response = [\u0026#39;time\u0026#39; =\u0026gt; $currentTime, \u0026#39;version\u0026#39; =\u0026gt; \u0026#39;1.1\u0026#39;];    分别访问：\nhttp://127.0.0.1:8080/api/getCurTime\nhttp://127.0.0.1:8080/api/v1/getCurTime  @startuml\nagent 浏览器 as br\nnode Docker服务器{\nport \u0026ldquo;port_8080\u0026rdquo; as hnp\nnode nginx-front as nginx{\nportin port_80\n}\nnode php-fpm-svr as fpm{\nportin portA_9000\n}\nnode php-fpm-svr-v1 as fpmv1{\nportin portB_9000\n}\nnode mysql_svr as mysql{\nportin portC_3306\n}\nhnp \u0026ndash; port_80\nnginx \u0026ndash; portB_9000\nnginx \u0026ndash; portA_9000\nfpm \u0026ndash; portC_3306\nfpmv1 \u0026ndash; portC_3306\n}\nbr \u0026ndash; hnp\n@enduml\n实验六 自动化编译打包 目标  通过Dockerfile构建前端镜像 前端镜像中只包含必要的静态文件  目的  掌握如何利用容器构建编译环境方法 掌握Dockerfile高级使用技巧  实验步骤 手动编译vuejs  运行nodejs容器，并初始化vuejs项目 1 2 3 4 5  k8s run -ti --rm -v ${PWD}/data/vuejs:/app node:19 bash # 容器shell npm install -g @vue/cli cd /app vue create my-vue-app    拷贝vue源文件 1  cp -vR exp6/vue_src/* data/vuejs/my-vue-app/src    编译vuejs 1 2 3  # 容器shell npm run build exit    拷贝静态文件 1  cp -vR data/vuejs/my-vue-app/dist/* data/dist/    浏览器访问： http://127.0.0.1:8080/  自动编译打包  拷贝Dockerfile并构建镜像 1  cp exp6/Dockerfile data/    制作镜像 1 2  cd data k8s build -t front:v1.0 .    运行前端镜像 1  k8s run -d -ti --name front-1.0 -p 8081:80 --network my_network front:v1.0    浏览器访问： http://127.0.0.1:8081/  @startuml\nagent 浏览器 as br\nnode Docker服务器{\nport \u0026ldquo;port_8080\u0026rdquo; as hnp\nnode nginx-front as nginx{\nportin portA_80\n}\nport \u0026ldquo;port_8081\u0026rdquo; as hnp1\nnode nginx-front-v1 as nginxv1{\nportin portB_80\n}\nnode php-fpm-svr as fpm{\nportin portA_9000\n}\nnode php-fpm-svr-v1 as fpmv1{\nportin portB_9000\n}\nnode mysql_svr as mysql{\nportin portC_3306\n}\nhnp \u0026ndash; portA_80\nhnp1 \u0026ndash; portB_80\nnginx \u0026ndash; portB_9000\nnginx \u0026ndash; portA_9000\nnginxv1 \u0026ndash; portB_9000\nnginxv1 \u0026ndash; portA_9000\nfpm \u0026ndash; portC_3306\nfpmv1 \u0026ndash; portC_3306\n}\nbr \u0026ndash; hnp1\n@enduml\n实验七 镜像的分发与镜像仓库的使用 目标  通过镜像导出、导入实现镜像分发 通过镜像上传、下载到镜像仓库实现镜像分发  目的  了解如何使用镜像私有化镜像仓库 理解容器化软件分发方式  实验步骤 镜像导出和导入 1 2 3 4 5 6 7  #导出镜像 k8s save -o front-v1.0.tar front:v1.0 # 删除正在运行的容器和镜像 k8s kill front-1.0 k8s rm front-1.0 \u0026amp;\u0026amp; k8s rmi front:v1.0 #导入镜像 k8s load -i front-v1.0.tar   利用镜像仓库上传下载镜像 以腾讯云的个人镜像仓库为例\n1 2 3 4 5 6 7 8  # 登录镜像仓库 k8s login ccr.ccs.tencentyun.com --username=\u0026lt;username\u0026gt; # 设置镜像别名 k8s tag front:v1.0 ccr.ccs.tencentyun.com/consbs/front:v1.0 # 上传镜像 k8s push ccr.ccs.tencentyun.com/consbs/front:v1.0 # 下载镜像 k8s pull ccr.ccs.tencentyun.com/consbs/front:v1.0   实验八 限制容器使用资源 目标  通过设置参数实现容器最大能使用的CPU和内存资源数量  目的  了解如何限制容器计算资源使用的方法  实验步骤 限制CPU资源  启动主机压测程序stress  1 2 3  # 建议设置一个超时时间，防止参数错误将服务器压垮 k8s run --rm -it progrium/stress --cpu 1 --timeout 60s # --cpu=1 程序会让一个CPU核心使用率到达100%   登录docker服务器，用top命令观察stress进程消耗资源  1 2 3 4 5 6 7 8  # 打开另一个终端窗口 # （可选）mac上登录docker服务器 k8s run --rm -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh top # 按pid排序 N # 展开CPU信息 1   重新启动stress，并设置CPU=0.5核  1 2 3 4  # ctl+C 结束原来的street容器，重新启动 k8s run --cpus=0.5 --rm -it progrium/stress --cpu 1 --timeout 60s # --cpus=0.5 限制容器最大可用CPU资源为0.5个 #   重复步骤2  限制内存资源  启动主机压测程序stress  1 2 3  # 建议设置一个超时时间，防止参数错误将服务器压垮 k8s run --rm -it progrium/stress --vm 1 --vm-bytes 256M --timeout 60s # --vm 1 --vm-bytes 256M 程序会启动一个进程，申请256MB内存   登录docker服务器，用top命令观察stress进程消耗资源  1 2 3 4 5 6  # 打开另一个终端窗口 # （可选）mac上登录docker服务器 k8s run --rm -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh top # 按pid排序 N   重新启动stress，并设置CPU=0.5核  1 2 3 4  # ctl+C 结束原来的street容器，重新启动 k8s run --rm -m 128m -it progrium/stress --vm 1 --vm-bytes 256M --timeout 60s # -m 128m 限制容器最大可用内存为128MB # 会发现容器由于无法申请到足够的内存，启动后马上退出   实验九 利用gitlabCI自动化构建和上传镜像 目标  提交代码后，自动构建镜像并推送至镜像仓库  目的  利用工具实现软件自动容器化过程  实验步骤  拷贝文件 .gitlab-ci.yml和Dockerfile 文件到git仓库项目目录下。 1 2  cp exp9/.gitlab-ci.yml you-git-project-dir cp exp9/Dockerfile you-git-project-dir    在 GitLab 项目设置中打开 \u0026ldquo;CI/CD\u0026rdquo; 设置，找到 \u0026ldquo;Variables\u0026rdquo; 部分，并添加 镜像仓库、用户名、密码和镜像这四个变量，变量名称分别为:CI_REGISTRY CI_REGISTRY_USER CI_REGISTRY_PASSWORD CI_REGISTRY_IMAGE 提交代码到 GitLab 仓库。每次提交时，GitLab CI/CD 将自动运行构建流程，构建 Docker 镜像并上传至 GitLab 容器仓库。详细信息可以在GitLab项目的CI/CD\u0026ndash;Jobs页面查看。  demo： Dockerfile 请使用 Dockerfile 构建容器镜像。\nDockerfile 应与应用代码一起保存在 Git 仓库中，以便进行版本控制和分支管理。\n镜像构建与上传 推荐使用 GitLabCI 进行自动化镜像构建和上传。示例如下：\n 在 GitLab 项目仓库中创建文件 .gitlab-ci.yml:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # .gitlab-ci.yml # 更多语法规则参考：https://docs.gitlab.com/ee/ci/ stages:- builddocker-build:stage:buildonly:- tagsbefore_script:- k8s login -u \u0026#34;$CI_REGISTRY_USER\u0026#34; -p \u0026#34;$CI_REGISTRY_PASSWORD\u0026#34; $CI_REGISTRY# Default branch leaves tag empty (= latest tag)# All other branches are tagged with the escaped branch name (commit ref slug)script:- |pwd ls imageUrl=\u0026#34;$CI_REGISTRY_KGAPI/api_build:$CI_COMMIT_TAG\u0026#34; echo \u0026#34;Running on branch \u0026#39;$CI_COMMIT_BRANCH\u0026#39;: commit_tag = \u0026#39;$CI_COMMIT_TAG\u0026#39;\u0026#34; echo \u0026#34;******\u0026#34; echo \u0026#34;${imageUrl}\u0026#34; echo \u0026#34;******\u0026#34;- k8s build -f ./Dockerfile -t \u0026#34;${imageUrl}\u0026#34; .- k8s push \u0026#34;${imageUrl}\u0026#34;- k8s rmi \u0026#34;${imageUrl}\u0026#34;tags:- tmeit-knowledge  设置镜像仓库、镜像名称、用户名和密码等变量（GitLab 项目群组可使用同一套变量，如需独立的用户，可向运维申请）  1 2 3 4  变量设置： 设置 -\u0026gt; CI/CD -\u0026gt; Variables CI_REGISTRY_KGAPI -\u0026gt; tme-it-hr.tencentcloudcr.com/kgkpi   Dockerfile的内容如下：  1 2 3 4 5 6 7  FROMtme-it-hr.tencentcloudcr.com/kgkpi/api_mid:v1.1COPY . /var/www/html/TME_KG_STOCK_POINTS_API/RUN chmod -R 777 /var/www/html/TME_KG_STOCK_POINTS_API/public/RUN chmod -R 777 /var/www/html/TME_KG_STOCK_POINTS_API/storage/RUN chmod -R 777 /var/www/html/TME_KG_STOCK_POINTS_API/bootstrap/WORKDIR/var/www/html/TME_KG_STOCK_POINTS_APIEXPOSE9000  api_mid:v1.1的镜像的Dockerfile如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  FROMphp:7.4-fpmLABEL maintainer=\u0026#34;kugou_stock_points api Maintainers \u0026lt;jarvenwang@kugou.net\u0026gt;\u0026#34;RUN echo \u0026#34;deb http://mirrors.aliyun.com/debian/ bullseye main non-free contrib \\n \\ deb-src http://mirrors.aliyun.com/debian/ bullseye main non-free contrib \\n \\ deb http://mirrors.aliyun.com/debian-security/ bullseye-security main \\n \\ deb-src http://mirrors.aliyun.com/debian-security/ bullseye-security main \\n \\ deb http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib \\n \\ deb-src http://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib \\n \\ deb http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib \\n \\ deb-src http://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib\u0026#34; \u0026gt; /etc/apt/sources.listRUN apt-get update \u0026amp;\u0026amp; apt-get install -y vimRUN apt-get install -y zlib1g-devRUN apt-get install -y libzip-devRUN apt-get -y install gcc make autoconf libc-dev pkg-config\\  \u0026amp;\u0026amp; apt-get -y install libmcrypt-devRUN apt-get install -y gitRUN docker-php-ext-install mysqli\\  \u0026amp;\u0026amp; docker-php-ext-install sockets\\  \u0026amp;\u0026amp; docker-php-ext-install pdo_mysql\\  \u0026amp;\u0026amp; docker-php-ext-install zip\\  \u0026amp;\u0026amp; pecl install swoole-4.4.17\\  \u0026amp;\u0026amp; docker-php-ext-enable swoole\\  \u0026amp;\u0026amp; pecl install redis-5.2.1\\  \u0026amp;\u0026amp; docker-php-ext-enable redis\\  \u0026amp;\u0026amp; pecl install mcrypt\\  \u0026amp;\u0026amp; docker-php-ext-enable mcryptRUN php -r \u0026#34;copy(\u0026#39;https://install.phpcomposer.com/installer\u0026#39;, \u0026#39;composer-setup.php\u0026#39;);\u0026#34;\\  \u0026amp;\u0026amp; php composer-setup.php\\  \u0026amp;\u0026amp; mv composer.phar /usr/local/bin/composer\\  \u0026amp;\u0026amp; composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/  git合并时忽略.gitlab-ci.yml  1 2 3 4 5 6 7 8 9 10 11  1、git合并时忽略某个文件(代码片段) 2、git合并两个分支的某个文件 因为开发现场跟部署的环境不同,有很多ip地址每次都要改来改去;于是开两个分支master(用来保存部署现场的ip)和dev(开发环境的ip),开发功能时在dev分支,然后使用master合并,每个分支都保存着自己的config配置文件,不想dev分支被master合并时config文件也合并. 创建自定义merge driver git config --global merge.kg.driver true 在要被merge的分支上创建.gitattributes文件,并且在文件中置顶不merge的文件名 echo ‘.gitlab-ci.yml merge=kg merge=ours‘ \u0026gt;\u0026gt; .gitattributes 之后提交到远程仓库 之后合并分支   实验十 问题排查 目的  掌握常用容器运行时调试方法 了解容器运行常见错误  实验步骤 查看镜像或容器详细信息 1  k8s inspect \u0026lt;container/image id or name\u0026gt;   查看容器的标准输出 1 2 3  k8s logs \u0026lt;container id or name\u0026gt; -n 10 -f # -n \u0026lt;num\u0026gt; 显示最新num行日志 # -f 自动滚动更新   进入容器运行时控制台 1 2  docker attach \u0026lt;container id or name\u0026gt; # ctl+p ctl+q 退出（docker run没有加 -ti 参数无效）   在容器中执行命令 1  k8s exec -ti \u0026lt;container id or name\u0026gt; \u0026lt;command\u0026gt; \u0026lt;args\u0026gt;   无法启动或启动后退出 分别构建exp10/Dockerfile中注释的两种错误镜像\n1 2 3 4 5 6  # 正常启动 CMD [ \u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34; ]# 错误1：启动脚本中带 \u0026amp;# ENTRYPOINT [ \u0026#34;/mystart.sh\u0026#34; ]# 错误2：后台运行主程序# ENTRYPOINT [ \u0026#34;nginx\u0026#34; ]  分别启动这两种错误镜像：\n1  k8s run -ti \u0026lt;image name\u0026gt;   ","description":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。让打包应用以及依赖包到一个轻量级、可移植的容器中，发布到任何Linux机器上。","id":84,"section":"stack","tags":["docker",""],"title":"十个实验熟练掌握Docker","uri":"http://wangjinbao.netlify.app/en/stack/k8s/docker/"},{"content":"命令管理 GetArg*参数获取  GetArg 方法用以获取默认解析的命令行参数，参数通过输入索引位置获取，索引位置从 0 开始，但往往我们需要获取的参数是从 1 开始，因为索引 0 的参数是程序名称。  1 2 3 4 5 6 7 8 9 10  func ExampleGetArg() { gcmd.Init(\u0026#34;gf\u0026#34;, \u0026#34;build\u0026#34;, \u0026#34;main.go\u0026#34;, \u0026#34;-o=gf.exe\u0026#34;, \u0026#34;-y\u0026#34;) fmt.Printf( `Arg[0]: \u0026#34;%v\u0026#34;, Arg[1]: \u0026#34;%v\u0026#34;, Arg[2]: \u0026#34;%v\u0026#34;, Arg[3]: \u0026#34;%v\u0026#34;`, gcmd.GetArg(0), gcmd.GetArg(1), gcmd.GetArg(2), gcmd.GetArg(3), ) // Output: \t// Arg[0]: \u0026#34;gf\u0026#34;, Arg[1]: \u0026#34;build\u0026#34;, Arg[2]: \u0026#34;main.go\u0026#34;, Arg[3]: \u0026#34;\u0026#34; }    GetArgAll 方法用于获取所有的命令行参数。  1 2 3 4 5 6 7  func ExampleGetArgAll() { gcmd.Init(\u0026#34;gf\u0026#34;, \u0026#34;build\u0026#34;, \u0026#34;main.go\u0026#34;, \u0026#34;-o=gf.exe\u0026#34;, \u0026#34;-y\u0026#34;) fmt.Printf(`%#v`, gcmd.GetArgAll()) // Output: \t// []string{\u0026#34;gf\u0026#34;, \u0026#34;build\u0026#34;, \u0026#34;main.go\u0026#34;} }   GetOpt*选项获取  GetOpt 方法用以获取默认解析的命令行选项，选项通过名称获取，并且选项的输入没有顺序性，可以输入到任意的命令行位置。当给定名称的选项数据不存在时，返回 nil。注意判断不带数据的选项是否存在时，可以通过 GetOpt(name) != nil 方式。  1 2 3 4 5 6 7 8 9 10  func ExampleGetOpt() { gcmd.Init(\u0026#34;gf\u0026#34;, \u0026#34;build\u0026#34;, \u0026#34;main.go\u0026#34;, \u0026#34;-o=gf.exe\u0026#34;, \u0026#34;-y\u0026#34;) fmt.Printf( `Opt[\u0026#34;o\u0026#34;]: \u0026#34;%v\u0026#34;, Opt[\u0026#34;y\u0026#34;]: \u0026#34;%v\u0026#34;, Opt[\u0026#34;d\u0026#34;]: \u0026#34;%v\u0026#34;`, gcmd.GetOpt(\u0026#34;o\u0026#34;), gcmd.GetOpt(\u0026#34;y\u0026#34;), gcmd.GetOpt(\u0026#34;d\u0026#34;, \u0026#34;default value\u0026#34;), ) // Output: \t// Opt[\u0026#34;o\u0026#34;]: \u0026#34;gf.exe\u0026#34;, Opt[\u0026#34;y\u0026#34;]: \u0026#34;\u0026#34;, Opt[\u0026#34;d\u0026#34;]: \u0026#34;default value\u0026#34; }    GetOptAll 方法用于获取所有的选项。  1 2 3 4 5 6 7  func ExampleGetOptAll() { gcmd.Init(\u0026#34;gf\u0026#34;, \u0026#34;build\u0026#34;, \u0026#34;main.go\u0026#34;, \u0026#34;-o=gf.exe\u0026#34;, \u0026#34;-y\u0026#34;) fmt.Printf(`%#v`, gcmd.GetOptAll()) // May Output: \t// map[string]string{\u0026#34;o\u0026#34;:\u0026#34;gf.exe\u0026#34;, \u0026#34;y\u0026#34;:\u0026#34;\u0026#34;} }   获取 命令后追加的选项参数，如 go build ecf -server worker\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  //goframe框架中 opt := gconv.Map(parser.GetOptAll()) server := opt[\u0026#34;server\u0026#34;] if server == \u0026#34;worker\u0026#34; { service.Machinery().Worker(ctx) return nil } else { s := g.Server() //------不需要鉴权------ \ts.Group(\u0026#34;/api\u0026#34;, func(group *ghttp.RouterGroup) { ... }) //------需要鉴权------ \ts.Group(\u0026#34;/api\u0026#34;, func(group *ghttp.RouterGroup) { ... }) s.Run() return nil }   数据库结果处理 查询结果列表中添加字段 1 2 3 4 5 6 7 8 9 10 11  res, _ := model.All() gdbRes, ok := res.(gdb.Result) resList := gdbRes.List() if ok { for i, _ := range resList { //通过BU获取说明 \tsetid_desc := service.Common().GetBUDescByBU(resList[i][\u0026#34;setid\u0026#34;]) resList[i][\u0026#34;setid_desc\u0026#34;] = setid_desc ... } }   为空判断  数据集合  1 2 3 4 5 6 7 8  r, err := g.Model(\u0026#34;order\u0026#34;).Where(\u0026#34;status\u0026#34;, 1).All() if err != nil { return err } if len(r) == 0 { // 结果为空 }   也可以使用 IsEmpty 方法：\n1 2 3 4 5 6 7  r, err := g.Model(\u0026#34;order\u0026#34;).Where(\u0026#34;status\u0026#34;, 1).All() if err != nil { return err } if r.IsEmpty() { // 结果为空 }    数据记录  1 2 3 4 5 6 7  r, err := g.Model(\u0026#34;order\u0026#34;).Where(\u0026#34;status\u0026#34;, 1).One() if err != nil { return err } if len(r) == 0 { // 结果为空 }   也可以使用 IsEmpty 方法：\n1 2 3 4 5 6 7  r, err := g.Model(\u0026#34;order\u0026#34;).Where(\u0026#34;status\u0026#34;, 1).One() if err != nil { return err } if r.IsEmpty() { // 结果为空 }    数据字段值\n返回的是一个\u0026quot;泛型\u0026quot;变量，这个只能使用 IsEmpty 来判断是否为空了。  1 2 3 4 5 6 7  r, err := g.Model(\u0026#34;order\u0026#34;).Where(\u0026#34;status\u0026#34;, 1).Value() if err != nil { return err } if r.IsEmpty() { // 结果为空 }    字段值数组\n查询返回字段值数组本身类型为[]gdb.Value 类型，因此直接判断长度是否为 0 即可。  1 2 3 4 5 6 7 8  // Array/FindArray r, err := g.Model(\u0026#34;order\u0026#34;).Fields(\u0026#34;id\u0026#34;).Where(\u0026#34;status\u0026#34;, 1).Array() if err != nil { return err } if len(r) == 0 { // 结果为空 }   ORM 时区处理 设置loc=Local\n配置文件：\n1 2  database: link: \u0026#34;mysql:root:12345678@tcp(127.0.0.1:3306)/test?loc=Local\u0026#34;   示例代码：\n1 2 3 4  t1, _ := time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2020-10-27 10:00:00\u0026#34;) t2, _ := time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2020-10-27 11:00:00\u0026#34;) db.Model(\u0026#34;user\u0026#34;).Ctx(ctx).Where(\u0026#34;create_time\u0026gt;? and create_time\u0026lt;?\u0026#34;, t1, t2).One() // SELECT * FROM `user` WHERE create_time\u0026gt;\u0026#39;2020-10-27 18:00:00\u0026#39; AND create_time\u0026lt;\u0026#39;2020-10-27 19:00:00\u0026#39;   这里由于通过 time.Parse 创建的 time.Time 时间对象是 UTC 时区，那么提交到数据库执行时将会被底层的 driver 修改为+8 时区。\n1 2 3 4  t1, _ := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2020-10-27 10:00:00\u0026#34;, time.Local) t2, _ := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2020-10-27 11:00:00\u0026#34;, time.Local) db.Model(\u0026#34;user\u0026#34;).Ctx(ctx).Where(\u0026#34;create_time\u0026gt;? and create_time\u0026lt;?\u0026#34;, t1, t2).One() // SELECT * FROM `user` WHERE create_time\u0026gt;\u0026#39;2020-10-27 10:00:00\u0026#39; AND create_time\u0026lt;\u0026#39;2020-10-27 11:00:00\u0026#39;   这里由于通过 time.ParseInLocation 创建的 time.Time 时间对象是+8 时区，和 loc=Local 的时区一致，那么提交到数据库执行时不会被底层的 driver 修改。\ngen dao gf gen dao用于生成 model 数据结构定义文件\ngen model未来不再推荐这种方式，而是推荐使用 dao 的使用方式\ngoframe 中的 自动生成的 model 在dao文件夹下的internal文件夹下。\n不可以修改，Code generated by GoFrame CLI tool. DO NOT EDIT.\n所以自定义的 model 层在internal同级目录的.go 文件中编写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  package dao import ( \u0026#34;ecf/internal/dao/internal\u0026#34; \u0026#34;fmt\u0026#34; ) // internalUploadFileDao is internal type for wrapping internal DAO implements. type internalUploadFileDao = *internal.UploadFileDao // uploadFileDao is the data access object for table ecf_upload_file. // You can define custom methods on it to extend its functionality as you wish. type uploadFileDao struct { internalUploadFileDao } var ( // UploadFile is globally public accessible object for table ecf_upload_file operations. \t// UploadFile是全局公式的访问数据表对象 \tUploadFile = uploadFileDao{ internal.NewUploadFileDao(), } ) // Fill with you ideas below.  //todo //type SettingGetInput struct { //\tKey string //} func A() bool { ab := \u0026amp;internal.UploadFileDao{} UploadId := ab.Columns().UploadId fmt.Println(UploadId) // UploadFile是全局公式的访问数据表对象 \t// 获取指定字段 \tc := UploadFile.Columns().UploadId fmt.Println(c) return false }   ","description":"go语言起源、安装运行环境、编辑器、集成等","id":85,"section":"stack","tags":["golang",""],"title":"goframe框架-2","uri":"http://wangjinbao.netlify.app/en/stack/golang/goframe2/"},{"content":"手动编译安装 这是万能的安装方式：\n1  git clone https://github.com/gogf/gf \u0026amp;\u0026amp; cd gf/cmd/gf \u0026amp;\u0026amp; go install   验证安装成功 1 2 3 4 5  $ gf -v GoFrame CLI Tool v2.2.1, https://goframe.org GoFrame Version: cannot find goframe requirement in go.mod CLI Installed At: /usr/local/go/bin/gf Current is a custom installed version, no installation information.   创建项目模板 1  gf init demo -u   运行项目模板 项目模板可以执行以下命令运行：\n1  cd demo \u0026amp;\u0026amp; gf run main.go   会生成demo目录，里面就是个完整的项目\n把新项目独立出来 结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  ├── Makefile ├── README.MD ├── api │ └── v1 │ ├── hello.go │ └── user.go ├── go.mod ├── go.sum ├── hack │ └── config.yaml ├── internal │ ├── cmd │ │ └── cmd.go │ ├── consts │ │ └── consts.go │ ├── controller │ │ ├── hello.go │ │ └── user.go │ ├── dao │ │ ├── document.go │ │ └── internal │ │ └── document.go │ ├── logic │ │ └── middleware │ ├── model │ │ ├── do │ │ │ └── document.go │ │ └── entity │ │ └── document.go │ ├── packed │ │ └── packed.go │ └── service ├── main ├── main.go ├── manifest │ ├── config │ │ └── config.yaml │ ├── deploy │ │ └── kustomize │ │ ├── base │ │ │ ├── deployment.yaml │ │ │ ├── kustomization.yaml │ │ │ └── service.yaml │ │ └── overlays │ │ └── develop │ │ ├── configmap.yaml │ │ ├── deployment.yaml │ │ └── kustomization.yaml │ └── k8s │ ├── Dockerfile │ └── k8s.sh ├── resource │ ├── i18n │ ├── public │ │ ├── html │ │ ├── plugin │ │ └── resource │ │ ├── css │ │ ├── image │ │ └── js │ └── template └── utility   注册路由  查看internal/cmd/cmd.go，添加对象  1 2 3 4 5 6 7 8 9 10 11  ... s := g.Server() s.Group(\u0026#34;/api\u0026#34;, func(group *ghttp.RouterGroup) { group.Middleware(ghttp.MiddlewareHandlerResponse) group.Bind( controller.Hello, controller.User, ) }) s.Run() ...    添加控制器internal/controller/user.go  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package controller import ( \u0026#34;context\u0026#34; \u0026#34;github.com/gogf/gf/v2/frame/g\u0026#34; \u0026#34;ecf/api/v1\u0026#34; ) var ( User = cUser{} ) type cUser struct{} func (c *cUser) AuthLogin(ctx context.Context, req *v1.UserReq) (res *v1.UserRes, err error) { g.RequestFromCtx(ctx).Response.Writeln(\u0026#34;jarvenwang--AuthLogin\u0026#34;) return }    添加api/v1/user.go,添加 请求：UserReq，响应：UserRes  1 2 3 4 5 6 7 8 9  type UserReq struct { //path：路由地址  //method：post  //summary:概括  g.Meta `path:\u0026#34;/auth-login\u0026#34; tags:\u0026#34;AuthLogin\u0026#34; method:\u0026#34;post\u0026#34; summary:\u0026#34;登录\u0026#34;` } type UserRes struct { g.Meta `mime:\u0026#34;text/html\u0026#34; example:\u0026#34;string\u0026#34;` }   连接数据库  修改工具配置文件 ：hack/config.yaml  1 2 3 4 5 6 7 8 9 10 11  # CLI tool, only in development environment. # https://goframe.org/pages/viewpage.action?pageId=3673173 gfcli: gen: dao: - link: \u0026#34;mysql:root:654321@tcp(127.0.0.1:3306)/TME_ECF_DEV\u0026#34; tables: \u0026#34;ecf_document\u0026#34; removePrefix: \u0026#34;ecf_\u0026#34; jsonCase: \u0026#34;Snake\u0026#34; //指定model中生成的数据实体对象中json标签名称规则，参数不区分大小写  descriptionTag: true noModelComment: true   jsonCase 默认值 CamelLower\n   名称 必须 默认值 说明 示例     jsonCase  CamelLower 指定model中生成的数据实体对象中json标签名称规则，参数不区分大小写。参数可选为：Camel、CamelLower、Snake、SnakeScreaming、SnakeFirstUpper、Kebab、KebabScreaming。具体介绍请参考命名行帮助示例。 Snake：any_kind_of_string   removePrefix   删除数据表的指定前缀名称。多个前缀以,号分隔。 gf_   descriptionTag  false 用于指定是否为数据模型结构体属性增加desription的标签，内容为对应的数据表字段注释。 true   noModelComment  false 用于指定是否关闭数据模型结构体属性的注释自动生成，内容为数据表对应字段的注释。 true     执行命令 gf gen dao 生成数据对象  1 2 3 4 5  $gf gen dao generated: internal/dao/internal/document.go ... done!   数据库业务配置：\nmanifest/config/config.yaml\n1 2 3 4  database: default: link: \u0026#34;mysql:root:654321@tcp(127.0.0.1:3306)/TME_ECF_DEV\u0026#34; debug: true   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //控制器中添加 dao.Document.Ctx(ctx).Data(do.Document{ Setid: \u0026#34;TME01\u0026#34;, Deptid: \u0026#34;10000690\u0026#34;, Grade: 1, EcfName: \u0026#34;档案名称\u0026#34;, EcfCode: \u0026#34;ECFakfjdklfjdk\u0026#34;, Key1: \u0026#34;Key1\u0026#34;, Key2: \u0026#34;Key2\u0026#34;, Key3: \u0026#34;Key3\u0026#34;, FileCode: \u0026#34;FILEadflksajdlkf\u0026#34;, Class: \u0026#34;入职\u0026#34;, Style: \u0026#34;入职简历\u0026#34;, CreatedAt: time.Now().Unix(), }).Insert()   以上代码可能会报错，因为数据库驱动没有下载：\n安装mysql 驱动：\n1  go get -u github.com/gogf/gf/contrib/drivers/mysql/v2   区分环境配置文件 配置管理-文件配置 默认配置文件\n配置对象我们推荐使用单例方式获取，单例对象将会按照文件后缀toml/yaml/yml/json/ini/xml/properties文自动检索配置文件。默认情况下会自动检索配置文件config.toml/yaml/yml/json/ini/xml/properties并缓存，配置文件在外部被修改时将会自动刷新缓存。\n如果想要自定义文件格式，可以通过SetFileName方法修改默认读取的配置文件名称（如：default.yaml, default.json, default.xml等等）。例如，我们可以通过以下方式读取default.yaml配置文件中的数据库database配置项。\n1 2 3 4 5  // 设置默认配置文件，默认读取的配置文件设置为 default.yaml g.Cfg().GetAdapter().(*gcfg.AdapterFile).SetFileName(\u0026#34;default.yaml\u0026#34;) // 后续读取时将会读取到 default.yaml 配置文件内容 g.Cfg().Get(ctx, \u0026#34;database\u0026#34;)   文件可以是一个具体的文件名称或者完整的文件绝对路径。\n我们可以通过多种方式修改默认文件名称：\n 通过配置管理方法SetFileName修改。 修改命令行启动参数 - gf.gcfg.file。 修改指定的环境变量 - GF_GCFG_FILE。  假如我们的执行程序文件为main，那么可以通过以下方式修改配置管理器的配置文件目录(Linux下)：\n1 通过单例模式\n1  g.Cfg().GetAdapter().(*gcfg.AdapterFile).SetFileName(\u0026#34;default.yaml\u0026#34;)   2 通过命令行启动参数\n1  ./main --gf.gcfg.file=config.prod.toml   3 通过环境变量（常用在容器中）\n启动时修改环境变量：\n1  GF_GCFG_FILE=config.prod.toml; ./main   使用genv模块来修改环境变量：\n1  genv.Set(\u0026#34;GF_GCFG_FILE\u0026#34;, \u0026#34;config.prod.toml\u0026#34;)   实际操作：\n 步骤一：\n在manifest/config/目录下新增三个配置文件 ：\ndev.yaml\nuat.yaml\nprod.yaml  1 2 3 4 5 6 7 8 9 10 11 12 13 14  dev.yaml文件内容： server: address: \u0026#34;:8002\u0026#34; openapiPath: \u0026#34;/api.json\u0026#34; swaggerPath: \u0026#34;/swagger\u0026#34; logger: level : \u0026#34;all\u0026#34; stdout: true database: default: link: \u0026#34;mysql:root:654321@tcp(127.0.0.1:3306)/TME_ECF_DEV\u0026#34; debug: true    步骤二：\n在main.go文件修改如下：  1 2 3 4 5 6 7 8 9  func main() { genv.Set(\u0026#34;env\u0026#34;, \u0026#34;dev\u0026#34;) //环境配置文件 \tenvfile := genv.Get(\u0026#34;env\u0026#34;).String() + \u0026#34;.yaml\u0026#34; //环境配置文件 \tg.Cfg().GetAdapter().(*gcfg.AdapterFile).SetFileName(envfile) cmd.Main.Run(gctx.New()) }   配置目录： 目录配置方法\ngcfg配置管理器支持非常灵活的多目录自动搜索功能，通过SetPath可以修改目录管理目录为唯一的目录地址，同时，我们推荐通过AddPath方法添加多个搜索目录，配置管理器底层将会按照添加目录的顺序作为优先级进行自动检索。直到检索到一个匹配的文件路径为止，如果在所有搜索目录下查找不到配置文件，那么会返回失败。\n默认目录配置\ngcfg配置管理对象初始化时，默认会自动添加以下配置文件搜索目录：\n当前工作目录及其下的config、manifest/config目录：例如当前的工作目录为/home/www时，将会添加：\na. /home/www\nb. /home/www/config\nc. /home/www/manifest/config\n当前可执行文件所在目录及其下的config、manifest/config目录：例如二进制文件所在目录为/tmp时，将会添加：\na. /tmp\nb. /tmp/config\nc. /tmp/manifest/config\n当前main源代码包所在目录及其下的config、manifest/config目录(仅对源码开发环境有效)：例如main包所在目录为/home/john/workspace/gf-app时，将会添加：\na. /home/john/workspace/gf-app\nb. /home/john/workspace/gf-app/config\nc. /home/john/workspace/gf-app/manifest/config\n默认目录修改\n注意这里修改的参数必须是一个目录，不能是文件路径。\n我们可以通过以下方式修改配置管理器的配置文件搜索目录，配置管理对象将会只在该指定目录执行配置文件检索：\n 通过配置管理器的SetPath方法手动修改； 修改命令行启动参数 - gf.gcfg.path； 修改指定的环境变量 - GF_GCFG_PATH；  假如我们的执行程序文件为main，那么可以通过以下方式修改配置管理器的配置文件目录(Linux下)：\n通过单例模式\n1  g.Cfg().GetAdapter().(*gcfg.AdapterFile).SetPath(\u0026#34;/opt/config\u0026#34;)   通过命令行启动参数\n1  ./main --gf.gcfg.path=/opt/config/   通过环境变量（常用在容器中）\n启动时修改环境变量：\n1  GF_GCFG_PATH=/opt/config/; ./main   使用genv模块来修改环境变量：\n1  genv.Set(\u0026#34;GF_GCFG_PATH\u0026#34;, \u0026#34;/opt/config\u0026#34;)   部署打包二进制执行文件 交叉编译-build 支持把配置文件打包到执行文件中\n编译配置文件：\nbuild支持同时从命令行以及配置文件指定编译参数、选项。GoFrame框架的所有组件及所有生态项目都是使用的同一个配置管理组件，默认的配置文件以及配置使用请参考章节 配置管理。以下是一个简单的配置示例供参考（以config.yaml为例）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  gfcli: build: name: \u0026#34;gf\u0026#34; #当前系统架构，例如：386,amd64,arm arch: \u0026#34;all\u0026#34; system: \u0026#34;all\u0026#34; mod: \u0026#34;none\u0026#34; #可以不用，一般项目部署附带目录一起上传即可，不用打包到执行文件中，不方便修改配置参数 packSrc: \u0026#34;resource,manifest\u0026#34; version: \u0026#34;v1.0.0\u0026#34; output: \u0026#34;./bin\u0026#34; extra: \u0026#34;\u0026#34; #我本地的如下： build: name: \u0026#34;ecf\u0026#34; arch: \u0026#34;amd64\u0026#34; system: \u0026#34;linux\u0026#34; mod: \u0026#34;none\u0026#34; # packSrc: \u0026#34;resource,manifest\u0026#34; version: \u0026#34;v1.0.0\u0026#34; # output: \u0026#34;./bin\u0026#34; # extra: \u0026#34;\u0026#34;   日志配置 日志组件支持配置文件，当使用g.Log(单例名称)获取Logger单例对象时，将会自动通过默认的配置管理对象获取对应的Logger配置。默认情况下会读取logger.单例名称配置项，当该配置项不存在时，将会读取默认的logger配置项。配置项请参考配置对象结构定义：https://pkg.go.dev/github.com/gogf/gf/v2/os/glog#Config\n完整配置文件配置项及说明如下，其中配置项名称不区分大小写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  logger: path: \u0026#34;/var/log/\u0026#34; # 日志文件路径。默认为空，表示关闭，仅输出到终端 file: \u0026#34;{Y-m-d}.log\u0026#34; # 日志文件格式。默认为\u0026#34;{Y-m-d}.log\u0026#34; prefix: \u0026#34;\u0026#34; # 日志内容输出前缀。默认为空 level: \u0026#34;all\u0026#34; # 日志输出级别 ctxKeys: [] # 自定义Context上下文变量名称，自动打印Context的变量到日志中。默认为空 header: true # 是否打印日志的头信息。默认true stdout: true # 日志是否同时输出到终端。默认true rotateSize: 0 # 按照日志文件大小对文件进行滚动切分。默认为0，表示关闭滚动切分特性 rotateExpire: 0 # 按照日志文件时间间隔对文件滚动切分。默认为0，表示关闭滚动切分特性 rotateBackupLimit: 0 # 按照切分的文件数量清理切分文件，当滚动切分特性开启时有效。默认为0，表示不备份，切分则删除 rotateBackupExpire: 0 # 按照切分的文件有效期清理切分文件，当滚动切分特性开启时有效。默认为0，表示不备份，切分则删除 rotateBackupCompress: 0 # 滚动切分文件的压缩比（0-9）。默认为0，表示不压缩 rotateCheckInterval: \u0026#34;1h\u0026#34; # 滚动切分的时间检测间隔，一般不需要设置。默认为1小时 stdoutColorDisabled: false # 关闭终端的颜色打印。默认开启 writerColorEnable: false # 日志文件是否带上颜色。默认false，表示不带颜色   多个Logger的配置示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  logger: path: \u0026#34;/var/log\u0026#34; level: \u0026#34;all\u0026#34; stdout: false logger1: path: \u0026#34;/var/log/logger1\u0026#34; level: \u0026#34;dev\u0026#34; stdout: false logger2: path: \u0026#34;/var/log/logger2\u0026#34; level: \u0026#34;prod\u0026#34; stdout: true #我本地如下： server: address: \u0026#34;:8002\u0026#34; # openapiPath: \u0026#34;/api.json\u0026#34; # swaggerPath: \u0026#34;/swagger\u0026#34; logger: path: \u0026#34;./log/\u0026#34; file: \u0026#34;{Y-m-d}.log\u0026#34; level : \u0026#34;all\u0026#34; header: true stdout: false info: path: \u0026#34;./log/user/info/\u0026#34; file: \u0026#34;{Y-m-d}.log\u0026#34; level: \u0026#34;INFO\u0026#34; stdout: false error: path: \u0026#34;./log/user/error/\u0026#34; file: \u0026#34;{Y-m-d}.log\u0026#34; level: \u0026#34;ERRO\u0026#34; stdout: false   写入区分的目录类别日志：\n如下\n1 2 3 4 5 6 7 8  g.Log(\u0026#34;info\u0026#34;).Info(ctx, g.Map{\u0026#34;uid\u0026#34;: 1011110, \u0026#34;name\u0026#34;: \u0026#34;111john\u0026#34;}) type User struct { Uid int `json:\u0026#34;uid\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } g.Log(\u0026#34;error\u0026#34;).Error(ctx, User{100, \u0026#34;john\u0026#34;})   组件通用Handler\n组件提供了一些常用的日志Handler，方便开发者使用，提高开发效率。\nHandlerJson\n该Handler可以将日志内容转换为Json格式打印，方法名：\nglog.SetDefaultHandler(glog.HandlerJson)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package main import ( \u0026#34;context\u0026#34; \u0026#34;github.com/gogf/gf/v2/frame/g\u0026#34; \u0026#34;github.com/gogf/gf/v2/os/glog\u0026#34; ) func main() { ctx := context.TODO() #生成以json格式的日志 glog.SetDefaultHandler(glog.HandlerJson) g.Log().Debug(ctx, \u0026#34;Debugging...\u0026#34;) glog.Warning(ctx, \u0026#34;It is warning info\u0026#34;) glog.Error(ctx, \u0026#34;Error occurs, please have a check\u0026#34;) }   没有加载context的时候可以，用ctx := context.TODO()\n1  ctx := context.TODO()   自定义中间件 修改文件地址：internal/logic/middleware/middleware.go\n添加日志中间件： （前置中间件）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func (s *sMiddleware) MiddlewareLog(r *ghttp.Request) { //设置日志格式为json \tglog.SetDefaultHandler(glog.HandlerJson) rawQuery := r.URL.RawQuery host := r.URL.Host path := r.URL.Path method := r.Method clientIp := r.GetClientIp() //记录所有请求 \tctx := context.TODO() g.Log().Info(ctx, g.Map{\u0026#34;host\u0026#34;: host, \u0026#34;path\u0026#34;: path, \u0026#34;method\u0026#34;: method, \u0026#34;rawQuery\u0026#34;: rawQuery, \u0026#34;clientIp\u0026#34;: clientIp}) //前置中间件 \tr.Middleware.Next() }   添加报错处理中间件： (后置中间件)\n1 2 3 4 5 6 7 8 9 10 11  func (s *sMiddleware) MiddlewareErrorHandler(r *ghttp.Request) { r.Middleware.Next() if r.Response.Status \u0026gt;= http.StatusInternalServerError { r.Response.ClearBuffer() r.Response.WriteJson(ghttp.DefaultHandlerResponse{ Code: r.Response.Status, //请求成功 想改成200自己来 \tMessage: \u0026#34;服务器开小差了，请稍后再试\u0026#34;, Data: \u0026#34;\u0026#34;, }) } }   升级版本，捕获报错panic日志\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func (s *sMiddleware) MiddlewareErrorHandler(r *ghttp.Request) { r.Middleware.Next() if err := r.GetError(); err != nil { // 记录到自定义错误日志文件 //g.Log(\u0026#34;exception\u0026#34;).Error(err) ctx := context.TODO() g.Log(\u0026#34;panic\u0026#34;).Critical(ctx, err) r.Response.ClearBuffer() r.Response.WriteJson(ghttp.DefaultHandlerResponse{ Code: r.Response.Status, //请求成功 想改成200自己来 Message: \u0026#34;系统繁忙，请稍后再试\u0026#34;, Data: \u0026#34;\u0026#34;, }) } }   添加返回json格式中间件： （后置中间件）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  func (s *sMiddleware) MiddlewareResponseEcf(r *ghttp.Request) { r.Middleware.Next() //后置中间件 \tif r.Response.BufferLength() \u0026gt; 0 { return } //定义接受的相应结果及错误 \tvar ( msg string err = r.GetError() res = r.GetHandlerResponse() //s=r.params \t//code = gerror.Code(err) \t) //返回相应对象 及 获取不了的错误结果 \tif err != nil { code := gerror.Code(err) // 还没理解 后续补充 \tif code == gcode.CodeNil { code = gcode.CodeInternalError } r.Response.WriteJson(v1.DefaultHandlerResponse{ Code: http.StatusInternalServerError, //服务器内部错误 想改成500自己来 \tMsg: code.Message(), Data: nil, }) return } if ecfResponse, ok := res.(*v1.EcfRes); ok { //没有问题返回结果 \tr.Response.WriteJson(v1.DefaultHandlerResponse{ Code: ecfResponse.Code, //请求成功 想改成200自己来 \tMsg: ecfResponse.Msg, Data: ecfResponse.Data, }) } else { msg = \u0026#34;成功\u0026#34; //没有问题返回结果 \tr.Response.WriteJson(v1.DefaultHandlerResponse{ Code: http.StatusOK, //请求成功 想改成200自己来 \tMsg: msg, Data: res, }) } }    注意获取接口类型中的结构体字段的值，使用断言  1 2 3 4 5 6 7 8  if ecfResponse, ok := res.(*v1.EcfRes); ok { //没有问题返回结果 r.Response.WriteJson(v1.DefaultHandlerResponse{ Code: ecfResponse.Code, //请求成功 想改成200自己来 Msg: ecfResponse.Msg, Data: ecfResponse.Data, }) }   gtoken使用 一、下载gtoken\n1  go get github.com/goflyfox/gtoken   二、下载完包后整理依赖文件\n1  go mod tidy   三、在中间件包中添加login登录方法\n1 2 3 4 5 6 7 8 9 10 11 12  func AuthLogin(r *ghttp.Request) (string, interface{}) { username := r.GetPostString(\u0026#34;username\u0026#34;) passwd := r.GetPostString(\u0026#34;passwd\u0026#34;) // TODO 进行登录校验 \tif username == \u0026#34;\u0026#34; || passwd == \u0026#34;\u0026#34; { r.Response.WriteJson(gtoken.Fail(\u0026#34;账号或密码错误.\u0026#34;)) r.ExitAll() } return username, \u0026#34;\u0026#34; }   四、启动gtoken\n1 2 3 4 5 6  loginFunc := AuthLogin gfToken := \u0026amp;gtoken.GfToken{ LoginPath: \u0026#34;/auth-login\u0026#34;, //上面的方法地址,对应的是/api/auth-login \tLoginBeforeFunc: loginFunc, //只要固定类型方法：(r *ghttp.Request) (string, interface{}) \tLogoutPath: \u0026#34;/api/logout\u0026#34;, //暂时可以不写 }   五、postman请求接口，获取token\n 请求地址：/api/auth-login 输入账号/密码： 返回值如下：  1 2 3 4 5 6 7  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;token\u0026#34;: \u0026#34;F1om0nykaRN7gBi3u+Nr5RYYQSVCfkXjDGVz9lLaT+mnIoss6/knJ1uBT19A6QBW\u0026#34; } }   六、附带上面生成的token请求需鉴权接口\n 如请求地址：/api/info 选择Bearer Token，输入：F1om0nykaRN7gBi3u+Nr5RYYQSVCfkXjDGVz9lLaT+mnIoss6/knJ1uBT19A6QBW 返回如下：  1 2 3 4 5 6 7  { \u0026#34;code\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;成功\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;jarvenwang\u0026#34; } }   接口维护-gen service 设计背景 在业务项目实践中，业务逻辑封装往往是最复杂的部分，同时，业务模块之间的依赖十分复杂、边界模糊，无法采用Golang包管理的形式。如何有效管理项目中的业务逻辑封装部分，对于每个采用Golang开发的项目都是必定会遇到的难题。\n设计目标  增加logic分类目录，将所有业务逻辑代码迁移到logic分类目录下，采用包管理形式来管理业务模块。 业务模块之间的依赖通过接口化解耦，将原有的service分类调整为接口目录。这样每个业务模块将会各自维护、更加灵活 可以按照一定的项目规范，从logic业务逻辑代码生成service接口定义代码。同时，也允许人工维护这部分service接口。  命令使用(自动模式) 如果您是使用的GolandIDE，那么可以使用我们提供的配置文件：watchers.xml 自动监听代码文件修改时自动生成接口文件。使用方式，如下图：\nPreferences-\u0026gt;Tools-\u0026gt;File Watchers-\u0026gt;添加\u0026rsquo;Import\u0026rsquo;点击导入配置\n提供的配置文件：watchers.xml\n下载地址：https://goframe.org/download/attachments/49770772/watchers.xml?version=1\u0026amp;modificationDate=1655298456643\u0026amp;api=v2\n","description":"go语言起源、安装运行环境、编辑器、集成等","id":86,"section":"stack","tags":["golang",""],"title":"goframe框架-1","uri":"http://wangjinbao.netlify.app/en/stack/golang/goframe1/"},{"content":"一、工程目录结构 GoFrame业务项目基本目录结构如下（以Single Repo为例）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  / ├── api ├── hack ├── internal │ ├── cmd │ ├── consts │ ├── controller │ ├── dao │ ├── logic │ ├── model │ | ├── do │ │ └── entity │ └── service ├── manifest ├── resource ├── utility ├── go.mod └── main.go      目录/文件名称 说明 描述     api 对外接口 对外提供服务的输入/输出数据结构定义。考虑到版本管理需要，往往以api/v1\u0026hellip;存在。   hack 工具脚本 存放项目开发工具、脚本等内容。例如，CLI工具的配置，各种shell/bat脚本等文件。   internal 内部逻辑 业务逻辑存放目录。通过Golang internal特性对外部隐藏可见性。   - cmd 入口指令 命令行管理目录。可以管理维护多个命令行。   - consts 常量定义 项目所有常量定义。   - controller 接口处理 接收/解析用户输入参数的入口/接口层。   - dao 数据访问 数据访问对象，这是一层抽象对象，用于和底层数据库交互，仅包含最基础的 CURD 方法   - logic 业务封装 业务逻辑封装管理，特定的业务逻辑实现和封装。往往是项目中最复杂的部分。   - model 结构模型 数据结构管理模块，管理数据实体对象，以及输入与输出数据结构定义。   - - do 领域对象 用于dao数据操作中业务模型与实例模型转换，由工具维护，用户不能修改。   - - entity 数据模型 数据模型是模型与数据集合的一对一关系，由工具维护，用户不能修改。   - service 业务接口 用于业务模块解耦的接口定义层。具体的接口实现在logic中进行注入。   manifest 交付清单 包含程序编译、部署、运行、配置的文件。常见内容如下：   - config 配置管理 配置文件存放目录。   - docker 镜像文件 Docker镜像相关依赖文件，脚本文件等等。   - deploy 部署文件 部署相关的文件。默认提供了Kubernetes集群化部署的Yaml模板，通过kustomize管理。   resource 静态资源 静态资源文件。这些文件往往可以通过 资源打包/镜像编译 的形式注入到发布文件中。   go.mod 依赖管理 使用Go Module包管理的依赖描述文件。   main.go 入口文件 程序入口文件。      对外接口\n对外接口包含两部分：接口定义（api）+接口实现（controller）。\n服务接口的职责类似于三层架构设计中的UI表示层，负责接收并响应客户端的输入与输出，包括对输入参数的过滤、转换、校验，对输出数据结构的维护，并调用 service 实现业务逻辑处理。\n  接口定义 - api\napi包用于与客户端约定的数据结构输入输出定义，往往与具体的业务场景强绑定。\n  接口实现 - controller\ncontroller用于接收api的输入，调用内部的一个或多个service包实现业务场景，组织service的结果构造为api的输出数据结构。\n  业务实现\n业务实现包含两部分：业务接口（service）+业务封装（logic）。\n  业务实现的职责类似于三层架构设计中的BLL业务逻辑层，负责具体业务逻辑的实现以及封装。\n  业务接口 - service\nservice包用于解耦业务模块之间的调用。业务模块之间往往不会直接调用对应的业务模块资源来实现业务逻辑，而是通过调用service接口。service层只有接口定义，具体的接口实现注入在各个业务模块中。\n  业务封装 - logic\nlogic包负责具体业务逻辑的实现以及封装。项目中各个层级代码不会直接调用logic层的业务模块，而是通过service接口层来调用。\n  结构模型\nmodel包的职责类似于三层架构中的Model模型定义层。模型定义代码层中仅包含全局公开的数据结构定义，往往不包含方法定义。\n  这里需要注意的是，这里的model不仅负责维护数据实体对象（entity）结构定义，也包括所有的输入/输出数据结构定义，被api/dao/service共同引用。这样做的好处除了可以统一管理公开的数据结构定义，也可以充分对同一业务领域的数据结构进行复用，减少代码冗余。\n  数据模型 - entity\n与数据集合绑定的程序数据结构定义，通常和数据表一一对应。\n  业务模型 - model\n与业务相关的通用数据结构定义，其中包含大部分的方法输入输出定义。\n  数据访问 - dao\ndao包的职责类似于三层架构中的DAL数据访问层，数据访问层负责所有的数据访问收口。\n  二、请求分层流转  cmd\ncmd层负责引导程序启动，显著的工作是初始化逻辑、注册路由对象、启动server监听、阻塞运行程序直至server退出。 api\n上层server服务接收客户端请求，转换为api中定义的Req接收对象、执行请求参数到Req对象属性的类型转换、执行Req对象中绑定的基础校验并转交Req请求对象给controller层。 controller\ncontroller层负责接收Req请求对象后做一些业务逻辑校验，随后调用一个或多个service实现业务逻辑，将执行结构封装为约定的Res数据结构对象返回。 model\nmodel层中管理了所有的业务模型，service资源的Input/Output输入输出数据结构都由model层来维护。 service\nservice是接口层，用于解耦业务模块，service没有具体的业务逻辑实现，具体的业务实现是依靠logic层注入的。 logic\nlogic层的业务逻辑需要通过调用dao来实现数据的操作，调用dao时需要传递do数据结构对象，用于传递查询条件、输入数据。dao执行完毕后通过Entity数据模型将数据结果返回给service层。 dao\ndao层通过框架的ORM抽象层组件与底层真实的数据库交互。\n  ","description":"go语言起源、安装运行环境、编辑器、集成等","id":87,"section":"stack","tags":["golang",""],"title":"goframe目录","uri":"http://wangjinbao.netlify.app/en/stack/golang/gofamedir/"},{"content":"一、基本结构与基本数据类型 1、文件名、关键字与标识符 1.1 文件名  文件名 均由小写字母组成，如 scanner.go。 如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，如 scanner_test.go 文件名不包含 空格 或 其他特殊字符。  _ 本身就是一个特殊的标识符，被称为空白标识符。它可以像其他标识符那样用于变量的声明或赋值（任何类型都可以赋值给它），但任何赋给这个标识符的值都将被抛弃，因此这些值不能在后续的代码中使用，也不可以使用这个这个标识符作为变量对其它变量的进行赋值或运算。\n1.2 关键字 Go 代码中会使用到的 25 个关键字或保留字：\n           break default func interface   case defer go map   chan else goto package   const fallthrough if range   continue for import return    1.3 标识符 Go 语言还有 36 个预定义标识符:\n             append bool byte cap close complex   copy false float32 float64 imag int   int32 int64 iota len make new   print println real recover string true    程序一般由关键字、常量、变量、运算符、类型和函数组成。\n程序中可能会使用到这些分隔符：括号 ()，中括号 [] 和大括号 {}。\n程序中可能会使用到这些标点符号：.、,、;、: 和 …。\n程序的代码通过语句来实现结构化。每个语句不需要像 C 家族中的其它语言一样以分号 ;\n结尾，因为这些工作都将由 Go 编译器自动完成。\n如果你打算将多个语句写在同一行，它们则必须使用 ; 人为区分，但在实际开发中我们并不鼓励这种做法。\n2、Go 程序的基本结构和要素 2.1 包的概念、导入与可见性 包是结构化代码的一种方式：每个程序都由包（通常简称为 pkg）的概念组成，可以使用自身的包或者从其它包中导入内容。\n一个应用程序可以包含不同的包，而且即使你只使用 main 包也不必把所有的代码都写在一个巨大的文件里：你可以用一些较小的文件，并且在每个文件非注释的第一行都使用 package main 来指明这些文件都属于 main 包。\n标准库:\n在 Go 的安装文件里包含了一些可以直接使用的包，即标准库。\n一般情况下，标准包会存放在 $GOROOT/pkg/$GOOS_$GOARCH/ 目录下。\n如果对一个包进行更改或重新编译，所有引用了这个包的客户端程序都必须全部重新编译。\nGo 中的包模型采用了显式依赖关系的机制来达到快速编译的目的，编译器会从后缀名为 .o 的对象文件（需要且只需要这个文件）中提取传递依赖类型的信息。\n如果 A.go 依赖 B.go，而 B.go 又依赖 C.go：\n编译 C.go, B.go, 然后是 A.go.\n为了编译 A.go, 编译器读取的是 B.o 而不是 C.o.\n这种机制对于编译大型的项目时可以显著地提升编译速度。\n每一段代码只会被编译一次\n如果需要多个包，它们可以被分别导入：\n更短且更优雅的方法（被称为因式分解关键字，该方法同样适用于 const、var 和 type 的声明或定义）：\n1 2 3 4  import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; )    如果包名不是以 . 或 / 开头，如 \u0026ldquo;fmt\u0026rdquo; 或者 \u0026ldquo;container/list\u0026rdquo;，则 Go 会在 全局文件 进行查找； 如果包名以 ./ 开头，则 Go 会在 相对目录 中查找； 如果包名以 / 开头（在 Windows 下也可以这样使用），则会在系统的绝对路径中查找。  可见性规则:\n 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）； 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 private ）。  包的分级声明和初始化:\n可以在使用 import 导入包之后定义或声明 0 个或多个常量（const）、变量（var）和类型（type），这些对象的 作用域 都是全局的（在本包范围内），所以可以被本包中所有的函数调用 ,然后声明一个或多个函数（func）\n2.2 函数 这是定义一个函数最简单的格式：\nfunc functionName()\n函数里的代码（函数体）使用大括号 {} 括起来。\n左大括号 { 必须与方法的声明放在同一行，这是编译器的强制规定，否则你在使用 gofmt 时就会出现错误提示：\nbuild-error: syntax error: unexpected semicolon or newline before {\nGo 语言虽然看起来不使用分号作为语句的结束，但实际上这一过程是由编译器自动完成，因此才会引发像上面这样的错误\n2.3 注释 package main\nimport \u0026ldquo;fmt\u0026rdquo; // Package implementing formatted I/O.\nfunc main() {\nfmt.Printf(\u0026ldquo;Καλημέρα κόσμε; or こんにちは 世界\\n\u0026rdquo;)\n}\n\n上面这个例子通过打印 Καλημέρα κόσμε; or こんにちは 世界 展示了如何在 Go 中使用国际化字符，以及如何使用注释。\n 单行注释是最常见的注释形式，你可以在任何地方使用以  //  开头的单行注释。 多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段。  2.4 类型 可以包含数据的变量（或常量）可以使用不同的数据类型或类型来保存数据。使用 var 声明的变量的值会自动初始化为该类型的零值。类型定义了某个变量的值的集合与可对其进行操作的集合。\n   基本类型     int   float   bool   string       复合类型     struct   array   slice   map   channel       描述类型     interface    Go 语言中不存在类型继承\n2.5 Go 程序的一般结构 Go 程序的执行（程序启动）顺序如下：\n 按顺序导入所有被 main 包引用的其它包，然后在每个包中执行如下流程： 如果该包又导入了其它的包，则从第一步开始递归执行，但是每个包只会被导入一次。 然后以相反的顺序在每个包中初始化常量和变量，如果该包含有 init 函数的话，则调用该函数。 在完成这一切之后，main 也执行同样的过程，最后调用 main 函数开始执行程序。  2.6 类型转换 在必要以及可行的情况下，一个类型的值可以被转换成另一种类型的值。由于 Go 语言不存在隐式类型转换，因此所有的转换都必须显式说明，就像调用一个函数一样（类型在这里的作用可以看作是一种函数）：\nvalueOfTypeB = typeB(valueOfTypeA)\n类型 B 的值 = 类型 B(类型 A 的值)\n1 2  a := 5.0 b := int(a)   但这只能在定义正确的情况下转换成功，例如从一个取值范围较小的类型转换到一个取值范围较大的类型（例如将 int16 转换为 int32）。当从一个取值范围较大的转换到取值范围较小的类型时（例如将 int32 转换为 int16 或将 float32 转换为 int），会发生精度丢失（截断）的情况。当编译器捕捉到非法的类型转换时会引发编译时错误，否则将引发运行时错误。\n具有相同底层类型的变量之间可以相互转换：\n1 2 3  var a IZ = 5 c := int(a) d := IZ(c)   3、常量 常量使用关键字 const 定义，用于存储 不会改变 的数据。\n如：\n1 2 3 4 5  const Pi = 3.14159 显式类型定义： const b string = \u0026#34;abc\u0026#34; 隐式类型定义： const b = \u0026#34;abc\u0026#34;   常量的值必须是能够在编译时就能够确定的；你可以在其赋值表达式中涉及计算过程，但是所有用于计算的值必须在编译期间就能获得。\n1 2 3  正确的做法：const c1 = 2/3 错误的做法：const c2 = getNumber() // 引发构建错误: getNumber() used as value   因为在编译期间自定义函数均属于未知，因此无法用于常量的赋值，但内置函数可以使用，如：len()。\n在这个例子中，iota 可以被用作枚举值：\n1 2 3 4 5  const ( a = iota b = iota c = iota )   第一个 iota 等于 0，每当 iota 在新的一行被使用时，它的值都会自动加 1；所以 a=0, b=1, c=2 可以简写为如下形式：\n1 2 3 4 5  const ( a = iota b c )   简单地讲，每遇到一次 const 关键字，iota 就重置为 0\n4、变量 这种语法能够按照从左至右的顺序阅读，使得代码更加容易理解。\n示例：\n1 2 3  var a int var b bool var str string   你也可以改写成这种形式：\n1 2 3 4 5  var ( a int b bool str string )   5、基本类型和运算符 6、字符串 7、strings 和 strconv 包 8、时间和日期 9、指针 ","description":"go语言起源、安装运行环境、编辑器、集成等","id":88,"section":"stack","tags":["golang",""],"title":"学习go(第二部分)","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_part2/"},{"content":"一、起源与发展 起源 Go 语言起源 2007 年，并于 2009 年正式对外发布。它从 2009 年 9 月 21 日开始作为谷歌公司 20% 兼职项目，即相关员工利用 20% 的空余时间来参与 Go 语言的研发工作。该项目的三位领导者均是著名的 IT 工程师：\n Robert Griesemer（参与开发 Java HotSpot 虚拟机） Rob Pike（Go 语言项目总负责人，贝尔实验室 Unix 团队成员，参与的项目包括 Plan 9，Inferno 操作系统和 Limbo 编程语言） Ken Thompson（贝尔实验室 Unix 团队成员，C 语言、Unix 和 Plan 9 的创始人之一，与 Rob Pike 共同开发了 UTF-8 字符集规范）  时间轴：  2007 年 9 月 21 日：雏形设计 2009 年 11 月 10日：首次公开发布 2010 年 1 月 8 日：当选 2009 年年度语言 2010 年 5 月：谷歌投入使用 2011 年 5 月 5 日：Google App Engine 支持 Go 语言  为什么要创造一门编程语言  C/C++ 的发展速度无法跟上计算机发展的脚步，十多年来也没有出现一门与时代相符的主流系统编程语言，因此人们需要一门新的系统编程语言来弥补这个空缺，尤其是在计算机信息时代。 对比计算机性能的提升，软件开发领域不被认为发展地足够快或者比硬件发展更加成功（有许多项目均以失败告终），同时应用程序的体积始终在不断地扩大，这就迫切地需要一门具备更高层次概念的低级语言来突破现状。 在 Go 语言出现之前，开发者们总是面临非常艰难的抉择，究竟是使用执行速度快但是编译速度并不理想的语言（如：C++），还是使用编译速度较快但执行效率不佳的语言（如：.NET、Java），或者说开发难度较低但执行速度一般的动态语言呢？显然，Go 语言在这 3 个条件之间做到了最佳的平衡：快速编译，高效执行，易于开发。  Go 语言的发展目标 Go 语言的主要目标 ：\n将 静态语言的 安全性 和 高效性  与 动态语言的 易开发性 进行有机结合，达到完美平衡，从而使编程变得更加有乐趣，而不是在艰难抉择中痛苦前行。\n因此，Go 语言是一门类型安全和内存安全的编程语言。虽然 Go 语言中仍有指针的存在，但并不允许进行指针运算。\nGo 语言的另一个目标是对于网络通信、并发和并行编程的极佳支持，从而更好地利用大量的分布式和多核的计算机，这一点对于谷歌内部的使用来说就非常重要了。设计者通过 goroutine 这种轻量级线程的概念来实现这个目标，然后通过 channel 来实现各个 goroutine 之间的通信。他们实现了分段栈增长和 goroutine 在线程基础上多路复用技术的自动化。\n这个特性显然是 Go 语言最强有力的部分，不仅支持了日益重要的多核与多处理器计算机，也弥补了现存编程语言在这方面所存在的不足。\nGo 语言中另一个非常重要的特性就是它的构建速度（编译和链接到机器代码的速度），一般情况下构建一个程序的时间只需要数百毫秒到几秒。作为大量使用 C++ 来构建基础设施的谷歌来说，无疑从根本上摆脱了 C++ 在构建速度上非常不理想的噩梦。这不仅极大地提升了开发者的生产力，同时也使得软件开发过程中的代码测试环节更加紧凑，而不必浪费大量的时间在等待程序的构建上。\n依赖管理  是现今软件开发的一个重要组成部分，但是 C 语言中“头文件”的概念却导致越来越多因为依赖关系而使得构建一个大型的项目需要长达几个小时的时间。人们越来越需要一门具有严格的、简洁的依赖关系分析系统从而能够快速编译的编程语言。这正是 Go 语言采用包模型的根本原因，这个模型通过严格的依赖关系检查机制来加快程序构建的速度，提供了非常好的可量测性。\n整个 Go 语言标准库的编译时间一般都在 20 秒以内，其它的常规项目也只需要半秒钟的时间来完成编译工作。这种闪电般的编译速度甚至比编译 C 语言或者 Fortran 更加快，使得编译这一环节不再成为在软件开发中困扰开发人员的问题。在这之前，动态语言将快速编译作为自身的一大亮点，像 C++ 那样的静态语言一般都有非常漫长的编译和链接工作。而同样作为静态语言的 Go 语言，通过自身优良的构建机制，成功地了去除了这个弊端，使得程序的构建过程变得微不足道，拥有了像脚本语言和动态语言那样的高效开发的能力。\n另外，Go 语言在执行速度方面也可以与 C/C++ 相提并论。\n由于内存问题（通常称为内存泄漏）长期以来一直伴随着 C++ 的开发者们，Go 语言的设计者们认为内存管理不应该是开发人员所需要考虑的问题。因此尽管 Go 语言像其它静态语言一样执行本地代码，但它依旧运行在某种意义上的虚拟机，以此来实现高效快速的垃圾回收（使用了一个简单的标记-清除算法）。\n尽管垃圾回收并不容易实现，但考虑这将是未来并发应用程序发展的一个重要组成部分，Go 语言的设计者们还是完成了这项艰难的任务。\nGo 语言还能够在运行时进行反射相关的操作。\n使用 go install 能够很轻松地对第三方包进行部署。\n此外，Go 语言还支持调用由 C 语言编写的海量库文件（第 3.9 节），从而能够将过去开发的软件进行快速迁移。\n关于特性缺失 许多能够在大多数面向对象语言中使用的特性 Go 语言都没有支持，但其中的一部分可能会在未来被支持。\n 为了简化设计，不支持函数重载和操作符重载 为了避免在 C/C++ 开发中的一些 Bug 和混乱，不支持隐式转换 Go 语言通过另一种途径实现面向对象设计来放弃类和类型的继承 尽管在接口的使用方面可以实现类似变体类型的功能，但本身不支持变体类型 不支持动态加载代码 不支持动态链接库 不支持泛型 通过 recover 和 panic 来替代异常机制 不支持断言 不支持静态变量  必杀技  简化问题，易于学习 内存管理，简洁语法，易于使用 快速编译，高效开发 高效执行 并发支持，轻松驾驭 静态类型 标准类库，规范统一 易于部署 文档全面 免费开源  二、安装与运行环境 Go 语言开发团队开发了适用于以下操作系统的编译器：\n Linux FreeBSD Mac OS X（也称为 Darwin）  目前有2个版本的编译器：Go 原生编译器 gc 和 非原生编译器 gccgo，这两款编译器都是在类 Unix 系统下工作 。其中，gc 版本的编译器已经被移植到 Windows 平台上，并集成在主要发行版中，你也可以通过安装 MinGW 从而在 Windows 平台下使用 gcc 编译器。这两个编译器都是以单通道的形式工作。\n你可以获取以下平台上的 Go 1.4 源码和二进制文件：\n Linux 2.6+：amd64、386 和 arm 架构 Mac OS X（Snow Leopard + Lion）：amd64 和 386 架构 Windows 2000+：amd64 和 386 架构  1、Go 原生编译器 gc： 主要基于 Ken Thompson 先前在 Plan 9 操作系统上使用的 C 工具链。\nGo 语言的编译器和链接器都是使用 C 语言编写并产生本地代码，Go 不存在自我引导之类的功能。因此如果使用一个有不同指令集的编译器来构建 Go 程序，就需要针对操作系统和处理器架构（32 位操作系统或 64 位操作系统）进行区别对待。\n这款编译器使用非分代、无压缩和并行的方式进行编译，它的编译速度要比 gccgo 更快，产生更好的本地代码，但编译后的程序不能够使用 gcc 进行链接。\n2、gccgo 编译器： 一款相对于 gc 而言更加传统的编译器，使用 GCC 作为后端。GCC 是一款非常流行的 GNU 编译器，它能够构建基于众多处理器架构的应用程序。编译速度相对 gc 较慢，但产生的本地代码运行要稍微快一点。它同时也提供一些与 C 语言之间的互操作性。\n从 Go 1 版本开始，gc 和 gccgo 在编译方面都有等价的功能。\n3、Go 环境变量 Go 开发环境依赖于一些操作系统环境变量，你最好在安装 Go 之间就已经设置好他们。如果你使用的是 Windows 的话，你完全不用进行手动设置，Go 将被默认安装在目录 c:/go 下。这里列举几个最为重要的环境变量：\n $GOROOT 表示 Go 在你的电脑上的安装位置，它的值一般都是 $HOME/go，当然，你也可以安装在别的地方。 $GOARCH 表示目标机器的处理器架构，它的值可以是 386、amd64 或 arm(苹果M1 芯片)。 $GOOS 表示目标机器的操作系统，它的值可以是 darwin、freebsd、linux 或 windows。 $GOBIN 表示编译器和链接器的安装位置，默认是 $GOROOT/bin，如果你使用的是 Go 1.0.3 及以后的版本，一般情况下你可以将它的值设置为空，Go 将会使用前面提到的默认值。  Go 编译器支持交叉编译，也就是说你可以在一台机器上构建运行在具有不同操作系统和处理器架构上运行的应用程序，也就是说编写源代码的机器可以和目标机器有完全不同的特性（操作系统与处理器架构）。\n为了区分本地机器和目标机器，你可以使用 $GOHOSTOS 和 $GOHOSTARCH 设置目标机器的参数，这两个变量只有在进行交叉编译的时候才会用到，如果你不进行显示设置，他们的值会和本地机器（$GOOS 和 $GOARCH）一样。\n $GOPATH 默认采用和 $GOROOT 一样的值，但从 Go 1.1 版本开始，你必须修改为其它路径。它可以包含多个包含 Go 语言源码文件、包文件和可执行文件的路径，而这些路径下又必须分别包含三个规定的目录：src、pkg 和bin，这三个目录分别用于存放源码文件、包文件和可执行文件。 $GOARM 专门针对基于 arm 架构的处理器，它的值可以是 5 或 6，默认为 6。 $GOMAXPROCS 用于设置应用程序可使用的处理器个数与核数，详见第 14.1.3 节  4、linux安装 传送门：/en/stack/golang/install_linux/\n5、mac安装 传送门：/en/stack/golang/get_started/\n6、调试器 1、dlv\n1  dlv debug --headless --listen=:2345 --log --api-version 2   2、在 fmt.Printf 中使用下面的说明符来打印有关变量的相关信息：\n %+v 打印包括字段在内的实例的完整信息\n+%#v 打印包括字段和限定类型名称在内的实例的完整信息 %T 打印某个类型的完整说明  3、panic 语句\n4、关键字 defer 来跟踪代码执行过程\n7、构建并运行 Go 程序 从 Go 1 版本开始，使用 Go 自带的更加方便的工具来构建应用程序：\n go build 编译并安装自身包和依赖包 go install 安装自身包和依赖包  Go语言是 编译型 的 静态语言（和C语言一样），所以在运行Go语言程序之前，先要将其编译成二进制的可执行文件。\ngo build: 可以将Go语言程序代码编译成二进制的可执行文件，但是需要我们手动运行该二进制文件；\ngo build 命令用来启动编译，它可以将Go语言程序与相关依赖编译成一个可执行文件，其语法格式如下。\ngo build fileName 其中 fileName 为所需要的参数，可以是一个或者多个 Go 源文件名（当有多个参数时需要使用空格将两个相邻的参数隔开），也可以省略不写。\n使用 go build 命令进行编译时，不同参数的执行结果也是不同的。\n如编译打包linux 生产环境 的包：\n1  GOOS=linux GOARCH=amd64 GIN_MODE=release go build main.go    当参数不为空时如果 fileName 为同一 main 包下的所有源文件名（可能有一个或者多个），编译器将生成一个与第一个 fileName 同名的可执行文件（如执行\ngo build abc.go def.go \u0026hellip;会生成一个 abc.exe 文件）；如果 fileName 为非 main 包下的源文件名，编译器将只对该包进行语法检查，不生成可执行文件。 当参数为空时如果当前目录下存在 main 包，则会生成一个与当前目录名同名的“目录名.exe”可执行文件（如在 hello 目录中执行 go build命令时，会生成 hello.exe 文件）；如果不存在 main 包，则只对当前目录下的程序源码进行语法检查，不会生成可执行文件。  go run 更加方便，它会在编译后直接运行Go语言程序，编译过程中会产生一个临时文件，但不会生成可执行文件，这个特点很适合用来调试程序。\ngo run命令将编译和执行指令合二为一，会在编译之后立即执行Go语言程序，但是不会生成可执行文件。\ngo run命令的语法格式如下：\n1  go run fileName   其中 fileName 为所需要的参数，参数必须是同一 main 包下的所有源文件名，并且不能为空。\n8、其它工具 Go 自带的工具集主要使用脚本和 Go 语言自身编写的，目前版本的 Go 实现了以下三个工具：\n go install 是安装 Go 包的工具，类似 Ruby 中的 rubygems。主要用于安装非标准库的包文件，将源代码编译成对象文件。 go fix 用于将你的 Go 代码从旧的发行版迁移到最新的发行版，它主要负责简单的、重复的、枯燥无味的修改工作，如果像 API 等复杂的函数修改，工具则会给出文件名和代码行数的提示以便让开发人员快速定位并升级代码。Go 开发团队一般也使用这个工具升级 Go 内置工具以及 谷歌内部项目的代码。go fix 之所以能够正常工作是因为 Go 在标准库就提供生成抽象语法树和通过抽象语法树对代码进行还原的功能。该工具会尝试更新当前目录下的所有 Go 源文件，并在完成代码更新后在控制台输出相关的文件名称。 go test 是一个轻量级的单元测试框架  9、与 C 进行交互 工具 cgo 提供了对 FFI（外部函数接口）的支持，能够使用 Go 代码安全地调用 C 语言库，你可以访问 cgo 文档主页：http://golang.org/cmd/cgo。cgo 会替代 Go 编译器来产生可以组合在同一个包中的 Go 和 C 代码。在实际开发中一般使用 cgo 创建单独的 C 代码包。\n如果你想要在你的 Go 程序中使用 cgo，则必须在单独的一行使用 import \u0026ldquo;C\u0026rdquo; 来导入，一般来说你可能还需要 import \u0026ldquo;unsafe\u0026rdquo;。\n然后，你可以在 import \u0026ldquo;C\u0026rdquo; 之前使用注释（单行或多行注释均可）的形式导入 C 语言库（甚至有效的 C 语言代码），它们之间没有空行，例如：\n1 2 3  // #include \u0026lt;stdio.h\u0026gt; // #include \u0026lt;stdlib.h\u0026gt; import \u0026#34;C\u0026#34;   名称 \u0026ldquo;C\u0026rdquo; 并不属于标准库的一部分，这只是 cgo 集成的一个特殊名称用于引用 C 的命名空间。在这个命名空间里所包含的 C 类型都可以被使用，例如 C.uint、C.long 等等，还有 libc 中的函数 C.random() 等也可以被调用。\n当你想要使用某个类型作为 C 中函数的参数时，必须将其转换为 C 中的类型，反之亦然，例如：\n1 2 3  var i int C.uint(i) // 从 Go 中的 int 转换为 C 中的无符号 int int(C.random()) // 从 C 中 random() 函数返回的 long 转换为 Go 中的 int   下面的 2 个 Go 函数 Random() 和 Seed() 分别调用了 C 中的 C.random() 和 C.srandom()。\n示例 3.2 c1.go\n1 2 3 4 5 6 7 8 9 10 11 12  package rand // #include \u0026lt;stdlib.h\u0026gt; import \u0026#34;C\u0026#34; func Random() int { return int(C.random()) } func Seed(i int) { C.srandom(C.uint(i)) }   C 当中并没有明确的字符串类型，如果你想要将一个 string 类型的变量从 Go 转换到 C 时，可以使用 C.CString(s)；同样，可以使用 C.GoString(cs) 从 C 转换到 Go 中的 string 类型。\nGo 的内存管理机制无法管理通过 C 代码分配的内存。\n开发人员需要通过手动调用 C.free 来释放变量的内存：\n1  defer C.free(unsafe.Pointer(Cvariable))   这一行最好紧跟在使用 C 代码创建某个变量之后，这样就不会忘记释放内存了。下面的代码展示了如何使用 cgo 创建变量、使用并释放其内存：\n示例 3.3 c2.go\n1 2 3 4 5 6 7 8 9 10 11 12  package print // #include \u0026lt;stdio.h\u0026gt; // #include \u0026lt;stdlib.h\u0026gt; import \u0026#34;C\u0026#34; import \u0026#34;unsafe\u0026#34; func Print(s string) { cs := C.CString(s) defer C.free(unsafe.Pointer(cs)) C.fputs(cs, (*C.FILE)(C.stdout)) }   ","description":"go语言起源、安装运行环境、编辑器、集成等","id":89,"section":"stack","tags":["golang",""],"title":"学习go(第一部分)","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_part1/"},{"content":"一、下载 去官网下载 ，国内地址：https://golang.google.cn/dl/\n1  $ wget https://golang.google.cn/dl/go1.16.7.linux-amd64.tar.gz   二、解压(需要root权限) 1  $ sudo tar -C /usr/local -xzf go1.16.7.linux-amd64.tar.gz   三、项目目录 1  $ mkdir -p /home/go/src /home/go/pkg /home/go/bin   四、环境变量 1 2 3 4 5 6 7 8 9 10  vi /etc/profile shift + g 可以跳转到最后一行 然后按a,回车到新的一行 export GOROOT=/usr/local/go export GOPATH=/home/gopath export PATH=$PATH:$GOROOT/bin:$GOPATH/bin 然后按ESC,输入 :wq source /etc/profile   五、校验环境 1  $ go env   六、测试程序 1 2  $ cd /home/go/src $ vi main.go   1 2 3 4 5 6  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, World!\u0026#34;) }   然后按ESC,输入 :wq\n1  go run ./main.go   ","description":"整理在mac上的golang安装、配置及版本升级","id":90,"section":"stack","tags":["golang",""],"title":"linux安装golang","uri":"http://wangjinbao.netlify.app/en/stack/golang/install_linux/"},{"content":"1、左大括号 { 不能单独放一行 在其他大多数语言中，{ 的位置你自行决定。Go比较特别，遵守分号注入规则（automatic semicolon injection）：编译器会在每行代码尾部特定分隔符后加;来分隔多条语句，比如会在 ) 后加分号：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 错误示例 func main() { println(\u0026#34;hello world\u0026#34;) } // 等效于 func main(); // 无函数体 { println(\u0026#34;hello world\u0026#34;) } ./main.go: missing function body ./main.go: syntax error: unexpected semicolon or newline before { // 正确示例 func main() { println(\u0026#34;hello world\u0026#34;) }   2、未使用的变量 如果在函数体代码中有未使用的变量，则无法通过编译，不过 全局变量 声明但不使用是\n可以的。即使变量声明后为变量赋值，依旧无法通过编译，需在某处使用它：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // 错误示例 var gvar int // 全局变量，声明不使用也可以  func main() { var one int // error: one declared and not used  two := 2 // error: two declared and not used  var three int // error: three declared and not used  three = 3 } // 正确示例 // 可以直接注释或移除未使用的变量 func main() { var one int _ = one two := 2 println(two) var three int one = three var four int four = four }   3、未使用的 import 如果你 import一个包，但包中的变量、函数、接口和结构体一个都没有用到的话，将编译失败。可以使用_下划线符号作为别\n名来忽略导入的包，从而避免编译错误，这只会执行 package 的 init()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // 错误示例 import ( \u0026#34;fmt\u0026#34; // imported and not used: \u0026#34;fmt\u0026#34;  \u0026#34;log\u0026#34; // imported and not used: \u0026#34;log\u0026#34;  \u0026#34;time\u0026#34; // imported and not used: \u0026#34;time\u0026#34; ) func main() { } // 正确示例 // 可以使用 goimports 工具来注释或移除未使用到的包 import ( _ \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) func main() { _ = log.Println _ = time.Now }   4、获取命令⾏参数 与其他主要编程语⾔的差异\n main 函数不⽀持传⼊参数func main(arg []string ) 在程序中直接通过 os.Args 获取命令⾏参数  5、编写测试程序  源码⽂件以 _test 结尾：xxx_test.go 测试⽅法名以 Test 开头：func TestXXX(t *testing.T) {…}  6、变量赋值  赋值可以进⾏⾃动类型推断 在⼀个赋值语句中可以对多个变量进⾏同时赋值  基本数据类型:\n类型\n1 bool\n2 string\n3 int int8 int16 int32 int64\n4 uint uint8 uint16 uint32 uint64 uintptr\n5 byte // alias for uint8\n6 rune // alias for int32,represents a Unicode code point\n7 float32 float64\n8 complex64 complex128\n7、⽤ == 比较数组  相同维数且含有相同个数元素的数组才可以⽐较 每个元素都相同的才相等  8、简短声明的变量只能在函数内部使用 1 2 3 4 5 6 7 8 9 10  // 错误示例 myvar := 1 // syntax error: non-declaration statement outside function body func main() { } // 正确示例 var myvar = 1 func main() { }   9、使用简短声明来重复声明变量 不能用简短声明方式来单独为一个变量重复声明，:=左侧至少有一个新变量，才允许多变量的重复声明：\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 错误示例 func main() { one := 0 one := 1 // error: no new variables on left side of := } // 正确示例 func main() { one := 0 one, two := 1, 2 // two 是新变量，允许 one 的重复声明。比如 error 处理经常用同名变量 err  one, two = two, one // 交换两个变量值的简写 }   10、map遍历是顺序不固定 map是一种hash表实现，每次遍历的顺序都可能不一样。\nGo 的运行时是有意打乱迭代顺序的，所以你得到的迭代结果可能不一致。但也并不总会打乱，得到连续相同的 5 个迭代结果也是可能的\n1 2 3 4 5 6 7 8 9 10 11 12  func main() { m := map[string]string{ \u0026#34;1\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;: \u0026#34;3\u0026#34;, } for k, v := range m { println(k, v) } }   11、自增和自减运算 很多编程语言都自带前置后置的 ++、– 运算。但 Go 特立独行，去掉了前置操作，同时 ++、— 只作为运算符而非表达式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 错误示例 func main() { data := []int{1, 2, 3} i := 0 ++i // syntax error: unexpected ++, expecting }  fmt.Println(data[i++]) // syntax error: unexpected ++, expecting : } // 正确示例 func main() { data := []int{1, 2, 3} i := 0 i++ fmt.Println(data[i]) // 2 }   12、运算符的优先级 除了位清除（bit clear）操作符，Go 也有很多和其他语言一样的位操作符，但优先级另当别论。\n优先级列表：\n   Precedence Operator     5 * / % \u0026laquo; \u0026raquo; \u0026amp; \u0026amp;^   4 + -   3 == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;=   2 \u0026amp;\u0026amp;   1 2个竖线    13、new() 与 make() 的区别 new(T) 和 make(T,args) 是 Go 语言内建函数，用来分配内存，但适用的类型不同。\nnew(T) 会为 T 类型的新值分配已置零的内存空间，并返回地址（指针），即类型为 *T 的值。换句话说就是，返回一个指针，该指针指向新分配的、类型为 T 的零值。适用于值类型，如数组、结构体等。\nmake(T,args) 返回初始化之后的 T 类型的值，这个值并不是 T 类型的零值，也不是指针 *T，是经过初始化之后的 T 的引用。make() 只适用于 slice、map 和 channel.\n14、gin-从中间件将参数传递给路由控制器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  func MiddleWare() gin.HandlerFunc { return func(c *gin.Context) { c.Set(\u0026#34;request\u0026#34;, \u0026#34;test_request\u0026#34;) } } router.Use(MiddleWare()){ router.GET(\u0026#34;/middleware\u0026#34;, func(c *gin.Context) { // 两种方式都可以获取  request := c.MustGet(\u0026#34;request\u0026#34;).(string) request2, _ := c.Get(\u0026#34;request\u0026#34;) c.JSON(http.StatusOK, gin.H{ \u0026#34;request\u0026#34;: request, \u0026#34;request2\u0026#34;: request2, }) }) }   15、go get报错：zip: not a valid zip file 解决方式:\n方式1：执行 go clean -modcache清理缓存（无效）\n1 2 3 4 5 6 7 8 9 10  User@3-WIN10BG0088 MINGW64 /d/Users/WorkSpace/Go/projects/gin-study $ go clean -modcache User@3-WIN10BG0088 MINGW64 /d/Users/WorkSpace/Go/projects/gin-study $ go mod tidy go: finding module for package github.com/gin-gonic/gin go: downloading github.com/gin-gonic/gin v1.9.1 go: github.com/ice-fire-song/gin-study imports github.com/gin-gonic/gin: zip: not a valid zip file   方式2：更换GOPROXY为七牛云的go代理（有效）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  User@3-WIN10BG0088 MINGW64 /d/Users/WorkSpace/Go/projects/gin-study $ go env -w GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; User@3-WIN10BG0088 MINGW64 /d/Users/WorkSpace/Go/projects/gin-study $ go env|grep PROXY set GONOPROXY= set GOPROXY=https://goproxy.cn,direct User@3-WIN10BG0088 MINGW64 /d/Users/WorkSpace/Go/projects/gin-study $ go mod tidy go: finding module for package github.com/gin-gonic/gin go: downloading github.com/gin-gonic/gin v1.9.1 go: found github.com/gin-gonic/gin in github.com/gin-gonic/gin v1.9.1 go: downloading github.com/gin-contrib/sse v0.1.0 go: downloading github.com/mattn/go-isatty v0.0.19 go: downloading golang.org/x/net v0.10.0 go: downloading github.com/stretchr/testify v1.8.3 go: downloading google.golang.org/protobuf v1.30.0 go: downloading github.com/go-playground/validator/v10 v10.14.0 go: downloading github.com/pelletier/go-toml/v2 v2.0.8 go: downloading github.com/ugorji/go/codec v1.2.11 go: downloading gopkg.in/yaml.v3 v3.0.1 go: downloading github.com/bytedance/sonic v1.9.1 go: downloading github.com/goccy/go-json v0.10.2 go: downloading github.com/json-iterator/go v1.1.12 go: downloading golang.org/x/sys v0.8.0 go: downloading github.com/davecgh/go-spew v1.1.1 go: downloading github.com/pmezard/go-difflib v1.0.0 go: downloading github.com/gabriel-vasile/mimetype v1.4.2 go: downloading github.com/go-playground/universal-translator v0.18.1 go: downloading github.com/leodido/go-urn v1.2.4 go: downloading golang.org/x/crypto v0.9.0 go: downloading golang.org/x/text v0.9.0 go: downloading github.com/go-playground/locales v0.14.1 go: downloading github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd go: downloading github.com/modern-go/reflect2 v1.0.2 go: downloading github.com/chenzhuoyu/base64x v0.0.0-20221115062448-fe3a3abad311 go: downloading golang.org/x/arch v0.3.0 go: downloading github.com/twitchyliquid64/golang-asm v0.15.1 go: downloading github.com/klauspost/cpuid/v2 v2.2.4 go: downloading github.com/go-playground/assert/v2 v2.2.0 go: downloading github.com/google/go-cmp v0.5.5 go: downloading gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405 go: downloading golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543   ","description":"golang开发中的一些小注意点整理","id":91,"section":"stack","tags":["golang",""],"title":"golang注意事项","uri":"http://wangjinbao.netlify.app/en/stack/golang/tips/"},{"content":"一、下载 去官网下载 ，国内地址：https://golang.google.cn/dl/\n选择对应的版本即可，我本地使用的是https://golang.google.cn/dl/go1.18.3.darwin-arm64.pkg\n二、安装及设置环境变量 修改文件：\n/etc/profile\n1 2 3 4 5 6 7 8 9  $ sudo vim /etc/profile # 在文件尾部加上： #golang export GOROOT=/usr/local/go export GOPATH=/Users/wangdante/go export GOBIN=$GOROOT/bin export PATH=$PATH:$GOBIN # 使生效 $ source /etc/profile   我使用zsh，所以也修改~/.zshrc\n1 2 3 4 5 6 7 8  vim ~/.zshrc #golang export GOROOT=/usr/local/go export GOPATH=/Users/wangdante/go export GOBIN=$GOROOT/bin export PATH=$PATH:$GOBIN # 使生效 source ~/.zshrc   打开新terminal\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  go env # 即可查看到GOPATH生效了 GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;/usr/local/go/bin\u0026#34; GOCACHE=\u0026#34;/Users/wangdante/Library/Caches/go-build\u0026#34; GOENV=\u0026#34;/Users/wangdante/Library/Application Support/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOEXPERIMENT=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;darwin\u0026#34; GOINSECURE=\u0026#34;\u0026#34; GOMODCACHE=\u0026#34;/Users/wangdante/go/pkg/mod\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;darwin\u0026#34; GOPATH=\u0026#34;/Users/wangdante/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/local/go\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/local/go/pkg/tool/darwin_amd64\u0026#34; GOVCS=\u0026#34;\u0026#34; GOVERSION=\u0026#34;go1.18.5\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; GOAMD64=\u0026#34;v1\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;clang\u0026#34; CXX=\u0026#34;clang++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; GOWORK=\u0026#34;\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -arch x86_64 -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/9s/kn4nm_092wq6vp1crgf6q7th0000gn/T/go-build1296574441=/tmp/go-build -gno-record-gcc-switches -fno-common\u0026#34;   三、新建三个文件夹 1 2  mkdir -p $GOPATH/{bin,src,pkg}   四、运行第一个go程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  cd /Users/wangdante/go/src/ # (你的项目目录名称随便取) mkdir wjb cd wjb $ pwd /Users/wangdante/go/src/wjb #新建一个文件： vim test.go # 内容： package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, World!\u0026#34;) } #保存并运行，方式两种 #方式一 $ go run test.go 1 ↵ Hello, World! #方式二 进入项目目录： sudo go install #PS：报错 #go: go.mod file not found in current directory or any parent directory; see \u0026#39;go help modules\u0026#39; #解决方法：与 golang 的包管理有关。 #go env -w GO111MODULE=auto 之后在GOPATH下面的bin目录生成一个hello的可执行文件 sh hello (#go build test.go)   五、go环境的卸载 步骤一： 删除/usr/local下的go目录(备注: 这个目录是安装go的时候自动生成的. 如果删除完, 使用 go version, 会报找不到go命令)\n步骤二： 删除Path环境变量 （备注: 这里,我只是想换一个版本, 所以, goPath还是需要的,所以不用删除）\n步骤三： 删除配置文件信息: 在 /etc/profile  或者 $HOME/.profile 或者 $HOME/.bahs_profile 或 ~/.zshrc 中删除bin的设置\n步骤四： 删除mac os x的安装包安装的文件, 删除 /etc/paths.d/go 文件\n(我只用了第一步, 重新安装, 其他都还继续使用)\n六、升级go版本 (升级前先卸载之前的golang版本)\n1 2 3 4 5 6  #之前 $ go version go version go1.17.11 darwin/arm64 #之后 $ go version 127 ↵ go version go1.18.5 darwin/amd64   步骤一、官网下载版本1.18.5 下载地址：https://golang.google.cn/dl/\n步骤二、删除/usr/local/go 删除/usr/local下的go目录(备注: 这个目录是安装go的时候自动生成的. 如果删除完, 使用 go version, 会报找不到go命令)\n步骤三、双击amd安装包 双击 go1.18.5.darwin-arm64.pkg 安装包，一路下一步\n之后go version验证\n","description":"整理在mac上的golang安装、配置及版本升级","id":92,"section":"stack","tags":["golang",""],"title":"golang安装、配置及版本升级","uri":"http://wangjinbao.netlify.app/en/stack/golang/get_started/"},{"content":"定义了对象之间的一对多依赖关系，使得当一个对象改变状态时，其所有依赖对象都会收到通知并自动更新\n *个人理解说法：\n步骤1 定义一个观察者的接口，有一个方法update(string)\n步骤2 定义一个主题结构体，包含多个观察者的切片 和 状态 字段，主要结构体有自己的三个方法，Attach(追加观察者)、SetState(设置状态)、Notify(通知所有观察者修改状态) 。\n步骤3 实例化可以实现观察者接口的观察者实例 和 对应的 update(string)方法\n步骤4 执行：实例化 观察者1 和 观察者2，初始化主题结构体，把观察者1，2都attache到切片中，之后使用主题的SetState设置状态，所有观察者都修改\n 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  package main import \u0026#34;fmt\u0026#34; type Observer interface { Update(string string) } type Subject struct { observers []Observer state string } func (s *Subject) Attach(observer Observer) { s.observers = append(s.observers, observer) } func (s *Subject) SetState(state string) { s.state = state s.Notify() } func (s *Subject) Notify() { for _, observer := range s.observers { observer.Update(s.state) } } type ConcreteObserver struct { name string } func (co *ConcreteObserver) Update(state string) { fmt.Printf(\u0026#34;Observer %s received the state: %s\\n\u0026#34;, co.name, state) } func main() { subject := \u0026amp;Subject{} observer1 := \u0026amp;ConcreteObserver{name: \u0026#34;Observer 1\u0026#34;} observer2 := \u0026amp;ConcreteObserver{name: \u0026#34;Observer 2\u0026#34;} subject.Attach(observer1) subject.Attach(observer2) subject.SetState(\u0026#34;new state\u0026#34;) }   运行如下：\n1 2 3  $go run main.go Observer Observer 1 received the state: new state Observer Observer 2 received the state: new state   ","description":"定义了对象之间的一对多依赖关系，使得当一个对象改变状态时，其所有依赖对象都会收到通知并自动更新","id":93,"section":"stack","tags":["golang"],"title":"Golang的观察者模式","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_observer/"},{"content":"装饰器模式可通过在接口中封装其它接口并添加行为来实现\n如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import \u0026#34;fmt\u0026#34; type Component interface { Operation() string } type ConcreteComponent struct{} func (c *ConcreteComponent) Operation() string { return \u0026#34;Concrete Component\u0026#34; } type Decorator struct { component Component } func (d *Decorator) Operation() string { return \u0026#34;Decorator \u0026#34; + d.component.Operation() } func main() { component := \u0026amp;ConcreteComponent{} decorator := \u0026amp;Decorator{component: component} fmt.Println(component.Operation()) fmt.Println(decorator.Operation()) }   结果：\n1 2 3  $go run main.go Concrete Component Decorator Concrete Component   ","description":"装饰器模式可通过在接口中封装其它接口并添加行为来实现","id":94,"section":"stack","tags":["golang"],"title":"Golang的装饰器模式","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_decorator/"},{"content":"通过工厂方法创建对象，而无需指定创建对象的具体类\n如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  package main import \u0026#34;fmt\u0026#34; type Product interface { GetInfo() string } type ConcreteProduct1 struct { } func (p *ConcreteProduct1) GetInfo() string { return \u0026#34;Product 1\u0026#34; } type ConcreteProduct2 struct { } func (p *ConcreteProduct2) GetInfo() string { return \u0026#34;Product 2\u0026#34; } type Factory struct { } func (f *Factory) CreateProduct(productType int) Product { switch productType { case 1: return \u0026amp;ConcreteProduct1{} case 2: return \u0026amp;ConcreteProduct2{} default: return nil } } func main() { factory := \u0026amp;Factory{} product1 := factory.CreateProduct(1) product2 := factory.CreateProduct(2) fmt.Println(product1.GetInfo()) fmt.Println(product2.GetInfo()) }   结果：\n1 2 3  $go run main.go Product 1 Product 2   ","description":"工厂模式将对象的创建封装在一个类中，并提供一个公共接口来创建对象。在Go语言中，可以使用接口来实现工厂模式","id":95,"section":"stack","tags":["golang"],"title":"Golang的工厂模式","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_factory/"},{"content":"对于设计模式，更多的则是仁者见仁智者见智，要在实际工作中不断的积累，再进行深度的思考，才能逐渐形成的一种思维。\n单例模式 也叫单子模式，是常用的模式之一，在它的核心结构中只包含一个被称为单例的特殊类，能够保证系统运行中一个类只创建一个实例，本节我们就来介绍一下Go语言中的单例模式。\n单例模式实现 Go语言实现单例模式的有四种方式，分别是 懒汉式 、 饿汉式 、 双重检查 和 sync.Onc。\n不管那种模式最终目的只有一个，就是只实例化一次，只允许一个实例存在\n1) 懒汉式——非线程安全 懒汉式 :创建对象时比较懒，先不急着创建对象，在需要加载配置文件的时候再去创建\n非线程安全，指的是在多线程下可能会创建多次对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //使用结构体代替类 type Tool struct { values int } //建立私有变量 var instance *Tool //获取单例对象的方法，引用传递返回 func GetInstance() *Tool { if instance == nil { instance = new(Tool) } return instance }   在非线程安全的基本上，利用 Sync.Mutex 进行加锁保证线程安全，但由于每次调用该方法都进行了加锁操作，在性能上不是很高效\n1 2 3 4 5 6 7 8 9 10 11 12 13  //锁对象 var lock sync.Mutex //加锁保证线程安全 func GetInstance() *Tool { lock.Lock() defer lock.Unlock() if instance == nil { instance = new(Tool) } return instance }   2) 饿汉式 直接创建好对象，不需要判断为空，同时也是线程安全，唯一的缺点是在导入包的同时会创建该对象，并持续占有在内存中。\nGo语言饿汉式可以使用 init 函数，也可以使用 全局变量。\ninit 函数:\n1 2 3 4 5 6 7 8 9 10 11 12  type cfg struct { } var cfg *config func init() { cfg = new(config) } // NewConfig 提供获取实例的方法 func NewConfig() *config { return cfg } type config struct { }   全局变量:\n1 2 3 4 5 6 7 8  type config struct { } //全局变量 var cfg *config = new(config) // NewConfig 提供获取实例的方法 func NewConfig() *config { return cfg }   3) 双重检查 在懒汉式（线程安全）的基础上再进行优化，减少加锁的操作，保证线程安全的同时不影响性能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  //锁对象 var lock sync.Mutex //第一次判断不加锁，第二次加锁保证线程安全，一旦对象建立后，获取对象就不用加锁了。 func GetInstance() *Tool { if instance == nil { lock.Lock() if instance == nil { instance = new(Tool) } lock.Unlock() } return instance }   4) sync.Once 通过 sync.Once 来确保创建对象的方法只执行一次\n1 2 3 4 5 6 7 8 9  var once sync.Once func GetInstance() *Tool { once.Do(func() { instance = new(Tool) }) return instance }   sync.Once 内部本质上也是双重检查的方式，但在写法上会比自己写双重检查更简洁，以下是 Once 的源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func (o *Once) Do(f func()) { //判断是否执行过该方法，如果执行过则不执行  if atomic.LoadUint32(\u0026amp;o.done) == 1 { return } // Slow-path.  o.m.Lock() defer o.m.Unlock() //进行加锁，再做一次判断，如果没有执行，则进行标志已经扫行并调用该方法  if o.done == 0 { defer atomic.StoreUint32(\u0026amp;o.done, 1) f() } }   ","description":"单例模式也叫单子模式,在它的核心结构中只包含一个被称为单例的特殊类，能够保证系统运行中一个类只创建一个实例","id":96,"section":"stack","tags":["golang"],"title":"Golang的单例模式","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_singleton/"},{"content":"标准的Go语言代码库中包含了大量的包，并且在安装 Go 的时候多数会自动安装到系统中。我们可以在 $GOROOT/src/pkg 目录中查看这些包。下面简单介绍一些我们开发中常用的包\n1) fmt fmt 包实现了格式化的标准输入输出，这与C语言中的 printf 和 scanf 类似。其中的 fmt.Printf() 和 fmt.Println() 是开发者使用最为频繁的函数。\n格式化短语派生于C语言，一些短语（%- 序列）是这样使用：\n %v：默认格式的值。当打印结构时，加号（%+v）会增加字段名； %#v：Go样式的值表达； %T：带有类型的 Go 样式的值表达。  2) io 这个包提供了原始的 I/O 操作界面。它主要的任务是对 os 包这样的原始的 I/O 进行封装，增加一些其他相关，使其具有抽象功能用在公共的接口上。\n3) bufio bufio 包通过对 io 包的封装，提供了数据缓冲功能，能够一定程度减少大块数据读写带来的开销。\n在 bufio 各个组件内部都维护了一个缓冲区，数据读写操作都直接通过缓存区进行。当发起一次读写操作时，会首先尝试从缓冲区获取数据，只有当缓冲区没有数据时，才会从数据源获取数据更新缓冲。\n4) sort sort 包提供了用于对切片和用户定义的集合进行排序的功能。\n5) strconv strconv 包提供了将字符串转换成基本数据类型，或者从基本数据类型转换为字符串的功能。\n6) os os 包提供了不依赖平台的操作系统函数接口，设计像 Unix 风格，但错误处理是 go 风格，当 os 包使用时，如果失败后返回错误类型而不是错误数量。\n7) sync sync 包实现多线程中锁机制以及其他同步互斥机制。\n8) flag flag 包提供命令行参数的规则定义和传入参数解析的功能。绝大部分的命令行程序都需要用到这个包。\n9) encoding/json JSON 目前广泛用做网络程序中的通信格式。encoding/json 包提供了对 JSON 的基本支持，比如从一个对象序列化为 JSON 字符串，或者从 JSON 字符串反序列化出一个具体的对象等。\n10) html/template 主要实现了 web 开发中生成 html 的 template 的一些函数。\n11) net/http net/http 包提供 HTTP 相关服务，主要包括 http 请求、响应和 URL 的解析，以及基本的 http 客户端和扩展的 http 服务。\n通过 net/http 包，只需要数行代码，即可实现一个爬虫或者一个 Web 服务器，这在传统语言中是无法想象的。\n12) reflect reflect 包实现了运行时反射，允许程序通过抽象类型操作对象。通常用于处理静态类型 interface{} 的值，并且通过 Typeof 解析出其动态类型信息，通常会返回一个有接口类型 Type 的对象\n13) os/exec os/exec 包提供了执行自定义 linux 命令的相关实现。\n14) strings strings 包主要是处理字符串的一些函数集合，包括合并、查找、分割、比较、后缀检查、索引、大小写处理等等。\nstrings 包与 bytes 包的函数接口功能基本一致。\n15) bytes bytes 包提供了对字节切片进行读写操作的一系列函数。字节切片处理的函数比较多，分为基本处理函数、比较函数、后缀检查函数、索引函数、分割函数、大小写处理函数和子切片处理函数等。\n16) log log 包主要用于在程序中输出日志。\nlog 包中提供了三类日志输出接口，Print、Fatal 和 Panic。\n Print 是普通输出； Fatal 是在执行完 Print 后，执行 os.Exit(1)； Panic 是在执行完 Print 后调用 panic() 方法  ","description":"标准的Go语言代码库中包含了大量的包，并且在安装 Go 的时候多数会自动安装到系统中","id":97,"section":"stack","tags":["golang",""],"title":"Golang的常用内置包简介","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_pkg_normal/"},{"content":"GOPATH GOPATH 是 Go语言中使用的一个 环境变量 ，它使用绝对路径提供项目的工作目录\n工作目录 是一个工程开发的相对参考目录，好比当你要在公司编写一套服务器代码，你的工位所包含的桌面、计算机及椅子就是你的工作区\n工作区 概念与工作目录的概念也是类似的。如果不使用工作目录的概念，在多人开发时，每个人有一套自己的目录结构，读取配置文件的位置不统一，输出的二进制运行文件也不统一，这样会导致开发的标准不统一，影响开发效率。\nGOPATH 适合处理大量 Go语言源码、多个包组合而成的复杂工程。\n使用命令行查看GOPATH信息 在命令行中运行 go env 后，命令行将提示以下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  $ go env GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOEXE=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/home/davy/go\u0026#34; GORACE=\u0026#34;\u0026#34; GOROOT=\u0026#34;/usr/local/go\u0026#34; GOTOOLDIR=\u0026#34;/usr/local/go/pkg/tool/linux\\_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; CC=\u0026#34;gcc\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34;   命令行说明如下：\n GOARCH 表示 目标处理器架构 GOBIN 表示 编译器和链接器 的安装位置 GOOS 表示 目标操作系统 GOPATH 表示 当前工作目录 GOROOT 表示 Go 开发包的安装目录  在 Go 1.8 版本之前，GOPATH 环境变量默认是空的。从 Go 1.8 版本开始，Go 开发包在安装完成后，将 GOPATH 赋予了一个默认的目录，参见下表。\n   平台 GOPATH默认值 举例     win平台 %USERPROFILE%/go C:\\Users\\用户名\\go   unix平台 $HOME/go /home/用户名/go    使用GOPATH的工程结构 在 GOPATH 指定的工作目录下，代码总是会保存在 $GOPATH/src 目录下。在工程经过 go build、go install 或 go get 等指令后，会将产生的二进制可执行文件放在 $GOPATH/bin 目录下，\n生成的中间缓存文件会被保存在 $GOPATH/pkg 下\n如果需要将整个源码添加到版本管理工具（Version Control System，VCS）中时，只需要添加 $GOPATH/src 目录的源码即可。bin 和 pkg 目录的内容都可以由 src 目录生成。\n设置和使用GOPATH 本节以Linux为演示平台，为大家演示使用 GOPATH 的方法。\n1) 设置当前目录为GOPATH 选择一个目录，在目录中的命令行中执行下面的指令：\n1  export GOPATH=`pwd`   该指令中的 pwd 将输出当前的目录，使用反引号```将 pwd 指令括起来表示命令行替换，也就是说，使用pwd将获得 pwd 返回的当前目录的值。例如，假设你的当前目录是“/home/davy/go”，那么使用pwd将获得返回值“/home/davy/go”。\n使用 export 指令可以将当前目录的值设置到环境变量 GOPATH中。\n2) 建立GOPATH中的源码目录 使用下面的指令创建 GOPATH 中的 src 目录，在 src 目录下还有一个 hello 目录，该目录用于保存源码。\nmkdir -p src/hello\nmkdir 指令的 -p 可以连续创建一个路径。\n3) 添加main.go源码文件 使用 Linux 编辑器将下面的源码保存为 main.go 并保存到 $GOPATH/src/hello 目录下。\n1 2 3 4 5 6 7  package main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(\u0026#34;hello\u0026#34;) }   4) 编译源码并运行 此时我们已经设定了 GOPATH，因此在 Go语言中可以通过 GOPATH 找到工程的位置。\n在命令行中执行如下指令编译源码：\n1  go install hello   编译完成的可执行文件会保存在 $GOPATH/bin 目录下。\n在 bin 目录中执行 ./hello，命令行输出如下：\nhello world\n在多项目工程中使用GOPATH 在很多与 Go语言相关的书籍、文章中描述的 GOPATH 都是通过修改系统全局的环境变量来实现的。然而，根据笔者多年的 Go语言使用和实践经验及周边朋友、同事的反馈，这种设置全局 GOPATH 的方法可能会导致当前项目错误引用了其他目录的 Go 源码文件从而造成编译输出错误的版本或编译报出一些无法理解的错误提示。\n比如说，将某项目代码保存在 /home/davy/projectA 目录下，将该目录设置为 GOPATH。随着开发进行，需要再次获取一份工程项目的源码，此时源码保存在 /home/davy/projectB 目录下，如果此时需要编译 projectB 目录的项目，但开发者忘记设置 GOPATH 而直接使用命令行编译，则当前的 GOPATH 指向的是 /home/davy/projectA 目录，而不是开发者编译时期望的 projectB 目录。编译完成后，开发者就会将错误的工程版本发布到外网\n因此，建议大家无论是使用命令行或者使用集成开发环境编译 Go 源码时，GOPATH 跟随项目设定。在 Jetbrains 公司的 GoLand 集成开发环境（IDE）中的 GOPATH 设置分为全局 GOPATH 和项目 GOPATH，如下图所示。\n图中的 Global GOPATH 代表全局 GOPATH，一般来源于系统环境变量中的 GOPATH；Project GOPATH 代表项目所使用的 GOPATH，该设置会被保存在工作目录的 .idea 目录下，不会被设置到环境变量的 GOPATH 中，但会在编译时使用到这个目录。建议在开发时只填写项目 GOPATH，每一个项目尽量只设置一个 GOPATH，不使用多个 GOPATH 和全局的 GOPATH。\n","description":"GOPATH 是 Go语言中使用的一个环境变量，它使用绝对路径提供项目的工作目录","id":98,"section":"stack","tags":["golang",""],"title":"Golang包的GOPATH详解","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_gopath/"},{"content":"FinalShell工具 功能 云端同步,免费海外服务器远程桌面加速,ssh加速,本地化命令输入框,支持自动补全,命令历史,自定义命令参数\n下载 Windows版下载地址:\nhttp://www.hostbuf.com/downloads/finalshell_install.exe\nmacOS版下载地址:\nhttp://www.hostbuf.com/downloads/finalshell_install.pkg\n1  ctrl按住 + 左击\u0026#34;打开\u0026#34;   mac版安装路径 /Applications/FinalShell.app/\n配置文件路径 /Users/$USER/Library/FinalShell/\nmac版卸载\n删除安装目录 /Applications/FinalShell.app/\n","description":"FinalShell是一体化的的服务器,网络管理软件,不仅是ssh客户端,还是功能强大的开发,运维工具,充分满足开发,运维需求.","id":99,"section":"stack","tags":["linux",""],"title":"finalShell终端","uri":"http://wangjinbao.netlify.app/en/stack/linux/finalshell/"},{"content":"任何源代码文件必须属于某个包，同时源码文件的第一行有效代码必须是package pacakgeName语句，通过该语句声明自己所在的包\n包的基本概念 Go语言的包借助了 目录树 的组织形式，一般包的名称就是其源文件所在目录的名称，虽然Go语言没有强制要求包名必须和其所在的目录名同名，\n但还是建议 包名 和 所在目录同名，这样结构更清晰\n包可以定义在很深的目录中，包名的定义是不包括目录路径的，但是包在引用时一般使用全路径引用。比如在GOPATH/src/a/b/下定义一个包 c。\n在包 c 的源码中只需声明为 package c，而不是声明为 package a/b/c，\n但是在导入 c 包时，需要带上路径，例如 ** import \u0026ldquo;a/b/c\u0026rdquo; **\n包的习惯用法  包名一般是 小写的，使用一个简短且有意义的名称。 包名一般要 和所在的目录同名 ，也可以不同，包名中不能包含-等特殊符号。 包一般使用 域名作为目录名称，这样能保证包名的唯一性，比如 GitHub 项目的包一般会放到GOPATH/src/github.com/userName/projectName目录下。 包名为 main 的包为应用程序的入口包，编译不包含 main 包的源码文件时不会得到可执行文件。 一个文件夹下的所有源码文件只能属于同一个包，同样属于同一个包的源码文件不能放在多个文件夹下  包的导入 要在代码中引用其他包的内容，需要使用 import 关键字导入使用的包。具体语法如下：\n1  import \u0026#34;包的路径\u0026#34;   注意事项：\n import 导入语句通常放在源码文件开头 包声明语句的下面 导入的包名需要使用 双引号包裹起来 包名是从GOPATH/src/后开始计算的，使用/进行路径分隔  包的导入有两种写法，分别是单行导入和多行导入。\n单行导入 单行导入的格式如下：\n1 2  import \u0026#34;包 1 的路径\u0026#34; import \u0026#34;包 2 的路径\u0026#34;   多行导入 多行导入的格式如下：\n1 2 3 4  import ( \u0026#34;包 1 的路径\u0026#34; \u0026#34;包 2 的路径\u0026#34; )   包的导入路径 包的引用路径有两种写法，分别是 全路径导入 和 相对路径导入\n全路径导入 包的绝对路径就是GOROOT/src/或GOPATH/src/后面包的存放路径，如下所示：\n1 2 3  import \u0026#34;lab/test\u0026#34; import \u0026#34;database/sql/driver\u0026#34; import \u0026#34;database/sql\u0026#34;   上面代码的含义如下：\n test 包是自定义的包，其源码位于GOPATH/src/lab/test目录下； driver 包的源码位于GOROOT/src/database/sql/driver目录下； sql 包的源码位于GOROOT/src/database/sql目录下。  相对路径导入 相对路径只能用于导入GOPATH下的包，标准包的导入只能使用全路径导入\n例如包 a 的所在路径是GOPATH/src/lab/a，包 b 的所在路径为GOPATH/src/lab/b，如果在包 b 中导入包 a ，则可以使用相对路径导入方式。示例如下:\n1 2  // 相对路径导入 import \u0026#34;../a\u0026#34;   当然了，也可以使用上面的全路径导入，如下所示：\n1 2  // 全路径导入 import \u0026#34;lab/a\u0026#34;   包的引用格式 包的引用有四种格式，下面以 fmt 包为例来分别演示一下这四种格式。\n一、标准引用格式 1  import \u0026#34;fmt\u0026#34;   此时可以用fmt.作为前缀来使用 fmt 包中的方法，这是常用的一种方式。\n示例代码如下：\n1 2 3 4 5 6 7  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;C语言中文网\u0026#34;) }   二、自定义别名引用格式 在导入包的时候，我们还可以为导入的包设置别名，如下所示：\n1  import F \u0026#34;fmt\u0026#34;   其中 F 就是 fmt 包的别名，使用时我们可以使用F.来代替标准引用格式的fmt.来作为前缀使用 fmt 包中的方法。\n示例代码如下：\n1 2 3 4 5 6 7  package main import F \u0026#34;fmt\u0026#34; func main() { F.Println(\u0026#34;C语言中文网\u0026#34;) }   三、省略引用格式 1  import . \u0026#34;fmt\u0026#34;   这种格式相当于把 fmt 包直接合并到当前程序中，在使用 fmt 包内的方法是可以不用加前缀fmt.，直接引用。\n示例代码如下：\n1 2 3 4 5 6 7 8  package main import . \u0026#34;fmt\u0026#34; func main() { //不需要加前缀 fmt.  Println(\u0026#34;C语言中文网\u0026#34;) }   四、匿名引用格式 在引用某个包时，如果只是希望执行包初始化的 init 函数，而不使用包内部的数据时，可以使用匿名引用格式，如下所示：\n1  import _ \u0026#34;fmt\u0026#34;   匿名导入的包与其他方式导入的包一样都会被编译到可执行文件中。\n使用标准格式引用包，但是代码中却没有使用包，编译器会报错。如果包中有 init 初始化函数，则通过import _ \u0026ldquo;包的路径\u0026quot;这种方式引用包，仅执行包的初始化函数，即使包没有 init 初始化函数，也不会引发编译器报错。\n示例代码如下：\n1 2 3 4 5 6 7 8 9 10  package main import ( _ \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { fmt.Println(\u0026#34;C语言中文网\u0026#34;) }   注意：\n 一个包可以有多个 init 函数，包加载时会执行全部的 init 函数，但并 不能保证执行顺序，所以不建议在一个包中放入多个 init 函数，将需要初始化的逻辑放到一个 init 函数里面。 包不能出现环形引用 的情况，比如包 a 引用了包 b，包 b 引用了包 c，如果包 c 又引用了包 a，则编译不能通过。 包的重复引用是允许 的，比如包 a 引用了包 b 和包 c，包 b 和包 c 都引用了包 d。这种场景相当于重复引用了 d，这种情况是允许的，并且 Go 编译器保证包 d 的 init 函数只会执行一次。  包加载 Go 包的初始化 Go语言包的初始化有如下特点：\n 包初始化程序从 main 函数引用的包开始，逐级查找包的引用 ，直到找到没有引用其他包的包，最终生成一个 包引用的 有向无环图 Go 编译器会将有向无环图 转换为一棵树 ，然后从树的叶子节点开始逐层向上对包进行初始化 单个包的初始化过程如上图所示，先初始化常量，然后是全局变量，最后执行包的 init 函数  ","description":"包（package）是多个 Go 源码的集合，是一种高级的代码复用方案。Go语言中为我们提供了很多内置包，如 fmt、os、io 等","id":100,"section":"stack","tags":["golang",""],"title":"Golang包的基本概念","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_package/"},{"content":"常用命令 系统所有shell版本 cat /etc/shells\n1 2 3 4 5 6 7 8 9 10 11  ubuntu@k3s:~$ cat /etc/shells # /etc/shells: valid login shells /bin/sh /usr/bin/sh /bin/bash /usr/bin/bash /bin/rbash /usr/bin/rbash /usr/bin/dash /usr/bin/screen /usr/bin/tmux   系统家目录 echo $HOME\n1 2  ubuntu@k3s:~$ echo $HOME /home/ubunt   系统命令查找目录 echo $PATH\n1 2  ubuntu@k3s:~$ echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin   系统默认shell echo $SHELL\n1 2  ubuntu@k3s:~$ echo $SHELL /bin/bash   查看当前执行脚本名称 echo $0\n1 2 3 4 5 6 7 8 9  ubuntu@k3s:~$ echo $0 -bash # 例子： 切换sh ubuntu@k3s:~$ /bin/sh （切换sh，退出exit） $ echo $0 /bin/sh $ exit ubuntu@k3s:~$   shell脚本编写 vim hello.sh\n1 2 3 4 5  #!/bin/bash  echo \u0026#34;Hello Shell\u0026#34; date whoami   chmod a+x hello.sh\n./hello.sh\n举例：\n1 2 3 4 5 6  #!/bin/bash  echo \u0026#34;请输入您的姓名：\u0026#34; name=$1 channel=$2 echo \u0026#34;你好，$name,欢迎来到 $channel!\u0026#34;   1 2 3  ubuntu@k3s:~$ ./game.sh 王大大 学习 请输入您的姓名： 你好，王大大,欢迎来到 学习!   常用语法符号  $# : 传递给脚本或函数的位置参数的个数 $? : 上一命令的退出状态码。0 通常表示没有错误，非 0值表示有错误 $* : 传递给脚本或函数的位置参数，双引号包围时作为一个整体 $@ : 传递给脚本或函数的位置参数 $$ : 当前shell进程的进程ID（PID） $! : 最后一个后台命令的进程ID $0 : 当前脚本的名称 $1-n : 脚本或函数的位置参数  if 语句 1 2 3 4 5 6 7  if condition; then echo \u0026#34;猜对了\u0026#34; elif [[ $guess -lt $number]]; then echo \u0026#34;小了\u0026#34; else echo \u0026#34;大了\u0026#34; fi   上面的condition可以是[]，[[]]，或(()):\n []是最基本的条件测试表达式 [[]]是扩展测试命令，提供了比[]更强大的功能 (())是数学表达式，支持常见的+-*/数学运算  .profile/.bashrc 都要存储一些环境变量\n.bash_profile 在用户登录的时候执行的并且只执行一次\n.bashrc 每次新打开一个终端或新建一个shell对话执行的\n通常.bash_profile里面会调用.bashrc ，所以推荐把环境变量放到.bashrc文件中\n PS : 修改.bashrc配置文件之后要生效\nsource .bashrc\nps:不同shell的配置文件不同：\nzsh 的配置文件 .zshrc 文件\nbash 的配置文件 .bashrc 文件\nfish 的配置文件 .config.fish 文件\n /目录下的配置文件 /etc文件夹下的 profile 和 bashrc 文件\nalias 别名 在 .bashrc 定义别名\nalias la='ls -A'\n随机数 echo $((RANDOM * 10 + 1 ))\n","description":"shell知识点","id":101,"section":"stack","tags":["linux",""],"title":"shell知识点","uri":"http://wangjinbao.netlify.app/en/stack/linux/shell/"},{"content":"命令 格式：\ncommand [-options] [parameter]\n command: 命令本身 -options: [可选，非必填] 命令的一些选项，可以通过选项控制命令的行为细节 parameter: [可选，非必填] 命令的参数，多数用于命令的指向目标等  HOME目录 和 工作目录： HOME目录 ：每个Linux操作用户在linux系统的个人账户目录，默认在: /home/用户名\n工作目录 ： 打开命令终端时的目录，默认设置的工作目录就是HOME目录\nls ls [-a -l -h] [linux路径]\n -a 选项，表示all意思，列出全部文件（包括隐藏文件/文件夹） -l 选项，表示以列表示展示内容 -h 选项，易查看k,m,g  cd 和 pwd cd [linux路径]\ncd 有参数，去到目录\ncd 无参数，默认回到home目录\npwd\n输出当前目录\n特殊路径符：\n . 当前目录 .. 上一级目录 ~ HOME目录  mkdir mkdir [-p] linux路径\n-p 表示自动创建不存在的父目录\n注意：创建文件夹需要修改权限，请确保操作均在HOME目录内，不要在HOME外操作涉及到权限问题，HOME外无法成功\ntouch/cat/more  touch linux路径  1  touch test.txt    cat linux路径\n直接将内容全部显示出来  1  cat test.txt    more linux路径  1  more /etc/services   f : front翻上一页\nb : back翻上一页\n空格 ：翻下一页\nq ：退出\ncp cp [-r] 参数1 参数2\n -r 选项，可选：用于复制文件夹使用，表示递归  mv mv 参数1 参数2\nrm 语法：rm [-r -f] 参数1 参数2 \u0026hellip; 参数N\n -r 同cp命令一样，-r 选项用于删除文件夹 -f 表示force，强制删除（不会弹出提示确认信息） 参数1 参数2 \u0026hellip; 参数N 一次删除多个，空格隔开  通配符：\n 符号* \u0026ndash;表示通配符，匹配做任意内容 test* \u0026ndash;表示匹配任何以test开头的内容 *test \u0026ndash;表示匹配任何以test结尾的内容 *test * \u0026ndash;表示匹配任何包含test的内容  which 语法：which 查看命令位置\nfind  语法：find 起始路径 -name \u0026quot;被查找文件名\u0026quot;  1 2  find / -name \u0026#34;*test\u0026#34; find / -name \u0026#34;*test*\u0026#34;    语法：find 起始路径 -size \u0026quot;+|-n[kMG]\u0026quot;  1 2  find / -size -10k find / -size +100M   grep 语法：grep [-n] 关键字 \u0026quot;文件路径\u0026quot;\n -n ：可选，显示行数  1 2 3  grep \u0026#34;abc\u0026#34; test.txt grep -n \u0026#34;xyz\u0026#34; test.txt   wc 语法：wc [-c -m -l -w] 文件路径\n -c ，统计bytes数量 -m , 统计字符数量 -l ,统计行数 -w , 统计单词数量  1 2  wc test.txt wc -l test.txt   管道符 | 左边命令的结果，作为右边的输入\n","description":"Linux是一种开源的操作系统内核.","id":102,"section":"stack","tags":["linux",""],"title":"基础知识","uri":"http://wangjinbao.netlify.app/en/stack/linux/linux1/"},{"content":"方法一：使用命令修改时区 1. 打开终端 2. 运行命令 1  sudo timedatectl set-timezone \u0026lt;时区\u0026gt;   将\u0026lt;时区\u0026gt;替换为你要设置的时区，例如 Asia/Shanghai\n3.输入用户密码确认修改 4.通过运行命令timedatectl可以验证时区是否已成功修改 方法二：通过编辑/etc/timezone文件修改时区 1. 打开终端 2. 运行命令 1  sudo nano /etc/timezone   使用合适的文本编辑器打开/etc/timezone文件\n3. 在文件中输入你要设置的时区，例如Asia/Shanghai 4. 保存并关闭文件 5. 运行命令 1  sudo dpkg-reconfigure -f noninteractive tzdata   来更新时区配置\n6. 输入用户密码确认修改 7. 通过运行命令date或者timedatectl可以验证时区是否已成功修改 方法三：通过软链接修改时区 1. 打开终端 2. 运行命令cd /etc进入/etc目录 3. 运行命令 1  sudo ln -sf /usr/knowledge/zoneinfo/\u0026lt;时区\u0026gt; localtime   将\u0026lt;时区\u0026gt;替换为你要设置的时区，例如Asia/Shanghai\n4. 输入用户密码确认修改 5. 通过运行命令date或者timedatectl可以验证时区是否已成功修改 注意：以上方法需要使用管理员权限，确保在修改时区时谨慎操作，避免因设置错误导致系统时间混乱。\n时间同步 1 2 3  mount /dev/sr0 /mnt yum install ntpdate -y ntpdate cn.ntp.org.cn   ","description":"Linux系统时区的修改","id":103,"section":"stack","tags":["linux",""],"title":"时区","uri":"http://wangjinbao.netlify.app/en/stack/linux/date/"},{"content":"单例模式 单例模式是一种 创建唯一实例的设计模式。它通常用于管理资源，例如数据库连接或者日志记录。\n单例模式可以确保 一个类只有一个实例 ，这样就可以避免多个实例同时访问共享资源。在PHP中，单例模式也被广泛应用于 缓存管理 和 路由器 等组件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026lt;?php class Singleton { private static $_instance = null; // 构造方法私有化  private function __construct() {} // 提供一个public方法供外部调用，以获取实例对象  public static function getInstance() { if (is_null(self::$_instance)) { self::$_instance = new Singleton(); } return self::$_instance; } // 防止克隆实例  public function __clone() { exit(\u0026#39;Clone is not allowed:\u0026#39; . E_USER_ERROR); } } ?\u0026gt;  工厂模式 特点： 将对象使用与对象创建分离 ,调用者直接向工厂请求,减少代码的耦合.提高系统的可维护性与可扩展性。\n应用场景： 提供一种类，具有为您创建对象的某些方法，这样就可以使用工厂类创建对象，而不直接使用new。这样如果想更改创建的对象类型，只需更改该工厂即可\n工厂模式是一种 创建对象的设计模式 。它提供了一个通用的接口来创建对象，这样就可以使一个类实例化任何具体类。\n工厂模式在PHP中有很多应用，例如在创建数据库连接对象时。如果需要在程序中使用不同的数据库连接，可以使用工厂模式来创建连接对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026lt;?php class Button {} class MacButton extends Button {} class WinButton extends Button {} interface AbstractFactory { public function createButton(); } class MacFactory implements AbstractFactory { public function createButton() { return new MacButton(); } class WinFactory implements AbstractFactory { public function createButton() { return new WinButton(); } } ?\u0026gt;  观察者模式 特点： 观察者模式(Observer)，当 一个对象状态发生变化时，依赖它的对象全部会收到通知，并自动更新。观察者模式实现了低耦合，非侵入式的通知与更新机制。\n应用： 一个事件发生后，要执行一连串更新操作。传统的编程方式，就是在事件的代码之后直接加入处理的逻辑。当更新的逻辑增多之后，代码会变得难以维护。这种方式是耦合的，侵入式的，增加新的逻辑需要修改事件的主体代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  \u0026lt;?php # 被观察者接口 interface Observable { // 添加/注册观察者  public function attach(Observer $observer); // 删除观察者  public function detach(Observer $observer); // 触发通知  public function notify(); } /** * 被观察者 * 职责：添加观察者到$observers属性中， * 有变动时通过notify()方法运行通知 */ class Order implements Observable { // 保存观察者  private $observers = array(); // 订单状态  private $state = 0; // 添加（注册）观察者  public function attach(Observer $observer) { $key = array_search($observer, $this-\u0026gt;observers); if ($key === false) { $this-\u0026gt;observers[] = $observer; } } // 移除观察者  public function detach(Observer $observer) { $key = array_search($observer, $this-\u0026gt;observers); if ($key !== false) { unset($this-\u0026gt;observers[$key]); } } // 遍历调用观察者的update()方法进行通知，不关心其具体实现方式  public function notify() { foreach ($this-\u0026gt;observers as $observer) { // 把本类对象传给观察者，以便观察者获取当前类对象的信息  $observer-\u0026gt;update($this); } } // 订单状态有变化时发送通知  public function addOrder() { $this-\u0026gt;state = 1; $this-\u0026gt;notify(); } // 获取提供给观察者的状态  public function getState() { return $this-\u0026gt;state; } }   适配器模式 目的 适配器模式是一种 将不兼容的对象或接口转换为兼容的对象或接口 的设计模式。它适用于使用不同的库或框架的程序，或者在API升级时需要调整现有代码的情况。\n在PHP中，适配器模式的一个使用例子是在将数据从不同的数据源导入数据库时。例如，如果需要从一个XML文件中导入数据并将其插入到一个MySQL数据库中，适配器可以将XML数据源转换为MySQL数据源，然后插入到数据库中。\n应用场景：  封装有缺陷的接口设计 统一多个类的接口设计，比如一个支付系统，有三种不同的支付方式，微信支付、支付宝支付、网银支付，这三种支付的实现方法都不一样，那么我们可以用适配器模式，让他们对外具有统一的方法，这样，我们在调用的时候就非常的方便。 兼容老版本的接口  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159  \u0026lt;?php /** * 适配器模式演示代码 * Target适配目标： IDataBase接口 * Adaptee被适配者： mysql和mysqli、postgresql的数据库操作函数 * Adapter适配器 ：mysql类和mysqli、postgresql类 */ /** * Interface IDatabase 适配目标，规定的接口将被适配对象实现 * 约定好统一的api行为 */ interface IDatabase { // 定义数据库连接方法  public function connect($host, $username, $password, $database); // 定义数据库查询方法  public function query($sql); // 关闭数据库  public function close(); } /** * Class Mysql 适配器 */ class Mysql implements IDatabase { protected $connect; // 连接资源  /** * 实现连接方法 * * @param $host host * @param $username 用户名 * @param $password 密码 * @param $database 数据库名 */ public function connect($host, $username, $password, $database) { $connect = mysql_connect($host, $username, $password); mysql_select_db($database, $connect); $this-\u0026gt;connect = $connect; //其他操作  } /** * 实现查询方法 * * @param $sql 需要被查询的sql语句 * @return mi */ public function query($sql) { return mysql_query($sql); } // 实现关闭方法  public function close() { mysql_close(); } } /** * Class Mysqli 适配器 */ class Mysqli implements IDatabase { protected $connect; // 连接资源  /** * 实现连接方法 * * @param $host host * @param $username 用户名 * @param $password 密码 * @param $database 数据库名 */ public function connect($host, $username, $password, $database) { $connect = mysqli_connect($host, $username, $password, $database); $this-\u0026gt;connect = $connect; //其他操作  } /** * 实现查询方法 * * @param $sql 需要被查询的sql语句 */ public function query($sql) { return mysqli_query($this-\u0026gt;connect, $sql); } // 实现关闭  public function close() { mysqli_close($this-\u0026gt;connect); } } /** * Class Postgresql 适配器 */ class Postgresql implements IDatabase { protected $connect; // 连接资源  /** * 实现连接方法 * * @param $host * @param $username * @param $password * @param $database */ public function connect($host, $username, $password, $database) { $this-\u0026gt;connect = pg_connect(\u0026#34;host=$hostdbname=$databaseuser=$usernamepassword=$password\u0026#34;); //其他操作  } /** * 实现查询方法 * * @param $sql 需要被查询的sql语句 */ public function query($sql) { // 其他操作  } // 实现关闭方法  public function close() { } } /** * 客户端使用演示 * 这里以mysql为例 * 只要模式设计好，不论有多少种数据库，实现和调用方式都是一样的 * 因为都是实现的同一个接口，所以都是可以随意切换的 */ $host = \u0026#39;localhost\u0026#39;; $username = \u0026#39;root\u0026#39;; $password = \u0026#39;root\u0026#39;; $database = \u0026#39;mysql\u0026#39;; //$client = new Postgresql(); //$client = new Mysql(); $client = new Mysqli(); $client-\u0026gt;connect($host, $username, $password, $database); $result = $client-\u0026gt;query(\u0026#34;select * from db\u0026#34;); while ($rows = mysqli_fetch_array($result)) { var_dump($rows); } $client-\u0026gt;close();   装饰器模式 装饰器模式是一种通过在运行时动态添加功能的设计模式。它通过包装目标对象来实现这一点，从而扩展或修改其行为。\n在PHP中，装饰器模式可以用于单元测试、日志记录、和调试等方面。通过使用装饰器模式，可以在目标类中添加或修改方法，而不会改变目标类本身。\n结构 MilkTea：原本的对象和装饰共同的接口 示例中指：奶茶\nOolong、Latte： 原本的对象 示例中指：声声乌龙、幽兰拿铁\nDecorator： 实现接口的装饰抽象类\nCream、…：具体的装饰 示例中：奶油、碧根果、开心果\n奶茶基类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /** * 奶茶 */ interface MilkTea { /** * 名称 * @return mixed */ public function name(); /** * 价格 * @return mixed */ public function price(); }   具体奶茶类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 声声乌龙 */ class Oolong implements MilkTea { public function name() { return \u0026#39;声声乌龙\u0026#39;; } public function price() { return 16; } }   小白拿铁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 幽兰拿铁 */ class Latte implements MilkTea { public function name() { return \u0026#39;幽兰拿铁\u0026#39;; } public function price() { return 17; } }   加料类基类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Decorator implements MilkTea { protected $milkTea; public function __construct(MilkTea $milkTea) { $this-\u0026gt;milkTea = $milkTea; } public function name() { if ($this-\u0026gt;milkTea != null) { return $this-\u0026gt;milkTea-\u0026gt;name(); } return \u0026#39;\u0026#39;; } public function price() { if ($this-\u0026gt;milkTea != null) { return $this-\u0026gt;milkTea-\u0026gt;price(); } return 0; } }   加料具体类\n奶油\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 奶油 */ class Cream extends Decorator { public function name() { return $this-\u0026gt;milkTea-\u0026gt;name() . \u0026#39;+ 奶油\u0026#39;; } public function price() { return $this-\u0026gt;milkTea-\u0026gt;price() + 4; } }   碧根果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 碧根果 */ class Pecan extends Decorator { public function name() { return $this-\u0026gt;milkTea-\u0026gt;name() . \u0026#39;+ 碧根果\u0026#39;; } public function price() { return $this-\u0026gt;milkTea-\u0026gt;price() + 2; } }   开心果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 开心果 */ class Pistachio extends Decorator { public function name() { return $this-\u0026gt;milkTea-\u0026gt;name() . \u0026#39;+ 开心果\u0026#39;; } public function price() { return $this-\u0026gt;milkTea-\u0026gt;price() + 4; } }   客户端使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /** * 我点一杯 幽兰拿铁+ 奶油+ 开心果 */ $latte = new Latte(); $cream = new Cream($latte); $pistachio = new Pistachio($cream); echo $pistachio-\u0026gt;name(); echo \u0026#39; \u0026#39; . $pistachio-\u0026gt;price() . \u0026#39;元\u0026#39; . PHP_EOL; /** * 点一杯加三个奶油的声声乌龙（因为我比较喜欢喝奶油） */ $oolong = new Oolong(); $cream = new Cream($oolong); $cream = new Cream($cream); $cream = new Cream($cream); echo $cream-\u0026gt;name(); echo \u0026#39; \u0026#39; . $cream-\u0026gt;price() . \u0026#39;元\u0026#39; . PHP_EOL;   输出：\n1 2  幽兰拿铁+ 奶油+ 开心果 25元 声声乌龙+ 奶油+ 奶油+ 奶油 28元   ","description":"常用设计模式：单例模式、工厂模式、观察者模式、适配器模式、装饰器模式","id":104,"section":"stack","tags":["php"],"title":"php常用设计模式代码","uri":"http://wangjinbao.netlify.app/en/stack/php/design/"},{"content":"一、安装  pip 安装  pip install django\n安装成功后会有 django-admin 命令\n 创建新项目  django-admin startproject website(项目名)  开启项目  python manage.py startapp app \u0026ndash;不能重名  启动项目  python manage.py runserver  指定 IP+端口 启动项目  python manage.py runserver 0.0.0.0:8080 二、迁移文件操作 1、创建迁移文件内容 +添加表结构 app/models.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class AssessmentInfo(models.Model): \u0026#39;\u0026#39;\u0026#39;业务考核表\u0026#39;\u0026#39;\u0026#39; apply_id = models.IntegerField(\u0026#39;考核申请ID\u0026#39;, default=0, db_index=True) user = models.CharField(\u0026#39;用户名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;) userText = models.CharField(\u0026#39;中文名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;, db_column=\u0026#39;user_text\u0026#39;) leader = models.CharField(\u0026#39;业务考核人用户名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;) leaderText = models.CharField(\u0026#39;业务考核人中文名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;, db_column=\u0026#39;leader_text\u0026#39;) kpi = JSONField(\u0026#39;KPI\u0026#39;, default=[]) score = models.FloatField(\u0026#39;评分\u0026#39;, default=0) level = models.CharField(\u0026#39;等级\u0026#39;, max_length=10, default=\u0026#39;\u0026#39;) comment = models.TextField(\u0026#39;评语\u0026#39;, max_length=1000, default=\u0026#39;\u0026#39;) dept = models.CharField(\u0026#39;服务部门\u0026#39;, max_length=255, default=\u0026#39;\u0026#39;) position = models.CharField(\u0026#39;职位\u0026#39;, max_length=20, default=\u0026#39;\u0026#39;) entryDate = models.DateField(\u0026#39;入场时间\u0026#39;, blank=True, null=True, db_column=\u0026#39;entry_date\u0026#39;) # 0 - 未提交， 1- 未考核， 2 - 已考核 status = models.IntegerField(\u0026#39;状态\u0026#39;, default=0) created = models.DateTimeField(\u0026#39;创建时间\u0026#39;, auto_now_add=True) updated = models.DateTimeField(\u0026#39;更新时间\u0026#39;, auto_now=True) STATUS_OFF = 4 class Meta: db_table = \u0026#39;app_assessment_info\u0026#39; index_together = [ [\u0026#39;user\u0026#39;, \u0026#39;apply_id\u0026#39;], [\u0026#39;leader\u0026#39;, \u0026#39;apply_id\u0026#39;], ]   +修改表结构 app/models.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  class Migration(migrations.Migration): dependencies = [ (\u0026#39;UserManage\u0026#39;, \u0026#39;0001_initial\u0026#39;), ] operations = [ migrations.CreateModel( name=\u0026#39;Org\u0026#39;, fields=[ (\u0026#39;id\u0026#39;, models.AutoField(verbose_name=\u0026#39;ID\u0026#39;, serialize=False, auto_created=True, primary_key=True)), (\u0026#39;oid\u0026#39;, models.CharField(default=\u0026#39;\u0026#39;, max_length=20, db_index=True)), (\u0026#39;name\u0026#39;, models.CharField(default=\u0026#39;\u0026#39;, max_length=20)), (\u0026#39;level\u0026#39;, models.IntegerField(default=0)), (\u0026#39;parent\u0026#39;, models.IntegerField(default=0)), (\u0026#39;created\u0026#39;, models.DateTimeField(auto_now_add=True)), (\u0026#39;updated\u0026#39;, models.DateTimeField(auto_now=True)), ], options={ \u0026#39;db_table\u0026#39;: \u0026#39;user_manage_orgs\u0026#39;, }, bases=(models.Model, common.utils.models.toDictMixin), ), migrations.AddField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;entryDate\u0026#39;, field=models.DateField(null=True, db_column=\u0026#39;entry_date\u0026#39;, blank=True), ), migrations.AddField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;oid\u0026#39;, field=models.CharField(default=\u0026#39;\u0026#39;, max_length=20), ), migrations.AddField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;position\u0026#39;, field=models.CharField(default=\u0026#39;\u0026#39;, max_length=20), ), migrations.AlterField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;last_login\u0026#39;, field=models.DateTimeField(null=True, blank=True), ), ]   2、执行迁移文件命令 python manage.py makemigration\npython manage.py migrate 2.1 项目添加新的数据表 步骤一: 先刷新一下当前数据库的表结构，避免出现 table already exists\npython manage.py makemigrations\npython manage.py migrate app \u0026ndash;fake\npython manage.py migrate UserManage \u0026ndash;fake\n步骤二: 加表结构\n编写新的 models\n步骤三: 执行 migrate\npython manage.py makemigrations\npython manage.py migrate app\npython manage.py migrate UserManage\n三、orm 增、删、改、查操作  ORM：Object Relational Mapping(对象关系映射)，是使用面向对象的思维来操作数据库。\n *增加 方式一 ： 类名.objects.create() models.Person.objects.create(name=username,pwd=password) 方式二 ： obj=models.类（属性=XX） obj.save() 举子：\nperson_obj = models.Person(name=username,pwd=password)\nperson_obj.save() *删除 方式一 ： 类名.objects.get(xxx).delete() person_obj = models.Person.objects.get(id=ids) # 获取 person 对象\nperson_obj.delete() # 删除数据库中的记录 方式二 ： 类名.objects.filter(xxx).delete() ret = models.Person.objects.filter(id=ids) # filter() 根据条件进行过滤。\nret.delete() *修改 方式一 ： obj =类名.objects.get(‘xxx’)\nobj.zz = xx\nobj.save()\nperson_obj = models.Person.objects.get(id=id)\nperson_obj.name = usrname\nperson_obj.age = age\nperson_obj.birthday = bir\nperson_obj.save()\n方式二 ： 类名.objects.filter(‘xxx’).update(关键字（类中的属性）=值\u0026hellip;..) models.Person.objects.filter(id=id).update(name=usrname, age=age, birthday=bir) *查询 方式一 ： 类名.objects.all() 获取所有记录 models.Person.objects.all()\nmodels.Person.objects.filter(is_active=True)\n注意：单独查询要用 try except\ntry:\nauth=Author.objects.get(id=1)\nauth.delete()\nexcept:\nprint(删除失败) 四、路由 1 2 3 4 5 6 7 8 9 10 11 12  from django.conf.urls import include, url urlpatterns = [ url(r\u0026#39;^$\u0026#39;, Home), url(r\u0026#39;^wxlogin/$\u0026#39;, WXLogin), url(r\u0026#39;^app/\u0026#39;, include(\u0026#39;app.urls\u0026#39;)), url(r\u0026#39;^accounts/\u0026#39;, include(\u0026#39;UserManage.urls\u0026#39;)), url(r\u0026#39;^os_web/partners_kpi/api/wxlogin/$\u0026#39;, WXLogin), url(r\u0026#39;^os_web/partners_kpi/api/app/\u0026#39;, include(\u0026#39;app.urls\u0026#39;)), url(r\u0026#39;^os_web/partners_kpi/api/accounts/\u0026#39;, include(\u0026#39;UserManage.urls\u0026#39;)), ]   五、F 对象 用于模型类的 A 字段属性与 B 字段属性两者的比较，即操作数据库中某一列的值。\n通常是对数据库中的字段值在不获取的情况下进行操作。F 对象内置在数据包 django.db.models 中，所以使用时需要提前导入\n1 2  from django.db.models import F F(\u0026#39;字段名\u0026#39;)   在使用 F 对象进行查询的时候需要注意：\n一个 F() 对象代表了一个 Model 的字段的值；F 对象可以在没有实际访问数据库获取数据值的情况下对字段的值进行引用。\nDjango 支持对 F 对象引用字段的算术运算操作，并且运算符两边可以是具体的数值或者是另一个 F 对象，下面我们通过实例进一步认识 F 对象。\n1 2 3 4 5 6 7 8 9  from django.db.models import F from index.models import Book #给Book所有实例价格（retail_price）涨价20元 Book.objects.all().update(retail_price=F(\u0026#39;retail_price\u0026#39;)+20) #获取该列所有值并加20 #利用传统的方法实现涨价20元 books = models.Book.objects.all() for book in books: book.update(retail_price=book.retail_price+20) book.save()   通过上述实例可以看出，使用 F 对象相对传统的方法要简单的多。那么如何通过 F 对象实现两个字段值（列）之间的比较呢？实例如下所示：\n1 2 3 4  #对数据库中两个字段的值进行比较，列出哪儿些书的零售价高于定价 books = Book.objects.filter(retail_price__gt=F(\u0026#39;price\u0026#39;)) for book in books: print(book.title, \u0026#39;定价:\u0026#39;, book.price, \u0026#39;现价:\u0026#39;, book.retail_price)   六、Q 对象 相比 F 对象更加复杂一点，它主要应用于包含逻辑运算的复杂查询。Q 对象把关键字参数封装在一起，并传递给 filter、exclude、get 等查询的方法。多个 Q 对象之间可以使用\u0026amp;或者|运算符组合（符号分别表示与和或的关系），从而产生一个新的 Q 对象。当然也可以使用~（非）运算符来取反，从而实现 NOT 查询。\nQ 对象的导入方式如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13  from django.db.models import Q from index.models import Book #查找c语言中文网出版的书或价格低于35的书 Book.objects.filter(Q(retail_price__lt=35)|Q(pub_id=\u0026#39;2\u0026#39;))#两个Q对象是或者的逻辑关系 #查找不是c语言中文出版的书且价格低于45的书 Book.objects.filter(Q(retail_price__lt=45)\u0026amp;~Q(pub_id=\u0026#39;2\u0026#39;))#条件1成立条件2不成立 q = Q() if applyId: q \u0026amp;= Q(apply_id=applyId) if status: q \u0026amp;= Q(status=status) if applyIdList: q \u0026amp;= ~Q(apply_id__in=applyIdList)   Q 对象也可以与类属性的字段名组合在一起使用，但是在这种情况下，Django 规定，Q 对象必须放在 前面，示例如下：\n1 2  Book.objects.filter(Q(price__lte=100),title__icontains=\u0026#34;p\u0026#34;)#组合使用 \u0026lt;QuerySet [\u0026lt;Book: Book object (1)\u0026gt;]\u0026gt;   常见的运算符：\n\u0026amp; 与操作\n| 或操作 Q(market_pricelt=50) | Q(market_pricegt=20)\n~ 非操作\nexact 判断，大小写敏感\ncontains 是否包含，大小写敏感\nstartwith 以什么值开头，大小写敏感\nendwith 以什么值结束，大小写敏感\nin 是否在哎包含的范围内 如 ： filter(status__in=[1, 2])\n常见的比较运算符：\ngt 大于 如：filter(num__gt=0)\ngte 大于等于\nlt 小于\nlte 小于等于\n七、聚合查询 1、整表聚合 语法：\n聚合函数：Sum,Avg,Count,Max,Min\n语法：MyModel.objects.aggregate(结果变量名=聚合函数(\u0026lsquo;列\u0026rsquo;))\n返回结果：结果变量名和值组成的字典\n格式为：{\u0026ldquo;结果变量名\u0026rdquo;:值}\n1 2 3 4  from django.db.models import * #或from django.db.models import Count Book.objects.aggregate(res=Count(\u0026#39;id\u0026#39;)) {\u0026#39;res\u0026#39;:4}   2、分组聚合 “先分组（.values），再聚合(.annotate)”\nannotate\n使用：QuerySet.annotate(结果变量名=聚合函数(\u0026lsquo;列\u0026rsquo;))\n返回值：QuerySet\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 先分组 query_set = Book.objects.values(‘pub’) # 再聚合 QuerySet.annotate(名=聚合函数(\u0026#39;列\u0026#39;)) querySetS = AssessmentInfo.objects.filter(q).values(\u0026#39;level\u0026#39;) classNum = querySetS.annotate(res=Count(\u0026#39;id\u0026#39;)) for i in classNum: if i.get(\u0026#39;level\u0026#39;) == \u0026#39;S\u0026#39;: temp[\u0026#39;Snum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;A\u0026#39;: temp[\u0026#39;Anum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;B\u0026#39;: temp[\u0026#39;Bnum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;C\u0026#39;: temp[\u0026#39;Cnum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;D\u0026#39;: temp[\u0026#39;Dnum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0)   八、执行原生 sql .query\n执行原生 sql：\n1 2  MyModel.objects.raw(sql语句，拼接参数) s1=Book.objects.raw(\u0026#39;select * from bookstore_book \u0026#39;)   九、关系映射 1、一对一：OneToOneField(类名,on_delete=xxx) 级联删除：\n1 models.CASCADE 同时删除\n2 models.PROTESCT 不能删除\n3 SET_NULL ForeignKey 为 null ，null=true\n4 SET_DEFAULT 外键设置默认值\n开启应用：步骤 1、2\n1、python manager.py startapp xxx\n2、settings.py -》INSTALLED_APPS=[\n.\n.\n.\n\u0026lsquo;XXX\u0026rsquo;\n]\n1 2 3 4 5 6 7 8 9 10 11 12  from django.db import models class Author(models.Model): name=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) class Wife(models.Model): name=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) author=models.OneToOneField(Author,on_delete=models.CASCADE) 正向查询：谁有外键，先查谁 from .models import wife wife=wife.objects.get(name=\u0026#39;王夫人\u0026#39;) print(wife.name,\u0026#39;的老公是\u0026#39;,wife.author.name) 反向查询：没有外键属性--反过来类名小写 print(author.wife.name)   2、一对多：ForeignField(类名,on_delete=xxx) 1 2 3 4 5 6 7 8 9  from django.db import models class Publisher(models.Model): name=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) class Book(models.Model): title=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) author=models.ForeignField(Publisher,on_delete=models.CASCADE) pub1=Publisher.objects.create(name=\u0026#39;清大学出版社\u0026#39;) Book.objects.create(title=\u0026#39;\u0026#39;C++,publisher=pub1)   十、cookie 和 session 的使用 1、cookie 以键-值对的形式\n每次向服务器发请求时，都会携带 cookie 给服务器\n1 2 3 4  HttpResponse.set_cookie(key,value=\u0026#39;\u0026#39;,max_age=None,expires=None) res=HttpResponse(\u0026#39;set cookie is ok\u0026#39;) res.set_cookie(\u0026#39;uname\u0026#39;,\u0026#39;gxn\u0026#39;,3600) return res   删除：\n1  HttpResponse.delete_cookie(key)   获取：\n1 2  request.COOKIES 字典(dict) request.COOKIES.get(\u0026#39;cookied名\u0026#39;,\u0026#39;默认值\u0026#39;\u0026#39;)   2、session 生成独立的存储空间（格子）sessionID-\u0026gt;借助 cookie 存储\nsession 要想成:必须有 cookie,session 数据很难被改，安全\n2.1 session 配置： 1 2 3 4 5 6 7  settings.py中:INSTALLED_APPS=[ \u0026#39;django.contrib.sessions\u0026#39;, ] 向MIDDLEWARE列表添加： MIDDLEWARE=[ \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, ]   2.2 session 配置项： settings.py 中相关配置项:\n1 2  SESSION_COOKIE_AGE=60*60*24*2*2 SESSION_EXPIRE_AT_BROWSER_CLOSE=True   浏览器关闭 session 失效\n定期清理 session\n1  python manage.py clearsessions   每晚定时任务，可删除过期的 session 数据\n2.3 session 使用： 保存：\n1 2 3 4 5  request.session[\u0026#39;KEY\u0026#39;]=VALUE def set_session(request): request.session[\u0026#39;uname\u0026#39;]=\u0026#39;wjb\u0026#39; return HttpResponse(\u0026#39;set sesssion is ok\u0026#39;)   获取：\n1 2 3 4 5 6  request.session[\u0026#39;KEY\u0026#39;] request.session.get(\u0026#39;KEY\u0026#39;,\u0026#39;默认值\u0026#39;) def get_session(request): value=request.session[\u0026#39;uname\u0026#39;] return=HttpResponse(\u0026#39;session value is %s\u0026#39;%(value))   ps:\n迁移文件防止报错:\ntable exists\n解决方法:\n1 2  python manage.py makemigrations python manage.py migrate app --fake   app 名称去 settings.py 中查看注册名称\n同时删除 django_migrations 表中的数据\n上传文件中文编码报错:\nUnicodeDecodeError: \u0026lsquo;ascii\u0026rsquo; codec can\u0026rsquo;t decode byte 0xe6 in position 260: ordinal not in range(128)\n解决方法:\n1 2 3 4 5  import sys # 设置中文编码 reload(sys) sys.setdefaultencoding(\u0026#39;utf8\u0026#39;)   ","description":"Django是一个由Python编写的具有完整架站能力的开源Web框架。使用Django，只要很少的代码，就可以轻松地完成一个正式网站的大部分内容，并进一步开发出全功能的Web","id":105,"section":"posts","tags":["shortcode"],"title":"django框架","uri":"http://wangjinbao.netlify.app/en/posts/django/"},{"content":"一、安装  pip 安装  pip install django\n安装成功后会有 django-admin 命令\n 创建新项目  django-admin startproject website(项目名)  开启项目  python manage.py startapp app \u0026ndash;不能重名  启动项目  python manage.py runserver  指定 IP+端口 启动项目  python manage.py runserver 0.0.0.0:8080 二、迁移文件操作 1、创建迁移文件内容 +添加表结构 app/models.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class AssessmentInfo(models.Model): \u0026#39;\u0026#39;\u0026#39;业务考核表\u0026#39;\u0026#39;\u0026#39; apply_id = models.IntegerField(\u0026#39;考核申请ID\u0026#39;, default=0, db_index=True) user = models.CharField(\u0026#39;用户名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;) userText = models.CharField(\u0026#39;中文名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;, db_column=\u0026#39;user_text\u0026#39;) leader = models.CharField(\u0026#39;业务考核人用户名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;) leaderText = models.CharField(\u0026#39;业务考核人中文名\u0026#39;, max_length=64, default=\u0026#39;\u0026#39;, db_column=\u0026#39;leader_text\u0026#39;) kpi = JSONField(\u0026#39;KPI\u0026#39;, default=[]) score = models.FloatField(\u0026#39;评分\u0026#39;, default=0) level = models.CharField(\u0026#39;等级\u0026#39;, max_length=10, default=\u0026#39;\u0026#39;) comment = models.TextField(\u0026#39;评语\u0026#39;, max_length=1000, default=\u0026#39;\u0026#39;) dept = models.CharField(\u0026#39;服务部门\u0026#39;, max_length=255, default=\u0026#39;\u0026#39;) position = models.CharField(\u0026#39;职位\u0026#39;, max_length=20, default=\u0026#39;\u0026#39;) entryDate = models.DateField(\u0026#39;入场时间\u0026#39;, blank=True, null=True, db_column=\u0026#39;entry_date\u0026#39;) # 0 - 未提交， 1- 未考核， 2 - 已考核 status = models.IntegerField(\u0026#39;状态\u0026#39;, default=0) created = models.DateTimeField(\u0026#39;创建时间\u0026#39;, auto_now_add=True) updated = models.DateTimeField(\u0026#39;更新时间\u0026#39;, auto_now=True) STATUS_OFF = 4 class Meta: db_table = \u0026#39;app_assessment_info\u0026#39; index_together = [ [\u0026#39;user\u0026#39;, \u0026#39;apply_id\u0026#39;], [\u0026#39;leader\u0026#39;, \u0026#39;apply_id\u0026#39;], ]   +修改表结构 app/models.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  class Migration(migrations.Migration): dependencies = [ (\u0026#39;UserManage\u0026#39;, \u0026#39;0001_initial\u0026#39;), ] operations = [ migrations.CreateModel( name=\u0026#39;Org\u0026#39;, fields=[ (\u0026#39;id\u0026#39;, models.AutoField(verbose_name=\u0026#39;ID\u0026#39;, serialize=False, auto_created=True, primary_key=True)), (\u0026#39;oid\u0026#39;, models.CharField(default=\u0026#39;\u0026#39;, max_length=20, db_index=True)), (\u0026#39;name\u0026#39;, models.CharField(default=\u0026#39;\u0026#39;, max_length=20)), (\u0026#39;level\u0026#39;, models.IntegerField(default=0)), (\u0026#39;parent\u0026#39;, models.IntegerField(default=0)), (\u0026#39;created\u0026#39;, models.DateTimeField(auto_now_add=True)), (\u0026#39;updated\u0026#39;, models.DateTimeField(auto_now=True)), ], options={ \u0026#39;db_table\u0026#39;: \u0026#39;user_manage_orgs\u0026#39;, }, bases=(models.Model, common.utils.models.toDictMixin), ), migrations.AddField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;entryDate\u0026#39;, field=models.DateField(null=True, db_column=\u0026#39;entry_date\u0026#39;, blank=True), ), migrations.AddField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;oid\u0026#39;, field=models.CharField(default=\u0026#39;\u0026#39;, max_length=20), ), migrations.AddField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;position\u0026#39;, field=models.CharField(default=\u0026#39;\u0026#39;, max_length=20), ), migrations.AlterField( model_name=\u0026#39;user\u0026#39;, name=\u0026#39;last_login\u0026#39;, field=models.DateTimeField(null=True, blank=True), ), ]   2、执行迁移文件命令 python manage.py makemigration\npython manage.py migrate 2.1 项目添加新的数据表 步骤一: 先刷新一下当前数据库的表结构，避免出现 table already exists\npython manage.py makemigrations\npython manage.py migrate app \u0026ndash;fake\npython manage.py migrate UserManage \u0026ndash;fake\n步骤二: 加表结构\n编写新的 models\n步骤三: 执行 migrate\npython manage.py makemigrations\npython manage.py migrate app\npython manage.py migrate UserManage\n三、orm 增、删、改、查操作  ORM：Object Relational Mapping(对象关系映射)，是使用面向对象的思维来操作数据库。\n *增加 方式一 ： 类名.objects.create() models.Person.objects.create(name=username,pwd=password) 方式二 ： obj=models.类（属性=XX） obj.save() 举子：\nperson_obj = models.Person(name=username,pwd=password)\nperson_obj.save() *删除 方式一 ： 类名.objects.get(xxx).delete() person_obj = models.Person.objects.get(id=ids) # 获取 person 对象\nperson_obj.delete() # 删除数据库中的记录 方式二 ： 类名.objects.filter(xxx).delete() ret = models.Person.objects.filter(id=ids) # filter() 根据条件进行过滤。\nret.delete() *修改 方式一 ： obj =类名.objects.get(‘xxx’)\nobj.zz = xx\nobj.save()\nperson_obj = models.Person.objects.get(id=id)\nperson_obj.name = usrname\nperson_obj.age = age\nperson_obj.birthday = bir\nperson_obj.save()\n方式二 ： 类名.objects.filter(‘xxx’).update(关键字（类中的属性）=值\u0026hellip;..) models.Person.objects.filter(id=id).update(name=usrname, age=age, birthday=bir) *查询 方式一 ： 类名.objects.all() 获取所有记录 models.Person.objects.all()\nmodels.Person.objects.filter(is_active=True)\n注意：单独查询要用 try except\ntry:\nauth=Author.objects.get(id=1)\nauth.delete()\nexcept:\nprint(删除失败) 四、路由 1 2 3 4 5 6 7 8 9 10 11 12  from django.conf.urls import include, url urlpatterns = [ url(r\u0026#39;^$\u0026#39;, Home), url(r\u0026#39;^wxlogin/$\u0026#39;, WXLogin), url(r\u0026#39;^app/\u0026#39;, include(\u0026#39;app.urls\u0026#39;)), url(r\u0026#39;^accounts/\u0026#39;, include(\u0026#39;UserManage.urls\u0026#39;)), url(r\u0026#39;^os_web/partners_kpi/api/wxlogin/$\u0026#39;, WXLogin), url(r\u0026#39;^os_web/partners_kpi/api/app/\u0026#39;, include(\u0026#39;app.urls\u0026#39;)), url(r\u0026#39;^os_web/partners_kpi/api/accounts/\u0026#39;, include(\u0026#39;UserManage.urls\u0026#39;)), ]   五、F 对象 用于模型类的 A 字段属性与 B 字段属性两者的比较，即操作数据库中某一列的值。\n通常是对数据库中的字段值在不获取的情况下进行操作。F 对象内置在数据包 django.db.models 中，所以使用时需要提前导入\n1 2  from django.db.models import F F(\u0026#39;字段名\u0026#39;)   在使用 F 对象进行查询的时候需要注意：\n一个 F() 对象代表了一个 Model 的字段的值；F 对象可以在没有实际访问数据库获取数据值的情况下对字段的值进行引用。\nDjango 支持对 F 对象引用字段的算术运算操作，并且运算符两边可以是具体的数值或者是另一个 F 对象，下面我们通过实例进一步认识 F 对象。\n1 2 3 4 5 6 7 8 9  from django.db.models import F from index.models import Book #给Book所有实例价格（retail_price）涨价20元 Book.objects.all().update(retail_price=F(\u0026#39;retail_price\u0026#39;)+20) #获取该列所有值并加20 #利用传统的方法实现涨价20元 books = models.Book.objects.all() for book in books: book.update(retail_price=book.retail_price+20) book.save()   通过上述实例可以看出，使用 F 对象相对传统的方法要简单的多。那么如何通过 F 对象实现两个字段值（列）之间的比较呢？实例如下所示：\n1 2 3 4  #对数据库中两个字段的值进行比较，列出哪儿些书的零售价高于定价 books = Book.objects.filter(retail_price__gt=F(\u0026#39;price\u0026#39;)) for book in books: print(book.title, \u0026#39;定价:\u0026#39;, book.price, \u0026#39;现价:\u0026#39;, book.retail_price)   六、Q 对象 相比 F 对象更加复杂一点，它主要应用于包含逻辑运算的复杂查询。Q 对象把关键字参数封装在一起，并传递给 filter、exclude、get 等查询的方法。多个 Q 对象之间可以使用\u0026amp;或者|运算符组合（符号分别表示与和或的关系），从而产生一个新的 Q 对象。当然也可以使用~（非）运算符来取反，从而实现 NOT 查询。\nQ 对象的导入方式如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13  from django.db.models import Q from index.models import Book #查找c语言中文网出版的书或价格低于35的书 Book.objects.filter(Q(retail_price__lt=35)|Q(pub_id=\u0026#39;2\u0026#39;))#两个Q对象是或者的逻辑关系 #查找不是c语言中文出版的书且价格低于45的书 Book.objects.filter(Q(retail_price__lt=45)\u0026amp;~Q(pub_id=\u0026#39;2\u0026#39;))#条件1成立条件2不成立 q = Q() if applyId: q \u0026amp;= Q(apply_id=applyId) if status: q \u0026amp;= Q(status=status) if applyIdList: q \u0026amp;= ~Q(apply_id__in=applyIdList)   Q 对象也可以与类属性的字段名组合在一起使用，但是在这种情况下，Django 规定，Q 对象必须放在 前面，示例如下：\n1 2  Book.objects.filter(Q(price__lte=100),title__icontains=\u0026#34;p\u0026#34;)#组合使用 \u0026lt;QuerySet [\u0026lt;Book: Book object (1)\u0026gt;]\u0026gt;   常见的运算符：\n\u0026amp; 与操作\n| 或操作 Q(market_pricelt=50) | Q(market_pricegt=20)\n~ 非操作\nexact 判断，大小写敏感\ncontains 是否包含，大小写敏感\nstartwith 以什么值开头，大小写敏感\nendwith 以什么值结束，大小写敏感\nin 是否在哎包含的范围内 如 ： filter(status__in=[1, 2])\n常见的比较运算符：\ngt 大于 如：filter(num__gt=0)\ngte 大于等于\nlt 小于\nlte 小于等于\n七、聚合查询 1、整表聚合 语法：\n聚合函数：Sum,Avg,Count,Max,Min\n语法：MyModel.objects.aggregate(结果变量名=聚合函数(\u0026lsquo;列\u0026rsquo;))\n返回结果：结果变量名和值组成的字典\n格式为：{\u0026ldquo;结果变量名\u0026rdquo;:值}\n1 2 3 4  from django.db.models import * #或from django.db.models import Count Book.objects.aggregate(res=Count(\u0026#39;id\u0026#39;)) {\u0026#39;res\u0026#39;:4}   2、分组聚合 “先分组（.values），再聚合(.annotate)”\nannotate\n使用：QuerySet.annotate(结果变量名=聚合函数(\u0026lsquo;列\u0026rsquo;))\n返回值：QuerySet\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 先分组 query_set = Book.objects.values(‘pub’) # 再聚合 QuerySet.annotate(名=聚合函数(\u0026#39;列\u0026#39;)) querySetS = AssessmentInfo.objects.filter(q).values(\u0026#39;level\u0026#39;) classNum = querySetS.annotate(res=Count(\u0026#39;id\u0026#39;)) for i in classNum: if i.get(\u0026#39;level\u0026#39;) == \u0026#39;S\u0026#39;: temp[\u0026#39;Snum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;A\u0026#39;: temp[\u0026#39;Anum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;B\u0026#39;: temp[\u0026#39;Bnum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;C\u0026#39;: temp[\u0026#39;Cnum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0) elif i.get(\u0026#39;level\u0026#39;) == \u0026#39;D\u0026#39;: temp[\u0026#39;Dnum\u0026#39;] = i.get(\u0026#39;res\u0026#39;, 0)   八、执行原生 sql .query\n执行原生 sql：\n1 2  MyModel.objects.raw(sql语句，拼接参数) s1=Book.objects.raw(\u0026#39;select * from bookstore_book \u0026#39;)   九、关系映射 1、一对一：OneToOneField(类名,on_delete=xxx) 级联删除：\n1 models.CASCADE 同时删除\n2 models.PROTESCT 不能删除\n3 SET_NULL ForeignKey 为 null ，null=true\n4 SET_DEFAULT 外键设置默认值\n开启应用：步骤 1、2\n1、python manager.py startapp xxx\n2、settings.py -》INSTALLED_APPS=[\n.\n.\n.\n\u0026lsquo;XXX\u0026rsquo;\n]\n1 2 3 4 5 6 7 8 9 10 11 12  from django.db import models class Author(models.Model): name=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) class Wife(models.Model): name=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) author=models.OneToOneField(Author,on_delete=models.CASCADE) 正向查询：谁有外键，先查谁 from .models import wife wife=wife.objects.get(name=\u0026#39;王夫人\u0026#39;) print(wife.name,\u0026#39;的老公是\u0026#39;,wife.author.name) 反向查询：没有外键属性--反过来类名小写 print(author.wife.name)   2、一对多：ForeignField(类名,on_delete=xxx) 1 2 3 4 5 6 7 8 9  from django.db import models class Publisher(models.Model): name=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) class Book(models.Model): title=models.CharField(\u0026#39;姓名\u0026#39;,max_length=11) author=models.ForeignField(Publisher,on_delete=models.CASCADE) pub1=Publisher.objects.create(name=\u0026#39;清大学出版社\u0026#39;) Book.objects.create(title=\u0026#39;\u0026#39;C++,publisher=pub1)   十、cookie 和 session 的使用 1、cookie 以键-值对的形式\n每次向服务器发请求时，都会携带 cookie 给服务器\n1 2 3 4  HttpResponse.set_cookie(key,value=\u0026#39;\u0026#39;,max_age=None,expires=None) res=HttpResponse(\u0026#39;set cookie is ok\u0026#39;) res.set_cookie(\u0026#39;uname\u0026#39;,\u0026#39;gxn\u0026#39;,3600) return res   删除：\n1  HttpResponse.delete_cookie(key)   获取：\n1 2  request.COOKIES 字典(dict) request.COOKIES.get(\u0026#39;cookied名\u0026#39;,\u0026#39;默认值\u0026#39;\u0026#39;)   2、session 生成独立的存储空间（格子）sessionID-\u0026gt;借助 cookie 存储\nsession 要想成:必须有 cookie,session 数据很难被改，安全\n2.1 session 配置： 1 2 3 4 5 6 7  settings.py中:INSTALLED_APPS=[ \u0026#39;django.contrib.sessions\u0026#39;, ] 向MIDDLEWARE列表添加： MIDDLEWARE=[ \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, ]   2.2 session 配置项： settings.py 中相关配置项:\n1 2  SESSION_COOKIE_AGE=60*60*24*2*2 SESSION_EXPIRE_AT_BROWSER_CLOSE=True   浏览器关闭 session 失效\n定期清理 session\n1  python manage.py clearsessions   每晚定时任务，可删除过期的 session 数据\n2.3 session 使用： 保存：\n1 2 3 4 5  request.session[\u0026#39;KEY\u0026#39;]=VALUE def set_session(request): request.session[\u0026#39;uname\u0026#39;]=\u0026#39;wjb\u0026#39; return HttpResponse(\u0026#39;set sesssion is ok\u0026#39;)   获取：\n1 2 3 4 5 6  request.session[\u0026#39;KEY\u0026#39;] request.session.get(\u0026#39;KEY\u0026#39;,\u0026#39;默认值\u0026#39;) def get_session(request): value=request.session[\u0026#39;uname\u0026#39;] return=HttpResponse(\u0026#39;session value is %s\u0026#39;%(value))   ps:\n迁移文件防止报错:\ntable exists\n解决方法:\n1 2  python manage.py makemigrations python manage.py migrate app --fake   app 名称去 settings.py 中查看注册名称\n同时删除 django_migrations 表中的数据\n上传文件中文编码报错:\nUnicodeDecodeError: \u0026lsquo;ascii\u0026rsquo; codec can\u0026rsquo;t decode byte 0xe6 in position 260: ordinal not in range(128)\n解决方法:\n1 2 3 4 5  import sys # 设置中文编码 reload(sys) sys.setdefaultencoding(\u0026#39;utf8\u0026#39;)   ","description":"Django是一个由Python编写的具有完整架站能力的开源Web框架。使用Django，只要很少的代码，就可以轻松地完成一个正式网站的大部分内容，并进一步开发出全功能的Web","id":106,"section":"stack","tags":["shortcode"],"title":"django框架","uri":"http://wangjinbao.netlify.app/en/stack/python/django/"},{"content":"Sample images from Pixabay\n","description":"cartoon gallery","id":107,"section":"gallery","tags":null,"title":"Cartoon","uri":"http://wangjinbao.netlify.app/en/gallery/cartoon/"},{"content":"Sample images from Pixabay\n","description":"photo gallery","id":108,"section":"gallery","tags":null,"title":"Photo","uri":"http://wangjinbao.netlify.app/en/gallery/photo/"},{"content":"jarvenwang 中国 Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","description":"Hugo, the world’s fastest framework for building websites","id":114,"section":"","tags":null,"title":"About","uri":"http://wangjinbao.netlify.app/en/about/"},{"content":"封装 在Go语言中封装 就是 把 抽象出来的字段 和 对字段的操作 封装在一起，数据被保护在内部，程序的其它包只能通过被授权的方法，才能对字段进行操作\n封装的好处：  隐藏实现细节； 可以对数据进行验证，保证数据安全合理  如何实现封装：  对结构体中的属性进行封装； 通过方法，包，实现封装  封装的实现步骤：  将结构体、字段 的首字母 小写 给结构体所在的包提供一个 工厂模式的函数 （NewPerson构造函数） ，首字母大写，类似一个构造函数 提供一个首字母大写的 Set 方法（类似其它语言的 public），用于对属性 判断并赋值 提供一个首字母大写的 Get 方法（类似其它语言的 public），用于获取属性的 值  示例：\n对于员工，不能随便查看年龄，工资等隐私，并对输入的年龄进行合理的验证。\n代码结构如下：\n1 2 3 4 5  company ├── main │ └── main.go └── model └── person.go   person.go 中的代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package model import \u0026#34;fmt\u0026#34; type person struct { Name string age int //其它包不能访问.. } // 写一个工厂模式的函数，相当于构造函数 func NewPerson(name string) *person { return \u0026amp;person{ Name: name, } } // 为了访问age和sal我们编写一个SetXxx的方法和GetXxx的方法 func (p *person) SetAge(age int) { if age \u0026gt; 0 \u0026amp;\u0026amp; age \u0026lt; 150 { p.age = age } else { fmt.Println(\u0026#34;年龄范围不正确..\u0026#34;) } } func (p *person) GetAge() int { return p.age }   main.go 中的代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;kg_info_dashboard_api/company/model\u0026#34; ) func main() { p := model.NewPerson(\u0026#34;jay\u0026#34;) p.SetAge(18) fmt.Println(p) fmt.Println(p.Name, \u0026#34;age=\u0026#34;, p.GetAge()) }   执行结果如下：\n1 2 3  $ go run main.go \u0026amp;{jay 18} jay age= 18   ","description":"在Go语言中封装就是把抽象出来的字段和对字段的操作封装在一起，数据被保护在内部，程序的其它包只能通过被授权的方法，才能对字段进行操作","id":118,"section":"stack","tags":["golang",""],"title":"Golang的封装和实现","uri":"http://wangjinbao.netlify.app/en/stack/golang/go_package_achieve/"}]